<?xml version="1.0"?>
<kb_documents>
<kb_document>
<kb_title>Using Linstat</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Linstat is the SSCC's primary Linux computing cluster. Linstat combines familiar statistical software like Stata, SAS, R, and Matlab with the power of Linux, making it ideal for jobs that require more memory or computing time than Winstat can provide. Linstat also gives you access to the SSCC's HTCondor flock, where you can run  multiple jobs at the same time.</p>
<p>Learning to run jobs on a Linux server is probably easier than you think. If you're new to Linux, be sure to read the section  <a href="#GettingStartedonLinstat">Getting Started on Linstat</a>. Veteran Linux users can probably stop reading when they reach that point, but should be sure to read the sections before that which describe some of the unique features of Linstat.</p>
<p>To log in to Linstat you'll use your SSCC username (typed in lower case) and password. If you've forgotten your password, you can <a href="https://www.ssc.wisc.edu/sscc_jsp/password/reset.jsp">reset it here</a>.</p>
<p><strong>If you are outside the United States please read <a href="https://ssc.wisc.edu/sscc/pubs/linstat_outside_us.htm">Connecting to Linstat from Outside the United States</a>.</strong></p>
<h2><a id="ConnectingtoLinstat" name="ConnectingtoLinstat"></a>Connecting to Linstat</h2>
<p>How you'll connect to Linstat depends on what kind of computer you're connecting from:</p>
<h3>Windows PCs or Winstat</h3>
<p>If your computer runs Windows, we suggest you connect using a program called X-Win32 (though there are many fine alternatives). X-Win32 is already installed and configured on Winstat, so one option is to log in to Winstat and run X-Win32 there. Alternatively, you can download and install a pre-configured version of X-Win32 from the SSCC web site. Simply download the installation file and then double-click on it.</p>
<p><a href="https://ssc.wisc.edu/sscc/downloads/download-xwin32.php">Download X-Win32 from the SSCC</a></p>
<p>You'll be asked to log in because X-Win32 is only licensed for UW faculy, staff, and students. Just give your usual SSCC username and password. To use it you'll need to first connect to the SSCC network using <a href="https://ssc.wisc.edu/sscc/pubs/vpn.htm">VPN</a>.</p>
<p>When you run X-Win32 it will place an icon in the lower right corner of your screen: <img alt="The X-Win32 Icon" height="30" src="https://ssc.wisc.edu/sscc/pubs/screenshots/5-2c/5-2_3.png" width="111"/></p>
<p>Click on the icon once and choose Linstat.                </p>
<p>For more details, including how to set up a connection to a particular Linstat server, see <a href="https://ssc.wisc.edu/sscc/pubs/5-2.htm">Connecting to SSCC Linux Computers using X-Win32</a>.</p>
<p><strong>If you are not on the UW-Madison campus you must establish a <a href="https://ssc.wisc.edu/sscc/pubs/vpn.htm">VPN connection</a> to campus before using X-Win32.</strong></p>
<h3>Macs or Computers running Linux</h3>
<p>Macs and Linux computers have client programs for connecting to Linux servers installed by default. Simply start a Terminal program (on a Mac it will be found under <span class="MenuOutput">Applications</span>, <span class="MenuOutput">Utilities</span>) and then type:</p>
<p class="InputCode">ssh -Y <span class="Parameter">username</span>@linstat.ssc.wisc.edu</p>
<p><span class="Parameter">username</span> should be replaced by your SSCC username. If your username on your computer is the same as your SSCC username, you can leave it out (<span class="InputCode">ssh -Y linstat.ssc.wisc.edu</span>). If you are plugged into the wired network in the Sewell Social Sciences Building you can leave out the domain (<span class="InputCode">ssh -Y linstat</span>).</p>
<p>For more details, including how to  connect to a particular Linstat server, see <a href="https://ssc.wisc.edu/sscc/pubs/linstat_from_mac.htm">Connecting to Linstat from a Mac</a>.</p>
<p>In order to display Linux graphics, including graphical user interfaces for Stata, Matlab, and other programs, Macs need to have an X windows program like <a href="https://www.xquartz.org/">XQuartz</a> installed.</p>
<h2><a id="Cluster" name="Cluster"></a>The Linstat Cluster</h2>
<p>When you connect to Linstat, you'll  be directed to the least busy of the four Linstat servers (<span class="InputCode">linstat1</span>, <span class="InputCode">linstat2</span>, <span class="InputCode">linstat3</span>, and <span class="InputCode">linstat4</span>) automatically. This will spread users among the four servers and help avoid situations where one server is much busier than another.</p>
<p> If you are running a long job and need to connect to the same server again to monitor it, log in to Linstat and then type <span class="InputCode">ssh <span class="Parameter">server</span></span>, where <span class="Parameter">server</span> should be replaced by the name of the server where you started the job. Be sure to note which server you're on when you start a long job. Most people have the server name in their prompt, but if you don't you can find out which server you're using by typing <span class="InputCode">printenv HOST</span>. It's also possible to connect to a specific server directly—the links in the previous section have instructions.</p>
<h2 id="BatchMode">Batch Mode</h2>
<p>If you run a program in batch mode, you can log out and the program will continue to run. Putting an ampersand (<span class="InputCode">&amp;</span>) at the end of a command will put it in batch mode. However, many programs need additional settings to work in batch mode, such as not starting a graphical user interface. These program-specific settings are described below when we talk about running programs.</p>
<h2><a id="ramdisk" name="ramdisk"></a>/ramdisk</h2>
<p><span class="InputCode">/ramdisk</span> is a special "directory" that is actually stored in RAM, making it extremely fast. The maximum size of <span class="InputCode">/ramdisk</span> is 32GB, and any files that are not in use will be deleted after one hour. The <span class="InputCode">/ramdisk</span> directory can be very helpful for programs that spend a lot of time reading and writing temporary files.</p>
<h2 id="stata">Stata</h2>
<p>We have a small number of Stata MP32 licenses, which are ideal for running computationally intensive do files. Do files run using the <span class="InputCode">stata</span> and <span class="InputCode">condor_stata</span> commands will be run using Stata MP32, though some HTCondor servers only have 8 cores and Stata MP32 will automatically adapt accordingly.</p>
<h2><a id="SAS" name="SAS"></a>SAS</h2>
<p>On Linstat, the default directory where SAS stores temporary data sets (the WORK library) is <span class="InputCode">/ramdisk</span>. This increases the speed of data-intensive programs significantly. It also prevents them from slowing down the entire server due to disk I/O bottlenecks.</p>
<p>If you need more than 32GB of temporary space, change the WORK directory to <span class="InputCode">/tmp</span>. You can do so by adding the <span class="InputCode">-work</span> option to your SAS command:</p>
<p class="InputCode">sas -work /tmp myprogram</p>
<p>You'll then be able to use  up to 243GB of space (or as much of it as is available at the time). For more details see <a href="https://ssc.wisc.edu/sscc/pubs/bigsas.htm">Running Large SAS Jobs on Linstat</a>.</p>
<h2><a id="Condor" name="Condor"></a>HTCondor
                </h2>
<p>The SSCC's HTCondor flock contains 136 CPUs and is ideal for  running multiple jobs at the same time. HTCondor can run Stata, SAS, Matlab, and R jobs as well as user-written programs. We've written scripts that make submitting jobs to HTCondor very easy—see <a href="https://ssc.wisc.edu/sscc/pubs/7-1.htm">An Introduction to HTCondor</a> for instructions. (You can also <a href="https://ssc.wisc.edu/sscc_jsp/condor/">submit Stata jobs to  HTCondor</a> flock via the web.)</p>
<h2>Mplus</h2>
<p>Due to licensing restrictions, Mplus is only installed on Linstat1, Linstat2, and Linstat3, and may only run one job at a time on each server. Because of the unusual way Mplus launches additional terminal sessions you'll need to stay logged in the entire time the program is running. <a href="https://ssc.wisc.edu/sscc/pubs/mplus_linstat.htm">Running Mplus on Linstat</a> has more details.</p>
<h2><a id="GettingStartedonLinstat" name="GettingStartedonLinstat"></a>Getting Started on Linstat</h2>
<p>Linux can be intimidating because it just waits for you to type commands without giving you any menus or icons to suggest what you can do. But if all you want to do is run jobs, you can get by with just a couple of Linux commands. Here's how:</p>
<h3>Get your job ready using your computer</h3>
<p>If you're on Winstat or a Windows PC that logs into the SSCC's PRIMO domain, your Linux home directory is available as the Z: drive, and Linux project directories are the V: drive. They're also available from Macs—see <a href="https://ssc.wisc.edu/sscc/pubs/diskfrommac.htm">Using SSCC Network Disk Space from Macs</a>. This means you can write your program, manage your files, etc. using the tools you're familiar with and still put the programs and related files on the Linux file system so Linstat can run them.</p>
<p>Put all the files relating to a given project in a single folder (or directory in Linux terminology), then write your programs on the assumption that that folder will be your working directory (i.e. a Stata program should say <span class="InputCode">use datafile</span>, not <span class="InputCode">use z:\research\datafile</span>). If you're only working on a single project then just declare <span class="MenuOutput">Z:</span> itself that project's "directory."</p>
<h3>Command #1: cd</h3>
<p>When you log into Linux, your "working directory" (where you "are" in the file system) starts out as your home directory—what Windows calls <span class="MenuOutput">Z:</span>. If that's where your project's files are, you can skip directly to running your job. Otherwise you'll need to go to your project's directory using the <span class="InputCode">cd</span> ("change directory") command. If your project's directory is on your Z: drive, type:</p>
<p class="InputCode">cd <span class="Parameter">myProject</span></p>
<p>Where <span class="InputCode"><span class="Parameter">myProject</span></span> should be replaced by the name you gave your project's directory.</p>
<p>If your project's directory is inside an official Linux project directory on the <span class="MenuOutput">V:</span> drive, type:</p>
<p class="InputCode">cd /project/<span class="Parameter">projectName</span>/<span class="Parameter">myProject</span></p>
<p></p>
<p>A few more points on the Linux file system:</p>
<ul>
<li>Directories are separated using the forward slash (/) rather than the backslash
                    (\).</li>
<li>There are no drives or drive letters in Linux. All directories are part of a single tree
                    structure with the "root" of the tree denoted by a slash (/).</li>
<li>If a directory path starts with a slash (/), it starts from the root (it is an "absolute" path). Thus <span class="InputCode">cd /project</span> means "go to the root directory, then to <span class="InputCode">project</span> underneath that"</li>
<li>If a directory path does not start with a slash, it is assumed to start with the current directory and go from there (it is a "relative" path). Thus <span class="InputCode">cd myProject</span> means "go to the <span class="InputCode">myProject</span> directory under the current directory."</li>
<li>Linux does not like spaces in file or directory names (you have to put the
                    whole path in quotes if it includes a space)</li>
<li> Unlike Windows, Linux is case-sensitive. <span class="InputCode">File</span> and <span class="InputCode">file</span> are two
                    different files.</li>
</ul>
<h3>Command #2: Run Your Program</h3>
<p>The command to run your program will depend on the program you want to use. Here are some of the most popular:</p>
<h4>Stata</h4>
<p>You can start Stata's graphical user interface by typing <span class="InputCode">xstata</span>.  You can also run a do file called <span class="InputCode">mydofile.do</span> in batch mode by typing:</p>
<p class="InputCode"> stata -b do mydofile &amp;</p>
<p> Alternatively you can submit it to HTCondor with:</p>
<p class="InputCode"> condor_stata mydofile &amp;</p>
<p> If you run <span class="InputCode">mydofile.do</span> in batch mode or on HTCondor, Stata will automatically log its output in <span class="InputCode">mydofile.log</span>.</p>
<h4>SAS</h4>
<p>You can start SAS's graphical user interface by typing <span class="InputCode">sas</span>, though it's somewhat clunkier than the Windows version. You can also run  a program called <span class="InputCode">myprogram.sas</span> in batch mode by typing:</p>
<p class="InputCode"> sas myprogram &amp;</p>
<h4>R</h4>
<p>To run R, simply type <span class="InputCode">R</span>. It does not have a graphical user interface but the commands are the same as in Windows R or RStudio. </p>
<p>To run an R program in batch mode, type:</p>
<p class="InputCode">R &lt; <span class="Parameter">myprogram</span>.R &gt; <span class="Parameter">myprogram</span>.log --no-save &amp;</p>
<p>To submit <span class="InputCode">myprogram.R</span> to HTCondor and save the output to <span class="InputCode">myprogram.log</span>, type:</p>
<p class="InputCode">condor_R <span class="Parameter">my program</span>.R <span class="Parameter">myprogram</span>.log</p>
<p>If your job uses multiple processors, type:</p>
<p class="InputCode">condormp_R program.R program.log &amp;</p>
<h3></h3>
<h4>Matlab</h4>
<p>You can start Matlab's graphical user interface by typing <span class="InputCode">matlab</span>. To run a Matlab program <span class="intro">myprogram.m</span> in the background and save its output in <span class="InputCode">myprogram.log</span>, type:</p>
<p class="InputCode">matlab -nodisplay -nojvm &lt; mprogram.m &gt; myprogram.log &amp;</p>
<p>To submit <span class="InputCode">myprogram.m</span> to HTCondor and save its output in <span class="InputCode">myprogram.log</span>, type:</p>
<p class="InputCode">condor_matlab myprogram.m myprogram.log &amp;</p>
<p>If your job uses multiple processors, type:</p>
<p class="InputCode">condormp_matlab <span class="Parameter">program</span>.m <span class="Parameter">program</span>.log &amp;</p>
<h3></h3>
<h4>Mplus</h4>
<p wrap="">To run an Mplus job, log into Linstat1, Linstat2, or Linstat3, and type:</p>
<p class="InputCode" wrap="">mplus <span class="Parameter">myprogram</span>.inp &amp;</p>
<p>where <span class="Parameter">myprogram.inp</span> should be replaced by the name of the Mplus program (the .inp file) you want to run.                </p>
<p>Linstat has many other programs available (see our <a href="https://ssc.wisc.edu/sscc_jsp/software/">software database</a>). See the documentation of the program you're interested in for details on how to run it.</p>
<h4 id="Mplus"></h4>
<h3>Learning More</h3>
<p>While this will get you started, there are several other SSCC Knowledge Base articles you can read to become a more flexible and efficient Linstat user.  <a href="https://ssc.wisc.edu/sscc/pubs/linstat_jobs.htm">Managing Jobs on Linstat</a> will teach you how to monitor and manage jobs while they run. <a href="https://ssc.wisc.edu/sscc/pubs/7-1.htm">An Introduction to HTCondor</a> will teach you more about the SSCC's HTCondor flock and how to use it. Finally, if you really want to make yourself at home in Linux, read the SSCC's <a href="https://www.ssc.wisc.edu/sscc/pubs/linuxos.htm">Getting Started in Linux</a><a href="https://ssc.wisc.edu/sscc/pubs/linuxos.htm"></a>. For a full list of articles, visit the <a href="https://ssc.wisc.edu/sscc/pubs/linux.htm">Linux section</a> of our <a href="https://ssc.wisc.edu/sscc/pubs/home.htm">Knowledge Base</a>. SSCC staff will also be happy to answer any questions you have about using Linstat and help you solve any problems you run into—just contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a>.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/5-2c/5-2_3.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Connecting to Linstat from a Mac</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Macs have all the software needed to connect to Linux servers installed by default, so connecting is very easy:</p>
<ol>
<li>Start the <span class="MenuOutput">Terminal</span> program (found in <span class="MenuOutput">Applications</span>, <span class="MenuOutput">Utilities</span>)</li>
<li>Type <span class="InputCode">ssh -Y </span><span class="Parameter">username</span><span class="InputCode">@linstat.ssc.wisc.edu</span></li>
</ol>
<p><span class="Parameter">username</span> should be replaced by your SSCC username. If your username on your Mac is the same as your SSCC username, you can leave it out (<span class="InputCode">ssh -Y linstat.ssc.wisc.edu</span>). If you are plugged into the wired network in the Sewell Social Sciences Building you can leave out the domain (<span class="InputCode">ssh -Y linstat</span>).</p>
<p>If you need to connect to a particular Linstat machine,  for example to monitor a long-running job, replace <span class="InputCode">linstat</span> with the name of the machine you need to connect to (<span class="InputCode">linstat1</span>, <span class="InputCode">linstat2</span>, <span class="InputCode">linstat3</span>, or <span class="InputCode">linstat4</span>).                </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Configuring Google Authenticator to Log in to Linstat</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Google Authenticator is an app that runs on your smartphone. Once configured, when you try to log in to Linstat from outside the United States the app will generate a code which you must enter before giving your password. Using Google Authenticator takes some configuration, but does not send all your network traffic through an intermediary like VPN or Winstat. This makes it a good choice for Linstat users outside the United States who are concerned about the performance of their interactive sessions. (How you connect has no bearing on how quickly jobs run.)</p>
<p>Configuring Google Authenticator requires a connection to Linstat. If you will be traveling we suggest configuring it before you leave the United States; otherwise you'll need to connect using VPN or Winstat once to set up Google Authenticator. Keep in mind that as long as you're in the United States you won't be asked to use Google Authenticator even if you have it configured.</p>
<h2>Installing Google Authenticator</h2>
<p>The Google Authenticator smartphone app can be installed for free by searching the application marketplace for your smartphone, or from these links:</p>
<ul>
<li><a href="https://itunes.apple.com/us/app/google-authenticator/id388497605?mt=8">iPhone</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.google.android.apps.authenticator2">Android</a></li>
<li><a href="http://www.windowsphone.com/en-us/store/app/authenticator/021dd79f-0598-e011-986b-78e7d1fa76f8">Windows Phone</a></li>
<li>BlackBerry: Go to <a href="http://m.google.com/authenticator">http://m.google.com/authenticator</a> on your phone to download and install the application. </li>
</ul>
<h2>Configuration on Linstat</h2>
<p>Once the application is installed, log into Linstat and type <span class="InputCode">google-authenticator</span>. Answer <span class="InputCode">y</span> to all the questions it asks. The result will look similar to the following:</p>
<pre class="InputCode">linstat1.ssc.wisc.edu&gt; google-authenticator
Do you want authentication tokens to be time-based (y/n) y
https://www.google.com/chart?chs=200x200&amp;chld=M|0&amp;cht=qr&amp;chl=otpauth://totp/example@linstat1.ssc.wisc.edu%3Fsecret%3DLNP6YAQQSXZ7TFN5
Your new secret key is: LNP6YAQQSXZ7TFN5
Your verification code is 007939
Your emergency scratch codes are:
  52302031
  85960129
  70252895
  88603301
  62022909
Do you want me to update your "/home/d/dtest/.google_authenticator" file (y/n) y
Do you want to disallow multiple uses of the same authentication
token? This restricts you to one login about every 30s, but it increases
your chances to notice or even prevent man-in-the-middle attacks (y/n) y
By default, tokens are good for 30 seconds and in order to compensate for
possible time-skew between the client and the server, we allow an extra
token before and after the current time. If you experience problems with poor
time synchronization, you can increase the window from its default
size of 1:30min to about 4min. Do you want to do so (y/n) y
If the computer that you are logging into isn't hardened against brute-force
login attempts, you can enable rate-limiting for the authentication module.
By default, this limits attackers to no more than 3 login attempts every 30s.
Do you want to enable rate-limiting (y/n) y
</pre>
<h2>Configuration on Your Phone</h2>
<p>Open the Google Authenticator app on your phone, and tap the icon to add a new account (the pencil in the upper right on iPhone, the three dots in the upper right on Android, the + in a circle at the bottom on Windows Phone). You can either select <span class="MenuOutput">Scan Barcode</span> or <span class="MenuOutput">Manual Entry</span> to enter the needed settings.</p>
<h3>Scan Barcode</h3>
<p>Copy the URL that the Linux <span class="InputCode">google-authenticator</span> command produced. It will be similar to:</p>
<p class="InputCode">https://www.google.com/chart?chs=200x200&amp;chld=M|0&amp;cht=qr&amp;chl=otpauth://totp/example@linstat1.ssc.wisc.edu%3Fsecret%3DLNP6YAQQSXZ7TFN5</p>
<p>Paste it into a web browser on your PC or Mac and it should produce a square (QR) barcode. Align your phone's camera with the code on your monitor—you may need to adjust the distance between your phone and the screen before the phone will recognize it. The app should automatically add a code on the main screen. The app will call it <span class="Parameter">username</span><span class="InputCode">@linstat1.ssc.wisc.edu</span> (or whichever Linstat you were logged into) but it will work for the entire Linstat cluster.</p>
<h3>Manual Entry</h3>
<p>The code you want is also produced by the <span class="InputCode">google-authenticator</span> command; it's listed on this line of output:</p>
<p class="InputCode">Your new secret key is: LNP6YAQQSXZ7TFN5</p>
<p>Give the account a name like <span class="InputCode">Linstat</span> and enter the code where it says <span class="MenuOutput">Key</span>. Make sure <span class="MenuOutput">Time Based</span> is checked.</p>
<h2>Configuration in SecureCRT</h2>
<p>If you connect to Linstat from a   Mac or Linux computer, or from a Windows computer using PuTTY, no further configuration is needed. However, SecureCRT does need to be configured to ask for the verification code.</p>
<p> (Recall that if you're connecting remotely and not using VPN you cannot use X-Win32. <a href="http://software.wisc.edu">SecureCRT</a> and <a href="http://www.putty.org/">PuTTY</a> are good alternatives, though neither of them can display graphics without forwarding them to a  
                separate program like X-Win32 or <a href="http://sourceforge.net/projects/xming/">Xming</a>.)</p>
<p>Open the Properties for your Linstat session.</p>
<p><img alt="Open the Properties of your Linstat session" height="453" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_google_auth/linstat_google_auth_2.png" width="512"/></p>
<p>Under <span class="MenuOutput">Category</span> on the left, click <span class="MenuOutput">Connection</span> and then <span class="MenuOutput">SSH2</span>. In the <span class="MenuOutput">Authentication</span> section, select <span class="MenuOutput">Keyboard Interactive</span> and click the up arrow until it is the top choice.</p>
<p><img alt="Under connection, SSH2, make Keyboard Interactive the top Authentication method" height="511" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_google_auth/linstat_google_auth_3.png" width="553"/></p>
<p>Save the session, and from now on when you connect you'll be prompted for your verification code before your password.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_google_auth/linstat_google_auth_2.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_google_auth/linstat_google_auth_3.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Managing Jobs on Linstat</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- #BeginEditable "Text" -->
<p>One of the main reasons for using Linstat is that it can run very long jobs. This article will teach you how to manage such jobs on Linstat.</p>
<h2><a id="ForegroundandBackgroundJobs" name="ForegroundandBackgroundJobs"></a>Foreground and Background Jobs</h2>
<p>Normally when you type a command, it is processed and you see the results (if 
  any) before the cursor returns and you can type a new command. These jobs are 
  said to be running in the foreground. If you put a job in the background, 
  the cursor returns immediately and you can keep giving commands and doing other 
  work while the your job is running. When the job finishes a message will appear 
  on your screen.</p>
<p>If a job is  running in the background it will keep running even if you log out, so you can start a long job before you leave in the evening, log out, 
  and get the results the next morning (or next week, or next month—though such jobs are good candidates for <a href="https://ssc.wisc.edu/sscc/pubs/7-1.htm">Condor</a>). Just keep track of which Linstat server you are using when you start a job, because if you need to manage that job you'll need to return to that server.</p>
<p>What you should not do when you have a job running in the background is start another CPU-intensive job—see the <a href="https://ssc.wisc.edu/sscc/policies/server_usage.htm">SSCC's Server Usage Policy</a>.</p>
<p>To run a job in the background,  add an ampersand (<span class="InputCode">&amp;</span>) at the end 
  of the command. For example, if you type:</p>
<p class="InputCode">stata -b do myprogram</p>
<p> Stata will start and run <span class="InputCode">myprogram.do</span> in the 
  foreground. Thus your session will be unavailable until the job is done. On the 
  other hand:</p>
<p class="InputCode">stata -b do myprogram &amp;</p>
<p>runs Stata in the background. The cursor returns immediately and you can do other things while Stata is running your program. When it is done you'll see a message like:
</p>
<pre class="InputCode">[1]    Done                          stata -b do myprogram</pre>
<p>A job which creates a separate window (<span class="InputCode">xstata</span>, for example) will be 
  completely functional in the background (in fact <span class="InputCode">xstata</span> puts itself in the background by default).</p>
<h3><a id="SwitchingBetweenForegroundandBackground" name="SwitchingBetweenForegroundandBackground"></a>Switching Between Foreground 
  and Background</h3>
<p>If you have a job running in the foreground and want to put it in the background, 
   press <span class="InputCode">CTRL-z</span> (if the  
  job has opened a separate window, you must return to your main Linstat window before 
  pressing <span class="InputCode">CTRL-z</span>). The current job will be suspended 
  and you will get your cursor back. Then type <span class="InputCode">bg</span> to put it in the 
  background—it will not run while suspended. You can also type <span class="InputCode">fg</span> to move it back 
  to the foreground, either from being suspended or from the background.</p>
<h2><a id="ManagingBackgroundJobs" name="ManagingBackgroundJobs"></a>Monitoring  Jobs</h2>
<p>The <span class="InputCode">ps</span> 
  command (think processes) gives you a list of processes you are running on the server. The output will be similar to the following:</p>
<pre class="InputCode">PID TTY          TIME CMD<br/>29413 pts/30   00:00:00 tcsh<br/> 1601 pts/30   00:00:00 emacs<br/> 1602 pts/30   00:00:00 emacs<br/> 1605 pts/30   00:00:00 ps</pre>
<p> <span class="InputCode">PID</span> is short for Process IDentifier, and is used when you need to specify a particular job. Keep in mind that Linstat is a cluster of four servers, and <span class="InputCode">ps</span> will only show you the jobs you are running on the server you're logged into. See <a href="#SwitchingBetweenLinstatServers">Switching Between Linstat Servers</a> to learn how to get back to the Linstat server where you started your job.</p>
<p>Unfortunately, the default <span class="InputCode">ps</span> output will only show jobs you started in your current session. To see all your jobs from any session, type:</p>
<p class="InputCode">ps aux | grep <span class="Parameter">username</span></p>
<p>where <span class="Parameter">username</span> should be replaced by your SSCC username (e.g. <span class="InputCode">ps aux | grep rdimond</span>). This lists all jobs on the server, then filters it to only show yours.</p>
<p>Another useful command for monitoring jobs is <span class="InputCode">top</span>. This will tell you the "top" jobs (in terms of resources used) currently running on the server. With it you can verify that your job is actually doing work by checking that its <span class="InputCode">%CPU</span> is greater than zero, though jobs can easily get stuck in a state where they use CPU without doing anything productive.</p>
<p> <span class="InputCode">top</span> also gives you a sense of how busy the server is. The Linstat servers have sixteen CPUs, so if <span class="InputCode">%CPU</span> adds up to more than 1600% programs will have to share the available CPU time. If the Linstat you're on has less CPU time available than your program is capable of using, consider switching to a different Linstat.</p>
<p>Unfortunately <span class="InputCode">top</span> does not monitor all the resources a server needs to run jobs. For example, SAS jobs occasionally generate enough disk traffic to slow down a server without anything unusual appearing in <span class="InputCode">top</span>.</p>
<h2><a id="KillingaJob" name="KillingaJob"></a>Killing a Job</h2>
<p>If you need to stop a running job, use the <span class="InputCode">kill</span> command. Simply type <span class="InputCode">kill</span> and then the  PID of the job you want to kill. For example:</p>
<p class="InputCode"> kill 1602</p>
<p>This doesn't actually stop the job, it merely requests that it shut down, giving 
  the program an opportunity to clean up temporary files and such. Unfortunately 
  both SAS and SPSS will not do so, so if you kill one of these jobs, please go 
  to the <span class="InputCode">/tmp</span> directory and manually delete any 
  files and directories belonging to you. On the other hand, adding the <span class="InputCode">-9</span> 
  switch to the <span class="InputCode">kill</span> command will kill a program 
  immediately with or without its consent. Thus:</p>
<p class="InputCode"> kill -9 1602</p>
<p><strong>will</strong> kill process 1602.</p>
<h2><a id="SwitchingBetweenLinstatServers" name="SwitchingBetweenLinstatServers"></a>Switching Between Linstat Servers</h2>
<p>Linstat is actually a cluster of four servers. When you log in you're assigned to a server randomly to try to balance the load between them. However, you can choose to connect to a specific server to monitor a job you started previously or if the server you're assigned to turns out to be particularly busy.</p>
<p>To switch to a different server, type:</p>
<p class="InputCode"> ssh <span class="Parameter">server</span></p>
<p>where <span class="Parameter">server</span> can be <span class="InputCode">linstat1</span>, <span class="InputCode">linstat2</span>, <span class="InputCode">linstat3</span>, or <span class="InputCode">linstat4</span>. Alternatively you can set up your client program to log in to one of those four servers directly.</p>
<p>Be sure to note which server you're on when you start a long job. If the server name is not in your prompt, you can identify it by typing:</p>
<p class="InputCode">printenv HOST</p>
<!-- #EndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Connecting to Linstat from Outside the Madison Area</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>While all computers are subject to regular attacks today, Linux servers draw particular attention. Most attacks originate outside the United States, while most SSCC members are in the United States. SSCC therefore blocks standard Secure Shell (ssh) connections to Linstat from outside the United States. This reduces the number of attacks Linstat is subjected to, but SSCC members can still connect to Linstat from anywhere in the world using  one of the following easy methods:</p>
<ul>
<li><strong><a href="https://ssc.wisc.edu/sscc/pubs/vpn.htm">Connect to the SSCC network using VPN before logging into Linstat.</a></strong> This is perhaps the simplest method. Recall that you must connect to the SSCC network to run X-Win32 anyway.</li>
<li><strong><a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">First log into Winstat and then connect to Linstat from within your Winstat session.</a></strong> This is also very simple, and also gives you access to all the software on Winstat. However it uses one of our Winstat licenses, so if you only need Linstat we suggest using VPN instead.</li>
<li><strong><a href="https://ssc.wisc.edu/sscc/pubs/linstat_google_auth.htm">Use the Google Authenticator app on your smartphone to obtain a code you then enter while logging in.</a></strong> This method requires more configuration, but may give somewhat better performance.</li>
<li><strong><a href="https://ssc.wisc.edu/sscc/pubs/linstat_public_key.htm">Create a pair of encryption keys that are stored on Linstat and your computer which can then be used to connect to Linstat from that specific computer.</a></strong> This method also requires more configuration but may give somewhat better performance.</li>
</ul>
<p>You only need to use one of these four methods. Note that the Google Authenticator and key pair methods must be set up while you are connected to Linstat. If you will be traveling and want to use these methods, we suggest configuring them before you leave. Otherwise you'll need to connect using VPN or Winstat once to set them up.                </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Configuring a Public/Private Key Pair to Log into Linstat</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Public key authentication uses two files to prove who you are rather than a password: a public key on the server and a private key on your local computer. Once configured, you'll be asked for the password associated with the key rather than your SSCC password whenever you log into Linstat from that computer. Using a key pair takes some configuration, but does not send all your network traffic through an intermediary like VPN or Winstat. This makes it a good choice for Linstat users outside the United States who are concerned about the performance of their interactive sessions. (How you connect has no bearing on how quickly jobs run.)</p>
<p>Configuring a key pair requires a connection to Linstat. If you will be traveling we suggest configuring it before you leave the United States; otherwise you'll need to connect using VPN or Winstat once to set up the key pair.</p>
<p>No matter how you connect to Linstat, the process of creating a key pair is very much the same:</p>
<ol>
<li>
<p>Generate a public/private key pair on your local computer</p>
</li>
<li>
<p>Add the key to <span class="InputCode">.ssh/authorized_keys</span> in your Linstat home directory</p>
</li>
<li>Configure the client program to use key authentication rather than passwords</li>
</ol>
<p>This article 
                has instructions for <a href="#SecureCRT">SecureCRT</a>, <a href="#PuTTY">PuTTY</a>, and <a href="#Mac_Linux">Mac/Linux</a>. (Recall that if you're connecting remotely and not using VPN you cannot use X-Win32. <a href="http://software.wisc.edu">SecureCRT</a> and <a href="http://www.putty.org/">PuTTY</a> are good alternatives, though neither of them can display graphics without forwarding them to a  
                separate program like X-Win32 or <a href="http://sourceforge.net/projects/xming/">Xming</a>.)</p>
<h2 id="SecureCRT">SecureCRT</h2>
<p>In SecureCRT, click <span class="MenuOutput">Tools</span>,  <span class="MenuOutput">Create Public Key</span>.</p>
<p><img alt="Key Generation Wizard" height="336" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_1.png" width="505"/></p>
<p>Set the <span class="MenuOutput">Key type</span> to <span class="MenuOutput">DSA</span>.</p>
<p><img alt="Set Key type to DSA" height="336" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_2.png" width="505"/></p>
<p>Enter a password for the key or, even better, a <a href="http://xkcd.com/936/">passphrase</a>, along with a comment. The comment could be used to remind you of the password, but must not allow others to guess it.</p>
<p><img alt="Choose a passphrase and comment" height="336" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_3.png" width="505"/></p>
<p>Set the <span class="MenuOutput">Key length in bits</span> to <span class="InputCode">1024</span>.</p>
<p><img alt="Set key length to 1024" height="336" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_5.png" width="505"/></p>
<p>Select the <span class="MenuOutput">OpenSSH Key</span> format, and then save the keys in a convenient location on your local hard drive (the default location is probably OK).</p>
<p><img alt="Choose the key format and location to save it" height="336" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_6.png" width="505"/></p>
<p>Click <span class="MenuOutput">Yes</span> when asked if you want to use this as your global public key.</p>
<p><img alt="" height="161" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_6.5.png" width="405"/></p>
<p>Now that the key has been generated it, use Notepad, TextPad or your favorite text editor and open <span class="InputCode">Identity.pub.</span> (The <span class="InputCode">.pub</span> extension indicates that this is the <em>public</em> key, to be shared with the server, rather than the <em>private</em> key which remains on your computer.)</p>
<p><img alt="Open the key in a text editor and copy the contents" height="207" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_7.png" width="577"/></p>
<p>If you are currently on the SSCC network  save the file as <span class="InputCode">z:\.ssh\authorized_keys</span>. The <span class="InputCode">.ssh</span> folder is hidden by default, so you'll need to type its name rather than clicking on it.</p>
<p>If not, copy the entire contents of the file, log in to Linstat, then open <span class="InputCode">.ssh/authorized_keys</span> using your preferred Linux text editor (<span class="InputCode">pico</span>, <span class="InputCode">emacs</span>, <span class="InputCode">vi</span>, etc.).</p>
<p><img alt="Log into Linstat and edit your authorized key file" height="208" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_8.png" width="646"/></p>
<p>Paste in the contents of the key, making sure it is all on one line, and save the file.</p>
<p><img alt="Paste in the key contents" height="191" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_9.png" width="655"/></p>
<p>If you haven't already, log into Linstat. Then run the following command:</p>
<p class="InputCode">chmod g-w ~/.ssh/authorized_keys</p>
<p>(SSCC uses "user private groups" to make it easy to share files in project directories while keeping files in home directories private. Unfortunately the program that manages key pair connections doesn't understand user private groups and insists keys must not have group write permissions for security reasons.)</p>
<p>Next, open the session properties for your Linstat connection.</p>
<p><img alt="Open properties for your Linstat session" height="189" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_10.png" width="625"/></p>
<p>Under <span class="MenuOutput">Category</span> on the left, click <span class="MenuOutput">Connection</span>, <span class="MenuOutput">SSH2</span>. Then select <span class="MenuOutput">PublicKey</span> in the <span class="MenuOutput">Authentication</span> section and click the up arrow until it is the top choice.</p>
<p><img alt="Make PublicKey the top Auth method" height="511" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_11.png" width="553"/></p>
<p>Click <span class="MenuOutput">OK</span>, and from now on when you log in to Linstat, you'll be prompted for your key passphrase rather than your SSCC password.</p>
<h2 id="PuTTY">PuTTY</h2>
<p>To create a public/private key pair in PuTTY, you need to run PuTTYgen. You can find it by searching or by clicking <span class="MenuOutput">Start</span>, <span class="MenuOutput">All Programs</span>, <span class="MenuOutput">PuTTY</span>, <span class="MenuOutput">PuTTYgen</span>.</p>
<p>Set the type to <span class="MenuOutput">SSH-2 DSA</span> and click <span class="MenuOutput">Generate</span>. </p>
<p><img alt="Generate a key" height="477" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_12.png" width="493"/></p>
<p>You will be asked to generate randomness by moving your mouse around. Once the generation finishes, enter a password for the key or, even better, a <a href="http://xkcd.com/936/">passphrase</a>, along with a comment. The comment could be used to remind you of the password, but must not allow others to guess it. Save both the public key and the private key in a convenient location on your local hard drive by clicking <span class="MenuOutput">Save public key</span> and <span class="MenuOutput">Save private key</span>. Then copy everything contained in the box <span class="MenuOutput">Public key for pasting into Open SSH authorized_keys file</span>.</p>
<p><img alt="Set a passphrase and then save. Copy the key itself." height="477" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_13.png" width="493"/></p>
<p>If you are on the SSCC network, open Notepad, TextPad, or your favorite text editor, paste in the key and save it as  <span class="InputCode">z:\.ssh\authorized_keys</span>. The <span class="InputCode">.ssh</span> folder is hidden by default, so you'll need to type its name rather than clicking on it.</p>
<p> If you are not on the SSCC network,  log in to Linstat, then open <span class="InputCode">.ssh/authorized_keys</span> using your preferred Linux text editor (<span class="InputCode">pico</span>, <span class="InputCode">emacs</span>, <span class="InputCode">vi</span>, etc.), paste in the key, and save it. Either way, make sure the entire key is pasted onto one line.</p>
<p><img alt="Edit .ssh/authorized_keys" height="125" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_14.png" width="675"/></p>
<p>If you haven't already, log into Linstat. Then run the following command:</p>
<p class="InputCode">chmod g-w ~/.ssh/authorized_keys</p>
<p>(SSCC uses "user private groups" to make it easy to share files in project directories while keeping files in home directories private. Unfortunately the program that manages key pair connections doesn't understand user private groups and insists keys must not have group write permissions for security reasons.)</p>
<p>Run PuTTY and load your previously saved Linstat profile.</p>
<p><img alt="Open your Linstat profile" height="448" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_15.png" width="466"/></p>
<p>Under <span class="MenuOutput">Category</span> on the left choose <span class="MenuOutput">Connection</span>, <span class="MenuOutput">SSH</span>, <span class="MenuOutput">Auth</span>. Then click <span class="MenuOutput">Browse</span> and find the private key you generated and saved.</p>
<p><img alt="Set Auth to the private key you generated" height="448" src="https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_16.png" width="466"/></p>
<p>Go back to <span class="MenuOutput">Session</span> to save the profile, then click <span class="MenuOutput">Open</span>. You'll be prompted for your key passphrase rather than your SSCC password.</p>
<h2 id="Mac_Linux">Mac or Linux</h2>
<p>On a Mac or Linux computer, open a terminal and run <span class="InputCode">ssh-keygen</span>. When it asks where to save the file press enter for the default location. Choose a password or, even better, a <a href="http://xkcd.com/936/">passphrase.</a></p>
<p>Then open the file <span class="InputCode">id_dsa.pub</span> using your favorite text editor and copy the contents. (The <span class="InputCode">.pub</span> extension indicates that this is the <em>public </em>key, to be shared with the server, rather than the <em>private</em> key which remains on your computer.)</p>
<p>Log in to Linstat, then open <span class="InputCode">.ssh/authorized_keys</span> using your preferred Linux text editor (<span class="InputCode">pico</span>, <span class="InputCode">emacs</span>, <span class="InputCode">vi</span>, etc.), paste in the key, and save it. Make sure the entire key is pasted onto one line.</p>
<p>Next run the following command:</p>
<p class="InputCode">chmod g-w ~/.ssh/authorized_keys</p>
<p>(SSCC uses "user private groups" to make it easy to share files in project directories while keeping files in home directories private. Unfortunately the program that manages key pair connections doesn't understand user private groups and insists keys must not have group write permissions for security reasons.)</p>
<p> The next time you connect you'll be prompted for the key passphrase, not your SSCC password. </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_1.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_2.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_3.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_5.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_6.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_6.5.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_7.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_8.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_9.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_10.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_11.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_12.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_13.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_14.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_15.png, https://ssc.wisc.edu/sscc/pubs/screenshots/linstat_public_key/linstat_public_key_16.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Articles on Using Linux</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>
<!-- #BeginEditable "Content" -->
<p>This page lists articles on using the Linux 
                                operating system.</p>
<h2>Basics</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/linstat_jobs.htm">Managing Jobs on Linstat</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/silo.htm">
									  Using Silo</a>
<br/>
<a href="https://ssc.wisc.edu/sscc/pubs/7-1.htm">An Introduction to Condor</a><a href="https://ssc.wisc.edu/sscc/pubs/linstat_jobs.htm"> </a><br/>
<a href="https://www.ssc.wisc.edu/sscc/pubs/linuxos.htm">Getting Started in Linux</a><a href="https://ssc.wisc.edu/sscc/pubs/linuxos.htm"></a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/computing_resources.htm">Computing Resources at the SSCC</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/disk.htm">Network Disk Space at the SSCC</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/linux_disk_space.htm">Managing Disk Space in Linux</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/1-15.htm">How to Change Your SSCC Passwords</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/7-28.htm">Printing from Linux</a><a href="https://ssc.wisc.edu/sscc/pubs/1-15.htm"> </a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/printfromlinux.htm">Using SSCC Network  Printers from Personal Linux Computers</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/diskfromlinux.htm">Using SSCC Network  Disk Space from Personal Linux Computers</a></p>
<h2> Connecting to Linux Servers</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/5-2.htm">Connecting to SSCC Linux Computers using X-Win32</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/linstat_from_mac.htm">Connecting to Linstat from a Mac</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/linstat_outside_us.htm">Connecting to Linstat from Outside the US</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/linstat_google_auth.htm">Configuring Google Authenticator to Log in to Linstat</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/linstat_public_key.htm">Configuring a Public/Private Key Pair to Log into Linstat</a><br/>
</p>
<h2>Tools</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/1-11.htm">Using SFTP</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/7-10.htm">Using Emacs</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/7-15.pdf">Using PICO on UNIX</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/7-17.pdf">Using nu/TPU on UNIX</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/7-8.htm">Using Compressed Data in Linux</a></p>
<h2> Advanced Topics</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/7-9.pdf">Configuring Your Login Session</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/7-14.pdf">Using the Revision Control System</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/flash.htm">Using the SSCC's High Performance Computing Cluster</a>
<br/>
</p>
<!-- #EndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Managing Disk Space in Linux</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- #BeginEditable "Text" -->
<p>Data storage is a major expense for the SSCC, as the performance and reliability required for research data makes "enterprise level" storage much more expensive than the hard drive of your average PC. Individual members can help reduce these costs by managing the files in their 
              home and project directories. This article	
              will discuss Linux tools for managing your disk space.</p>
<h2>Viewing Your Large Files</h2>
<p>Most files are so small (or rather, disk storage today is so large) that even large numbers of them take up trivial amounts of space. We don't want our members to spend their valuable time deciding what small files they can delete. Thus the first task is to identify your large files.</p>
<p>You can use the good old <span class="InputCode">ls -l</span> command, aliased as <span class="InputCode">ll</span> 
              for most people, but <span class="InputCode">du</span> (disk usage) is better at it, especially when combined with other tools.</p>
<p class="InputCode">du <span class="Parameter">directory</span> -ha</p>
<p>where <span class="Parameter"><span class="InputCode">directory</span></span> 
              should be replaced by the name of the directory you want to examine, 
              will give you a list of all files and subdirectories in that directory 
              and their sizes. Sizes will be given in appropriate units for easy reading by humans. Note that this list includes 
              all the contents of all the subdirectories of the directory you specify, so running this command on a high 
              level directory will probably give you more text than you can 
              use.</p>
<p>To view just the biggest files, you can send these results to the 
              <span class="InputCode">sort</span> program and then list only the 
              top results using <span class="InputCode">head</span>. The disadvantage 
              is that <span class="InputCode">sort</span> can't understand different units, so tell <span class="InputCode">du</span> to list all the file sizes in 
              megabytes.</p>
<p class="InputCode">du <span class="Parameter">directory</span> -ma 
              | sort -n -r | head -n20</p>
<p>This will show the twenty biggest files and directories underneath 
              the starting directory (you can choose how many to view by changing 
              the number after <span class="InputCode">-n</span>). These are the 
              files you should focus on.</p>
<h2>Options for Large Files</h2>
<p>Once you've identified the files worth paying attention to, then the question becomes what to do with them:</p>
<ul>
<li>Compress large files that are not in active use. <a href="https://ssc.wisc.edu/sscc/pubs/7-8.htm">Using Compressed Data in Linux</a> has instructions.</li>
<li>Share large data files among researchers rather than everyone making their own copy</li>
<li>Delete intermediate data files that can be reproduced at will, keeping just the raw data and the version of the data you're currently working on (along with all the code that gets you from one to the other)</li>
<li>Delete data files that are no longer needed (but only if you're sure it's no longer needed)</li>
</ul>
<h2>Using Temporary Space</h2>
<p>One easy way to make sure you don't forget to delete a file when 
              you're done with it is to put it in temporary space. In Linux, files 
              stored in <span class="InputCode">/temp30days</span> are deleted 
              after thirty days, but you are welcome to use as much space as you 
              need during that time—just make yourself a directory there. If 
              you store files you'll only need briefly in <span class="InputCode">/temp30days</span>, 
              you'll never have you worry about going back to delete them. Keep 
              in mind that <span class="InputCode">/temp30days</span> is not 
              backed up.</p>
<!-- #EndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Getting Started in Linux</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- #BeginEditable "Text" -->
<h2>Table of Contents</h2>
<ol class="TOC">
<li><a href="#xtocid215400">Introduction</a></li>
<li><a href="#xtocid274591">SSCC Linux Computers</a>
<ul>
<li><a href="#xtocid274592">Connecting to a Linux computer, 
                    logging in, logging out</a></li>
</ul>
</li>
<li><a href="#xtocid274590">The Linux operating system</a>
<ul>
<li><a href="#xtocid274594">How to Formulate a Linux Command</a></li>
<li><a href="#xtocid274595">A Few Simple Useful Utilities</a></li>
<li><a href="#xtocid274596">How Linux Stores Files: The Linux 
                    File System</a></li>
<li><a href="#xtocid274597">File Names under Linux</a></li>
<li><a href="#xtocid274598">Home Directories and the Present 
                    Working Directory</a></li>
<li><a href="#xtocid274599">Manipulating The File System</a>
<ul>
<li><a href="#xtocid2745910">Changing Your Present Working 
                        Directory</a></li>
<li><a href="#xtocid2745911">Listing directories</a></li>
<li><a href="#xtocid2745912">Making and Removing Directories</a></li>
<li><a href="#xtocid2745913">Copying, Moving, Renaming, 
                        and Removing Files</a></li>
</ul>
</li>
<li><a href="#xtocid2745914">Viewing The Contents of Files</a></li>
<li><a href="#xtocid2745915">Using Pipes to View The Output 
                    of Commands</a></li>
<li><a href="#xtocid2745916">Using Pipes to Print the Output 
                    of Commands</a></li>
<li><a href="#xtocid2745924">Command Shortcuts</a>
<ul>
<li><a href="#xtocid2745925">Wildcard Characters</a></li>
<li><a href="#xtocid2745926">Home Directory Abbreviation: 
                        The Tilde (~)</a></li>
<li><a href="#xtocid2745931">Path Abbreviations: The . and 
                        ..</a></li>
<li><a href="#xtocid2745928">Rerunning Commands and Editing 
                        the Command Line</a></li>
</ul>
</li>
<li><a href="#xtocid2745929">Getting Help</a></li>
<li><a href="#xtocid2745930">In Case of Emergency: What to Try 
                    When Things Go Wrong</a></li>
</ul>
</li>
<li><a href="#xtocid2154024">Managing Disk Space</a>
<ul>
<li><a href="#xtocid2154025">Categories of Disk Space</a></li>
<li><a href="#xtocid2154026">Determining How Much Disk Space 
                    You are Using</a></li>
<li><a href="#xtocid2154027">Compressing Large Files</a></li>
</ul>
</li>
<li><a href="#xtocid215401">Choosing the Proper Linux Computer</a>
<ul>
<li><a href="#xtocid215403">Condor</a></li>
<li><a href="#flash">High Performance Computing Cluster</a></li>
<li><a href="#xtocid215405">Software</a></li>
<li><a href="#xtocid215406">CPU Power</a></li>
<li><a href="#xtocid215407">System Load</a></li>
</ul>
</li>
<li><a href="#xtocid215409">Running Jobs</a>
<ul>
<li><a href="#xtocid2154010">Command Input and Output in Linux</a>
<ul>
<li><a href="#xtocid2154012">Redirection of Standard Output</a></li>
<li><a href="#xtocid2154014">Redirection of Standard Input</a></li>
<li><a href="#xtocid2154015">Pipes</a></li>
</ul>
</li>
<li><a href="#xtocid2154016">Running Jobs in the Foreground 
                    and Background</a></li>
<li><a href="#xtocid2154017">Switching Between Foreground and 
                    Background</a></li>
<li><a href="#xtocid2154018">Managing Background Jobs</a></li>
<li><a href="#xtocid2154019">Killing jobs</a></li>
<li><a href="#xtocid2154021">Running Multiple Jobs</a></li>
<li><a href="#xtocid2154022">Condor</a></li>
<li><a href="#xtocid2154023">Scripts</a></li>
<li><a href="#xtocid2154030">Running a Job Later</a></li>
</ul>
</li>
<li><a href="#xtocid215432">Summary of Commands</a></li>
<li><a href="#xtocid215433">Other Sources of Information</a></li>
</ol>
<h2><a id="xtocid215400" name="xtocid215400"></a>1. Introduction</h2>
<p>This handbook will introduce you to the Linux operating system, with a focus on using SSCC's Linstat servers. It is intended for those who want to use Linux for more than just a way to run statistical jobs. If your goal is just to run jobs on Linstat, <a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a> and <a href="https://ssc.wisc.edu/sscc/pubs/linstat_jobs.htm">Managing Jobs on Linstat</a> will probably teach you everything you need to know.</p>
<h2><a id="xtocid274591" name="xtocid274591">2. SSCC Linux Computers</a></h2>
<p>Linstat is the SSCC's cluster of  servers running Linux. When you connect to Linstat, you'll  be directed to one of the three Linstat servers (linstat1, linstat2 and linstat3)   automatically. This will spread users among the three servers and help   avoid situations where one server is much busier than another.</p>
<h3><a id="xtocid274592" name="xtocid274592"> Connecting to a Linux computer, logging 
              in, logging out </a></h3>
<p>Linux is designed for remote logins and can be used very successfully
            	 from anywhere in the world. To connect to a Linux server you
            	will need a client program capable of using a secure protocol,
            	ideally SSH. X-Win32 is our suggestion for 
              PC's. For details on downloading and using X-Win32,
              see <a href="https://www.ssc.wisc.edu/sscc/pubs/5-2.htm">Connecting
              to SSCC Linux Computers using X-Win32</a>.
              For other options see the Connecting to Linstat section of <a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm#ConnectingtoLinstat">Using Linstat</a>.</p>
<p>When you are finished with your login session, be sure to log off by typing <span class="InputCode">exit</span> at the Linux 
              prompt.</p>
<h2><a id="xtocid274590" name="xtocid274590"></a>3. The Linux Operating 
              System</h2>
<p align="left">Linux is a very powerful, flexible operating system.
              In a few minutes, it is possible to learn enough to get into the
              system, run statistical programs like Stata, and get out
              again. On the other extreme, those who have worked on Linux for
              years are still learning every day. This reflects both the power
              and the complexity of the operating system.</p>
<h3 align="left"><a id="xtocid274594" name="xtocid274594"> How to Formulate a Linux 
              Command</a></h3>
<p>When you log in to a Linux computer, a prompt will appear on the 
              screen, waiting for you to enter a command. At this point you can 
              enter any valid Linux command and the computer will run it.</p>
<p>The syntax of a Linux command is very simple: first, enter the 
              command name, followed by any options and any other parameters. 
              Spaces separate the command name from the options and the options 
              from the parameters. Once the command has been completely formed, 
              press Enter. When you press Enter, the command is executed.</p>
<p>For instance, if you want to know the current date and time, use 
              the <span class="InputCode">date</span> command. Then press Enter. 
              The current date and time will appear, followed by another prompt. 
              Your login session will look like this:</p>
<p class="InputCode">linstat2.ssc.wisc.edu&gt; date<br/>
              Mon Feb 18 10:52:55 CST 2008<br/>
            linstat2.ssc.wisc.edu&gt;</p>
<p>When the prompt appears (the prompt here is <span class="InputCode">linstat2.ssc.wisc.edu&gt;)</span>, 
              the computer is ready for you to enter another command. </p>
<p>Note that the prompt will vary depending on the machine on which 
              you are working. You can also customize the prompt to be anything 
              you like.</p>
<p>Unlike some other operating systems, Linux is case sensitive. The 
              command <span class="InputCode">date</span> is not the same as the 
              command <span class="InputCode">DATE</span>. You must always use 
              the proper case when running Linux commands. Fortunately, this is 
              simple, as virtually all Linux commands are lower case.</p>
<h3><a id="xtocid274595" name="xtocid274595"> A Few Simple Useful Utilities</a></h3>
<p>Below are some simple, useful commands that you can run right away. 
              Try these:</p>
<p class="InputCode">&gt; cal</p>
<p>displays the calendar for the current month. To see a calendar 
              for the whole year, try:</p>
<p class="InputCode">&gt; cal 1997</p>
<p>In this example, "1997" is a parameter to the command 
              cal: it is telling <span class="InputCode">cal</span> to give information for all of 1997, instead 
              of giving the default information for the current month. Be sure 
              to use the "19" or <span class="InputCode">cal</span> 
              will display the calendar for the year 97, not the year 1997.</p>
<p class="InputCode">&gt; cal 12 1997</p>
<p>displays the calendar for the month of December, 1997. Here, <span class="InputCode">cal</span> 
              is taking two parameters. The first parameter is the month and the 
              second parameter is the year.</p>
<p class="InputCode">&gt; who</p>
<p>displays a list of users currently logged into that computer, also 
              giving the time that the user logged in.</p>
<p class="InputCode">&gt; uptime</p>
<p>This extremely useful command tells the current time, how long 
              the computer has been up, how many users are currently logged on, 
              and how busy the computer has been for the last one, five, and 15 
              minutes. This is the "load average", the average number 
              of jobs that were waiting to run in that time increment. To understand 
              how to interpret the load average, see the <a href="#xtocid215407">System 
              Load </a> section later in this handbook.</p>
<p class="InputCode">&gt; hostname</p>
<p>displays the name of the computer on which you are working.</p>
<p class="InputCode">&gt; clear</p>
<p>clears your screen and puts a prompt on the top line of the screen.</p>
<p class="InputCode">&gt; lookup Gary Sandefur</p>
<p>The <span class="InputCode">lookup</span> command looks into the
               UW-Madison student, faculty, and staff information database and
               displays information about the person you are looking up. In the
               command above, information about UW-Madison Dean of the College of Letters and Science, Gary Sandefur, will be displayed, as well as information
              about any other person on campus with these names. </p>
<p>Most of the above commands were simple commands to run. Only one 
              of them required parameters (lookup) and none required options. 
              Later, commands will be introduced that require options to provide 
              important information. The critical point about these commands can 
              be seen from these examples: the command comes first; spaces separates 
              parameters from the command and parameters from each other.</p>
<h3><a id="xtocid274596" name="xtocid274596"> How Linux Stores Files: The Linux File 
              System</a></h3>
<p>All computers store files in some type of file system. These file 
              systems largely resemble each other: individual files are referenced 
              through folders or directories, terms that can be used interchangeably. 
              The term "directory" is preferred by Linux users.</p>
<p>Two features distinguish the Linux file system from Windows:</p>
<p>1. Linux uses a forward slash, instead of a backslash to indicate 
              the existence of a directory. For example, Windows might refer to 
              a file as:</p>
<p class="InputCode"> F:\home\r\rdimond\saswork\data</p>
<p>but Linux would refer to a file as:</p>
<p class="InputCode"> /home/r/rdimond/saswork/data</p>
<p>The items "home", "r", "rdimond", 
              and "saswork" are all directories, but the names are separated 
              by forward slashes in Linux, not backslashes, as in Windows.</p>
<p>2. Linux does not start a file name with the name of a disk. On 
              a Windows machine, the start of any file name is a disk name, such 
              as C: for the main hard disk or A: for the floppy. Linux attempts 
              to hide disks from the user. For instance, a directory might be 
              called:</p>
<p class="InputCode"> /home/r/rdimond</p>
<p>This path name refers to a directory called rdimond. The rdimond 
              directory is in the directory called r; the r directory is in the 
              directory called home; the home directory is in the directory called 
              root, and displayed as a preceding forward slash, the "/" 
              at the beginning of the name. The root directory is the starting 
              directory on Linux, from which all other files and directories are 
              descended. All files and directories on Linux exist at some place 
              relative to the root directory. The full path name of a file always 
              begins with a forward slash, with a reference to the root.</p>
<h3><a id="xtocid274597" name="xtocid274597">File Names under Linux</a></h3>
<p>File and directory names under Linux are quite freeform. (In this 
              section, we will use the expression "file names" to mean 
              "file or directory names".) All numbers and letters of 
              the alphabet are allowed in file names, as are several special characters 
              such as "." (dot) and "_" (underscore). Linux 
              has no naming regulations, such as the requirement that a dot appear 
              in the name. However, despite having few formal rules, the following 
              guidelines will assist you in working with files.</p>
<ul>
<li>The first character of a file name should be a letter of the 
                alphabet or a number. Do not use a special character, such as 
                a dot, a plus sign or a minus sign. Any of these could lead to 
                difficulties when attempting to manipulate the file or directory.</li>
<li>Do not use spaces or tabs in file names.</li>
<li>File names with multiple periods such as filename.ext.ext are 
                valid.</li>
<li>Keep in mind that Linux is case sensitive: the names outfile,
                Outfile and OutFile represent three different files. However,
                it is not wise to create files in which the only difference among
                names is the case, as this can confuse PCs if you ever map your
                Linux home directory as a network drive on a PC. </li>
<li>Although virtually all file names are legal, there are a few 
                names that should be avoided: core and .rhosts. The system uses 
                the name core for a dump of certain data when a command fails. 
                (If you ever see one of these files in one of your directories, 
                the file can be safely removed.) If you create a file called .rhosts 
                you may unintentionally permit others to access your home directory. 
                Of course, this is an uncommon name, and one that you are not 
                likely to create accidentally.</li>
<li>Filenames starting with a period are special files called "hidden 
                files" and will only be displayed in a directory listing 
                if you use <span class="InputCode">ls</span> with the <span class="InputCode">-f</span> 
                or <span class="InputCode">-a</span> option.</li>
</ul>
<p>File naming conventions are only conventions and are not used to 
              distinguish file type. Some commonly-used conventions are:</p>
<p>             </p>
<table align="center" border="0" width="75%">
<tr>
<td>.do (Stata command files)<br/>
                  .dta (data files stored in Stata format) <br/>
                  .gif (graphics file)<br/>
                  .gz (compressed file)<br/>
                  .htm (Web page)<br/>
                  .html (Web page)<br/>
                  .jpg (graphics file)<br/>
                  .jpeg (graphics file)<br/>
                  .log (SAS or Stata log file)<br/>
                .lst (SAS listing)<br/> </td>
<td>pdf (Adobe pdf file)<br/>
                  .ps (PostScript file)<br/>
                  .sas (SAS source file)<br/>
                  .sas7bdat (data files stored in SAS format)<br/>
                  .sps (SPSS source file)<br/>
                  .tar (archive file)<br/>
                  .tex (TeX file)<br/>
                  .zip (compressed file)<br/>
                .Z (compressed file)</td>
</tr>
</table>
<h3><a id="xtocid274598" name="xtocid274598"> Home Directories and the Present Working 
              Directory</a></h3>
<p>All user accounts have a part of the file system that is their 
              own. This is called their home directory. When you first log in, 
              Linux makes your home directory your present working directory. 
              Your present working directory is the directory where files and 
              directories will be listed, created, changed, or removed by default, 
              unless you instruct the computer to perform the action in another 
              location (examples to follow, below).</p>
<p>Home directories are located in a subdirectory of the directory 
              called /home. /home consists of a series of directories, one for 
              each letter of the alphabet. Home directories are under the letter 
              of the alphabet corresponding to the first letter of your login 
              name. For instance, the home directory of the user account named 
              swald is at /home/s/swald and the home directory of the user account 
              named mcdermot is at /home/m/mcdermot.</p>
<p>Home directories are the place for you to put your files. You can 
              control access permissions for files in your home directory, allowing 
              others to see files, or to change files, or denying them these privileges.</p>
<h3><a id="xtocid274599" name="xtocid274599"> Manipulating The File System</a></h3>
<p>The Linux tools used most often by users are the commands that 
              allow users to manipulate files and directories. These commands 
              include:</p>
<table align="center" border="0" width="75%">
<tr>
<td width="23%">ls</td>
<td width="77%">display the tables of a directory</td>
</tr>
<tr> </tr>
<tr>
<td width="23%">pwd</td>
<td width="77%">display the full path name of the present working 
                  directory</td>
</tr>
<tr>
<td width="23%">cd</td>
<td width="77%">change present working directory</td>
</tr>
<tr>
<td width="23%">mkdir</td>
<td width="77%">create a new directory</td>
</tr>
<tr>
<td width="23%">rmdir</td>
<td width="77%">remove a directory</td>
</tr>
<tr>
<td width="23%">cp</td>
<td width="77%">copy a file</td>
</tr>
<tr>
<td width="23%">mv</td>
<td width="77%">move or rename a file</td>
</tr>
<tr>
<td width="23%">rm</td>
<td width="77%">remove a file</td>
</tr>
</table>
<p>             </p>
<h4><a id="xtocid2745910" name="xtocid2745910">Changing Your Present Working Directory 
              </a></h4>
<p>To determine your present working directory, use the <span class="InputCode">pwd</span> 
              command:</p>
<p class="InputCode">&gt; pwd<br/>
              /home/r/rdimond</p>
<p>To change your present working directory, use the <span class="InputCode">cd</span> 
              command. For example, to change to the /tmp directory (the system 
              directory for temporary files):</p>
<p class="InputCode">&gt; cd /tmp</p>
<p>Remember that a space separates the command (<span class="InputCode">cd</span>) 
              from the parameter (<span class="InputCode">/tmp</span>). If the 
              command is successful, it will not display any information; it will 
              simply return a command prompt. To confirm that you really did change 
              to the /tmp directory, issue the <span class="InputCode">pwd</span> 
              command. For instance:</p>
<p class="InputCode">&gt; cd /tmp<br/>
              &gt; pwd<br/>
              /tmp</p>
<p>To return back to your home directory from any other directory, 
              enter the <span class="InputCode">cd </span>command without a parameter. 
              For instance: </p>
<p class="InputCode">&gt; cd<br/>
              &gt; pwd<br/>
              /home/r/rdimond</p>
<h4><a id="xtocid2745911" name="xtocid2745911">Listing directories</a></h4>
<p>Once you change directories, one of the first things you will want 
              to do is look at the tables of the directory. To do this, use 
              the <span class="InputCode">ls</span> command. For instance:</p>
<p class="InputCode">&gt; ls<br/>
              bin README            </p>
<p>There are two items in the present working directory, called 
              bin and README.  To determine if these items are files or directories,
              you must ask for a long listing. To do this, use the <span class="InputCode">-l</span> 
              option (long listing) to the <span class="InputCode">ls</span> command.
               Options in Linux begin with minus signs and are usually one letter
               long. For instance:</p>
<pre>
&gt; ls -l
total 52<br/>drwxrwx---  2 guest12 guest12  4096 Feb 18 11:09 bin<br/>-rw-r-----  1 guest12 guest12 38331 Feb 18 11:13 README
</pre>
<p>The dash "-" in the first column of the README line indicates 
              that this is a file. The "d" in the first column of the 
              bin line indicates that this is a directory. The "total" 
              line indicates how many blocks are taken up by items in this directory. 
              It is not usually useful and can be safely ignored.</p>
<p>Let's look at the long listing of the README file more closely:</p>
<pre>-rw-r-----  1 guest12 guest12 38331 Feb 18 11:13 README
1  2        3   4       5       6     7           8
</pre>
<p>The long listing provides a lot of information about the file in 
              a single line. As stated, the first character is the file type (labeled 
              1 above). Generally, this will either be a dash or a d, indicating 
              that it is an ordinary file or a directory. Following the file type 
              are nine characters (labeled 2 above) indicating the file permissions 
              (file permissions will be discussed in a later <a href="#xtocid2154036">section</a>). 
              The number following this (labeled 3 above) can be ignored; it is 
              for use by advanced Linux users. The next two fields (labeled 4 
              and 5 above) are the owner of the file and the group affiliation 
              of the file. All files on the Linux file system are owned by someone 
              and have some group affiliation. Next is the size of the file in 
              bytes (labeled 6 above). A byte is the equivalent of a single character. 
              Next comes the date and time that the file was modified (labeled 
              7 above). Finally comes the file name (labeled 8 above).</p>
<p>You can also list the tables of a directory without changing 
              to it. To do this, give the directory name that you want listed 
              as a parameter to the <span class="InputCode">ls</span> command. 
              For instance:</p>
<pre>&gt; ls -l /tmp
total 629
-rw-------   1 rdimond  system    147456 Aug  6 22:16 Ex25804
-rw-------   1 rdimond  system     81920 Aug  6 22:15 Rx25804
-rw-r--r--   1 root     system        59 Aug  6 13:34 lpq.00125519
-rw-------   1 flory    system    825012 Aug  5 11:54 ng5chi.dat
-rw-r--r--   1 tpan     system      3086 Aug  6 10:43 rrn.16443
-rw-r--r--   1 tpan     system    355337 Aug  6 10:43 rrnact.16443
drwxr-xr-x   2 pkovatch system       512 Aug  1 04:20 spss_125
</pre>
<p>Other useful options for the <span class="InputCode">ls</span> 
              command are listed below:</p>
<table align="center" border="0" width="75%">
<tr>
<td class="InputCode" width="17%">ls -a</td>
<td width="83%">(all) Include "dot" files, those beginning 
                  with a dot</td>
</tr>
<tr>
<td class="InputCode" width="17%">ls -F</td>
<td width="83%">(File types) Identify file types with codes;
                  / for directories, * for executables, and @ for symbolic links</td>
</tr>
<tr>
<td class="InputCode" width="17%">ls -R</td>
<td width="83%">(Recursive) Recursively list all subdirectories</td>
</tr>
<tr>
<td class="InputCode" width="17%">ls -r</td>
<td width="83%">(reverse) Sort in reverse order</td>
</tr>
<tr>
<td class="InputCode" width="17%">ls -s</td>
<td width="83%">(size) Display the size in kilobytes</td>
</tr>
<tr>
<td class="InputCode" width="17%">ls -t</td>
<td width="83%">(time) Sort by time modified</td>
</tr>
<tr>
<td class="InputCode" width="17%">ls -u</td>
<td width="83%">(used) Show time of last access</td>
</tr>
</table>
<br/>
<h4><a id="xtocid2745912" name="xtocid2745912">Making and Removing Directories</a></h4>
<p>Within your home directory, you have the ability to organize your 
              files as you please. This means that you can create subdirectories 
              within your home directory. To do this, use the <span class="InputCode">mkdir</span> 
              command. For instance:</p>
<pre>&gt; ls -l<br/>total 52<br/>drwxrwx---  2 guest12 guest12  4096 Feb 18 11:09 bin<br/>-rw-r-----  1 guest12 guest12 38331 Feb 18 11:13 README<br/>&gt; mkdir homework<br/>&gt; ls -l<br/>total 56<br/>drwxrwx---  2 guest12 guest12  4096 Feb 18 11:09 bin<br/>drwxrwx---  2 guest12 guest12  4096 Feb 18 11:24 homework<br/>-rw-r-----  1 guest12 guest12 38331 Feb 18 11:13 README</pre>
<p>In this example, a new directory was created called "homework". 
              Use <span class="InputCode">cd</span> to change to the homework 
              directory. For instance:</p>
<pre>&gt; pwd
/home/g/guest12
&gt; cd homework
&gt; pwd
/home/g/guest12/homework
</pre>
<p>If you decided that this directory was not needed after all, you 
              could remove the directory using the <span class="InputCode">rmdir</span> 
              command. For instance:</p>
<pre>&gt; ls -l<br/>total 56<br/>drwxrwx---  2 guest12 guest12  4096 Feb 18 11:09 bin<br/>drwxrwx---  2 guest12 guest12  4096 Feb 18 11:24 homework<br/>-rw-r-----  1 guest12 guest12 38331 Feb 18 11:13 README<br/>&gt; rmdir homework<br/>&gt; ls -l<br/>total 52<br/>drwxrwx---  2 guest12 guest12  4096 Feb 18 11:09 bin<br/>-rw-r-----  1 guest12 guest12 38331 Feb 18 11:13 README</pre>
<p>The homework directory is now gone. This only works if the directory 
              is empty, that is, it has no files or directories within it.</p>
<h4><a id="xtocid2745913" name="xtocid2745913">Copying, Moving, Renaming, and Removing 
              Files</a></h4>
<p>Files are created in a number of ways. You can use an editor,
              such  as EMACS or PICO to create a file; statistical programs,
              such as  SAS or SPSS create files; you might create files using
              a PC application like TextPad,  with your Linux home directory
              as a network drive. In any case, once files are created, it is
              often necessary to copy, move, rename, or remove them.</p>
<p>To copy a file, use the <span class="InputCode">cp</span> command. 
              For instance, if you have a file called README and you wish to copy 
              it to readme.new, you would do this:</p>
<pre>&gt; cp README readme.new<br/>&gt; ls -l<br/>total 92<br/>drwxrwx---  2 guest12 guest12  4096 Feb 18 11:09 bin<br/>-rw-r-----  1 guest12 guest12 38331 Feb 18 11:13 README<br/>-rw-r-----  1 guest12 guest12 38331 Feb 18 11:32 readme.new</pre>
<p>The original file has not been changed in any way, but a new file 
              has been created. This new file is a copy of the original, with 
              a different name. Also, because Linux is case sensitive, the file 
              names were specified with the appropriate cases. The new file name 
              has a dot in the name, and a suffix. As stated earlier, suffixes 
              to Linux are entirely unimportant (although they may be important 
              to particular applications!). There may be as many letters before 
              or after the dot as desired. Finally, note that the last modification 
              date on the new file is different from the last modification date 
              on the old file. The new file's modification date is the creation 
              date.</p>
<p>Now, let's create a directory called Documentation and move the 
              new file to that directory using the <span class="InputCode">mv</span> 
              command:</p>
<pre>&gt; mkdir Documentation<br/>&gt; mv readme.new Documentation<br/>&gt; ls -l Documentation<br/>total 40<br/>-rw-r-----  1 guest12 guest12 38331 Feb 18 11:32 readme.new</pre>
<p>The readme.new file is now in the Documentation directory (again, 
              notice that the D in Documentation is capitalized).</p>
<p>The <span class="InputCode">cp</span> command can also be used 
              to make a copy of a file, using the same file name as the original, 
              but placing it in a different directory. For instance:</p>
<pre>&gt; cp README Documentation<br/>&gt; ls -l Documentation<br/>total 80<br/>-rw-r-----  1 guest12 guest12 38331 Feb 18 11:35 README<br/>-rw-r-----  1 guest12 guest12 38331 Feb 18 11:32 readme.new</pre>
<p>In this example, the file called README is copied to the directory 
              called Documentation, the name not changing.</p>
<p>The <span class="InputCode">mv</span> command can be used to rename 
              a file. For instance:</p>
<pre>&gt; mv readme.new oldreadme<br/>&gt; ls -l<br/>total 80<br/>-rw-r-----  1 guest12 guest12 38331 Feb 18 11:32 oldreadme<br/>-rw-r-----  1 guest12 guest12 38331 Feb 18 11:35 README</pre>
<p>A note of caution about using the <span class="InputCode">cp</span> 
              and <span class="InputCode">mv</span> commands: If you copy or move 
              a file to a file name that already exists, the existing file will 
              be overwritten without notice. </p>
<p>Now the Documentation directory has two copies of the same file 
              with two different names. You can remove a file using the <span class="InputCode">rm</span> 
              command. For instance:</p>
<pre>&gt; cd Documentation<br/>&gt; rm oldreadme<br/>&gt; ls -l<br/>total 40<br/>-rw-r-----  1 guest12 guest12 38331 Feb 18 11:35 README
            </pre>
<p>You can also remove the Documentation directory and all of its 
              tables, but you cannot use the <span class="InputCode">rmdir</span> 
              command, which is only for removing empty directories. To remove 
              a directory, including all of its tables, use the <span class="InputCode">-r</span> 
              option to the <span class="InputCode">rm</span> command. For example:</p>
<pre>&gt; cd<br/>&gt; rm -r Documentation<br/>&gt; ls -l<br/>total 52<br/>drwxrwx---  2 guest12 guest12  4096 Feb 18 11:09 bin
            </pre>
<p>This will remove the Documentation directory and all of its tables 
              with no questions asked. This is somewhat dangerous. A better way 
              to use <span class="InputCode">rm</span> is to use the <span class="InputCode">-i</span> 
              option also, which forces you to confirm that you really want to 
              remove each file or directory. For example:</p>
<pre>
&gt; cd
&gt; rm -r -i Documentation
rm: remove Documentation/README? y
rm: remove Documentation? y
&gt; ls -l
total 52<br/>drwxrwx---  2 guest12 guest12  4096 Feb 18 11:09 bin
            </pre>
<p>The <span class="InputCode">rm</span> command now asks you to confirm 
              that you really want to remove each item. You can answer y or Y 
              (or any other answer that begins with a y or Y, such as yes, yep 
              or yessireebob) and the item will be removed. Any other answer and 
              the item will not be removed.</p>
<p>One warning about removing Linux files: once a file is removed, 
              it may be gone forever. When a user accidentally removes a file, 
              SSCC staff can sometimes restore the file from the nightly backups, 
              but this is not always possible. Use the <span class="InputCode">-i</span> 
              option when using the <span class="InputCode">rm</span> command 
              to protect your data.</p>
<h3><a id="xtocid2745914" name="xtocid2745914"> Viewing The Contents of Files</a></h3>
<p>To view the tables of a file, you can use the <span class="InputCode">more</span> 
              command:</p>
<p class="InputCode">&gt; more filename</p>
<p> Replace "filename" with the name of the file you wish 
              to view. The file will be displayed one screenful at a time. There 
              are many subcommands within <span class="InputCode">more</span>, 
              but the following are the most useful:</p>
<table align="center" border="0" width="75%">
<tr>
<td width="13%">space</td>
<td width="87%">scroll down a full screen</td>
</tr>
<tr>
<td width="13%">Enter</td>
<td width="87%">scroll down a single line</td>
</tr>
<tr>
<td width="13%">b</td>
<td width="87%">scroll up a full screen</td>
</tr>
<tr>
<td width="13%">q</td>
<td width="87%">quit out of <span class="InputCode">more</span> and return to the command line</td>
</tr>
</table>
<p>To use a subcommand, simply type in the command when the system 
              pauses after displaying a screen of information.</p>
<h3><a id="xtocid2745915" name="xtocid2745915">Using Pipes to View The Output of Commands</a></h3>
<p>Very often, the information scrolling across the screen is not 
              the tables of a file, but other information, such as the long 
              listing of a directory. You can still use the <span class="InputCode">more</span> 
              command to view the output, but you use it through a special Linux 
              feature called a pipe. To use a pipe, type the command as you usually 
              would, but after the command, instead of pressing Enter, place the 
              pipe symbol "|", depicted on your keyboard as a solid 
              or broken line and then type the <span class="InputCode">more</span> 
              command. This will take the output of the <span class="InputCode">ls</span> 
              command and place it in the <span class="InputCode">more</span> 
              command. For instance:</p>
<p class="InputCode">&gt; ls -l /tmp | more</p>
<p>This can be used with any command that displays more than a screen 
              full of information. For example:</p>
<p class="InputCode">&gt; cal 1997 | more</p>
<p>This command would display the calendar for 1997, but it would 
              be displayed within the <span class="InputCode">more</span> command, 
              allowing you to scroll up or down, as desired.</p>
<p>Pipes are one of the most powerful features of Linux.</p>
<h3><a id="xtocid2745916" name="xtocid2745916"> Using Pipes to Print the Output of Commands</a></h3>
<p> Linux pipes give the user the ability to print any data 
              that can be displayed on the screen. For instance, if you wish to 
              print out a listing of your home directory, do the following:</p>
<p class="InputCode">&gt; ls -l | enscript</p>
<p>In this example, no listing is printed to the screen; the computer 
              returns a prompt to you without showing you the listing. The output 
              of the <span class="InputCode">ls</span> command is sent to the 
              default printer. </p>
<h3><a id="xtocid2745924" name="xtocid2745924"> Command Shortcuts</a></h3>
<p>Once users begin to use Linux commands with some regularity, they 
              rapidly start to desire certain shortcuts for some operations. Linux 
              provides shortcuts and alternative methods for performing actions 
              in abundance. This section introduces some relatively simple shortcuts 
              that are not necessary for users to perform their work, but may 
              be useful to beginning level students.</p>
<h4><a id="xtocid2745925" name="xtocid2745925"></a>Wildcard Characters</h4>
<p>Wildcard characters allow you to specify many files at once, or 
              to specify a single file concisely. The wildcard characters are 
              the asterisk (*), the question mark (?), and the square brackets 
              ([]). You can use wildcard characters with commands like<span class="InputCode"> 
              ls</span>, <span class="InputCode">cp</span>, <span class="InputCode">mv</span> 
              and <span class="InputCode">rm</span> to perform an action on several 
              files. Below are examples of the use of wildcard characters with 
              the <span class="InputCode">ls</span> command:            </p>
<p class="InputCode">&gt; ls R*<br/>
              README<br/>
              README.old</p>
<p>The asterisk means "zero or more of any character." In 
              this example, the <span class="InputCode">ls</span> command listed 
              two files beginning with an R.</p>
<p><span class="InputCode">&gt; ls *.old<br/>
              hmwork1.old <br/>
              README.old</span><br/>
<br/>
              Wild card characters can appear anywhere in a file name: in the 
              beginning, middle, or end. In this example, the <span class="InputCode">ls</span> 
              command listed two files ending with .old.</p>
<p class="InputCode">&gt; ls *old*
              <br/>
              hmwork1.old <br/>
              oldnotes <br/>
              README.old</p>
<p>Multiple wild card characters can be used. In this example, the 
              <span class="InputCode">ls</span> command listed three files that 
              had old somewhere within the file name.</p>
<p class="InputCode">&gt; ls hmwork?<br/>
              hmwork1<br/>
              hmwork2<br/>
              hmwork3<br/>
              hmwork4</p>
<p>A question mark stands for one character within the list or range 
              shown. In this example, the <span class="InputCode">ls</span> command 
              listed four files that started with hmwork and then had a single 
              character following.</p>
<p class="InputCode">&gt; ls hmwork[2-4]<br/>
              hmwork2<br/>
              hmwork3<br/>
              hmwork4</p>
<p>The <span class="InputCode">ls</span> command listed three files 
              that started with hmwork and then had a single character following 
              in the range of 2 to 4. This range might have been a to z (including 
              all lower case letters), or N to m (including the second half of 
              capitalized letters and the first half of lower case letters).</p>
<p>Any of these wild card characters can be used multiple times, and 
              in combination with each other.</p>
<h4><a id="xtocid2745926" name="xtocid2745926">Home Directory Abbreviation: The Tilde 
              (~)</a></h4>
<p>As configured for new SSCC users, Linux allows you to use the
              tilde (~) as an abbreviation for your home directory. In any command
              where  you want to specify your home directory, you may use the
              tilde instead.  For example:</p>
<p class="InputCode">&gt; cd ~/data <br/>
              &gt; ls ~</p>
<p>The user changes to the data subdirectory of her home directory 
              and then listed the tables of her home directory.</p>
<p>The tilde followed immediately by a user's login name is an abbreviation 
              for that user's login directory. For example:</p>
<p class="InputCode">&gt; ls ~smith <br/>
              &gt; cd ~jones/sas</p>
<p>This will list the directory called /home/s/smith and then change
               to the directory called /home/j/jones/sas provided the proper
              permissions are set on the directories. </p>
<h4><a id="xtocid2745931" name="xtocid2745931"></a>Path Abbreviations: The . and ..</h4>
<p>Two other abbreviations, the .. and the . are shortcuts that can 
              save you keystrokes. .., also called dot-dot, can be used to refer 
              to the directory up one level from the current directory. For example:</p>
<pre>&gt; pwd
/home/g/guest12/homework
&gt; cd ..
&gt; pwd
/home/g/guest12
&gt; cd ..
&gt; pwd
/home/g
&gt; cd
&gt; pwd
/home/g/guest12 </pre>
<p>Each <span class="InputCode">cd ..</span> command moved the present 
              working directory up one level. The <span class="InputCode">cd</span> 
              command without a parameter moved the present working directory 
              back to the home directory, as we saw before. </p>
<p>., also called dot, is a shortcut used to refer to the current
              directory.  For example:</p>
<pre>&gt; mv /project/sandefur/wave9/ameier/2003/readme.new .</pre>
<p>moves the file readme.new from the location specified to the users 
              current working directory. </p>
<h4><a id="xtocid2745928" name="xtocid2745928">Rerunning Commands and Editing the Command 
              Line</a></h4>
<p>As configured for new SSCC users, Linux allows users to edit the 
              command line. This can be as simple as rerunning the previous command 
              to making modifications in the command currently on the screen. 
              This is performed using the arrow keys. Use the up arrow to display 
              previous commands. Each strike of the up arrow key will step backwards 
              through the list of previous commands. When you find the command 
              that you want to rerun, simply press Enter. If you go past the command, 
              use the down arrow to step forward through commands.</p>
<p>If you find a command that you want to rerun, but it is slightly 
              off, use the left and right arrows to move across the command line, 
              use the backspace key to remove a character, and add any character 
              you wish. When the command is properly displayed, press Enter to 
              execute the command.</p>
<p>The exclamation point can also run a previous command. Type an 
              exclamation point followed by the first letters of a command and 
              the last command that began with those letters will be rerun. For 
              example:</p>
<p class="InputCode">&gt; !emacs</p>
<p>This will run the last <span class="InputCode">emacs</span> command. 
              This might be quite useful if, for instance, the last <span class="InputCode">emacs</span> 
              command was something like:</p>
<p class="InputCode">&gt; emacs ~jones/progs/oldstuff/dissert.dat</p>
<h3><a id="xtocid2745929" name="xtocid2745929"> Getting Help</a></h3>
<p>On-line help is available on Linux through the command called <span class="InputCode">man</span>,
               which is short for manual pages. The <span class="InputCode">man</span> 
              command displays reference pages on the screen. These pages can
               be written obscurely. If you do not understand a reference page,
               contact SSCC's help desk for assistance.</p>
<p>If you don't know exactly what command you need to use, you can 
              find a command using the <span class="InputCode">-k</span> option 
              to the <span class="InputCode">man</span> command. The <span class="InputCode">-k</span> 
              option searches for key words in the NAME section of the man page. 
              For example:</p>
<p class="InputCode">&gt; man -k compare </p>
<p>will list on the screen Linux commands that can be used to compare 
              files. </p>
<h3><a id="xtocid2745930" name="xtocid2745930"> In Case of Emergency: What to Try When 
              Things Go Wrong</a></h3>
<p>Sometimes the system just stops working properly for no reason 
              apparent to the new user. When this happens, here are a few keystrokes 
              that might help you.</p>
<p>The <b>&lt;<span class="InputCode">Ctrl-C</span>&gt;</b> keystroke 
              is the interrupt command. It should cancel the current operation 
              and return the prompt to the screen.</p>
<p>The <b>&lt;<span class="InputCode">Ctrl-S</span>&gt;</b> keystroke 
              stops items from displaying on the screen temporarily. This is not 
              useful to a beginning Linux user, but users may accidentally type 
              this, perhaps when intending to type an upper case S. The <b>&lt;<span class="InputCode">Ctrl-Q</span>&gt;</b> 
              keystroke will override the &lt;<span class="InputCode">Ctrl-S</span>&gt; 
              keystroke, allowing the screen to begin displaying again.</p>
<p>Some times, the computer is taking input and waiting for the end 
              of the input. A <b>&lt;<span class="InputCode">Ctrl-D</span>&gt;</b> 
              is the end of file (or end of input) character. Type this keystroke 
              if the system is awaiting input from you and you have given it all 
              the input. This may happen when, for instance, you use the <span class="InputCode">cat</span> 
              command, but forget to give the file name. The system will wait 
              for you to type in what you want printed to the screen. It will 
              take as many characters as you can type, including returns and will 
              not return the prompt to you until it gets the end of file character, 
              the &lt;<span class="InputCode">Ctrl-D</span>&gt;.<br/>
</p>
<h2><a id="xtocid2154024" name="xtocid2154024">4. Managing Disk Space </a></h2>
<p>In this section you will learn about the disk space available to 
              you at SSCC and how to manage it.</p>
<h3><a id="xtocid2154025" name="xtocid2154025"> Categories of Disk Space</a></h3>
<p>SSCC provides two categories of storage space for individual users:
            	home directory space and short term disk
            	space. Both types of individual disk space are described in the SSCC's <a href="https://www.ssc.wisc.edu/sscc/pubs/intro.htm#xtocid2714138">Member Handbook</a> including quotas and backup policies.</p>
<p>If you are working on a research project with a group of people,                 we can provide you with separate storage space on Windows or Linux                that you can all share.  If you'd like project space you may <a href="https://www.ssc.wisc.edu/sscc_jsp/account/project">fill out the online form</a>. If you need your account added to a research  project space, ask the person who set up the project (usually a faculty  member) to contact SSCC's Help Desk on your behalf.</p>
<p>Please help keep costs down by using disk space wisely:</p>
<ul>
<li>Compress large files.<br/>
</li>
<li>Remove unneeded files.<br/>
</li>
<li>Move files to project disks, if appropriate.<br/>
</li>
<li>Do not make copies of standard data files archived by CDE or 
                other agencies or individuals.</li>
</ul>
<h3><a id="xtocid2154026" name="xtocid2154026">Determining How Much Disk Space You are 
              Using </a></h3>
<p>To determine how much disk space you are using, use the <span class="InputCode">quota</span> 
              command. For example</p>
<pre>&gt; quota  <br/>Disk quotas for user rdimond (uid 1931):  <br/>     Filesystem  blocks   quota   limit   grace   files   quota   limit     grace  <br/>griffon:/home/t  936904  1024000 1024000            8119       0       0     <br/></pre>
<p>In the column labeled "Used" is the amount of disk space 
              you are using, in kilobytes. The quota column tells what your current 
              disk quota is. </p>
<p>Often, this is not sufficient information. You want to know specifically 
              which directories are using the disk space. To determine this, use 
              the <span class="InputCode">du</span> command, which will tell you 
              how many kilobytes are in each of your subdirectories. For example:            </p>
<pre>&gt; du -k ~
29414 /home/s/somerset/data
8 /home/s/somerset/News
240 /home/s/somerset/Stuff
224 /home/s/somerset/Personal/gifs
77 /home/s/somerset/Personal/letters
2329 /home/s/somerset/Personal
164 /home/s/somerset/docs/reqs
703 /home/s/somerset/docs/faqs
13 /home/s/somerset/docs/tmp
42 /home/s/somerset/docs/soc361
1569 /home/s/somerset/docs/soc365
339 /home/s/somerset/docs/olddocs/homework
19878 /home/s/somerset/docs/olddocs
9049 /home/s/somerset/docs/travel
35343 /home/s/somerset/docs
202 /home/s/somerset/jobsearch/apps/old
221 /home/s/somerset/jobsearch/apps
238 /home/s/somerset/jobsearch
8336 /home/s/somerset/saslib
155 /home/s/somerset/practice
80024 /home/s/somerset</pre>
<p>This user is using 80 MB of disk space. Most of the disk space 
              usage is in the docs subdirectory, particularly in the olddocs subdirectory 
              of the docs directory. Also, a lot of disk space is being used by 
              the data directory. </p>
<p>You can also get a complete listing of the sizes of all files using 
              the <span class="InputCode">-a </span>option to the <span class="InputCode">du</span> 
              command. For example, below might be the output of the <span class="InputCode">du 
              -ak</span> command, after the output has been sorted (numerically, 
              and in descending order) and the first ten lines requested (the 
              <span class="InputCode">head</span> command): </p>
<pre>&gt; du -ak ~ | sort -n -r | head
80024 /home/s/somerset
35343 /home/s/somerset/docs
29414 /home/s/somerset/data
19878 /home/s/somerset/docs/olddocs
11088 /home/s/somerset/docs/olddocs/thesis
9049 /home/s/somerset/docs/travel
8336 /home/s/somerset/saslib
7712 /home/s/somerset/data/brazil
6208 /home/s/somerset/saslib/course.ssd04
5264 /home/s/somerset/docs/olddocs/diagrams</pre>
<p>This output includes both files and directories. A comparison with 
              the output from the <span class="InputCode">du -k</span>, above, 
              shows that the largest files are ~somerset/docs/olddocs/thesis, 
              ~somerset/data/brazil, ~somerset/saslib/course.ssd04, and ~somerset/docs/olddocs/diagrams. 
              In the interest of conserving disk space, user somerset may want 
              to delete or compress some of these files. </p>
<p>To determine the amount of disk space available on a project disk, 
              use the <span class="InputCode">df</span> command. For example, 
              if you own a directory called /project/irp/bozeman, you can determine 
              the total amount of free space by running this <span class="InputCode">df</span> 
              command:</p>
<p class="InputCode">&gt; df -k /project/irp/bozeman<br/>
              Filesystem 1024-blocks Used Available Capacity Mounted on<br/>
              irp1#irp 8220960 1692974 6507568 21% /project/irp</p>
<p>In this example, about 6.5 GB of disk space is available. Again, 
              the units are kilobytes, which was requested when the <span class="InputCode">-k</span> 
              flag was used.</p>
<h3><a id="xtocid2154027" name="xtocid2154027"> Compressing Large Files </a></h3>
<p>A good way to save disk space is to compress files. A compression
               savings rate of 75% is typical and even 95% is achievable, particularly
               for ordinary data files. </p>
<p>Two compression programs are commonly used on Linux: <span class="InputCode">compress</span> 
              and <span class="InputCode">gzip</span>. The syntax for both is 
              basically the same: issue the command, followed by the name of the 
              file you wish to compress. The <span class="InputCode">-v</span> 
              option is useful, as the compression commands will tell you the 
              percentage of file space you saved by compressing the file. For 
              example: </p>
<p class="InputCode">&gt; compress -v vt20.alpha.tar<br/>
              vt20.alpha.tar:Compression:74.18% - replaced with vt20.alpha.tar.Z</p>
<p>or </p>
<p class="InputCode">&gt; gzip -v vt20.alpha.tar <br/>
              vt20.alpha.tar: 89.2% -- replaced with vt20.alpha.tar.gz </p>
<p>The compression commands will change the names of the files, the 
              <span class="InputCode">compress</span> command adding a ".Z" 
              suffix, and the <span class="InputCode">gzip</span> command adding 
              a ".gz" suffix. </p>
<p>To uncompress files, use the commands <span class="InputCode">uncompress</span> 
              or <span class="InputCode">gunzip</span>: </p>
<p class="InputCode">&gt; uncompress vt20.alpha.tar.Z</p>
<p>or </p>
<p class="InputCode">&gt; gunzip vt20.alpha.tar.gz</p>
<p>The compressed file will be replaced by an uncompressed file without 
              the suffix. </p>
<p>Once compressed, files can be uncompressed and then used. However, 
              it is inefficient, both with respect to SSCC computing resources 
              and your time, to constantly uncompress and then recompress files, 
              particularly large data files. There are two ways to use compressed 
              files without uncompressing them. First, some data analysis programs 
              allow you to read in compressed data. Second, some programs that 
              cannot use compressed data can read data from a special type of 
              file called a named pipe. </p>
<p>Programs such as SAS, SPSS, and STATA allow data to be read from 
              the output of commands. Using the <span class="InputCode">zcat</span> 
              command or the <span class="InputCode">gunzip -c</span> command, 
              the compressed file can be printed to standard output so that software 
              programs can read the files. For instructions on how to use compressed 
              data with commercial software programs, see SSCC Knowledge Base articles on 
              the use of these programs available on SSCC's web site.</p>
<h2><a id="xtocid215401" name="xtocid215401">5. Choosing the Proper Linux Computer </a></h2>
<p>In addition to the three Linstat servers, SSCC also has a Condor Flock and High Performance Computing cluster for running large jobs. When selecting a Linux computer on which to run a job, you must                 consider which machines have the software that you want to use and                 which machines have the computing resources necessary for your project. Visit our <a href="https://www.ssc.wisc.edu/sscc/pubs/computing_resources.htm">Computing Resources at the SSCC web page</a>               for details.</p>
<h3><a id="xtocid215403" name="xtocid215403">Condor </a></h3>
<p>SSCC has a cluster of Linux servers for running large STATA,
               SAS, R, MatLab, Fortran, and C/C++ programs. This cluster has a powerful
              batch pooling utility installed called Condor which was developed
              at UW-Madison's Computer Science Department. For more information
              on Condor, refer  to the SSCC Knowledge Base article, <a href="https://www.ssc.wisc.edu/sscc/pubs/7-1.htm">An
               Introduction to Condor</a>.</p>
<h3><a id="flash" name="flash">High Performance Computing  Cluster</a></h3>
<p>The SSCC has a High Performance Computing cluster called FLASH.    See <a href="https://www.ssc.wisc.edu/sscc/pubs/flash.htm">Using the SSCC's High Performance Computing Cluster</a> for instructions on using these machines. If                 you have parallelized C/C++, Fortran, or R programs you'd like                 to run on this cluster, please contact <a href="mailto:rhorrisb@ssc.wisc.edu">Ryan                   Horrisberger</a>. </p>
<h3><a id="xtocid215405" name="xtocid215405"> Software </a></h3>
<p>Almost all the software installed on Linstat is installed on all three   Linstat servers. The two exceptions (due to licensing restrictions) are   SPSS and Stat/Transfer. They are installed on Linstat1. If you run SPSS   or Stat/Transfer on another Linstat server they will automatically   connect to Linstat1 and run your job there, but if you need to manage   that job later you'll need to log in to Linstat1 to do so. </p>
<p>Software availability information for all of SSCC's computers can  be found on <a href="https://www.ssc.wisc.edu/sscc_jsp/software/">SSCC's 
              Software Availability web page</a>.</p>
<h3><a id="xtocid215406" name="xtocid215406">CPU Power</a></h3>
<p> The three Linstat servers have very
              similar processors. However, for large jobs that will take more than a
              few minutes to run, Condor is ideal. Please see <a href="https://www.ssc.wisc.edu/sscc/pubs/7-1.htm">An
               Introduction to Condor</a>.</p>
<h3><a id="xtocid215407" name="xtocid215407">System Load</a></h3>
<p>If you are going to use the computer intensively, for a STATA
              program,  for example, then you should look for a machine that
              is not busy.  There are several ways to determine if a machine
              is busy, and, if  it is busy, what it is doing. Going to <a href="https://www.ssc.wisc.edu/sscc_jsp/status.jsp">SSCC's
               Server Status web page</a>               is the easiest way to get a quick snapshot of how busy a system
              is.            </p>
<p>The Linux operating system provides its own set of commands to 
              get the same information. For example: </p>
<pre>&gt; uptime
13:33  up 1 day,  2:34,  4 users,  load average: 3.36, 3.31, 3.47
</pre>
<p>The <span class="InputCode">uptime</span> command tells the current 
              time, the length of time the computer has been running (in this 
              example, one day, two hours, 34 minutes), how many users are currently 
              logged onto the system and the load average for the past one, five, 
              and 15 minutes. The load average is the average number of jobs waiting 
              to run over the particular time increment. The higher the number, 
              the busier the system. A Linstat server is busy if its load 
              average exceeds four and is very busy if their load average exceeds 
              six. </p>
<p>To find out how busy Condor is, use the <span class="InputCode">condor_status</span> 
              command. </p>
<p>Another excellent command for monitoring system activity is the 
              <span class="InputCode">top</span> command. The <span class="InputCode">top</span> 
              command lists jobs currently running, ordered by CPU usage, with 
              the command using the greatest amount of CPU time on top of the 
              list. The output of the <span class="InputCode">top</span> command 
              looks like this: </p>
<pre> load averages:   0.16,  0.24,  0.23                       15:33:03
94 processes:  1 running, 1 waiting, 15 sleeping, 75 idle,2stopped
Cpu states: 10.0% user,  0.0% nice,  7.9% system, 82.0% idle
Memory:Real:471M/767M act/tot Virtual:16M/2243M use/tot Free: 181M

  PID USERNAME PRI NICE  SIZE   RES STATE   TIME    CPU COMMAND
 9124 esimpson  42    0 8192K 1327K WAIT    4:27 10.50% sas
10235 odrucker  42    0 7736K 4128K sleep   0:03  1.80% stata<pine>
 9387 mcdermot  44    0 2504K  393K run     0:00  0.40% top
  896 root      44    0 1704K  229K sleep   0:01  0.10% telnetd
   77 root      42    0 1600K   57K sleep  19:30  0.00% update
  488 root      44    0 1728K  122K sleep   0:38  0.00% snmpd
  365 root      44    0 2032K  335K sleep   0:22  0.00% rpc.lockd
  561 root      44    0 1992K  106K sleep   0:17  0.00% httpd
 8463 swald     42    0 4488K  180K sleep   0:12  0.00% xterm
  484 root      44    0 2432K  204K sleep   0:11  0.00% os_mibs
    1 root      44    0  440K   40K sleep   0:07  0.00% init
32490 root      44    0 1704K   40K sleep   0:05  0.00% telnetd
  150 root      44    0 1656K  122K sleep   0:02  0.00% syslogd
  452 root      32  -12 2072K  270K sleep   0:02  0.00% xntpd
 8459 mcdermot  44    0 4464K  729K sleep   0:01  0.00% xterm
</pine></pre>
<p>The listing is updated every few seconds. The load averages are 
              on the first line. Next is a list of how many processes are currently 
              running (94 in this example). The third line shows the percent of 
              time the CPU is spending in various modes. The most important item 
              in this line is the idle percentage. If the idle percentage is non-zero, 
              then the computer is not busy at all. The fourth line shows how 
              much memory is in use. </p>
<p>The table at the bottom is the most interesting part of <span class="InputCode">top</span> 
              output. It lists jobs that are currently running. In this snapshot, 
              user esimpson is running SAS, using about 10% of CPU time. User 
              odrucker is running Stata. He is taking about 2% of the 
              CPU time. The <span class="InputCode">top</span> command is taking 
              about half a percent and other commands are taking trivial amounts.            </p>
<p>Because the Linstat servers have multiple CPUs, the percent of 
              CPU used may total as much as 800%. Enter <span class="InputCode">q</span> 
              to exit the <span class="InputCode">top</span> command.</p>
<h2><a id="xtocid215409" name="xtocid215409">6. Running Jobs </a></h2>
<p>Any time you give Linux something to do, you've created a job. 
              Of course many Linux commands execute almost instantly (<span class="InputCode">cd</span>, 
              <span class="InputCode">ls</span>, etc.), but others may run for 
              hours, days, or even longer. In these cases, how a job is run will 
              impact both what you can do and how the system performs for all 
              other users. The SSCC's Linux servers are a shared resource, and 
              it is up to each member to share nicely.            </p>
<h3><a id="xtocid2154010" name="xtocid2154010"> Command Input and Output in Linux </a></h3>
<p>Linux was designed to have many tools that do specialized tasks. 
              In the Linux model, data flows from one command to another command, 
              each command doing what it does best. To implement this model, every 
              Linux command has three files associated with it. These files are 
              called: </p>
<ul>
<li>standard input </li>
<li>standard output </li>
<li>standard error </li>
</ul>
<p>Standard input is the place from which commands get their data. 
              By default, this is the keyboard. Standard output is the place that 
              commands put their output. By default, this is the screen. Standard 
              error is the place that commands put their error messages. By default, 
              this is the screen, also. But it is important to note that standard 
              output and standard error are not the same thing. It just happens 
              that, by default, they send data to the same place. Collectively, 
              these are called standard input and output, or standard I/O, abbreviated 
              stdio. <br/>
</p>
<table align="center" border="1" width="75%">
<tr>
<td><b>Stdio Elements</b></td>
<td><b>Default</b></td>
<td><b>Abbreviation</b></td>
</tr>
<tr>
<td>standard input</td>
<td>keyboard</td>
<td>stdin</td>
</tr>
<tr>
<td>standard output</td>
<td>screen</td>
<td>stdout</td>
</tr>
<tr>
<td>standard error</td>
<td>screen</td>
<td>stderr</td>
</tr>
</table>
<p>Standard I/O can be redirected so that it comes from, or goes to, 
              any place. Standard input can come from the keyboard, or from a 
              file, or from another command. Standard output can be sent to the 
              screen, or to a file, or into another command (as standard input 
              to that command). This is the power of the standard I/O system.            </p>
<p>The symbols used to redirect output are: <br/>
</p>
<table align="center" border="0" width="75%">
<tr>
<td width="11%">&gt; </td>
<td width="89%">redirect stdout from command to a file</td>
</tr>
<tr>
<td width="11%">&gt;&gt; </td>
<td width="89%">redirect stdout from command to a file, appending</td>
</tr>
<tr>
<td width="11%">&gt;&amp; </td>
<td width="89%">redirect stdout and stderr from command to a file</td>
</tr>
<tr>
<td width="11%">&gt;&gt;&amp; </td>
<td width="89%">redirect stdout and stderr from command to a file, 
                  appending</td>
</tr>
<tr>
<td width="11%">&lt; </td>
<td width="89%">redirect stdin from file to a command</td>
</tr>
<tr>
<td width="11%">|</td>
<td width="89%"> pipe the stdout of one command into the stdin 
                  of another command</td>
</tr>
</table>
<p>             </p>
<h4><a id="xtocid2154012" name="xtocid2154012">Redirection of Standard Output </a></h4>
<p>One of the most common ways to manipulate standard I/O is to redirect 
              standard output from a command into a file. For example, if you 
              want to save a long listing of one of your directories, you can 
              do this: </p>
<p class="InputCode">% ls -l Documentation &gt; doc.list</p>
<p>The "greater than" sign (&gt;) redirects data from the 
              <span class="InputCode">ls</span> command to a file called doc.list. 
              Without the redirection, the listing would appear on the screen, 
              but with the redirection, the command only returns the prompt, with 
              no listing. If the file doc.list already exists, then it will be 
              overwritten by the data from the <span class="InputCode">ls</span> 
              command. To append data to the file, instead of overwriting the 
              current data, use two "greater than" signs: </p>
<p class="InputCode">% ls -l Documentation &gt; doc.list<br/>
              % ls -l Programs &gt;&gt; doc.list</p>
<p>In this example, the first command redirected the listing of the 
              Documentation directory into the file called doc.list, creating 
              a new file or overwriting an existing file. Then, the second command 
              appended the listing of the Programs directory into the doc.list 
              file. The doc.list file contains listings for both directories, 
              now. </p>
<h4><a id="xtocid2154014" name="xtocid2154014">Redirection of Standard Input </a></h4>
<p>Some commands can take information from sources other than the 
              keyboard. They use standard input. For instance, if you wanted to 
              mail the doc.list file to someone, you could use the <span class="InputCode">Mail</span> 
              command to do so, instead of invoking pine or another mailer: </p>
<p class="InputCode">% Mail -s "Documentation Listing" odrucker 
              &lt; doc.list</p>
<p>In this example, the <span class="InputCode">Mail</span> command 
              is used. Mail is sent to odrucker with the subject line "Documentation 
              Listing" (the parameter to the <span class="InputCode">-s</span> 
              option) and the tables of the mail message is the doc.list file.            </p>
<h4><a id="xtocid2154015" name="xtocid2154015">Pipes </a></h4>
<p>The most common use of redirection of standard I/O is with pipes,
              which take the output of one command and give it to the input of
              another command. Some common uses are exemplified below: </p>
<p class="InputCode">% ls -l Documentation | enscript</p>
<p>In this example, the listing of the Documentation directory is 
              sent directly to the <span class="InputCode">enscript</span> command 
              so that the file can be printed. The listing is never saved on disk 
              or displayed on the screen. </p>
<p class="InputCode">% ls -lR | more</p>
<p>The <span class="InputCode">-R</span> option to ls instructs <span class="InputCode">ls</span> 
              to recursively list all directories and subdirectories. This could 
              lead to a very long list. In this example, the output of the <span class="InputCode">ls</span> 
              command is piped through the <span class="InputCode">more</span> 
              command, allowing you to read the listing one screen at a time.            </p>
<h3><a id="xtocid2154016" name="xtocid2154016">Running Jobs in the Foreground and Background 
              </a></h3>
<p>Normally when you type a command, it is processed and you see the 
              results (if any) before the cursor returns and you can type a new 
              command. These jobs are said to be running in the foreground, and 
              that may be exactly what you want if your job will run very quickly 
              or you cannot proceed until you have your results. But you can tell 
              Linux not to wait. When you put a job in the background, the cursor 
              returns immediately and you can keep giving commands and doing other 
              work while the your job is running. When it finishes, a message 
              will appear on your screen.</p>
<p>To run a job in the background, simply add an ampersand (&amp;) 
              at the end of the command line. For example:</p>
<p class="InputCode">&gt; stata -b do myprogram</p>
<p> Stata will start and run <span class="InputCode">myprogram.do</span> 
              in the foreground. Thus the session will be unavailable until the 
              job is done. On the other hand,</p>
<p class="InputCode">&gt; stata -b do myprogram &amp;</p>
<p>will start Stata in the background. The cursor returns immediately,
              and the user can  edit other programs, organize files, etc. while
              waiting for the job to finish. When it is done you will see: </p>
<pre class="InputCode">[1]    Done                          stata -b do myprogram</pre>
<p>Note that a job which creates a separate window (emacs, for example) 
              will be completely functional in the background. What makes it a 
              background process is that your shell (the main session window) 
              is ready for more commands. On the other hand if a program without 
              a window is running in the background and needs input from you (for 
              example if SAS runs out of resources), it will halt until you put 
              in the foreground and give it the input it needs.</p>
<p>Note that a job running in the background will keep running even 
              if you log out, so it is quite possible to start a long job before 
              you leave in the evening, log out, and get the results the next 
              morning. Remember that Linstat is actually a cluster of three servers and when you log in   you're assigned to a server randomly (to try to balance the load between   them). However, you can choose to connect to a specific server to monitor   a job you started previously or if the server you're assigned to turns   out to be particularly busy.</p>
<p>To switch to a different server, type:</p>
<p> ssh server</p>
<p>where server can be linstat1, linstat2 or linstat3. Alternatively you can set up your client program to log in to one of those three servers directly.</p>
<h3 class="PageBreak"><a id="xtocid2154017" name="xtocid2154017"></a>Switching Between 
              Foreground and Background</h3>
<p>If you have a job running in the foreground and you want to do 
              something else, simply press <span class="InputCode">CTRL-z</span> 
              (note that if the current job has opened a window of some sort, 
              you must return to your shell window before pressing <span class="InputCode">CTRL-z</span>). 
              The current job will be suspended and you will get your cursor back. 
              If you want the job to run while you are doing other things, type 
              <span class="InputCode">bg</span> to put it in the background. You 
              can also type <span class="InputCode">fg</span> to move it back 
              to the foreground, either from being suspended or from the background.</p>
<h3><a id="xtocid2154018" name="xtocid2154018"></a>Managing Background Jobs</h3>
<p>It can be very easy to lose track of jobs you have running in the 
              background, but there are several commands that can tell you about 
              them.</p>
<p><span class="InputCode">jobs</span> will list all the jobs you 
              started this session that are not yet complete. For example:</p>
<pre class="InputCode">&gt; jobs<br/>[1]  - Running                       emacs<br/>[2]  + Suspended                     emacs</pre>
<p>The number in brackets is the job number, and you can use that 
              number preceded by a percent sign (%) to refer to the job. Naming 
              a job will move it to the foreground, so in this case <span class="InputCode">%2</span> 
              is similar to <span class="InputCode">fg</span> (except you don't 
              have to keep track of which job is considered the "current" 
              job). Adding an ampersand moves it to the background, so <span class="InputCode">%2 
              &amp;</span> is similar to <span class="InputCode">bg</span>.</p>
<p>You can list jobs started in a previou session using the <span class="InputCode">ps</span> 
              command (think processes). The syntax is <span class="InputCode">ps x
              -u <span class="Parameter">username</span></span>. For example:</p>
<pre>&gt; ps -u rdimond<br/>  PID TTY          TIME CMD<br/>29413 pts/30   00:00:00 tcsh<br/> 1601 pts/30   00:00:00 emacs<br/> 1602 pts/30   00:00:00 emacs<br/> 1605 pts/30   00:00:00 ps</pre>
<p>Note how the bracketed numbers have been replaced by the PID (Process 
              IDentification) and the list is more complete, including your shell 
              (in this case the <span class="InputCode">tcsh</span> shell), and 
              the <span class="InputCode">ps</span> command itself. Note that 
              PID's cannot be used to move things from foreground to background. 
              On the other hand this is the only way to check on jobs from previous 
              sessions.</p>
<h3><a id="xtocid2154019" name="xtocid2154019"></a>Killing a Job</h3>
<p>Sometimes you will change your mind about a job, and occasionally 
              things even go wrong. In these cases, the <span class="InputCode">kill</span> 
              command can be invaluable. Simply type <span class="InputCode">kill</span> 
              and then the job number or PID. For example:</p>
<p class="InputCode">&gt; kill %2</p>
<p>or </p>
<p class="InputCode">&gt; kill 1602</p>
<p>This doesn't actually stop the job, it merely requests that it 
              shut down, giving the program an opportunity to clean up temporary 
              files and such. Unfortunately both SAS and SPSS will not do so, 
              so if you kill one of these jobs, please go to the <span class="InputCode">/tmp</span> 
              directory and manually delete all files and directories belonging 
              to you. On the other hand, adding the <span class="InputCode">-9</span> 
              signal to the <span class="InputCode">kill</span> command will kill 
              a program immediately with or without its consent. Thus:</p>
<p class="InputCode">&gt; kill -9 1602</p>
<p><strong>will</strong> kill process 1602.</p>
<h3><a id="xtocid2154021" name="xtocid2154021"></a>Running Multiple Jobs</h3>
<p>Linux will allow you to put as many jobs as you want in the background, 
              and it will try to work on them all at once. This means it is quite 
              possible for a single user to run so many jobs that everyone else 
              is "crowded out." If necessary SSCC staff will intervene 
              to stop this. On the other hand, Condor handles multiple jobs very 
              efficiently and has plenty of available capacity. So if you are 
              planning on doing any resource intensive computing, you really should 
              check out Condor.</p>
<p>The general rule on the interactive (non-Condor) Linstat servers is that
               you should only have one major job running at a time on each server.
              Text editors, email, etc. are not a problem, but Stata, SAS, SPSS,
              and most user-written programs are resource intensive and will
              affect others. Keep in mind that Linux will split the available
              CPU time among all the running jobs. So if you run three jobs simultaneously,
              they will  each take three times as long to run, saving you no
              time but making  much less CPU time available for others (the one
              exception to this  would be if the server has an idle CPU, but
              you shouldn't count  on this).</p>
<p>If you have multiple jobs to run, please read <a href="https://www.ssc.wisc.edu/sscc/policies/server_usage.htm">SSCC's
              CPU Usage Policy</a>. </p>
<h3><a id="xtocid2154022" name="xtocid2154022"></a>Condor</h3>
<p>Condor is designed to process large numbers of jobs. For full details 
              please see <a href="https://www.ssc.wisc.edu/sscc/pubs/7-1.htm">An 
              Introduction to Condor</a>, 
              but the essence of Condor is that we have a pool of Linux servers 
              which only run jobs submitted to them through the Condor program. 
              Unlike standard Linux jobs, Condor jobs never interfere with each 
              other, since each job gets exclusive use of a CPU. Thus if you submit 
              your jobs to Condor, they will not slow down the server for anyone 
              else (or be slowed down by anyone else).</p>
<p>The price is that it takes about 30 seconds for Condor to process
               a job and assign it to a machine. Thus if you are running a 20
              second  job and will be waiting for the results, it would be counterproductive
               to use Condor. But if you have many jobs to run, or a single big
               job, Condor is a great tool. It's not quite a panacea since it
              can  only be used for Stata, R, MatLab, and most user-written C/C++
              and FORTRAN code, but that covers the bulk of the computing done
              at the SSCC.            </p>
<p>We have written several scripts which make submitting Stata jobs 
              to Condor almost identical to running them as usual. The standard 
              command for running a Stata do file in batch mode is stata -b do 
              dofile (where dofile would be replaced by the name of the do file 
              you want to run. To submit the job to Condor instead, simply replace 
              stata with one of the following:</p>
<p class="InputCode">&gt; condor_stata -b do dofile</p>
<p>condor_stata is the command you'll normally use. It will send your 
              job to a multi-processor machine if one is available, but if not 
              it will send your job to the first available machine. </p>
<p>If you want to run programs other than Stata using Condor, or want 
              to submit many jobs at once, please see <a href="https://www.ssc.wisc.edu/sscc/pubs/7-1.htm">An 
              Introduction to Condor</a>.</p>
<h3><a id="xtocid2154023" name="xtocid2154023"></a>Scripts</h3>
<p>Consider the following two scripts. Both run three SAS jobs. The 
              one on the left will tie up the server it is run on, the one on 
              the right will not. And it will execute in about the same amount 
              of time:</p>
<table align="center" border="1" cellpadding="5">
<tr>
<th nowrap="nowrap" scope="col">Bad Script</th>
<th nowrap="nowrap" scope="col">Good Script</th>
</tr>
<tr>
<td nowrap="nowrap" valign="top" width="50%"> <p class="InputCode">sas 
                    prog1 &amp;<br/>
                    sas prog2 &amp;<br/>
                    sas prog3 &amp;</p></td>
<td nowrap="nowrap" valign="top" width="50%"> <p class="InputCode">sas 
                    prog1<br/>
                    sas prog2<br/>
                sas prog3</p></td>
</tr>
</table>
<p>The bad script places all three jobs in the background, so they 
              all run at the same time and compete for resources. The good script 
              runs them in the foreground, so they will run one at a time. However 
              you do not need to wait for them: simply run the script itself in 
              the background and your shell will be available for other work.            </p>
<p>Of course if you could use Condor those three SAS programs would 
              be run on three different CPUs and thus execute in one third the 
              time.</p>
<h3><a id="xtocid2154030" name="xtocid2154030"></a>Running a Job Later</h3>
<p>The <span class="InputCode">at</span> command allows you to run 
              a job at a time you specify. For example, you could run a big, resource 
              intensive job at 1:00 AM when no one is likely to be on. There are 
              several ways to use <span class="InputCode">at</span>.</p>
<p>If you want to just type in the job you want to run later, type</p>
<p class="InputCode">&gt; at <span class="Parameter">time</span></p>
<p>and you can then enter the command(s) at the prompt (<span class="InputCode">at&gt;</span>). 
              When you are done, press <span class="InputCode">CTRL-D</span>. 
              The time parameter will understand just about any reasonable format, 
              including <span class="InputCode">at 1:00</span>, <span class="InputCode">at 
              1:00am</span>, <span class="InputCode">at 1am</span>, <span class="InputCode">at 
              13:00</span> (1:00pm), <span class="InputCode">at noon</span>, <span class="InputCode">at 
              midnight</span>, or <span class="InputCode">at teatime</span> (4:00pm). 
              Note that if you do not specify <span class="InputCode">am</span> 
              or <span class="InputCode">pm</span>, it is assumed you are using 
              24-hour time.</p>
<p>You can also put the commands you want executed in a file. To do 
              this type:</p>
<p class="InputCode">&gt; at time -f <span class="Parameter">file</span></p>
<p>To list the jobs currently waiting to run, type:</p>
<p class="InputCode"> &gt; atq</p>
<p>To remove a job, type:</p>
<p class="InputCode">&gt; atrm <span class="Parameter">job</span></p>
<p> where <span class="Parameter"><span class="InputCode">job</span></span> 
              is an ID obtained by listing your jobs. </p>
<p>Note that if you submit your jobs to Condor, they will not affect 
              other users and will get plenty of resources no matter when you 
              run them.</p>
<h2><a id="xtocid215432" name="xtocid215432">7. Summary of Commands</a></h2>
<p>The table below is a quick reference for the most common Linux 
              commands. Following the link will take you to a more in-depth explanation 
              of the command.</p>
<table align="center" border="1" width="80%">
<tr>
<td width="30%"><b>Command Name</b></td>
<td width="100%"><b>Command Description</b></td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2154030">at</a></td>
<td width="100%">run a job at a specified time</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2745910">cd</a></td>
<td width="100%">change directory</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid274595">clear</a></td>
<td width="100%">clear the terminal screen</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2154027">compress, uncompress</a></td>
<td width="100%">compress and expand file</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid215407">condor_status</a></td>
<td width="100%">lists state of SSCC's Condor flock</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2745913">cp</a></td>
<td width="100%">copy files and directories</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2154026">df</a></td>
<td width="100%">report file system disk space usage</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2154026">du</a></td>
<td width="100%">estimate file space usage</td>
</tr>
<tr>
<td width="30%"><a href="https://www.ssc.wisc.edu/sscc/pubs/intro.htm#xtocid2714129">enscript</a></td>
<td width="100%">print file(s)</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid274592">exit</a></td>
<td width="100%">log off</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2154027">gzip, gunzip</a></td>
<td width="100%">compress and expand file</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid274595">hostname</a></td>
<td width="100%">display name of computer logged into</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2154018">jobs</a></td>
<td width="100%">display status of jobs in the current session</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2154019">kill</a></td>
<td width="100%">terminate a job</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid274595">lookup</a></td>
<td width="100%">display information about UW employees and students</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2745911">ls</a></td>
<td width="100%">list directory tables</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2745929">man</a></td>
<td width="100%">display the on-line help pages</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2745912">mkdir</a></td>
<td width="100%">create a directory</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2745914">more</a></td>
<td width="100%">display a file one screenful at a time</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2745913">mv</a> </td>
<td width="100%">move or rename files</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2154018">ps</a></td>
<td width="100%">display job status</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2745910">pwd</a></td>
<td width="100%">display present working directory</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2154026">quota</a></td>
<td width="100%">display disk usage and limits</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2745913">rm</a></td>
<td width="100%">remove (delete) files or directories</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid2745912">rmdir</a></td>
<td width="100%">remove (delete) directories</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid215405">soft</a></td>
<td width="100%">list SSCC software availability</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid274592">ssh</a></td>
<td width="100%">remote login and remote execution of commands</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid215407">top</a></td>
<td width="100%">display top CPU processes</td>
</tr>
<tr>
<td width="30%"><a href="#xtocid215407">uptime</a></td>
<td width="100%">tell how busy the system is</td>
</tr>
</table>
<h2><a id="xtocid215433" name="xtocid215433">Other Sources of Information</a></h2>
<p>Many resources are available to learn about the Linux operating
               system, both at SSCC and at your local book store. SSCC staff
              maintain  numerous on-line Knowledge Base articles on Linux topics including
              the use  of editors, such as EMACS and PICO, and use of statistical
              software  like SAS, STATA, and SPSS. All of SSCC's Knowledge Base articles
              are available  online at <a href="https://www.ssc.wisc.edu/sscc/pubs">https://www.ssc.wisc.edu/sscc/pubs</a>.</p>
<p>SSCC also teaches mini-courses, ranging from one-hour courses,
               to classes that meet for half a day, or for an hour a week for
              several  weeks. See BROADCAST, SSCCNEWS, or <a href="https://www.ssc.wisc.edu/sscc_jsp/training/index.jsp">SSCC's
               training web pages</a>               for registration and other information about these courses.</p>
<p> </p>
<!-- #EndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Articles on Using OS X</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>
<!-- InstanceBeginEditable name="Content" -->
<p>This page lists articles on using OS X
                    operating system with SSCC resources.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/printfrommac.htm">Using SSCC Printers from Macs</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/diskfrommac.htm">Using SSCC Network Disk Space from Macs</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/linstat_from_mac.htm">Connecting to Linstat from a Mac</a><br/>
<span class="news"><a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">Using Winstat</a></span><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/working_from_home.htm">Working From Home and Other Remote Locations</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/screen_sharing.htm">Connecting to Your Office Computer Using Screen Sharing (Mac)</a> </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Running Mplus Jobs on Linstat</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Mplus is now available on Linstat, the SSCC's Linux computing cluster, where it can use up to 16 cores and much more memory than on Winstat. This can make large Mplus jobs run much more quickly. Running jobs on Linstat is probably easier than you think. If you've never used Linstat before, start by reading <a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a>.                </p>
<p></p>
<p>Linstat is a cluster of of Linux servers. If you log in to "Linstat" you could be assigned to any of the individual servers, which helps spread the load among them. However, our Mplus license only allows us to install it on three servers, Linstat1, Linstat2, and Linstat3. Thus if your goal is to run Mplus you should log in directly to one of these servers rather than just Linstat. <a href="https://ssc.wisc.edu/sscc/pubs/5-2.htm">Connecting to SSCC Linux Computers using X-Win32</a> and <a href="https://ssc.wisc.edu/sscc/pubs/linstat_from_mac.htm">Connecting to Linstat from a Mac</a> have instructions.</p>
<p>We are also only allowed to have one Mplus job running on each server at a time. If you are told it is currently in use on all three servers we're afraid you'll have to wait. (If this happens to you a lot, let the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a> know and we'll look into transferring more licenses from Winstat to Linstat.)</p>
<p>Any files you want to use on Linstat need to be stored on the SSCC's Linux file system. If you're using a Windows computer on the SSCC network, the Z:\ drive is your Linux home directory and the V:\ drive is Linux project space. The Mplus editor is not available for Linux, but you can write your input files using Mplus on Winstat and then save them on Z:\ or V:\. <a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm#GettingStartedonLinstat">Getting Started On Linstat</a> will teach you how to organize your files for easy use in Linux programs.</p>
<p>Once everything is set up, running an Mplus program is very easy. Just type:</p>
<p class="InputCode">mplus <span class="Parameter">myinputfile</span>.inp</p>
<p>where <span class="Parameter">myinputfile</span><span class="InputCode">.inp</span> should be replaced by the actual name of your input file.</p>
<p>You'll see Mplus open several terminal windows. The way Mplus uses multiple cores is unusual in that rather than having the program start additional processes directly, it launches additional terminal sessions that then start additional processes. Unfortunately this means that you need to stay logged in to Linstat the entire time the program is running. Mplus will also continue to write output to your original Linux terminal, so there's no point in running it in the background. Create a new Linstat session if you want to do additional work, but keep in mind you won't be able to start another Mplus job.                </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Articles for New Users</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>
<!-- #BeginEditable "Content" -->
<p>This page lists articles of particular interest to new SSCC users.
	  			While there is no "required reading" <i>per se</i>, a little
	  			 time spent perusing this section could save you a lot of confusion
	  			down	
		the road. It could also be useful for those seeking basic information
	  			about using SSCC resources.</p>
<h2>Welcome!</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/welcome.htm">Welcome to the SSCC! (For SSCC Members)</a><span class="news"><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/welcomelab.htm">Welcome to the SSCC! (For Lab Users)</a></span><br/>
</p>
<h2>What the SSCC Provides</h2>
<p><a href="https://ssc.wisc.edu/sscc/statconsult.htm">Statistical Consulting</a><br/>
<a href="https://ssc.wisc.edu/sscc_jsp/software/">SSCC Software</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/computing_resources.htm">Computing Resources at the SSCC<br/>
</a><a href="https://ssc.wisc.edu/sscc/pubs/disk.htm">Network Disk Space at the SSCC</a></p>
<h2>Your Account</h2>
<p><a href="https://ssc.wisc.edu/sscc_jsp/password/">Change Your Password</a><br/>
<a href="https://ssc.wisc.edu/sscc_jsp/password/reset.jsp">Reset Your Password </a><br/>
<a href="https://ssc.wisc.edu/sscc_jsp/software/"></a> </p>
<h2>Using SSCC Servers</h2>
<p><span class="news"><a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">Using Winstat </a></span><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/silo.htm">Using Silo</a></p>
<h2>Setting Up Your Computer</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/5-24.htm">Setting Up Network Printers in Windows</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/softwarecenter.htm">Installing New Software using Software Center<br/>
</a><a href="https://ssc.wisc.edu/sscc/pubs/printfrommac.htm">Using SSCC Printers from Macs</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/diskfrommac.htm">Using SSCC Network Disk Space from Macs</a></p>
<h2>Remote Access</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/working_from_home.htm">Working From Home and Other Remote Locations<br/>
</a></p>
<h2>Statistical Software</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Stata for Researchers</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_Introduction.html">R for Researchers</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/sfs/">Stata for Students<br/>
</a><a href="https://ssc.wisc.edu/sscc/pubs/spss/classintro/spss_students1.html">SPSS  for the Classroom</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-17.htm">Using	Stat/Transfer</a> </p>
<h2>Policies</h2>
<p>See our <a href="https://ssc.wisc.edu/sscc/policies/home.htm">policies page</a> for a full list, but these are some some of the most
	  		important:</p>
<p><a href="https://ssc.wisc.edu/sscc/policies/desktopsupp.htm">Desktop Support Policy</a><br/>
<a href="https://ssc.wisc.edu/sscc/policies/server_usage.htm">Server Usage Policy</a><br/>
<a href="https://ssc.wisc.edu/sscc/policies/backup.htm">SSCC Data Integrity</a><br/>
<a href="https://ssc.wisc.edu/sscc/policies/privacy.pdf">Privacy Standards for SSCC Staff</a></p>
<!-- #EndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Using NVivo on Winstat</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>For the most part, using NVivo on Winstat is no different from using it on any other computer. (Unfortunately, SSCC staff cannot give general advice on how to use NVivo, though we can sometimes answer specific questions. The SSCC does not have any expertise in qualitative research.) However, there is one setting change that everyone who uses NVivo on Winstat should make.</p>
<p>Click <span class="MenuOutput">File</span>, <span class="MenuOutput">Options</span>, and under the <span class="MenuOutput">General</span> tab change <span class="MenuOutput">Update projects on network drives</span> from <span class="MenuOutput">On close</span> to <span class="MenuOutput">On save</span>.</p>
<table border="0" cellpadding="3" class="noBorder">
<tr>
<td><img align="middle" alt="Choose On save" height="687" src="https://ssc.wisc.edu/sscc/pubs/screenshots/nvivo/nvivo1.png" width="730"/></td>
</tr>
</table>
<p>The problem here is not really Winstat; it's that when using Winstat you save everything on network drives like <span class="MenuOutput">U:</span>. When you open an NVivo project that's saved on a network drive, NVivo makes a copy of the project on your local hard drive and works with the copy rather than the original. If you leave <span class="MenuOutput">Update projects on network drives</span> set to the default of <span class="MenuOutput">On close</span>, then even when you tell NVivo to save your work it only saves it in the local copy. Nothing is saved to the network until you close NVivo. If Nvivo crashes (which it does all too frequently) then all your work is lost even though you thought you were saving it. Veteran NVivo users know that this is a big problem, but setting <span class="MenuOutput">Update projects on network drives</span> to <span class="MenuOutput">On save</span> eliminates it completely.</p>
<p> Unfortunately, due to the way NVivo stores settings there is no way for SSCC staff to change this setting for everyone. If you use NVivo, please take a moment to change it right now. If you work with other NVivo users, and especially if you teach others to use NVivo, please be sure they make this change as well.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/nvivo/nvivo1.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Upgrading to Office 2013 using SSCC's Software Center</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>If your University-owned  PC running Windows 7 or 8 logs in to the SSCC's domain (PRIMO), you can upgrade to Office 2013 very easily using Software Center. This article will show you how.</p>
<p>Click on the Windows logo or <span class="MenuOutput">Start</span> button, <span class="MenuOutput">All Programs</span>, <span class="MenuOutput">Microsoft System Center 2012 R2</span>, <span class="MenuOutput">Configuration Manager</span>, and then <span class="MenuOutput">Software Center</span>. (If Software Center is not available then you cannot use this method.) This will give you a list of software you can install using Software Center. Check the box next to <span class="MenuOutput">Microsoft Office 2013 x86</span> and  click <span class="MenuOutput">Install Selected</span>.</p>
<p><img alt="Software Center" height="418" src="https://ssc.wisc.edu/sscc/pubs/screenshots/office2013/office2013_1.png" width="600"/></p>
<p>Software Center will then install the new version—feel free to use other programs while it does. When the <span class="MenuOutput">STATUS</span> of Office 2013 changes to <span class="MenuOutput">Installed</span> you can close Software Center.</p>
<p>The first time you use Office 2013 you will be asked to activate it. Just choose to activate over the Internet and the process will be completed automatically.</p>
<p>If you have the 64-bit version of Office 2010 (or any 64-bit components) Software Center will not be able to remove them automatically. You can uninstall Office 2010 yourself and then restart Software Center (you may have to press F5 to refresh the list of available programs), or contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a> to have SSCC staff install it for you.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/office2013/office2013_1.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Installing the pbnm Package</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<div id="TOC">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#source-install-from-x-drive">Source install from X drive</a></li>
<li><a href="#source-install-from-internet">Source install from Internet</a></li>
</ul>
</div>
<div class="section level2" id="overview">
<h2>Overview</h2>
<p>The pbnm package is an R package which contains functions to perform a parametric bootstrap. The package supports bootstraps on the coefficients from models constructed using lm, glm, lmer, or glmer functions.</p>
<p>The pbnm package is available as a source package on the SSCC's website. The install procedure for a source package is different than installing a package from CRAN. This article describes how to install the pbnm package.</p>
</div>
<div class="section level2" id="source-install-from-x-drive">
<h2>Source install from X drive</h2>
<p>If you have access to the X drive on the SSCC network, use the following instructions to install pbnm.</p>
<ul>
<li><p>Open a new file explorer window.</p></li>
<li><p>Navigate to the X:\SSCC Tutorials\pbnm\downloads folder.</p></li>
<li><p>Find the most recent version of the .tar.gz file.</p></li>
<li><p>Open R or RStudio.</p></li>
<li><p>Enter the following command in the console window. You will need to replace "pbnm_0.3.0.9001" with the name of the most recent .tar.gz file found in the pbnm\downloads folder.</p>
<p>install.packages("X:/SSCC Tutorials/pbnm/downloads/pbnm_0.3.0.9001.tar.gz", repos=NULL,type="source")</p></li>
<li><p>The pbnm package is finished installing when the following is displayed in the console.</p>
<pre><code>* DONE (pbnm)</code></pre></li>
</ul>
</div>
<div class="section level2" id="source-install-from-internet">
<h2>Source install from Internet</h2>
<p>If you do not have access to the X drive on the SSCC network, use the following instructions to install pbnm.</p>
<ul>
<li><p>Open a browser.</p></li>
<li><p>Navigate to the <a class="uri" href="https://www.ssc.wisc.edu/sscc/pubs/pbnm/downloads/">https://www.ssc.wisc.edu/sscc/pubs/pbnm/downloads/</a>.</p></li>
<li><p>Find the most recent version of the .tar.gz file.</p></li>
<li><p>Click on the file and select the Save File option. Click the Ok button to save the file Save the file to a known folder. On a windows machine this can be your download folder.</p></li>
<li><p>Open R or RStudio.</p></li>
<li><p>Enter the following command in the console window. You will need to replace "pbnm_0.3.0.9001" with the name of the most recent .tar.gz file found in the pbnm\downloads folder. You will need to replace path with the path to the folder that you saved the .tar.gz file to.</p>
<p>install.packages("path/pbnm_0.3.0.9001.tar.gz", repos=NULL,type="source")</p></li>
<li><p>The pbnm package is finished installing when the following is displayed in the console.</p>
<pre><code>* DONE (pbnm)</code></pre></li>
</ul>
<p>Last Revised: 6/24/2016</p>
</div>

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>SSCC - Social Science Computing Cooperative</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Malicious software or "malware" is now a profitable business and today's computers face a wide variety of threats. This article will help you secure your Windows PC against some of the most common threats we're seeing in the summer of 2010. Unfortunately, the threat environment is constantly changing and other steps will no doubt be necessary in the future.</p>
<p>Computers in the Sewell Social Science Building that connect to the SSCC's Windows Domain (PRIMO) are kept secure by SSCC staff. You do not need to update them. However, you should reboot your office PC regularly so the patches we install can be applied. You are responsible for securing your laptop and/or home PC, but SSCC staff will be happy to assist you if you run into problems.</p>
<p>Computers running Mac OS are currently less vulnerable, primarily because it is more profitiable to find ways to compromise Windows PCs. Mac owners should still run <a href="#InstallSymantecEndPointProtection">anti-virus software</a> and keep it and their operating system up-to-date, and take other basic precautions.</p>
<h2><a id="AvoidThreatsontheWeb" name="AvoidThreatsontheWeb"></a>Avoid Threats on the Web</h2>
<p>Some of the most common threats today involve placing malicious code in a Flash file or other media displayed by a browser plugin. The file can be placed on a web site controlled by the hacker, or in a web advertisement to be run on completely legitimate web sites. When the file is viewed, the malicious code takes advantage of flaws in the player to infect the computer.                </p>
<h3>Update Plugins</h3>
<p>Many of these flaws have been fixed, but you need to download and install the latest version of the plugin to be protected. You can check whether you have the latest versions of your plugins by visting Mozilla's <a href="http://www.mozilla.com/en-US/plugincheck/">Plugin Check</a>. This works for all the major web browsers, not just Firefox. If you need to update some of your plugins it will direct you to the appropriate web site.</p>
<h3>Consider Blocking Flash</h3>
<p>Flash is the most frequent vector for plugin-based attacks, and unfortunately it's not unusual for there to be malicious Flash files on the web exploiting flaws that have not yet been corrected. If  you use Mozilla Firefox, you can greatly reduce your exposure to such attacks by installing an Add-on called FlashBlock. It replaces all Flash objects with a "Play" button and only shows the Flash if you click the button. Some people find it makes browsing the web more pleasant as well as more secure.</p>
<p> To install FlashBlock, click <span class="MenuOutput">Tools</span>, <span class="MenuOutput">Add-ons</span>, <span class="MenuOutput">Get Add-ons</span> and then search for FlashBlock.</p>
<h3>Avoid Dubious Web Sites and Downloads</h3>
<p>Hackers often set up web sites offering pirated movies, pornography or other inducements. The real purpose is to infect the computers of visitors. Sometimes you get what you pay for.</p>
<p>Be even more cautious about downloading and installing free programs you find on the web. There are many legitimate and useful free programs available on the web (R comes to mind), but there are others that act as "trojan horses" to install malware.  Searching the web for reviews of any programs you're considering installing is a wise precaution.</p>
<h2><a id="UpdateWindows" name="UpdateWindows"></a>Update Windows</h2>
<p>Malware continues to take advantage of flaws in Windows itself. Thus it's still vital that you keep Windows up-to-date. Windows mostly updates itself now, but you should verify that it is doing so successfully. It's also important to reboot your computer on a regular basis (ideally at the end of each day) so that patches can be applied. Even computers the SSCC secures need to be rebooted so the patches we install can take effect.</p>
<p>To check that Windows is being updated, go to <a href="http://windowsupdate.microsoft.com">windowsupdate.microsoft.com</a> and run the <span class="MenuOutput">Express</span> update. It should not find any "High Priority" updates to install (they should have been installed for you automatically). It should also say <span class="MenuOutput">Automatic Updates: Turned ON</span>.</p>
<p>Windows 7 is significantly more secure than Windows XP. If your computer can run Windows 7, consider upgrading. You can purchase Windows 7 from the <a href="http://wiscsoftware.wisc.edu/wisc/">WISC catalog</a>.</p>
<h2><a id="InstallSymantecEndPointProtection" name="InstallSymantecEndPointProtection"></a>Install Symantec Endpoint Protection</h2>
<p>Anti-virus software is not as effective as it once was, but it is still an important part of keeping your PC secure. The University has purchased a site license for Symantec Endpoint Protection so it is free for all UW faculty, staff and students to install on their computers. You can download it from the <a href="http://www.cio.wisc.edu/security/antivirus.aspx">UW CIO's Security</a> web site.</p>
<h2><a id="ScanYourPC" name="ScanYourPC"></a>Scan Your PC</h2>
<p>There are  many free programs for detecting malware on your PC (plus a few that pretend they will and then actually install malware). Which is best changes rapidly because malware authors find ways to avoid the most popular detection programs.</p>
<p>Right now we suggest using <a href="http://www.malwarebytes.org/">Malwarebytes</a> to scan your PC. It is free and easy to install and use.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Articles on Printing</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>
<!-- #BeginEditable "Content" -->
<p>This page lists articles regarding printing.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/5-24.htm">Setting Up Network Printers	in Windows</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/printfrommac.htm">Using SSCC Printers from Macs</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/7-28.htm">Printing	from Linux</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/printfromlinux.htm">Using SSCC Network  Printers from Personal Linux Computers</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/goprint.htm">Paying for Printing in the SSCC Labs</a> <br/>
</p>
<p> </p>
<!-- #EndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Using SSCC Network Printers from Personal Linux Computers</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>This article will show you how to use the SSCC's network printers from your personal computer running Linux. The details and pictures apply to Ubuntu 10.4, but the general procedure should work on any desktop-oriented Linux distribution.                </p>
<p>Go to <span class="MenuOutput">System</span> -&gt; <span class="MenuOutput">Administration</span> -&gt; <span class="MenuOutput">Printing</span>. Click <span class="MenuOutput">Add</span> to add a new printer.</p>
<p><img alt="Printing screen" height="250" src="https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux1.png" width="450"/></p>
<p> Next expand <span class="MenuOutput">Network Printer</span> and  select <span class="MenuOutput">Windows Printer via Samba</span>.</p>
<p><img alt="Select Device" height="519" src="https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux2.png" width="600"/></p>
<p>Type the name of the printer you want to use in the box under <span class="MenuOutput">SMB Printer</span>.</p>
<table align="center" border="1" cellpadding="3">
<caption align="top">
<a id="Names" name="Names"></a>SSCC Network Printers
                  </caption>
<tr>
<th scope="col">Room</th>
<th scope="col">Printer Name</th>
</tr>
<tr>
<td align="center">4218</td>
<td align="center" class="InputCode">primo/print/sscc4218</td>
</tr>
<tr>
<td align="center">3218</td>
<td align="center" class="InputCode">primo/print/sscc3218</td>
</tr>
<tr>
<td align="center">2470</td>
<td align="center" class="InputCode">primo/print/sscc2470</td>
</tr>
</table>
<p>Select <span class="MenuOutput">Set authentication details now</span> and type your SSCC username and password. If your password contains any special characters (<span class="InputCode">&amp;</span>, <span class="InputCode">@</span>, etc.) type a backslash (<span class="InputCode">\</span>) before that character.</p>
<p><img alt="Enter printer information" height="519" src="https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux3.png" width="600"/></p>
<p>Click <span class="MenuOutput">Verify</span> and your computer will confirm that it can connect with the printer. Then click <span class="MenuOutput">Forward</span> and your computer will search for appropriate printer drivers but fail. Instead type <span class="InputCode">lexmark</span> in the <span class="MenuOutput">Make and model</span> box and click <span class="MenuOutput">Forward</span>.</p>
<p><img alt="Download printer driver by name" height="430" src="https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux6v2.png" width="650"/></p>
<p>Select <span class="MenuOutput">Postscript-Lexmark</span> under <span class="MenuOutput">Downloadable Drivers</span> and and click <span class="MenuOutput">Forward</span> to download and install it.</p>
<p><img alt="Download drivers" height="430" src="https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux6_5.png" width="650"/></p>
<p>Next it will ask you which options to use. Set <span class="MenuOutput">Trays</span> to <span class="MenuOutput">Tray1+2+3</span>. (If you leave it at the default it will only be able to use tray 1, which is the colored paper used for cover sheets.)</p>
<p><img alt="Installable Options" height="434" src="https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux7.png" width="650"/></p>
<p>Give the printer a short name and optional description and location and click <span class="MenuOutput">Apply</span>. Do not print a test page at this time.</p>
<p><img alt="Name the printer" height="434" src="https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux8.png" width="650"/></p>
<p>Before actually using the printer, you need to tell it to use tray 3 rather than tray 1 (which contains colored paper). Right-click on the printer and choose <span class="MenuOutput">Properties</span>, then click <span class="MenuOutput">Printer Options</span> on the left and set  <span class="MenuOutput">Media source</span> to <span class="MenuOutput">Tray 3</span>.</p>
<p><img alt="Printer Properties" height="350" src="https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux10.png" width="629"/></p>
<p>Click <span class="MenuOutput">OK</span> and you're ready to print to the SSCC's printers.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux1.png, https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux2.png, https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux3.png, https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux6v2.png, https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux6_5.png, https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux7.png, https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux8.png, https://ssc.wisc.edu/sscc/pubs/screenshots/printfromlinux/printfromlinux10.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Using SSCC Printers from Macs</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>This article will show you how to use the SSCC's network printers from your  computer running OS X. </p>
<ol>
<li>If you are not plugged into the wired network in the Sewell Social Science Building, you first need to establish a <a href="https://ssc.wisc.edu/sscc/pubs/vpn.htm">VPN connection</a> to the SSCC network.</li>
<li>You'll next need to know the name of the printer you are connecting to. Please see the <a href="https://ssc.wisc.edu/sscc/downloads/download-printer-list.php" target="new" title="List of Printer Names on SSCC">list of printer names</a> to find your printer info. If you need help gathering this information,  speak with the department that hosts the printer or SSCC staff. </li>
<li>Open the <span class="MenuOutput">System Preferences</span> by clicking the Apple icon in the upper left of the screen and choosing <span class="MenuOutput">System Preferences</span></li>
<li>Click <span class="MenuOutput">Printers &amp; Scanners</span></li>
<li>Click the <span class="MenuOutput">+ </span>button on the lower left to add a printer.</li>
<li>If you see an <span class="MenuOutput">Advanced</span> button, skip to step 7. Otherwise, Control-click on the box just above <span class="MenuOutput">More Printers</span>, choose <span class="MenuOutput">Customize Toolbar</span>, drag the <span class="MenuOutput">Advanced</span> icon from this box onto the toolbar and click <span class="MenuOutput">Done</span>.</li>
<img alt="" class="CenterImage" height="482" src="https://ssc.wisc.edu/sscc/pubs/screenshots/printfrommac/10_9_1B_new.jpg" width="547"/>
<li>Click <span class="MenuOutput">Advanced</span></li>
<li>Change the <span class="MenuOutput">Type</span> of the printer to <span class="MenuOutput">Windows</span></li>
<li>Type the <span class="MenuOutput">URL</span>, <span class="MenuOutput">Name </span>and <span class="MenuOutput">Location</span> of the printer you want to use.  The info for the printers in the SSCC labs is as follows:  
                    <table border="1" cellpadding="3">
<tr>
<th>Name</th>
<th>Location</th>
<th>URL</th>
</tr>
<tr>
<td>SSCC4218</td>
<td>Room 4218</td>
<td>smb://print.ads.ssc.wisc.edu/sscc4218</td>
</tr>
<tr>
<td>SSCC3218</td>
<td>Room 3218</td>
<td>smb://print.ads.ssc.wisc.edu/sscc3218</td>
</tr>
<tr>
<td>SSCC2470</td>
<td>Room 2470</td>
<td>smb://print.ads.ssc.wisc.edu/sscc2470 </td>
</tr>
</table>
<img alt="" height="485" src="https://ssc.wisc.edu/sscc/pubs/screenshots/printfrommac/10_9_2B.jpg" width="547"/> <br/>
</li>
<li>Click on<strong>  Choose a Driver...</strong> and then select<strong> Generic PCL Driver</strong>. The generic driver is sufficient for most printers, but if you need access to special features please contact the SSCC Help Desk for assistance in installing drivers specific to your printer. <br/>
</li>
<li>Click <span class="MenuOutput">Add</span>. You may be asked to configure additional available options for your printer, including duplexing and paper handling. </li>
</ol>
<p>The first time you print to the printer you'll be asked for your username and password. Set <span class="MenuOutput">Connect as: </span>to <span class="MenuOutput">Registered User</span>, for your <span class="MenuOutput">Name</span> type your SSCC username and give your SSCC password.  Check <span class="MenuOutput">Remember this password in my keychain</span> and you won't be asked to give it again when you print in the future.</p>
<p><img alt="Giving your username and password" class="CenterImage" height="394" src="https://ssc.wisc.edu/sscc/pubs/screenshots/printfrommac/10_9_3B.jpg" width="576"/></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/printfrommac/10_9_1B_new.jpg, https://ssc.wisc.edu/sscc/pubs/screenshots/printfrommac/10_9_2B.jpg, https://ssc.wisc.edu/sscc/pubs/screenshots/printfrommac/10_9_3B.jpg</img_base_url>
</kb_document>
<kb_document>
<kb_title>Running Python on Linstat</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Python and Jupyter Notebook are available on Linstat. This article will show you how to set them up and use them.</p>
<h2>Setting Up</h2>
<p>Some setting up is required before you can (easily) run Python or Jupyter Notebook. We've created a script that does this for you, so all you need to do is log into Linstat and run:</p>
<p class="InputCode">setup_python</p>
<p>You then need to log out of Linstat and log back in so the new settings can take effect.</p>
<h2>Running Jupyter Notebook</h2>
<p>To run Jupyter Notebook, type:</p>
<p class="InputCode">jupyter notebook</p>
<p>This will first start a local web server that will do the actual work and then start a Chromium web browser (the open source version of Chrome) to interface with it. When you're done using Jupyter Notebook, you need to both close the web browser and shut down the web server. You can close the web browser in the usual way by closing its window. Then close the web server by pressing <span class="InputCode">Ctrl-c</span>. If you started Jupyter in the background or no longer have the session you started it in available, you can shut it down with:</p>
<p class="InputCode">jupyter notebook stop</p>
<p>Jupyter will start in your current working directory. Note that Jupyter can only see files and directories that are underneath the directory that it starts in, so make sure you're in or above the directory you want to work in before you start Jupyter. For example, if you start Jupyter in your home directory (the initial working directory when you log in) it will only be able to see files and directories in your home directory. If you want to work with files in a project directory, <span class="InputCode">cd</span> to that directory before starting Jupyter.</p>
<h2>Running Python Scripts</h2>
<p>You can run a Python script (.py file) by typing:</p>
<p class="InputCode">python <span class="Parameter">myscript</span>.py &amp;</p>
<p>Where <span class="Parameter">myscript</span> should be replaced by the actual name of your script. This will put the job in the background, which means you can do other work with your Linux session or log out completely and your job will continue running. For more information, see <a href="https://ssc.wisc.edu/sscc/pubs/linstat_jobs.htm">Managing Jobs on Linstat</a>.</p>
<h2 class="MenuOutput">Installing Packages</h2>
<p>Python distinguishes between packages that are installed globally (meaning all users of a given computer have access to them) and packages that are installed for a particular user. Linstat has all the packages that are part of the Anaconda distribution installed globally, including pandas, matplotlib, numpy, scipy and many others. Individual users cannot install packages globally, or change packages that were installed globally. However, users can install packages for themselves, including updated versions of globally installed packages.These packages will be stored in your home directory.</p>
<p>Packages should be installed using <span class="InputCode">pip</span>. To install a package for yourself type:</p>
<p class="InputCode">pip install --user <span class="Parameter">packagename</span></p>
<p>where <span class="Parameter">packagename</span> should be replaced by the name of the package you want to install (for example, <span class="InputCode">pip install --user pandas-datareader</span>). </p>
<p>You can install more current versions of globally installed packages with:</p>
<p class="InputCode">pip install --user --upgrade <span class="Parameter">packagename</span></p>
<p>You should only do so, however, if you need the latest version of a package immediately, as packages can take substantial space in your home directory. SSCC staff update the Python installation on Linstat each semester.</p>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Installing Python Packages on Winstat</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>SSCC members who use Python on Winstat are welcome to install any packages they need, but need to be mindful that the Winstat environment is not quite the same as a regular Windows PC.</p>
<p>Python distinguishes between packages that are installed globally (meaning all users of a given computer have access to them) and packages that are installed for a particular user. Winstat has all the packages that are part of the Anaconda distribution installed globally, including pandas, matplotlib, numpy, scipy and many others. Individual users cannot install packages globally, or change packages that were installed globally. However, users can install packages for themselves, including updated versions of globally installed packages. These packages will be stored on your U: drive.</p>
<p>Packages should be installed using <span class="InputCode">pip</span>. (Unfortunately, <span class="InputCode">conda</span> is currently not compatible with Winstat.) You can run <span class="InputCode">pip</span> by first starting the Anaconda Prompt, which you can find under <span class="MenuOutput">Anaconda</span> in the programs list or by typing <span class="InputCode">anaconda</span> in the search box.</p>
<p><img alt="" class="CenterImage" height="113" src="https://ssc.wisc.edu/sscc/pubs/screenshots/python_winstat/anaconda_prompt.PNG" width="251"/></p>
<p>This will give you a command line interface. To install a package for yourself type:</p>
<p class="InputCode">pip install --user <span class="Parameter">packagename</span></p>
<p>where <span class="Parameter">packagename</span> should be replaced by the name of the package you want to install (for example, <span class="InputCode">pip install --user pandas-datareader</span>). The package will be installed in <span class="InputCode">U:\python</span>, which will be created automatically if necessary.</p>
<p>You can install more current versions of globally installed packages with:</p>
<p class="InputCode">pip install --user --upgrade <span class="Parameter">packagename</span></p>
<p>You should only do so, however, if you need the latest version of a package immediately, as packages can take substantial space in your U: drive. SSCC staff update the Python installation on Winstat each semester.<br/>
</p>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/python_winstat/anaconda_prompt.PNG</img_base_url>
</kb_document>
<kb_document>
<kb_title>Installing R on Your Personal Computer</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>R is an open-source statistical package commonly used by statisticians developing new statistical methods. While it is more difficult to learn and use than Stata, SAS or SPSS, some cutting-edge techniques have only been implemented in R.</p>
<p>R is already installed on Winstat, on the SSCC Linux servers and in the SSCC computer labs. But  since R is open-source, you are free to download, install and use R on your computer as well. This article will help you to do so on either a Windows computer or a Mac.                </p>
<h2>Windows</h2>
<p>Go to the <a href="http://cran.r-project.org/bin/windows/base/">R for Windows download page</a>, then click <span class="MenuOutput">Download R </span><span class="Parameter">#.#.#</span><span class="MenuOutput"> for Windows</span>, where  <span class="Parameter">#.#.#</span> will be the version number of the current version. Your browser will then download the file <span class="MenuOutput">r-</span><span class="InputCode">#.#.#</span><span class="MenuOutput">-win32.exe</span>. When the download is complete, double-click on the file to start the installation.</p>
<h2>Mac</h2>
<p>Go to the <a href="http://cran.r-project.org/bin/macosx/">R for Mac OS X download page</a>, then click on <span class="MenuOutput">R-</span><span class="Parameter">#.#.#</span><span class="MenuOutput">.dmg</span> where <span class="Parameter">#.#.#</span> will be the version number of the current version. When that file has finished downloading, double-click on it to start the installation.</p>
<h2>Packages</h2>
<p>If your computer is always connected to the SSCC network, you may want to store your packages on your <span class="MenuOutput">U:</span> drive. Then if you ever want to run R on Winstat or in the SSCC computer labs your packages will already be installed. See <a href="https://ssc.wisc.edu/sscc/pubs/r-packages.htm">Using R Packages on SSCC Computers</a> for instructions.</p>
<h2>Updating R</h2>
<p>To update R, uninstall it and then install the latest version as described above.</p>
<p>If you had R store your packages on the <span class="MenuOutput">U:</span> drive, they'll  be available immediately. Otherwise they are stored with the program and you'll need to move them from the old version's  folder to the new version's. In Windows the default library location is <span class="InputCode">C:\Program Files\R\R-#.#.#\library</span> and it is similar on a Mac. For example, to move packages installed under R 2.9.1 to R 2.9.2, take the  <span class="InputCode">library</span> folder in <span class="InputCode">C:\Program Files\R\R-2.9.1</span> and put it under <span class="InputCode">C:\Program Files\R\R-2.9.2</span>.</p>
<p>This is a good time to make sure your packages are up to date: click <span class="MenuOutput">Packages</span>, <span class="MenuOutput">Update Packages</span>.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Using R Packages on SSCC Linux Servers</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Much of R's utility comes from packages that users have written. Base R comes with some packages, but you may need to install more.                </p>
<h2><a id="InstallingandLoadingPackages" name="InstallingandLoadingPackages"></a>Installing and Loading Packages</h2>
<p>In Windows R, you  install a package by clicking <span class="MenuOutput">Packages</span>, <span class="MenuOutput">Install Package(s)</span>. You'll then be asked the mirror to install from (it makes little difference, but the nearest to Madison is probably <span class="MenuOutput">USA (IA)</span>, located in Iowa) and the package you want to install. You'll get a warning that the program can't modify an HTML file that keeps a list of installed packages, but that won't prevent you from using the package.</p>
<p>In Linux R type:</p>
<p class="InputCode">install.packages("<span class="Parameter">package</span>")</p>
<p>where <span class="Parameter">package</span> should be replaced by the name of the package you want to install. You'll again be asked for the mirror to install from.</p>
<p>To load the package in Windows R, click <span class="MenuOutput">Packages</span>, <span class="MenuOutput">Load Package</span> and then the name of the package you want to load.</p>
<p>In Linux R, type:</p>
<p class="InputCode">library(<span class="Parameter">package</span>)</p>
<p>In future sessions you'll only need to  load the package, not install it again.</p>
<h2><a id="UpdatingPackages" name="UpdatingPackages"></a>Updating Packages</h2>
<p>You should check periodically to see if any of the packages you use have been updated.</p>
<p>In Windows R, click <span class="MenuOutput">Packages</span>, <span class="MenuOutput">Update Packages</span>.</p>
<p> In Linux R, type:</p>
<p class="InputCode">update.packages()</p>
<h2><a id="ManagingPackages" name="ManagingPackages"></a>Managing Packages</h2>
<p>By default, R on SSCC computers puts packages in your home directory (<span class="MenuOutput">U:</span> in Windows or <span class="MenuOutput">~</span> in Linux). If you work with a lot of packages this will clutter  your home directory. You can change where R packages are stored by doing the following:</p>
<h3>Create a Directory                </h3>
<p>First make a directory to store packages. In Windows, create a folder call <span class="InputCode">R_packages</span> on your <span class="MenuOutput">U:</span> drive. In Linux, create a directory called <span class="InputCode">R_packages</span> in your home directory by typing: </p>
<p class="InputCode">mkdir ~/R_packages</p>
<h3>Configure R to Use the Directory</h3>
<p>For Windows R, open a text editor like TextPad or Notepad (not Word). Type:</p>
<p class="InputCode">.libPaths("U:/R_packages")</p>
<p>Note that the slash is a forward slash, not the backslash normally used in Windows. Save the file on your <span class="MenuOutput">U:</span> drive as <span class="InputCode">.Rprofile</span>,  making sure the file name doesn't have <span class="InputCode">.txt</span> at the end.</p>
<p>For Linux R, open your preferred Linux text editor if you have one, or TextPad in Windows. Type</p>
<p class="InputCode">.libPaths("~/R_packages")</p>
<p>then save the file as <span class="InputCode">.Rprofile</span> in your Linux home directory. If you're using TextPad that means you must save it on your<span class="MenuOutput"> Z:</span> drive.</p>
<p>Once this file is created, packages will be saved in the directory <span class="InputCode">R_packages</span> instead of your home directory. If you have  installed packages previously, move them into <span class="InputCode">R_packages</span> or install them again.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata Tools for Reading Data from Web Page</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>A great deal of data can be found in web pages, and "web scraping" is the process of turning those web pages into usable data sets. Stata's capabilities in this area are limited, but SSCC staff have written several programs that can carry out simple web scraping tasks. This article will introduce you to the <span class="InputCode">readhtml</span> package we've developed. You can get it by starting Stata and typing:</p>
<p class="InputCode">net install readhtml, from(https://ssc.wisc.edu/sscc/stata/)</p>
<p>Alternatively, type:</p>
<p class="InputCode">net from https://ssc.wisc.edu/sscc/stata/</p>
<p>Then click on the <span class="MenuOutput">readhtml</span> link and  <span class="MenuOutput">click here to install</span>.</p>
<p>(If you get an error trying to use one of the above commands, try replacing <span class="InputCode">https</span> with <span class="InputCode">http</span>.)</p>
<p>The <span class="InputCode">readhtml</span> package is in the early stages of development, so you should check its results carefully—though if something goes wrong it's usually obvious. If you find it does not work properly for a given web page (keeping in mind it only reads tables and lists) please let us know by emailing <a href="mailto:helpdesk@ssc.wisc.edu">helpdesk@ssc.wisc.edu</a>, but it will never be able to handle every web page. If you need to parse a web page <span class="InputCode">readhtml</span> can't handle, the code for the main programs may give you some ideas for how to do it.</p>
<h2>The readhtml package</h2>
<p>The <span class="InputCode">readhtml</span> package contains two main programs and two utility programs.</p>
<h3>readhtmltable</h3>
<p> The <span class="InputCode">readhtmltable</span> program reads a web page, identifies any tables it contains, and turns them into a data set. Try scraping the SSCC's training schedule with:</p>
<p class="InputCode">readhtmltable https://ssc.wisc.edu/sscc_jsp/training/</p>
<p>You can tell it to use the first row as variable names with:</p>
<p class="InputCode">readhtmltable https://ssc.wisc.edu/sscc_jsp/training/, varnames</p>
<p>The <span class="InputCode">varnames</span> option can be abbreviated to just <span class="InputCode">v</span>. This gives you a usable data set containing the SSCC's training schedule for the current semester.</p>
<h3>readhtmllist</h3>
<p>The <span class="InputCode">readhtmllist</span> program reads a web page, identifies any lists it contains, and turns them into a data set. Try:</p>
<p class="InputCode">readhtmllist https://ssc.wisc.edu/sscc/ssccnews/</p>
<p>This gives you a data set containing all the issues of SSCC News. Note that each year's issues are in a separate list, so <span class="InputCode">readhtmllist</span> created a variable for each list. In this case it might make sense to combine all the lists, but that won't always be true. The <span class="InputCode">readhtmltable</span> program will do something similar if a page contains multiple tables.</p>
<p>If you're interested in the links to the issues as well as their names, you can tell <span class="InputCode">readhtmllist</span> not to remove HTML markup with the <span class="InputCode">html</span> option:</p>
<p class="InputCode">readhtmllist https://ssc.wisc.edu/sscc/ssccnews/, html</p>
<p>Parsing the results and extracting the URL is left to the reader. Note that these are relative links, so to use them you'd have to put <span class="InputCode">https://ssc.wisc.edu/sscc/ssccnews/</span> before each one.</p>
<h3>Utility Programs</h3>
<p>The <span class="InputCode">readhtml</span> package also contains two utility programs which were written for the use of the other programs in the package, but you are welcome to use them independently. The <span class="InputCode">striphtml</span> program removes all HTML markup from a string—the <span class="InputCode">html</span> option tells <span class="InputCode">readhtmltable</span> or <span class="InputCode">readhtmllist</span> <em>not</em> to run <span class="InputCode">striphtml</span>. The <span class="InputCode">striphtmlcomments</span> program removes all HTML comments from a string. The <span class="InputCode">readhtmltable</span> and <span class="InputCode">readhtmllist</span> programs use it to remove content the web page author never meant to be seen, presumably for a reason. For example, the source code for the SSCC training schedule still contains code for some special classes we no longer teach, but they're "commented out" so they're not visible, and you would not want to include them in a data set of SSCC classes.</p>
<p>Acknowledgment: The <span class="InputCode">readhtml</span> package, and the names of the key programs, were inspired by R's <a href="https://cran.r-project.org/web/packages/XML/XML.pdf">XML package</a>.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Open Records and SSCC Email</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Recent events have reminded many SSCC members that their University email is subject to Open Records requests. This article will introduce some of the basic concepts of Open Records law and discuss technical aspects of SSCC email that are relevant to it.</p>
<p> Please keep in mind that SSCC staff are neither records managers nor lawyers. This article  includes links to authoritative sources on Open Records law and how to comply with it; for more information  please refer to <a href="http://archives.library.wisc.edu/records/">UW Records Management</a> or contact the <a href="http://archives.library.wisc.edu/records/contact-recmngt.html">University Records Officer</a>.</p>
<h2>Open Records Law                </h2>
<p>As a public institution, the University of Wisconsin-Madison is subject to Wisconsin's Open Records law. The University has created <a href="http://www.uwsa.edu/gc-off/records/training.htm">training materials</a> to help you understand your obligations under the law and what would need to be released in response to an Open Records request. The following discussion is based on that material.</p>
<h3>What is a Record?</h3>
<p>State law (Chapter 16.61) defines records as "all books, papers, maps, photographs, films, recordings, or other             documentary materials, regardless of their physical form or   characteristics,           produced or received by any state agency or   its officers or employees           in connection with the transaction   of public business." While this definition was written before email was in use, it is very broad and has been held to include email.</p>
<p>If you work for the University, then your job duties are "public business" and information related to your job duties will generally be a public record. "In other words, regardless of how you create or receive the information, if the information is related to your work for the University, and it is memorialized or recorded in any format, then it is a public record." (<a href="http://www.uwex.uwc.edu/admin-services/audit/records/">Public Records Fundamentals</a>) Thus, with certain exceptions, email related to your job duties is a public record. The inverse, that email not related to your job duties is not a public record, is more controversial.</p>
<h3>Record Retention</h3>
<p>Public records must be retained for an appropriate period. The appropriate period depends on the nature and table of the record, and is specified by Records Schedules which have been created by the University Records Officer and approved by the Wisconsin Public Records Board. Most SSCC email will fall under the <a href="http://archives.library.wisc.edu:2784/records/schedules/06.16.2008.UWS.General.Records.Schedule.Business.Communication.FINAL.pdf">Business Communication</a> schedule. It defines two types of business communication: "Routine" and "Transitory."</p>
<p> Routine communication is  substantial, but does not "set forth university policies, guidelines, procedures, or directives." Routine communication should be retained for "six months after a business activity or project is completed."</p>
<p> Transitory communication "has no business value after the information contained in the message has been conveyed or superseded, or the event to which the message is related has occurred." Transitory communication is the kind of thing you would have talked  about in person if email weren't so convenient. The retention instructions for transitory communication are "Retain for seven days or destroy when obsolete because the communication has been superseded or the related event has transpired." (See the <a href="http://archives.library.wisc.edu:2784/records/schedules/06.16.2008.UWS.General.Records.Schedule.Business.Communication.FINAL.pdf">schedule</a> for more details.)</p>
<p>Other records fall under different schedules. For example, the <a href="http://archives.library.wisc.edu:2784/records/schedules/GRS_StudentRec.pdf">Student Records</a> schedule<a href="http://archives.library.wisc.edu:2784/records/schedules/GRS_DeptAcadAdmin.pdf"></a> specifies that "Faculty records of grades given in whatever form" must be retained for five years. For more information see the list of <a href="http://archives.library.wisc.edu:2784/records/rda.html#general-records">General Records Schedules</a>.</p>
<p>Any records that are the subject of an Open Records request must be retained regardless of their regular schedule until the request has been completed.</p>
<h2>Open Records Requests</h2>
<p>If you receive an Open Records request, you should contact the <a href="http://legal.wisc.edu/">Office of Administrative Legal Services</a> (<abbr>OALS</abbr>) for assistance. They will help you determine what should be released. While "[t]he law specifically declares that it is the public policy of this state   that all persons are entitled to the greatest possible information" the law also "identifies certain information that cannot be released." (<a href="http://legal.wisc.edu/reference/public-records.html">OALS Public Records web page</a>) There are exceptions to the definition of a record, legal requirements to protect privacy such as FERPA and HIPAA, and other public interests that must be balanced against the public interest in disclosure. Former Chancellor Biddy Martin said the following on releasing the results of an Open Records request for a faculty member's email:</p>
<p> <em>I announced that the university would comply with the law and, as we   do in all cases, apply the kind of balancing test that the law allows,   taking such things as the rights to privacy and free expression into   account. We have done that analysis and will release the records later   today that we believe are in compliance with state law.</em></p>
<p><em>We are excluding records involving students because they are   protected under FERPA. We are excluding exchanges that fall outside the   realm of the faculty member's job responsibilities and that could be   considered personal pursuant to Wisconsin Supreme Court case law. We are   also excluding what we consider to be the private email exchanges among   scholars that fall within the orbit of academic freedom and all that is   entailed by it. Academic freedom is the freedom to pursue knowledge and   develop lines of argument without fear of reprisal for controversial   findings and without the premature disclosure of those ideas.</em> (<a href="http://www.news.wisc.edu/19190">Chancellor’s message on academic freedom and open records</a>, see Senior University Legal Counsel John Dowling's <a href="http://www.news.wisc.edu/19196">response to the requestor</a> for more details about what was excluded.)</p>
<p>The Wisconsin Supreme Court case law she refers to is almost certainly <a href="http://www.wicourts.gov/sc/opinion/DisplayDocument.pdf?table=pdf&amp;seqNo=52285">Schill vs. Wisconsin Rapids</a> where the Supreme Court ruled 5-2 that the Wisconsin Rapids school district should not release the personal emails  teachers  sent or received using their school district email accounts in response to an open records request. However, it is a complicated decision. Three justices ruled that personal emails on government accounts are not public records, with reasoning similar to that found in the University's training materials. Two ruled that they are public records, but that the public interest in giving employees  privacy overrides the public interest in disclosure. Two justices ruled that personal emails on government accounts are public records and should be disclosed. On the other hand, all parties agreed that there is no duty to retain personal emails.</p>
<h3>Other Legal Requests for Email</h3>
<p>Email can also become evidence in trials or other legal proceedings, and can be subpoenaed or demanded in discovery. In these cases it does not matter whether a given message is a record under Open Records law or not.</p>
<h2>Deleting SSCC Email</h2>
<p>Deleting email   that either is not a record or no longer needs to be retained makes   responding to Open Record requests much easier. Deleting unneeded email also saves disk space and improves email performance. However, selecting a message and pressing Delete does not necessarily make it disappear.</p>
<h3>Deleted Messages and Your Email Program</h3>
<p>Most email programs recognize that people sometimes delete messages by mistake and provide a way to recover deleted messages for a time, for example by moving it to a Trash folder rather than deleting it immediately. However, if a message is available in a Trash folder it must still be produced in response to an Open Records request. Thus you need to be aware of what your email program actually does when you press Delete.</p>
<h4>Thunderbird</h4>
<p>Thunderbird provides several options, which you can see by clicking <span class="MenuOutput">Tools</span>, <span class="MenuOutput">Account Settings</span>, <span class="MenuOutput">Server Settings</span> and looking under <span class="MenuOutput">When I delete a message</span>. The default is <span class="MenuOutput">Move it to this Folder: Trash</span>. SSCC automatically deletes messages from Trash folders after 30 days (see <a href="https://ssc.wisc.edu/sscc/policies/inbox.htm">Email Storage Limitations</a>). You can make sure it is deleted sooner by checking <span class="MenuOutput">Empty Trash on Exit</span>. The next option is <span class="MenuOutput">Just mark it as deleted</span>. If you select it, deleted email is not actually removed  until you "expunge" your Inbox. However, this is what Thunderbird actually does behind the scenes regardless of the setting you choose--the other settings just hide messages that are marked as deleted. <em>Thus it's very important that you leave</em> <span class="MenuOutput">Clean up ("Expunge") Inbox on exit</span> <em>checked or email will never actually be deleted from your Inbox.</em> The third option, <span class="MenuOutput">Remove it immediately</span>, is ideal for mass deletions of old messages where you're reasonably confident you won't change your mind.</p>
<p>Most other email programs provide similar options.</p>
<h4>SSCC Webmail</h4>
<p>By default SSCC Webmail moves messages to your Trash folder when they are deleted, and completely removes them from your Inbox at the same time. You can change this behavior if you want to by clicking <span class="MenuOutput">Settings</span>, <span class="MenuOutput">Server Settings</span>.                </p>
<h3>Deleted Messages and SSCC Backups</h3>
<p>Each night,  all messages on the SSCC email server except those in Trash folders are backed up. These backups are retained for one month and then deleted (the tapes are reused). If someone files an Open Records request for email, email that is available on backups must  be produced even if the original has been deleted. Note that WiscMail (@wisc.edu addresses) and other email providers have very different backup policies.</p>
<h3>Scenarios</h3>
<ul>
<li>You receive an email and delete it. Your email program is set to move deleted email to Trash, and not to delete trash automatically (the defaults). The email is available in your Trash folder for 30 days, and then it is automatically deleted by the SSCC.</li>
<li>You receive an email and delete it. Your email program is set to remove deleted messages immediately. The email is no longer available.</li>
<li>You receive an email and delete it the next day. Because it was on the server when nightly backups were created, it is available for one month from the SSCC backup tapes, and may also be available in your Trash for 30 days.</li>
<li>You receive an email and delete it several weeks, months, or years later. It is available from the SSCC backup tapes for one month from the night before it was deleted, and may also be available in your Trash for 30 days.</li>
</ul>
<p>We emphasize that you should not delete email that constitutes a record that must be retained. If you have any questions about what must be retained, or about Open Records in general, please contact <a href="http://archives.library.wisc.edu/records/">UW Records Management</a>.</p>
<h2>More Information</h2>
<ul>
<li><a href="http://archives.library.wisc.edu/">University Archives and Records Management</a></li>
<li><a href="http://archives.library.wisc.edu/records/resource.html#tutorials">Records Management Tutorials</a></li>
<li><a href="http://www.uwex.uwc.edu/admin-services/audit/records/">Public Records Fundamentals</a></li>
<li><a href="http://www.uwex.uwc.edu/admin-services/audit/businessComm/">Business Communication</a></li>
<li><a href="http://archives.library.wisc.edu:2784/records/rda.html#general-records">Records Schedules</a></li>
<li><a href="http://legal.wisc.edu/reference/public-records.html">OALS Public Records web site</a></li>
<li><a href="http://www.news.wisc.edu/19190">Chancellor’s message on academic freedom and open records</a></li>
<li> <a href="http://www.wicourts.gov/sc/opinion/DisplayDocument.pdf?table=pdf&amp;seqNo=52285">Schill vs. Wisconsin Rapids Decision</a></li>
</ul>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Articles on Remote Computing</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>
<!-- #BeginEditable "Content" -->
<p>This page lists articles dealing with using 
                                the SSCC Computing resources from home or anywhere 
                                else away from campus.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/working_from_home.htm">Working From Home and Other Remote Locations</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">Using Winstat</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/5-2.htm">Connecting to SSCC Linux Computers using X-Win32</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/linstat_from_mac.htm">Connecting to Linstat from a Mac</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/vpn.htm">Connecting to the SSCC Network via VPN</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/5-26.htm">Mapping a Drive to a Network Share in Windows</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/diskfrommac.htm">Using SSCC Network Disk Space from a Mac</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/remote_desktop.htm">Connecting to Your Office Computer Using Remote Desktop (Windows)</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/screen_sharing.htm">Connecting to Your Office Computer Using Screen Sharing (Mac)</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/5-35.htm">Transferring Files Using SecureFX</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/1-11.htm">Using SFTP</a> </p>
<!-- #EndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Connecting to Your Office Computer Using Remote Desktop (Windows)</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Remote Desktop allows you to connect to your office computer from home or another remote location. The result is similar to logging in to Winstat, though Winstat will generally give you better performance and stability. However, if you have software on your office computer that is not available on Winstat, remote desktop will allow you to use that software from home. Macs can also use Remote Desktop to connect to office computers running Windows (Macs connecting to Macs use <a href="https://ssc.wisc.edu/sscc/pubs/screen_sharing.htm">Screen Sharing</a> instead). Connecting to your office computer using Remote Desktop is  a great back-up plan in case you can't log in to Winstat, and we suggest all SSCC members learn how to do so.</p>
<p>If you have a Remote Desktop connection already set up that requires you start VPN before using it, you can modify it so VPN is no longer required. In Windows, open the connection then click on <span class="MenuOutput">Options</span> as described <a href="#add_gateway_win">here</a>. On a Mac, edit your connection and then add a new gateway as described <a href="#add_gateway_mac">here</a>.</p>
<h2>Setting Up Your Office Computer to Allow Remote Desktop</h2>
<p><strong>In order to allow Remote Desktop connections to your office PC, you will need to contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm" target="new" title="SSCC Help Desk">SSCC Help Desk</a> for us to enable this functionality on each of your devices</strong>. </p>
<p>You can simply email the Help Desk with your computer's name and we will enable Remote Desktop for you, no need to set up an office call. </p>
<p>To find your computer name, click <strong>Start</strong> and start typing "name" to search. Open <strong>View Your PC Name</strong> from the menu and look under<strong> Device Specifications</strong> for<strong> Device Name</strong>. The full name of your computer is what you see there plus <span class="InputCode">.ads.ssc.wisc.edu</span> (e.g. <span class="InputCode">damask</span> becomes <span class="InputCode">damask.ads.ssc.wisc.edu</span>). Computer names are not case-sensitive.</p>
<h2>Connecting to Your Office Computer            </h2>
<h3>Windows</h3>
<p>Click the Windows logo button, <span class="MenuOutput">All Programs</span>, <span class="MenuOutput">Accessories</span> and <span class="MenuOutput">Remote Desktop Connection</span>.            </p>
<p> You'll then need to type in the name 
              of your office computer.            </p>
<p><img alt="" height="253" src="https://ssc.wisc.edu/sscc/pubs/screenshots/RDP_Win10.PNG" width="407"/></p>
<p id="add_gateway_win">Select <span class="MenuOutput">Show Options</span> from the lower right hand corner.</p>
<p><img alt="" height="253" src="https://ssc.wisc.edu/sscc/pubs/screenshots/RDG1.jpg" width="407"/></p>
<p>Select the <span class="MenuOutput">Advanced</span> tab, then in the <em>Connect from anywhere</em> section click the <span class="MenuOutput">Settings</span> button.</p>
<p><img alt="" height="474" src="https://ssc.wisc.edu/sscc/pubs/screenshots/RDG2.jpg" width="407"/></p>
<p>Select <span class="MenuOutput">Use these RD Gateway server serttings</span> and in the <span class="MenuOutput">Server name</span> box enter <span class="InputCode">rdg.ssc.wisc.edu</span>. Under <em>Login settings</em>, check the box for <span class="MenuOutput">Use my RD Gateway credentials for the remote computer</span> and click <span class="MenuOutput">OK</span>. </p>
<p><img alt="" height="440" src="https://ssc.wisc.edu/sscc/pubs/screenshots/RDG3.jpg" width="407"/></p>
<p>You are then ready to connect to your remote computer.            </p>
<p>Once you connect, you'll see that the remote connection takes over 
              your screen and you can almost forget that you're not sitting in 
              your office. If you want to go back to using the computer you're 
              connecting from, click on the minimize button in the toolbar across 
              the top of the screen. When you're done, log out of your office computer as usual.</p>
<h3>Mac</h3>
<p>Remote Desktop Connection software can be downloaded and installed for free from the <a href="http://www.apple.com/osx/apps/app-store" target="new" title="Mac App Store">Mac App Store</a>. Once installed, it can be found in the <span class="MenuOutput">Applications</span> folder. </p>
<p id="add_gateway_mac">To set up your connection, click <span class="MenuOutput">New</span> in the upper left hand corner. Enter a name for the connection (ex. "My SSCC Desktop"), and the name of your office computer.  Enter the name of your office computer and your SSCC credentials (using <span class="InputCode">primo\</span><span class="Parameter">username</span> in the <span class="MenuOutput">User Name</span> field). From the <span class="MenuOutput">Gateway</span> dropdown box select <span class="MenuOutput">Add Gateway</span> to open the Gateway Preferences.</p>
<p><img alt="" height="776" src="https://ssc.wisc.edu/sscc/pubs/screenshots/RDG_MacOS.png" width="576"/></p>
<p>To add a new gateway, select <strong>Add Gateway</strong> from the drop down menu. In the <span class="MenuOutput">Gateway Name</span> field enter <span class="MenuOutput">SSCC RDG</span>. In <span class="MenuOutput">Server name</span> enter <span class="InputCode">rdg.ssc.wisc.edu.</span> Choose <strong>Use Desktop User Account</strong> and click <strong>Add</strong>. </p>
<p><img alt="" height="778" src="https://ssc.wisc.edu/sscc/pubs/screenshots/RDG_MacOS_2.png" width="576"/></p>
<p>Select the newly created gateway from the drop down menu and then close the <span class="MenuOutput">Edit Remote Desktops</span> window. You can now select the connection and <span class="MenuOutput">Start</span> to begin your remote desktop session.                </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/RDP_Win10.PNG, https://ssc.wisc.edu/sscc/pubs/screenshots/RDG1.jpg, https://ssc.wisc.edu/sscc/pubs/screenshots/RDG2.jpg, https://ssc.wisc.edu/sscc/pubs/screenshots/RDG3.jpg, https://ssc.wisc.edu/sscc/pubs/screenshots/RDG_MacOS.png, https://ssc.wisc.edu/sscc/pubs/screenshots/RDG_MacOS_2.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Using ResearchDrive</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>ResearchDrive is a University-funded and DoIT-provided data storage system available to all faculty PIs and academic staff with permanent PI status, and their research teams.  Five terabytes of storage is provided on request to each PI, with the option to purchase additional storage at $200 per terabyte per year.</p>
<p> ResearchDrive is secure enough for most research data, but is not appropriate for data covered by HIPAA or other sensitive data. RestrictedDrive is a related service that is secure enough to store sensitive data, but it must be paired with secure computers for analyzing it like those provided by Silo.</p>
<p>ResearchDrive is easy to use: you can map a drive to it just like SSCC network drives, from your own computer or Winstat. Performance is generally comparable to SSCC drives as well. At this point the tools for using ResearchDrive from Linux work on user machines but not servers like Linstat, but DoIT is working on that. </p>
<p>There are two primary advantages of ResearchDrive over SSCC network drives:</p>
<ul>
<li>You don't need an SSCC account to use ResearchDrive, though you do need a UW NetID</li>
<li>ResearchDrive is fully funded by the University, while hardware for data storage is one of SSCC's larger capital costs       </li>
</ul>
<p>However, there are several disadvantages of ResearchDrive compared to SSCC network drives:</p>
<ul>
<li>Users will need to map ResearchDrive, once on each computer they use, rather than it being mapped automatically</li>
<li>PIs must manage permissions on ResearchDrive rather than SSCC staff (some may consider this an advantage)</li>
<li>SSCC staff can provide little support for ResearchDrive; you'll need to work with the <a href="https://kb.wisc.edu/helpdesk/" target="new" title="DoIT Help Desk">DoIT Help Desk</a></li>
<li>ResearchDrive only retains backups of  deleted files for one month, compared to a year for SSCC, and does not retain as many older versions of files</li>
</ul>
<p>Based on these advantages and disadvantages, we would suggest using ResearchDrive for storing data that are not in active use (so you're less likely to need files restored from backup due to user error) or if you need to share files with UW-Madison researchers who don't have SSCC accounts and don't need them.                </p>
<p>For more information on ResearchDrive or to request a drive, please see <a href="https://kb.wisc.edu/researchdata/internal/page.php?id=93998" target="new" title="Getting Started with ResearchDrive">Getting Started with ResearchDrive</a>.</p>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>SAS and Excel Files on Winstat</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>This document explains how to use  Excel files in SAS on Winstat. Over the years, there have been many  versions of Excel, many versions of SAS, and many versions of the operating  systems on which they are used. As a  result the details of reading and writing Excel files in SAS have changed  often. Instructions you find elsewhere may or may not work on Winstat.</p>
<p>                  Some unsolicited advice:  if you have the option, working with files in comma-separated value  format (<em>csv</em>) is much more straightforward than working with Excel files. The relative simplicity of the <em>csv</em> format  means that methods of reading and writing these files are very stable, and it  will be possible to reproduce your work easily regardless of how Excel, SAS,  and Windows may change in the future.</p>
<p>                There are two methods we generally use for reading and  writing Excel files using SAS on Winstat: <span class="InputCode">PROC IMPORT</span> (and <span class="InputCode">PROC EXPORT</span>), and <em>libnames</em>. <span class="InputCode">PROC IMPORT</span> is what you use  when you use the Import Wizard, and is excellent for one-time file conversions. <em>Libnames</em> allow you to write data steps that access Excel files directly.</p>
<ul>
<li><a href="#PROCIMPORT">PROC IMPORT (and PROC EXPORT)</a></li>
<li><a href="#_LIBNAME_xxx_PCFILES">LIBNAMES</a></li>
</ul>
<h2><a id="PROCIMPORT" name="PROCIMPORT"></a>PROC IMPORT (and PROC EXPORT)</h2>
<p><span class="InputCode">PROC IMPORT</span> (and <span class="InputCode">PROC EXPORT</span>) can be used either by writing your own procedure code or by calling on the Import Wizard.</p>
<h3><a id="_Procedure_Code" name="_Procedure_Code"></a>Procedure Code</h3>
<p>The key to getting <span class="InputCode">PROC IMPORT</span> and <span class="InputCode">PROC EXPORT</span> to work  properly on Winstat is to choose the correct <span class="InputCode">DBMS=</span> option. The preferred <span class="InputCode">DBMS</span> is <span class="InputCode">EXCELCS</span>. For example:</p>
<p class="InputCode">PROC IMPORT OUT= class <br/>
<span class="indent3">DATAFILE= "<span class="Parameter">myfile.xls</span>" </span><br/>
<span class="indent3">DBMS=EXCELCS REPLACE;</span><br/>
<span class="indent3">RANGE="Data$"; </span><br/>
<span class="indent3">SCANTEXT=YES;</span><br/>
<span class="indent3">USEDATE=YES;</span><br/>
<span class="indent3">SCANTIME=YES;</span><br/>
   RUN;</p>
<p><span class="Parameter"><span class="Parameter">myfile.xls</span></span> should be replaced by the actual name of your Excel file, most likely including its location (e.g. <span class="InputCode">u:\myfolder\myfile.xls</span>). This works for both <span class="Parameter">xls</span> and <span class="Parameter">xlsx</span> files.</p>
<p>Specifications that do NOT work in current (64-bit) SAS are: EXCEL, EXCEL97, EXCEL2000, EXCEL2002,  EXCEL2003, EXCEL2007, or EXCEL2010. Two  other specifications that work, but have always had limited functionality, are:  XLS, and XLSX.</p>
<p>For more information, click <span class="MenuOutput">Help</span>, <span class="MenuOutput">SAS Help and Documentation</span> and go to the <span class="MenuOutput">Contents</span> tab. Then expand <span class="MenuOutput">SAS Products</span>, <span class="MenuOutput">SAS/Access 9.3</span>, <span class="MenuOutput">SAS/Access 9.3 Interface to PC Files: Reference</span>, and <span class="MenuOutput">Import and Export Wizards and Procedures</span>.</p>
<h3><a id="_Import_Wizard" name="_Import_Wizard"></a>Import Wizard</h3>
<p>To use the Import wizard, click <span class="MenuOutput">File</span>, <span class="MenuOutput">Import Data</span>. The key to using it successfully, just like when writing procedure code, is to choose the correct data source  option. Although the default option is  <span class="MenuOutput">Microsoft Excel Workbook (*.xls, *.xlsb, *.xlsm, *.xlsx)</span>, this does NOT work on Winstat. Instead, choose  <span class="MenuOutput">Microsoft Excel Workbook on PC Files Server</span>.<br/>
<img border="0" height="328" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sas_excel/clip_image001.jpg" width="516"/></p>
<h2><a id="_LIBNAME_xxx_PCFILES" name="_LIBNAME_xxx_PCFILES"></a>LIBNAMES</h2>
<p>Using <em>libnames</em> to access data in Excel spreadsheets is a  relatively new feature of SAS. The <em>libname</em> specification that works in SAS on Winstat is:</p>
<p class="InputCode">LIBNAME <span class="Parameter">myxls</span> PCFILES 
                    PATH='<span class="Parameter">myfile.xls</span>'; </p>
<p><span class="Parameter">myfile.xls</span> should be replaced by the actual name of your Excel file, most likely including its location (e.g. <span class="InputCode">u:\myfolder\myfile.xls</span>). This works for both <span class="Parameter">xls</span> and <span class="Parameter">xlsx</span> files. <span class="Parameter">myxls</span> can be replaced by any name you choose.</p>
<p>Accessing an Excel file via a <em>libname</em> treats the  file as if it were a folder or  directory, and then allows you to address individual worksheets or named ranges  within the file as if they were SAS data sets.</p>
<p>                There is one further detail to which you need to pay  attention. Worksheets in Excel are  identified to SAS with a dollar sign in their names, e.g. <span class="InputCode">Data$</span>. In order for SAS to interpret data sets names containing  characters it does not normally allow, you need to enclose the worksheet name  in quotes and then add a trailing <span class="InputCode">n</span>, like this:</p>
<p class="InputCode">data temp;<br/>
<span class="indent3">set myxls.'Data$'n;</span><br/>
<span class="indent3">bmi=(weight/height**2)*703;</span><br/>
                run; <br/>
</p>
<p>To read a named range, address it as if it were a SAS data  set (no quotes needed), like this:</p>
<p class="InputCode">data temp;<br/>
<span class="indent3">set myxls.range1;</span><br/>
<span class="indent3">bmi=(weight/height**2)*703;</span><br/>
run;</p>
<p>When writing data sets to an Excel file, both a spreadsheet  and a named range are created, regardless of which you specify.</p>
<p class="InputCode">data myxls.'test'n;<br/>
<span class="indent3">set temp;</span><br/>
                run;</p>
<p>                  In the SAS explorer, worksheets and named ranges appear as  SAS data sets.</p>
<p><img border="0" height="314" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sas_excel/clip_image002.jpg" width="263"/><img border="0" height="188" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sas_excel/clip_image003.jpg" width="262"/><br/>
                One final thing to note is that you will not be able to open  the Excel file outside of SAS until you clear the LIBNAME.</p>
<p class="InputCode">                  libname myxls clear;</p>
<p>For more information, click <span class="MenuOutput">Help</span>, <span class="MenuOutput">SAS Help and Documentation</span> and go to the <span class="MenuOutput">Contents</span> tab. Then expand <span class="MenuOutput">SAS Products</span>, <span class="MenuOutput">SAS/Access 9.3</span>, <span class="MenuOutput">SAS/Access 9.3 Interface to PC Files: Reference</span> and <span class="MenuOutput">LIBNAME  PCFILES Engine and PC Files Server on Microsoft Windows</span>.</p>
<p></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/sas_excel/clip_image001.jpg, https://ssc.wisc.edu/sscc/pubs/screenshots/sas_excel/clip_image002.jpg, https://ssc.wisc.edu/sscc/pubs/screenshots/sas_excel/clip_image003.jpg</img_base_url>
</kb_document>
<kb_document>
<kb_title>Launching SAS Files from Windows Explorer</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Most SAS files can be opened directly from  Windows  Explorer (aka the “Computer” icon on your Winstat desktop), either by  double-clicking, or by right-clicking and selecting an action from the pop-up  context menu. However, SAS has many components, and as a result the context menu has many options. This article will explain what those options mean.</p>
<p>One advantage of launching SAS files in this way rather than starting SAS by itself is that the working directory is automatically set to the location of the file. A possible disadvantage is that if you have written an <span class="InputCode">autoexec.sas</span> file it will not be run (unless you choose Batch Submit).</p>
<p>It's possible to change what SAS does when you double-click on a SAS file, but we don't recommend you do so. It's very complicated, and it's very difficult to undo mistakes!</p>
<h2>Launching Program Files</h2>
<p>When you double-click on a SAS program file (any file with  the extension <span class="InputCode">.sas</span>), it opens in the classic SAS interface (also known as the  SAS Display Manager) in the usual Editor window (the Enhanced Editor) using 64-bit SAS.                </p>
<p>If you right-click on a SAS program file, you'll get the following context menu:</p>
<p><img alt="Context menu for SAS programs" height="418" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sas_launch/sas_launch_1.jpg" width="322"/></p>
<table border="1" cellpadding="5" cellspacing="0">
<tr>
<th valign="top">Menu Item</th>
<th valign="top">Action</th>
</tr>
<tr>
<td class="MenuOutput" valign="top">Open</td>
<td valign="top">Opens the program in the Enhanced Editor (same as double-click)</td>
</tr>
<tr>
<td class="MenuOutput" valign="top">Batch Submit with SAS 64 Bit</td>
<td valign="top">Runs the program as a batch job after running <span class="InputCode">autoexec.sas</span>. Any output is saved as files.</td>
</tr>
<tr>
<td class="MenuOutput" valign="top">Open with SAS Enterprise Guide</td>
<td valign="top">Open the program as a Program object in SAS Enterprise Guide</td>
</tr>
<tr>
<td class="MenuOutput" valign="top">Open with SAS 32 Bit</td>
<td valign="top">Opens the program in the Enhanced Editor using 32-bit SAS</td>
</tr>
<tr>
<td class="MenuOutput" valign="top">Print</td>
<td valign="top">Prints the program to your default printer.</td>
</tr>
<tr>
<td class="MenuOutput" valign="top">Submit with SAS 9.3</td>
<td valign="top">Opens the program in the Program Editor, and runs it. Output appears in regular SAS windows.</td>
</tr>
</table>
<h2>Launching Data Files</h2>
<p>Double-clicking on a SAS data file (a file with the  extension <span class="InputCode">.sas7bdat</span>) opens it in the Display Manager interface in a Viewtable  window. However, if the data set has variables that are formatted with user-defined formats, SAS will not be able to find those formats and will refuse to open the data set.</p>
<p>                  If your data set has user-defined formats, you have two  options:</p>
<ol>
<li>Launch SAS from the Start  button, tell SAS where to find the formats using either <span class="InputCode">libname library</span> or <span class="InputCode">options fmtsearch</span>, then open the data set either from the SAS  Explorer or the Windows Explorer.</li>
<li>Launch the data set in SAS Enterprise  Guide from the context menu.  Enterprise  Guide will strip the user-defined formats out of your data set.</li>
</ol>
<p>If you right-click on a SAS data file, you'll get the following context menu:</p>
<p><img alt="Context menu for a SAS data set" height="365" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sas_launch/sas_launch_2.jpg" width="321"/></p>
<table border="1" cellpadding="5" cellspacing="0">
<tr>
<th valign="top"><p> </p>
<p>Menu item</p></th>
<th valign="top">Action</th>
</tr>
<tr>
<td class="MenuOutput" valign="top">Open</td>
<td valign="top">Opens the data set in a Viewtable—fails if it has user-defined formats (same as double-click)</td>
</tr>
<tr>
<td class="MenuOutput" valign="top">Open with SAS Enterprise Guide</td>
<td valign="top">Open the data set as a Data object—ignores user-defined formats</td>
</tr>
<tr>
<td class="MenuOutput" valign="top">Open with SAS 32 bit</td>
<td valign="top">Opens the data set in a Viewtable—fails if there are user-defined formats. Uses 32-bit SAS.</td>
</tr>
<tr>
<td class="MenuOutput" valign="top">Print</td>
<td valign="top">Prints the entire data set to your default printer—fails if there are user-defined formats</td>
</tr>
</table>
<h2>Launching Output Files</h2>
<p>SAS “list” output files (files with the extension <span class="InputCode">.lst</span>)  are text files that can be opened with any suitable text editor or word  processor.  This is the default form of  output for SAS batch submissions, and is the  form of output that the SAS Display Manager produces the most quickly (although the slower html output is now the  default).  A downside of these list output files is  that they are produced with SAS fonts, and often look awful in other programs.  However, they remain a staple of “draft”  quality output. To view these files using SAS fonts, it is convenient to  open them in the SAS Display Manager.</p>
<p>                  Double-clicking on a SAS output file opens it in a Preview  window in the Display Manager.</p>
<p>If you right-click on a SAS output file, you'll get the following context menu:</p>
<p><img alt="Context menu for SAS output files" height="345" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sas_launch/sas_launch_3.jpg" width="320"/></p>
<table border="1" cellpadding="05" cellspacing="0">
<tr>
<th valign="top">Menu item</th>
<th valign="top">Action</th>
</tr>
<tr>
<td class="MenuOutput" valign="top">Open</td>
<td valign="top">Opens the file in Preview window, uses SAS fonts (same as double-click)</td>
</tr>
<tr>
<td class="MenuOutput" valign="top">Open with SAS Enterprise Guide</td>
<td valign="top">Open the file as a Text object, does NOT use SAS fonts</td>
</tr>
<tr>
<td class="MenuOutput" valign="top">Open with SAS 32 bit</td>
<td valign="top">Opens the file in Preview window, uses SAS fonts. Uses 32-bt SAS</td>
</tr>
<tr>
<td class="MenuOutput" valign="top">Print</td>
<td valign="top">Prints the output file from SAS to your default printer</td>
</tr>
</table>
<p> </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/sas_launch/sas_launch_1.jpg, https://ssc.wisc.edu/sscc/pubs/screenshots/sas_launch/sas_launch_2.jpg, https://ssc.wisc.edu/sscc/pubs/screenshots/sas_launch/sas_launch_3.jpg</img_base_url>
</kb_document>
<kb_document>
<kb_title>Managing Output in SAS 9.3</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>SAS makes it possible to save your statistical tables and  graphs in many different forms, including text (ASCII) files, rich text (RTF or  Word) files, PDF files, Excel tables, LaTeX files, HTML (web page) files, and  for graphics a variety of graphics file formats.  You can save your results to some of these  output destinations using the SAS Display Manager, the standard graphical user  interface.  All of these output  destinations can be reached via SAS commands as well.</p>
<p>                  If you are primarily interested in saving your tables and  graphs in a Word file, skip ahead to the “RTF Output” section.</p>
<ul>
<li><a href="#_New_Default_Output">New Default Output Settings</a></li>
<li><a href="#_How_do_I">How do I get my old defaults back?</a></li>
<li><a href="#_HTML_Output_Style">HTML Output Style</a></li>
<li><a href="#_HTML_(&amp;_Graphics)">HTML (&amp; Graphics) File  Locations</a></li>
<li><a href="#_RTF_Output">RTF Output</a></li>
<li><a href="#_Combining_Log_and">Combining Log and Listing  Output</a></li>
</ul>
<h2><a href="#_New_Default_Output"></a><a href="#_Combining_Log_and"></a><a id="_New_Default_Output" name="_New_Default_Output"></a>New Default Output Settings</h2>
<p>In  version 9.3 or later of SAS, the default form of  output  changed from text (“Listing” output in SAS jargon) to HTML.  Additionally, ODS graphics is now on by  default, where previously it was off.</p>
<p>                  There are two main advantages to HTML output.  First, you get statistical tables and graphs  all integrated into one output stream.   (This is also an advantage of RTF or PDF output.)  Second, it makes it easy to cut-and-paste  selected tables from SAS to Word without having to worry as much about  formatting and using SAS monospace fonts in Word (also an advantage of RTF  output). An advantage of using ODS graphics is that a good graphic  can help you more quickly understand your data.</p>
<p>  A disadvantage of ODS graphics is that creating all those graphics may slow down the  execution of your SAS job. If your job creates large amounts of output, even HTML output can slow the job significantly.</p>
<h2><a id="_How_do_I" name="_How_do_I"></a>How do I get my old defaults back?</h2>
<p>There are two good ways to get Listing output and turn off HTML  output and ODS graphics.  One is to  change your SAS registry settings (i.e. the things you get by clicking <span class="MenuOutput">Tools</span>, <span class="MenuOutput">Options</span>), the other is to put several commands in an  autoexec file.  Both will work every time  you start a new SAS session, so you only need to make this change once.</p>
<p>                  Registry settings have the advantage that they are set  through SAS’s menus and dialog boxes, so you don’t need to learn any new  code.  Autoexec files have the advantage  that they are capable of executing any type of SAS command, and they are more likely to successfully carry over to a new version of SAS.</p>
<h3>SAS Registry Settings</h3>
<p>To change your registry settings to the old defaults, click  on  <span class="MenuOutput">Tools</span>,  <span class="MenuOutput">Options</span>, <span class="MenuOutput">Preferences</span>, and then the <span class="MenuOutput">Results</span> tab.</p>
<p>                  Check <span class="MenuOutput">Create listing</span>, and uncheck both <span class="MenuOutput">Create HTML</span> and  <span class="MenuOutput">Use ODS Graphics</span>.  Click <span class="MenuOutput">OK</span>.<br/>
                  You will notice that it is possible to have both Listing and  HTML output at the same time, although it is hard to image how that would be  useful most of the time.  There are a  couple of other, useful settings that are discussed below.</p>
<p> If you use both 64-bit and 32-bit versions of SAS, you will  need to make these changes once for each version.  (Your settings for 32-bit SAS are saved in  your <span class="InputCode">U:\SAS</span> folder.  For 64-bit SAS  they are in your <span class="InputCode">U:\SAS64</span> folder.)</p>
<p><img alt="SAS preferences changed to the old defaults" border="0" height="374" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sas_output_1.jpg" width="469"/><br/>
</p>
<h3>Autoexec.sas commands</h3>
<p>You can put commands you want to run at the beginning of every  SAS session in a file named <span class="InputCode">autoexec.sas</span> in the root folder of your <span class="InputCode">U:\</span>  drive or in the SAS startup folder.  For  32-bit SAS the SAS startup folder is <span class="InputCode">U:\SAS</span>, for 64-bit SAS it is <span class="InputCode">U:\SAS64</span>.  These are otherwise just ordinary SAS command  files.  (If you use the appropriate startup  folders you may have a different <span class="InputCode">autoexec.sas</span> for each version.)</p>
<p>                  A set of three commands will return you to the old output  defaults:</p>
<p class="InputCode">                  ods listing;<br/>
                  ods html close;<br/>
                  ods graphics off;</p>
<p>                  (As with SAS registry settings, there are a number of other configurations  you could consider here.)</p>
<h2><a id="_HTML_Output_Style" name="_HTML_Output_Style"></a>HTML Output Style</h2>
<p>If you are using HTML output, there are at least two reasons  you might consider changing the default style of HTML output from <span class="InputCode">htmlblue</span> to  something else. First, if you are simply cutting-and-pasting a few tables from  your results to a Word document, you lose all the internal table lines, the  cell borders.  (The color scheme  shouldn't concern you too much if you cut-and-paste, because the color does not  paste into Word.)   Second, if you are  saving complete files of HTML output and editing them in some other software  like Word, the blue color scheme will then carry over into your final document.</p>
<p>                  You can change the output style either via the registry  (Click <span class="MenuOutput">Tools</span>, <span class="MenuOutput">Options</span>, <span class="MenuOutput">Preferences</span>, <span class="MenuOutput">Results</span>) or your autoexec.sas file.  Two styles you might consider are <span class="InputCode">minimal</span> and <span class="InputCode">journal</span>.</p>
<p class="InputCode">                  ods html  style=minimal;</p>
<h2><a id="_HTML_(&amp;_Graphics)" name="_HTML_(&amp;_Graphics)"></a>HTML (&amp; Graphics) File Locations</h2>
<p>By default your HTML and ODS graphics files are saved in  your temporary WORK library, and are deleted when you close your SAS session.  As with Listing output, the Log, and the  Program Editor, you can save your HTML results through the menus:  <span class="MenuOutput">File</span>, <span class="MenuOutput">Save As</span>.  You can save your HTML output either as an  archive (a single file) or as regular HTML (which may be a collection of files  if you have any graphics).</p>
<p>                  You can also automatically save your HTML output to a  permanent location, either through registry settings or through autoexec code:</p>
<p class="InputCode">                  ods html  path='u:\' body='sashtml.htm' style=journal;</p>
<p>                  Note, however, that the settings or code above will  overwrite any existing file(s) with the same name(s) when you start a new SAS  session: using <span class="MenuOutput">File,</span> <span class="MenuOutput">Save As</span> is a safer practice for most of us.</p>
<h2><a id="_RTF_Output" name="_RTF_Output"></a>RTF Output</h2>
<p>If you are interested in using your results in a Word  document, why not just save them in a Word-friendly format to begin with?</p>
<p>                  As you would expect by now, there are two ways to get your  results into an RTF document: via the display manager interface, or via ods  commands.  However, in the case of RTF  output these produce quite different documents, and most people will prefer the  RTF documents produced by ods commands.</p>
<p>                  To save an RTF file using the menus, first note that you can  only save Listing output (from the Output window).  You cannot save HTML output or graphics this  way.  With the Output window active,  select <span class="MenuOutput">File, </span><span class="MenuOutput">Save As</span>,  then change the file type to RTF, and save your  file.</p>
<p>                  The resulting document is essentially a text file that has  been formatted with SAS monospace fonts.   Tables are not really tables, they are drawn with font characters, and  if you try to use this document on a computer that does not have SAS installed,  the document will look awful.<br/>
</p>
<p>The better way to save RTF files is through the pair of ODS  commands:</p>
<p class="InputCode">                  ods rtf file='u:\example.rtf'  style=journal;<br/>
<br/>
                  /* your SAS PROCs go here */<br/>
<br/>
                ods rtf close;</p>
<p>                  The resulting document has tables that can be edited as  tables in Word (so changing font face, size, or spacing does not misalign your  table), and uses a Times Roman font.</p>
<h2><a id="_Combining_Log_and" name="_Combining_Log_and"></a>Combining Log and Listing Output</h2>
<p>When you are trying to debug a lengthy SAS command file,  sometimes it is useful to have both the SAS code and the results it produces in  one output stream (like in Stata or SPSS), so that you can see which output  table matches just which PROC.</p>
<p>                  To do this, you must have Listing output turned on, and  redirect your output as well as your log to a file.</p>
<p class="InputCode">                  ods listing;<br/>
                  proc printto print='u:\singlefile.txt’  log=’u:\singlefile.txt';<br/>
                run;<br/>
<br/>
                /* your SAS PROCs go here */<br/>
<br/>
                  proc printto; /*Send your output and  log back to their default windows */<br/>
                  run;</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/sas_output_1.jpg</img_base_url>
</kb_document>
<kb_document>
<kb_title>Connecting to Your Office Computer Using Screen Sharing (Mac)</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Screen Sharing allows you to connect to your office Mac using another Mac from home or another remote location. The result is similar to logging in to Winstat, though Winstat will generally give you better performance and stability. However, if you have software on your office computer that is not available on Winstat, Screen Sharing will allow you to use that software from home. Connecting to your office computer using Screen Sharing is also a great back-up plan in case you can't log in to Winstat, and we suggest all SSCC Mac users learn how to do so.</p>
<p>If your office computer runs Windows, you can connect to it from a Mac using <a href="https://ssc.wisc.edu/sscc/pubs/remote_desktop.htm">Remote Desktop</a>.</p>
<h2>Setting Up Your Office Computer to Allow Screen Sharing</h2>
<p>The first step is to set up your office computer so it will share its screen. Go to <span class="MenuOutput">Apple</span>, <span class="MenuOutput">System Preferences</span>, <span class="MenuOutput">Sharing</span> and check <span class="MenuOutput">Screen Sharing</span>. While you're here, note the address you'll use to connect to your Mac (it will start with <span class="InputCode">vnc://</span>).</p>
<h2>Connecting to your Office Computer</h2>
<p>In order to connect to an SSCC computer using Screen Sharing, you must first establish a VPN 
              connection to the SSCC network. Otherwise your attempts to connect 
              will be blocked by the SSCC's firewall. <a href="https://ssc.wisc.edu/sscc/pubs/vpn.htm">Connecting 
              to the SSCC Network via VPN</a> has full instructions. </p>
<p>Once VPN is set up, start the VPN connection. Then open the <span class="MenuOutput">Finder</span> and click <span class="MenuOutput">Go</span>, <span class="MenuOutput">Connect to Server</span> (or <kbd>⌘ command</kbd>+<kbd>K</kbd>). In the <span class="MenuOutput">Server Address</span> box, type the address of your office Mac and click <span class="MenuOutput">Connect</span>. Click the plus sign (<span class="MenuOutput">+</span>) to save the connection in your <span class="MenuOutput">Favorite Servers</span>.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Researchers: Combining Data Sets </kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This is part eight of the Stata for Researchers series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Introduction</a>. If you're new to Stata we highly recommend reading the articles in order.</em> </p>
<p>Combining two data sets is a common data management task, and one that's very easy to carry out. However, it's also very easy to get wrong. Before combining data sets be sure you understand the structure of both data sets and the logic of the way you're combining them. Otherwise you can end up with a data set that you think is ready for analysis, but is really utter nonsense. Stata tries to make sure you've thought through what you're doing, but can't tell you what makes sense and what doesn't.</p>
<p>Stata always works with one data set at a time, so you will always be combining 
	the data set in memory (the master data set) with another data set on disk 
	(called the using data set, for reasons that will be clear when you see the syntax).</p>
<h2><a id="AppendingDataSets" name="AppendingDataSets"></a>Appending Data Sets</h2>
<p><img alt="When appending, data sets are stacked." height="288" src="https://ssc.wisc.edu/sscc/pubs/screenshots/5-10/5-10_1.png" width="432"/></p>
<p>Stata calls it appending  when you  add the observations 
                  from the using data set to the master data set. Appending makes sense when the observations in both data sets represent the same kind of thing, but not the same things. For example, you might append a data set of people from Wisconsin to a data set of people from Illinois. The data sets should have the same or mostly the same variables, with the same names. If a variable only appears in one data set, observations from the other data set will be given missing values for that variable.</p>
<p>The syntax is to carry out an append is simple: load the the master data set and then type:</p>
<p class="InputCode">append using <span class="Parameter">dataset</span></p>
<p>where <span class="Parameter"><span class="InputCode">dataset</span></span> is the name of the data set you want to append.</p>
<h2><a id="MergingDataSets" name="MergingDataSets"></a>Merging Data Sets</h2>
<h3><img alt="When merging, data sets are placed side by side." height="432" src="https://ssc.wisc.edu/sscc/pubs/screenshots/5-10/5-10_2.png" width="432"/></h3>
<p>Stata calls it merging when observations from the two data sets are combined. There are, in theory, four kinds of merges:</p>
<p>In a one-to-one merge, one observation from the master data set is combined with one observation from the using data set. A one-to-one merge makes sense when the observations in both data sets describe the same things, but have different information about them. For example, you might merge the answers people gave in wave one of a survey with the answers the same people gave in wave two of the survey.</p>
<p>In a one-to-many or many-to-one merge, one observation from one data set is combined with many observations from the other (the difference between one-to-many and many-to-one being whether the master data set has the "many" or the using data set). These merges make sense when you have hierarchical data, and one data set contains information about the level one units while the other contains information about the level two units. For example, you might merge information about households with information about the individuals who live in those households.</p>
<p>In principle there are also many-to-many merges. In practice they are rarely if ever useful. If you find yourself wanting to do a many-to-many merge, you should rethink what you're doing. Often what you really need to do is identify and correct duplicate identifiers, and then your merge will work as one-to-one or one-to-many.</p>
<p>In all the merges we'll discuss, Stata combines observations that have the same value of a key variable, typically an ID. You can also match based on multiple variables (e.g. combine data for the same state and year). In a one-to-many or many-to-one merge, it is the identifier for the level two units that is the key variable (e.g. household ID, not individual ID). It's very important that the key variable have the same format in both data sets.</p>
<p>If an observation in one data set does not match with an observation in the other, it will be given missing values for the variables from the other data set. Since the viability of a research project often depends on how many observations actually merge (e.g. how many people from wave one of the survey could  be found in wave two?) Stata gives you tools for figuring out how many observations actually merged and for examining those that didn't.</p>
<p>If a variable exists in both data sets, the values from the master data set will be kept and the values from the using data set will be discarded. Occasionally this is what you want, but it's more likely to be an error. In general you should set up your data such that the only variables the files to be merged have in common are the key variables.</p>
<p>The syntax for a merge is:</p>
<p class="InputCode">merge <span class="Parameter">type</span> <span class="Parameter">keyvars</span> using <span class="Parameter">dataset</span></p>
<p>The  <span class="Parameter">type</span> must be  <span class="InputCode">1:1</span> (one-to-one), <span class="InputCode">1:m</span> (one-to many), <span class="InputCode">m:1</span> (many-to-one) or <span class="InputCode">m:m</span> (many to many); <span class="Parameter">keyvars</span> is the key variable or variables; and <span class="InputCode">dataset</span> is the name of the data set you want to merge.</p>
<h2><a id="AnExampleofCombiningDataSets" name="AnExampleofCombiningDataSets"></a>An Example of Combining Data Sets</h2>
<p>The examples include several files containing fictional student information from 2007. <span class="InputCode">scores.dta</span> contains the students' scores on a standardized test, <span class="InputCode">demographics.dta</span> contains demographic information about them, and <span class="InputCode">teachers.dta</span> contains information on their teachers. Take a moment to look at each file, then start a do file that loads <span class="InputCode">scores</span>.</p>
<p>In this data set, each observation represents a student. <span class="InputCode">browse</span> and you'll see that you have a student ID (<span class="InputCode">id</span>), a teacher ID (<span class="InputCode">teacher</span>) and a <span class="InputCode">score</span> for each.</p>
<p>Your first task is to add in the demographic information. In <span class="InputCode">demographics.dta</span> each observation also represents a student, with the variables being <span class="InputCode">id</span> and  <span class="InputCode">race</span>. Thus this is a job for a one-to-one merge and the key variable is <span class="InputCode">id</span>.</p>
<p class="InputCode">merge 1:1 id using demographics</p>
<p>Stata will report that all 60 observations matched. It will also create a variable called <span class="InputCode">_merge</span>. A one in <span class="InputCode">_merge</span> means an observation only came from the master data set; a two means it only came from the using data set; and a three means an observation successfully matched and thus came from both. In this case we see that all observations matched and thus have <span class="InputCode">_merge</span> equal to three, so there's no need to keep the variable. In fact we need to drop it (or rename it) before doing any further merges:</p>
<p class="InputCode">drop _merge</p>
<p>Next add  information about teachers. In <span class="InputCode">teachers.dta</span> each observation represents a teacher, and each teacher has many students. That makes this a many-to-one merge (since the many students are currently in memory and the one teacher is in the using data set). The key variable is not <span class="InputCode">id</span>, since that refers to the students, but <span class="InputCode">teacher</span>:</p>
<p class="InputCode">merge m:1 teacher using teachers</p>
<p>Again, all 60 observations merged properly, so you can drop <span class="InputCode">_merge</span>.</p>
<p class="InputCode">drop _merge</p>
<h2><a id="CombiningPanelData" name="CombiningPanelData"></a>Combining Panel Data</h2>
<p>Now suppose you were tracking these students for multiple years. The data set <span class="InputCode">panel2007.dta</span> contains a simplified version of this data set: just <span class="InputCode">id</span> and <span class="InputCode">score</span>. The data set <span class="InputCode">panel2008.dta</span> has the same variables for a different year. How would you combine them?</p>
<p>The proper way to combine them depends on what data structure you want. This is hierarchical data where a level two unit is a student and a level one unit is a student's data for a particular year. Thus it can be represented in wide form (one observation per student), or in long form (one observation per student per year).</p>
<p>To put the data in long form simply stack the two data sets using <span class="InputCode">append</span>. However, you'll need to know which year each observation represents. To do that,  add a <span class="InputCode">year</span> variable to both data set, with the value 2007 for the 2007 data and the value 2008 for the 2008 data. You can do so with the following do file:</p>
<p class="InputCode">clear all<br/>
  set more off<br/>
  capture log close<br/>
  log using combine1.log, replace<br/>
<br/>
  use panel2007<br/>
  gen year=2007<br/>
  save panel2007_append<br/>
<br/>
  use panel2008<br/>
  gen year=2008<br/>
<br/>
  append using panel2007_append<br/>
  save appendedData,replace
  <br/>
<br/>
  log close
</p>
<p>To put the data in wide form,  do a one-to-one merge with <span class="InputCode">id</span> as the key variable. But first you need to change the variable names. Recall that in wide form, it is the variable names that tell you which level one unit you're talking about. So instead of <span class="InputCode">score</span>, you need <span class="InputCode">score2007</span> and <span class="InputCode">score2008</span>.</p>
<p class="InputCode">clear all<br/>
set more off<br/>
capture log close<br/>
log using combine2.log, replace<br/>
<br/>
  use panel2007<br/>
rename score score2007<br/>
save panel2007_merge<br/>
<br/>
use panel2008<br/>
rename score score2008<br/>
<br/>
merge 1:1 id using panel2007_merge<br/>
save mergedData,replace
<br/>
<br/>
log close
</p>
<p>This time you'll see that one observation does not match. You can see which one by typing:</p>
<p class="InputCode">l if _merge==2</p>
<p>Student number 55 was not in <span class="InputCode">panel2008</span> and thus couldn't be matched. As a result we have no idea what his or her test score was in 2008. Unfortunately this is very common—students move out of school districts between tests all the time.</p>
<p>If your entire research agenda depends on having both test scores, you may need to drop observations that don't exist in both data sets. You can do so at this point by adding:</p>
<p class="InputCode">drop if _merge!=3</p>
<p>You can also specify which observations should be kept directly in the merge command:</p>
<p class="InputCode">merge 1:1 id using panel2007_merge, keep(match)</p>
<p><span class="InputCode">keep(match)</span> means only keep observations which match. The alternatives are <span class="InputCode">master</span> and <span class="InputCode">using</span>, and you can list more than one. For example, to keep observations which match and observations that only come from the master data set, while throwing away observations that only come from the using data set, you'd say <span class="InputCode">keep(master match)</span>.</p>
<h2><a id="CommonProblemswithMerges" name="CommonProblemswithMerges"></a>Common Problems with Merges</h2>
<p>Merges will uncover all sorts of problems with your data set (and if they're not fixed merging will introduce new ones). Here are a two common ones and how to fix them:</p>
<h3>Key Variables Stored in Different Formats</h3>
<p>While Stata will happily match different kinds of numbers (ints and floats, for example) it can't match numbers and strings. IDs can be stored as either (as long as you choose a numeric type that has enough precision—see <a href="https://ssc.wisc.edu/sscc/pubs/sfr-data.htm#VariableTypesandPrecision">Working with Data</a>) and it's not uncommon to find that your data sets store the ID in different ways. In that case it's usually best to convert the numbers to strings:</p>
<p class="InputCode">gen idString=string(id)<br/>
  drop id<br/>
  rename idString id</p>
<p>The <span class="InputCode">string()</span> function takes a number and converts it to a string. You can give it a second argument containing the format in which the number should be "written" if needed.</p>
<h3><a id="DuplicateIDs" name="DuplicateIDs"></a>Duplicate IDs</h3>
<p>If you try to do a merge and you get an error message like "variable id does not uniquely identify observations in the master data" this means you have duplicate IDs in the data set mentioned. This problem needs to be fixed before you proceed. Do not simply change the type of merge for the relevant data set from "one" to "many" hoping to make the error message go away—the resulting data set will not make sense for the affected observations.</p>
<p>One possible source of duplicates is round-off error due to saving the IDs in an inappropriate variable type. In this case you'll need to go back to the original data and ensure the identifiers are stored as a type that won't round them, like long, double, or string.</p>
<p>Note that for purposes of merging, missing values are treated just like any other value. If you have observations with missing IDs Stata will count them as duplicates. You'll probably have to drop them before merging.</p>
<p>But most of the time duplicate IDs result from errors in the data. You'll need to do something about them before you can perform your merge.</p>
<p>Start a do file that loads the data set <span class="InputCode">merge_error</span>. This data set contains students, but some of them have duplicate IDs that need to be fixed.</p>
<p>You can see how many problems you have with <span class="InputCode">duplicates report</span>:</p>
<p class="InputCode">duplicates report id</p>
<p>This  tells you how many observations have the same value of <span class="InputCode">id</span>. The output tells you that no ID appears more than twice, but twelve observations have duplicate IDs.</p>
<p>For further examination,  create a variable that tells you how many copies there are of each ID:</p>
<p class="InputCode">bysort id: gen copies=_N</p>
<p>Then you can look at just the problem observations with:</p>
<p class="InputCode">browse if copies&gt;1</p>
<p>For the observations with <span class="InputCode">id</span> equal to 9, 26, and 33, the two observations with the same ID are identical. This suggests the same student was entered twice and you can fix the problem by simply dropping the extra observations. Do so with:</p>
<p class="InputCode">duplicates drop</p>
<p>Note that unlike the <span class="InputCode">duplicates report</span> command you ran earlier, this command does not have a varlist. This means it only drops duplicate observations if they have the same value for all variables, not just <span class="InputCode">id</span>. You can give it a <em>varlist</em> so it drops observations if only those variables have the same values, but be very careful doing so.</p>
<p>At this point in  complex problems you may want to drop the <span class="InputCode">copies</span> variable you created earlier and recreate it so <span class="InputCode">browse if copies&gt;1</span> will no longer show the observations you have already fixed, but there's no need in this data set.</p>
<p>For the observations with <span class="InputCode">id</span> equal to 64, 74, and 94, the other variables show that the observations with the same ID are not the same person. This is a major problem for merging: you can't be sure which "student #64" in this data set goes with the "student #64" in the hypothetical other data set.</p>
<p>Adding more variables may help. For example, in this case, merging by both <span class="InputCode">id</span> and <span class="InputCode">race</span> would  allow you to correctly match the two subjects with id equal to 94. Merging by <span class="InputCode">id</span>, <span class="InputCode">race</span>, and <span class="InputCode">grade</span> would  allow you to correctly match the subjects with id equal to 74. Just keep in mind that if the data set you wanted to merge with this one were for the subsequent school year like in our previous example you'd have to subtract one from its <span class="InputCode">grade</span> variable first. If you choose to go this route, recreate the <span class="InputCode">copies</span> variable using the complete set of variables you plan to match by in the <em>by</em> prefix and see how many duplicates are left.</p>
<p>Nothing will help with the two observations with <span class="InputCode">id</span> equal to 64, and in a larger data set it's less likely that matching by a few more variables will allow you to uniquely identify subjects. In such cases you'll probably need to drop all the observations you can't uniquely identify, since you reliably can't match any them. You can do so with:</p>
<p class="InputCode">drop if copies&gt;1</p>
<h2>Exercises</h2>
<ol>
<li>An alternative way to combine data sets into wide form is to first append them and then reshape. Combine <span class="InputCode">panel2007</span> and <span class="InputCode">panel2008</span> into wide form using this method. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_combine1.htm">Solution</a>)</li>
<li>If you combine the two years of data into long form using <span class="InputCode">append</span>, how can you find the observation  which doesn't appear in 2008? (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_combine2.htm">Solution</a>)</li>
<li>Combine <span class="InputCode">error2007.dta</span> and <span class="InputCode">error2008.dta</span> by merging it into the wide form, fixing whatever problems you find. Then append the two data sets and try to locate the same problems. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_combine3.htm">Solution</a>)</li>
</ol>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-graphics.htm">Graphics</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-hier.htm">Hierarchical Data</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/5-10/5-10_1.png, https://ssc.wisc.edu/sscc/pubs/screenshots/5-10/5-10_2.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Researchers: Working With Data</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This is part four of the Stata for Researchers series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Introduction</a>. If you're new to Stata we highly recommend reading the articles in order.</em></p>
<p>Now that you understand Stata's basic syntax, you're ready to start working with your data. This article will teach you how to make new variables, modify existing variables, and create labels.</p>
<h2><a id="GenerateandReplace" name="GenerateandReplace"></a>Generate and Replace</h2>
<p>The basic commands for creating and changing variables are <span class="InputCode">generate</span> (usually abbreviated <span class="InputCode">gen</span>) and <span class="InputCode">replace</span> (which, like other commands that can destroy information, has no abbreviation). <span class="InputCode">gen</span> creates new variables; <span class="InputCode">replace</span> changes the values of existing variables. Their core syntax  is identical:</p>
<p class="InputCode">gen <span class="Parameter">variable</span>=<span class="Parameter">expression</span></p>
<p>or</p>
<p class="InputCode">replace <span class="Parameter">variable</span>=<span class="Parameter">expression</span></p>
<p>where <span class="Parameter">variable</span> is the name of the variable you want to create or change, and <span class="Parameter">expression</span> is the mathematical expression whose result you want to put in it. Expressions can be as simple as a single number or involve all sorts of complicated functions. Stata has a large library of functions you can use in <span class="InputCode">gen</span> and <span class="InputCode">replace</span> expressions, far too many for us to cover them all (though we'll introduce some as we go). For a full list, type <span class="InputCode">help functions</span>—we'll talk about learning from the help files in  <a href="https://ssc.wisc.edu/sscc/pubs/sfr-learning.htm">Learning More</a>.</p>
<p>If an expression includes a missing value at any point, the result is missing. Usually this is exactly what you'd expect and want.</p>
<p>You should never change data interactively, so before proceeding create a do file. Open the do file editor (type <span class="InputCode">doedit</span> or click on the button that looks like a pencil writing in a notebook). Immediately click <span class="MenuOutput">File</span>, <span class="MenuOutput">Save as...</span> and save the do file as <span class="InputCode">data1</span> (Stata will fill in <span class="InputCode">.do</span> at the end). Then start your do file with the following commands, as described in the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-do.htm">previous section</a>:</p>
<p class="InputCode">clear all<br/>
                  capture log close<br/>
                  set more off<br/>
                  log using data.log, replace<br/>
<br/>
                  use auto<br/>
<br/>
                  //real work goes here<br/>
<br/>
                  save autoVersion2,replace
                  <br/>
                  log close
                </p>
<p>Now you're ready to go to work. The work itself will go after <span class="InputCode">use auto</span> and before <span class="InputCode">log close</span>.</p>
<p>The prices in the auto data set are in 1978 dollars, so it might be useful to convert them to 2019 dollars. To do so you need to multiply the prices by a conversion factor which is the CPI in 2019 divided by the CPI in 1978, or about 4. The code will be:</p>
<p class="InputCode">gen price2019=price*4</p>
<p>You can now compare them with:</p>
<p class="InputCode">l make price*</p>
<p>Add these lines to your do file, then click the Do button on the far right (the one that looks like sheet of paper with a little "play" symbol in the corner) or press <span class="InputCode">Ctrl-d</span>. Switch to the main Stata window to see the results.</p>
<p>But let's be a little more precise and use 4.03 as the conversion factor. Go back to the do file and change the line:</p>
<p class="InputCode">gen price2019=price*4</p>
<p>to:</p>
<p class="InputCode">gen price2019=price*4.03</p>
<p>and run the do file again. The do file starts by clearing the previous data set from memory and loading the original from disk, so there's no need to "fix" the old version of <span class="InputCode">price2019</span>. It's simply created again the way we now want it.</p>
<p>Having both  <span class="InputCode">price</span> and a <span class="InputCode">price2019</span> variables allowed us to compare their values and check for plausibility. But if you only want to work with 2019 dollars and are confident you've got the formula right, you can use the <span class="InputCode">replace</span> command to change the existing <span class="InputCode">price</span> variable instead of creating a new one:                </p>
<p class="InputCode">replace price=price*4.03</p>
<p>Run this version and you'll get the message <span class="MenuOutput">(74 real changes made)</span>. Given that the data set has 74 observations, this tells us all of them were changed as we'd expect. Once you start including <em>if</em> conditions, how many observations were actually changed can be very useful information.</p>
<p>If a <span class="InputCode">gen</span> command has an <em>if</em> condition, the resulting variable will (and must) still exist for all observations. However it will be assigned a missing value for observations where the <em>if</em> condition is not true. If a <span class="InputCode">replace</span> command has an <em>if</em> condition, observations where the <em>if</em> condition is not true will be left unchanged.</p>
<p>Suppose you wanted to collapse the five-point scale of the <span class="InputCode">rep78</span> variable  into a three-point
            	scale. Add the following code to your do file to do so:</p>
<p class="InputCode">gen rep3=1 if rep78&lt;3<br/>
                  replace rep3=2 if rep78==3<br/>
                  replace rep3=3 if rep78&gt;3 &amp; rep78&lt;.</p>
<p>The first line creates the new variable <span class="InputCode">rep3</span>, but only sets it to one
                  for cases where <span class="InputCode">rep78</span> is less
                  than             	 three. The
                  others get missing. The second line changes some of those missings
                  to twos, and the third changes more
                  of them to threes. Note how the third line specifically excludes
                  observations where <span class="InputCode">rep78</span> is
                  missing. What will the value of <span class="InputCode">rep3</span> be for those cases? Missing,  because it was never
                  set to anything else. Observations where <span class="InputCode">rep78</span> is missing were implicitly or explicitly excluded from all three commands. (If you forgot to exclude missing values from the last command, then <span class="InputCode">rep3</span> would be three for cars where <span class="InputCode">rep78</span> is missing, an all-too-common mistake.)</p>
<h2><a id="Recode" name="Recode"></a>Recode</h2>
<p>The <span class="InputCode">recode</span> command gives you an alternative way of creating <span class="InputCode">rep3</span>. It is designed solely for recoding tasks and is much less flexible than <span class="InputCode">gen</span> and <span class="InputCode">replace</span>. In fact, anything <span class="InputCode">recode</span> can do can also be done with <span class="InputCode">gen</span> and <span class="InputCode">replace</span>, so learning it is optional. But it can do some things more easily. The syntax is:</p>
<p class="InputCode">recode <span class="Parameter">var</span> (<span class="Parameter">rule 1</span>) (<span class="Parameter">rule 2</span>) (<span class="Parameter">more rules as needed...</span>), gen(<span class="Parameter">newvar</span>)</p>
<p>The <span class="InputCode">gen</span> option at the end is not required—if it's not there then the original variable will be changed rather than creating a new variable with the new values. You can also have <span class="InputCode">recode</span> work on a list of variables, recoding them all in the same way.</p>
<p>The core of the recode command is a list of rules, in parentheses, that tell it how a variable is to be recoded. They take the form <span class="InputCode">(</span><span class="Parameter">inputValue</span><span class="InputCode">=</span><span class="Parameter">outputValue</span><span class="InputCode">)</span>. The <span class="Parameter">inputValue</span> can be a single number, a list of numbers, or a range of numbers specified with <span class="Parameter">start</span>/<span class="Parameter">end</span>. <span class="Parameter">outputValue</span> will always be a single number. Anything not covered by a rule is left unchanged. Here's a <span class="InputCode">recode</span> version of converting <span class="InputCode">rep78</span> to a three-point scale:</p>
<p class="InputCode">recode rep78 (1 2=1) (3=2) (4/5=3), gen(rep3b)</p>
<p> (The only reason for listing 1 and 2 but giving a range for 4 through 5 was to demonstrate both styles.)  Missing values required no special handling: since  missing was not listed in the input values of any rule, observations with missing values remain unchanged.</p>
<p>If you did everything correctly, rep3 and rep3b will be identical. Check that with an assert:</p>
<p class="InputCode">assert rep3==rep3b</p>
<p>Run the do file to find out how you did.</p>
<h2><a id="CreatingIndicatorVariables" name="CreatingIndicatorVariables"></a>Creating Indicator Variables</h2>
<p>In creating indicator variables, you can take advantage of the fact that Stata treats true as one and false as zero by setting a variable equal to a condition. Consider:</p>
<p class="InputCode">gen gasGuzzler=(mpg&lt;20)</p>
<p>(The parentheses are optional, but make it easier to read.) This creates an indicator variable called <span class="InputCode">gasGuzzler</span> which is one (true) for cars where <span class="InputCode">mpg</span> is less than twenty and zero (false) where <span class="InputCode">mpg</span> is greater than or equal to twenty. You can see the effect with:</p>
<p class="InputCode">l make mpg if gasGuzzler</p>
<p>We know that no car has a missing value for <span class="InputCode">mpg</span> but, if any did, the above code would assign it a zero for <span class="InputCode">gasGuzzler</span> as if it were known to have good gas mileage. <span class="InputCode">gasGuzzler</span> should be missing for such cases, which you can do with:</p>
<p class="InputCode">gen gasGuzzler=(mpg&lt;20) if mpg&lt;.</p>
<h2><a id="Egen" name="Egen"></a>Egen</h2>
<p>The <span class="InputCode">egen</span> command, short for <em>extended
                  generate</em>, gives you access to another library of functions—type <span class="InputCode">help egen</span> for a full list.  <span class="InputCode">egen</span> functions tend to be more complex, and often work across observations.</p>
<p>Suppose you wanted to find the mean value of <span class="InputCode">mpg</span> and store it in a variable. <span class="InputCode">egen</span> has
                  a <span class="InputCode">mean</span> function which will give you
                  exactly what you want: </p>
<p class="InputCode">egen meanMPG=mean(mpg)<br/>
</p>
<p>The <span class="InputCode">mean()</span> function finds the mean of a column. To find the mean of a row, or, more likely, part of a row,  use <span class="InputCode">rowmean()</span>:</p>
<p class="InputCode">egen rm=rowmean(mpg rep78)</p>
<p>For each car, <span class="InputCode">rm</span> will contain the mean of that car's <span class="InputCode">mpg</span> and <span class="InputCode">rep78</span>, not that that's likely to be a useful quantity. A more typical use of <span class="InputCode">rowmean()</span> is to construct a respondent's mean response to a group of questions.</p>
<p></p>
<p>The <span class="InputCode">egen</span> functions generally handle missing values by calculating their result across whatever data are available. Thus for observations where <span class="InputCode">rep78</span> is missing, <span class="InputCode">rm</span> is just <span class="InputCode">mpg</span>. Most of the time that's what you want: if you have 10,000 observations and 1 of them has a missing value you wouldn't want Stata to tell you it's impossible to calculate a mean. However, it can be problematic: if you use <span class="InputCode">rowmean()</span> to calculate mean responses to a group of questions but some people didn't answer all the questions, the result will be the same as if you had filled in all the missing values with the mean—a very bad idea.</p>
<p>With <span class="InputCode">egen</span>, what follows the equals sign is a single function and not a mathematical expression. If you wanted to set a variable to one-half of a mean you'd have to first use <span class="InputCode">egen</span> to calculate the mean and then use a <span class="InputCode">replace</span> command to divide it by 2.</p>
<p>Here are a few of the most commonly used functions in the egen library:</p>
<table border="1">
<tr>
<th>Name</th>
<th>Description</th>
</tr>
<tr>
<td>min()</td>
<td>Minimum value</td>
</tr>
<tr>
<td>max()</td>
<td>Maximum value</td>
</tr>
<tr>
<td>mean()</td>
<td>Mean</td>
</tr>
<tr>
<td>median()</td>
<td>Median</td>
</tr>
<tr>
<td>sd()</td>
<td>Standard Deviation</td>
</tr>
<tr>
<td>total()</td>
<td>Total</td>
</tr>
</table>
<p>All of these functions act across observations. The parentheses will usually contain a single variable for the function to act on, but can contain a mathematical expression instead. These functions also have row equivalents (<span class="InputCode">rowmin</span>, <span class="InputCode">rowmax</span>, etc.) that do the same thing but across variables on a single row. There are plenty of other useful egen functions, such as <span class="InputCode">std</span> (create a standardized version of a variable), <span class="InputCode">group</span> (create a group identifier based on the values of one or more categorical variables), or even <span class="InputCode">mtr</span> (marginal tax rate for a married couple in the US with a given amount of income in a given year). You can get a complete list by typing <span class="InputCode">help egen</span>, and you should plan on reading through it some time early in your Stata career.</p>
<h2><a id="DropandKeep" name="DropandKeep"></a>Drop and Keep</h2>
<p>The <span class="InputCode">drop</span> command allows you to remove either variables or observations from your data set. If you give it a <em>varlist</em>, it will remove those variables:</p>
<p class="InputCode">drop rep3b</p>
<p>removes the variable <span class="InputCode">rep3b</span>  from your data set.</p>
<p>If you give it an <em>if</em> condition, <span class="InputCode">drop</span> will remove all observations where that condition is true:</p>
<p class="InputCode">drop if gasGuzzler</p>
<p>The <span class="InputCode">keep</span> command works in the same way, but in the opposite sense. <span class="InputCode">keep rep3b</span> would remove all variables except <span class="InputCode">rep3b</span>, while <span class="InputCode">keep if gasGuzzler</span> would remove all observations that are not gas guzzlers.</p>
<h2><a id="Rename" name="Rename"></a>Rename</h2>
<p>You can rename a variable by typing:</p>
<p class="InputCode">rename <span class="Parameter">oldName</span> <span class="Parameter">newName</span></p>
<p>Renaming variables with gibberish names (<span class="InputCode">H2V06</span> and the like) may take a bit of time, but will save you time in the end.</p>
<p>Variable names must be one word with no spaces. However, you can use either capital letters or underscores (_) to mark word boundaries. A variable name like <span class="InputCode">numinhh</span> looks like gibberish, but if you put it in the form <span class="InputCode">numInHH</span> or <span class="InputCode">num_in_hh</span> then the reader has a fighting chance of realizing it means "number in household."</p>
<p>The rename command also has the ability to rename large numbers of variables based on patterns. Type <span class="InputCode">help rename</span> for more information.</p>
<p>The variable name <span class="InputCode">rep3</span> doesn't convey much information, so let's change it:</p>
<p class="InputCode">rename rep3 repairRecord</p>
<p></p>
<h2><a id="Labels" name="Labels"></a>Labels</h2>
<p>Labels allow you to convey more information about your data. You only have to type them once, so they can be as long
                  as you want. Labels can be applied to variables or to their values (or entire data sets, which we won't discuss).</p>
<p>This data set already has a good set of variable labels, as you can see in the Variables window. The only one that might be confusing is the label on <span class="InputCode">foreign</span>, so we'll change it using the <span class="InputCode">label variable</span> command. The syntax to set a variable label is: </p>
<p class="InputCode">label variable <span class="Parameter">var "</span><span class="Parameter">label"</span></p>
<p>So type:</p>
<p class="InputCode">label variable foreign "Car Origin"</p>
<p>Look at the Variables window again to see the results.</p>
<p> Next let's explore value labels by labeling the values of the <span class="InputCode">repairRecord</span> (formerly known as <span class="InputCode">rep3</span>, the new variable we recoded to collapse <span class="InputCode">rep78</span> from a five point scale to a three point scale). Value labels
                  are a mapping from a set of integers to a set of descriptions, so the first step is to create the map. To do so, use the <span class="InputCode">label define</span> command: </p>
<p class="InputCode">label define <span class="Parameter">mapName</span> <span class="Parameter"> value1</span> <span class="Parameter">"label1</span>" <span class="Parameter">value2</span> "<span class="Parameter">label2</span>"...</p>
<p>Thus:</p>
<p class="InputCode">label define rep 1 "Bad" 2"Average" 3"Good"</p>
<p>Then  tell Stata to label the values of the <span class="InputCode">repairRecord</span> variable
                  using the <span class="InputCode">rep</span> mapping you just
                  defined. The syntax  is:</p>
<p class="InputCode">label values <span class="Parameter">variable</span> <span class="Parameter">map</span></p>
<p>And thus:</p>
<p class="InputCode">label values repairRecord rep</p>
<p>To see the results, add:</p>
<p class="InputCode">list repairRecord</p>
<p>Once a map is defined you can apply it to any number of variables: just replace the single variable in the  <span class="InputCode">label values</span> command above with a list of variables. Suppose you're working with survey data
                  and your variables include the gender of the respondent, the
                  gender of the respondent's spouse, and the genders of all the
                  respondent's children. You could define just one map called <span class="InputCode">gender</span> and
                  then use it to label the values of all the gender variables.</p>
<p>Two final 
                  commands for value labels: <span class="InputCode">label dir</span> gives you a list of all the defined labels, and <span class="InputCode">label
                list</span> tells you what they mean.</p>
<h2><a id="VariableTypesandPrecision" name="VariableTypesandPrecision"></a>Variable Types and Precision</h2>
<p>Stata can store numbers in five different types of variables. <span class="InputCode">byte</span>, <span class="InputCode">int</span> and <span class="InputCode">long</span> are all integers of various sizes. The smallest, <span class="InputCode">byte</span>, can only store numbers below 100 but takes up very little memory, making it ideal for indicator and categorical variables. <span class="InputCode">int</span> can store numbers up to about 32,000 and <span class="InputCode">long</span> up to about two billion. For numbers with fractions, your choices are <span class="InputCode">float</span> (the default) and <span class="InputCode">double</span>. Both can store very large numbers, but their precision is limited: a <span class="InputCode">float</span> only has about seven digits of accuracy and a <span class="InputCode">double</span> sixteen. For details type <span class="InputCode">help data_types</span>.</p>
<p>While social scientists rarely have seven meaningful digits in their data, keep in mind that identifiers are just big numbers as far as Stata is concerned. For example, you probably think of your UW ID as a string of ten small integers ("nine, zero, two...") but to Stata it's a single, very large number. If you tried to store UW IDs as the default <span class="InputCode">float</span>, they'd be rounded since a <span class="InputCode">float</span> can't store ten digits accurately (which would defeat the purpose of storing an ID). Such IDs should be stored using <span class="InputCode">doubles</span>, <span class="InputCode">longs</span> or <span class="InputCode">strings</span>.</p>
<p>The type of a variable is set when it is created. To create a variable that is not a float, put the desired type right after <span class="InputCode">gen</span> or <span class="InputCode">egen</span> and before the variable name:</p>
<p class="InputCode">gen byte highMPG=(mpg&gt;25)</p>
<p>If you declare that a variable is an integer (<span class="InputCode">byte</span>, <span class="InputCode">int</span> or <span class="InputCode">long</span>) but the expression you set it equal to contains fractions, the fractional part will be truncated, not rounded. There is also a <span class="InputCode">round()</span> function if you need it.</p>
<p>Much of the time it's not worth worrying about finding the most efficient numeric types for your variables. However, if your data set is large, using small types like <span class="InputCode">byte</span> where possible can save a lot of memory and disk space. The <span class="InputCode">compress</span> command will look for variables that can be stored in smaller types without losing precision, and  will change them automatically. </p>
<h2><a id="Strings" name="Strings"></a>Strings</h2>
<p>Strings are variables that contain text rather than numeric values. It's quite possible for that text to be made up of numbers, but Stata will not try to evaluate them. You can recognize a string because it will have quotes around it:</p>
<p class="InputCode">gen x1="123"</p>
<p>makes <span class="InputCode">x1</span> a string, and is completely different from</p>
<p class="InputCode">gen x2=123</p>
<p>For example, you can't add x1 and x2. You can write <span class="InputCode">if x1=="123"</span> and even <span class="InputCode">if x1&gt;"123"</span> but the latter will be evaluated according to alphabetical order, not numeric. </p>
<p>Stata noticed that you were setting <span class="InputCode">x1</span> equal to a string, and thus made <span class="InputCode">x1</span> a string variable automatically.  However:</p>
<p class="InputCode">replace x1=123</p>
<p>or</p>
<p class="InputCode">replace x2="123"</p>
<p>will not work because you can't change a variable from string to numeric or vice versa—but you can make it look like you did.</p>
<h3><a id="ChangingtheTypeofaVariable" name="ChangingtheTypeofaVariable"></a>Changing the Type of a Variable</h3>
<p>Suppose you needed to do some math with the numbers contained in <span class="InputCode">x1</span>. Right now you can't, because <span class="InputCode">x1</span> is a string. Here's how you can change that:</p>
<p class="InputCode">gen temp=real(x1)<br/>
                  drop x1<br/>
                  rename temp x1</p>
<p>The <span class="InputCode">real()</span> function takes one argument, a string, and returns that string converted to a number. If the string contains anything but numbers <span class="InputCode">real()</span> will return missing. Having stored the numbers in <span class="InputCode">x1</span> as <span class="InputCode">temp</span>, you then drop <span class="InputCode">x1</span> and make <span class="InputCode">temp</span> the new <span class="InputCode">x1</span>. <span class="InputCode">x1</span> is now a numeric variable. You can turn numeric variables into strings using the same process—just replace the <span class="InputCode">real()</span> function with the <span class="InputCode">string()</span> function.                </p>
<h2>Exercises</h2>
<p>For the exercises that use the automobile data set, make sure your do file loads the original data set.</p>
<ol>
<li>Using the automobile data set, suppose the cost of manufacturing a car is the sum of the following:
                    
                    <ul>
<li>$1.50 per pound of weight</li>
<li>$0.25 per pound to ship if it is foreign</li>
<li>$100 if its <span class="InputCode">rep78</span> is 5 (presumably to hire better engineers)</li>
</ul>
<p>Calculate the profit  (price minus cost) from selling each car. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_data1.htm">Solution</a>)</p>
</li>
<li>Consider <span class="InputCode">interviews.dta</span>. It contains the month and year in which each subject was born and the month and year in which that subject was interviewed. Find the age of the subject at the time of the interview in months. Then find it in whole years (i.e. what the person would say if you asked "How old are you?"). Don't worry about days (or if you prefer, assume that interviews always occur later in the month than birthdays). For extra credit, read up on Stata dates and repeat the process using them. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_data2.htm">Solution</a>)</li>
<li>
<p>Going back to the automobile data set, the <span class="InputCode">make</span> variable is comprised of the manufacturer of the car followed by the name of the car. Create a new variable containing just the manufacturer.</p>
<p> This exercise will probably require you to type <span class="InputCode">help functions</span> and/or <span class="InputCode">help egen</span> and look through the list of functions available. In fact that's kind of the point: finding functions that will do what you need to do is a big part of Stata programming. <a href="https://ssc.wisc.edu/sscc/pubs/sfr-learning.htm">Learning More</a> has some tips for understanding the help files. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_data3.htm">Solution</a>)</p>
</li>
<li>Now consider <span class="InputCode">statecounty.dta</span>. It has a two-part identifier: <span class="InputCode">state</span> and <span class="InputCode">county</span>. Combine them into a single identifier such that county 1 in state 1 becomes 101 and county 5 in state 12 becomes 1205. Now do it again by turning them into strings first, making the code for county 1, state 1 "0101". (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_data4.htm">Solution</a>)</li>
<li>Use the automobile data set again. Create value labels so that when listing <span class="InputCode">mpg</span> you see "12 (Lowest MPG)" and "41 (Highest MPG)" for the cars with the lowest and highest values of <span class="InputCode">mpg</span> respectively. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_data5.htm">Solution</a>)</li>
</ol>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-stats.htm"> Statistics</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-syntax.htm">Usage and Syntax</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Researchers: Do Files</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This is part three of the Stata for Researchers series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Introduction</a>. If you're new to Stata we highly recommend reading the articles in order.</em></p>
<p>Up to this point we've used Stata interactively: we've typed commands in the command window, hit Enter, and observed the results. But now that we've covered the basics of Stata syntax, the next step is learning how to create and change variables. You should <em><strong>never</strong></em> change your data interactively, so we'll first talk about how to write do files.</p>
<h2>Writing a Do File</h2>
<p>Do files are simply text files whose names end with <span class="InputCode">.do</span> and
                  which contain Stata commands exactly the way you'd type them
                  into the command window. Sometimes people call them programs, though Stata uses this term for something else (see <a href="https://ssc.wisc.edu/sscc/pubs/stata_prog2.htm">Stata Programming Tools</a>). You can write do files using any text editor, but the Do File Editor built into Stata has tools and features designed to help programmers so we recommend using it. Do not write Stata code using Word—it will automatically insert things like "smart quotes" and other formatting that Stata cannot understand.</p>
<p>Start the Do File Editor by clicking on the button that looks like a pencil writing in a notebook or by typing <span class="InputCode">doedit</span>.</p>
<h2>Setting Up</h2>
<p>Almost every do file should start with the following commands (or something very much like them):</p>
<p class="InputCode">clear all<br/>
                  capture log close<br/>
                set more off</p>
<p>The first command clears the memory so you don't have to worry about what might have happened before your do file was run. The second closes any open log files. The third tells Stata not to pause whenever the screen fills and wait for you to press a key (while saying <span class="Blue">--more--</span> at the bottom).</p>
<h2><a id="KeepingLogs" name="KeepingLogs"></a>Starting a Log</h2>
<p>A research do file should have a corresponding log file which records
                  all the commands the do file ran and their results. To start logging, the command is: </p>
<p class="InputCode">log using <span class="Parameter">filename</span>.log,
                  replace</p>
<p>where <span class="Parameter">filename</span> is the name of the
                  file you want Stata to use as a log. Give the log file the same name as the do file it records, so it's obvious which log file goes with which do file.  The <span class="InputCode">replace</span> option
                  tells Stata that if a log file with that name already exists, usually from a previous attempt to run the do file, it should be
                  replaced by the current log. </p>
<p>If you do not specify the <span class="InputCode">.log</span> at
                  the end of the filename, Stata will save the log using its Stata
                  Markup and Control Language. SMCL has its uses, but it can only
                  be read by Stata's Viewer. If your filename ends with <span class="InputCode">.log</span>,
                  Stata will save the log as plain text which you can read in any
                  text editor. </p>
<h2>Loading Data</h2>
<p>Next you will usually load a data set:</p>
<p class="InputCode">use <span class="Parameter">dataset</span></p>
<p>If the dataset is in the current working directory, you don't need to specify its location.</p>
<h2>Do Your Work</h2>
<p>At this point you'll be ready to do your work. Generally this means data preparation, exploratory analysis, or analysis you intend to report or publish. We recommend you have separate do files for each of these, as they are very different processes and have different requirements. We'll talk more about this in <a href="https://ssc.wisc.edu/sscc/pubs/sfr-projects.htm">Project Management</a>.</p>
<h4>Save your Data</h4>
<p>If this do file is for data preparation, you'll need to save your work at the end:</p>
<p class="InputCode">save <span class="Parameter">newDataset</span>, replace</p>
<p>The <span class="InputCode">replace</span> option again  allows Stata to overwrite the output from previous attempts to run the do file.</p>
<p><strong>Never, ever save your output data set over your input data set. </strong>(In other words, the starting <span class="InputCode">use</span> command and the ending <span class="InputCode">save</span> command should never act on the same file.) If you do, the data set your do file was written to work with will no longer exist. If it turns out you made a mistake, you can't easily recover. If the data set was stored on the SSCC network, you can call the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a> and ask to have the file restored from backup but this is definitely not ideal.</p>
<p>Clearing everything from memory, loading the data set you want to use, and then saving any changes you make to a different file makes your do file <em>reproducible</em>: you can run it again any time you want and get the exact same results. If the input data set changes, you'll be applying the exact same procedures to the new data. If it turns out you made a mistake, all you need to do is correct the error in your code and run the do file again. If you need to make changes you can do so without starting over. It may take a bit of effort at first to get into the habit of writing reproducible code, but the effort will pay off very quickly.</p>
<h2>Close your log</h2>
<p>The last line of the do file will normally be:</p>
<p class="InputCode">log close</p>
<p>If you don't close the do file's log, any commands you run after the do file finishes will be logged as if they were part of the do file. If your do file crashes before reaching the <span class="InputCode">log close</span> command it will leave the log file open. That's why you need <span class="InputCode">capture log close</span> at the beginning. (The <span class="InputCode">capture</span> prefix basically says "If the following command generates any errors I don't care. Please don't crash my do file." We use it here because <span class="InputCode">log close</span> will generate an error if there is no open log. At this point in your Stata career you should not use <span class="InputCode">capture</span> for anything else—fix the errors instead.)</p>
<h2>Running a Do File</h2>
<p>The easiest way to run a do file is to press <span class="InputCode">Ctrl-d</span> in the Do File Editor, or click the icon on the far right that looks like a "play" button over some code. If you first select just part of the do file then only that part will be run.</p>
<p> Running parts of your code rather than the entire do file can save a lot of time, but code taken out of context won't always work. For example, if you run a command that creates a variable <span class="InputCode">x</span>, realize you made a mistake, and then fix it, you can't simply select that command and run it again unless you first drop the existing version of <span class="InputCode">x</span>. If you find yourself getting confused by these kinds of issues, run the entire do file rather than a selection so everything is run in its proper context.</p>
<p>You can also tell Stata to run a do file with the do command:</p>
<p class="InputCode">do myDoFile</p>
<p>This means do files can run other do files. For complicated projects it can be very helpful to have a master do file that runs all the other do files in the proper sequence.</p>
<h2>How long should a do file be?</h2>
<p>For data preparation work, it's easy to "daisy-chain" do files: <span class="InputCode">dofile1</span> loads <span class="InputCode">dataset1</span>, modifies it, and saves it as <span class="InputCode">dataset2</span>; <span class="InputCode">dofile2</span> loads <span class="InputCode">dataset2</span>, modifies it, and saves it as <span class="InputCode">dataset3</span>, etc. When you're done, a master do file can run them all. Thus there's very little downside to breaking up one long do file into two or more short do files. Our suggestion is that you keep your do files short enough that when you're working on one of them you can easily wrap your head around it. You also want to keep do files short so they run as quickly as possible: working on a do file usually requires running it repeatedly, so moving any code that you consider "done" to a different do file will save time.</p>
<h2>Comments</h2>
<p>Comments are  text included in a do file for the benefit
                  of human readers, not for Stata. Comments can explain what the do file does and why, and if
                  anyone else ever needs to read and understand your do file they'll be very grateful for good comments. But <em>you</em> are the most likely beneficiary of your comments, when you have to figure out how your do file works months or years after writing it.</p>
<p>You don't need to comment every command—most Stata
                  code is fairly easy to read. But be sure to comment any code 
                  that required particular cleverness to write, or you'll need to be just as clever to figure out what it does later.</p>
<p>Comments need to be marked as such so that Stata will not try to execute them. <span class="InputCode">/*</span> means Stata should ignore everything until it sees <span class="InputCode">*/</span>, while <span class="InputCode">//</span> means Stata should ignore the rest of that line. Here's how one might comment the solution to one of the exercises in the previous section:</p>
<p class="InputCode">// make a list of cars I might be interested in buying<br/>
                list make price mpg rep78 if price&lt;4000 | (price&lt;5000 &amp; rep78&gt;3 &amp; rep78&lt;.)<br/>
/* <br/>
                  Note:<br/>
                Some cars will appear on the list even though they have<br/>
a missing value for rep78.<br/>
                This is not an error.<br/>
                If their price is less than $4,000 I don't care about their<br/>
repair record.<br/>
*/</p>
<p>A useful programmer's trick is to "comment out" code you don't want to run right now but don't want to delete entirely. For example, if you temporarily wanted to focus on just the cars that meet the <span class="InputCode">price&lt;4000</span> condition, you could change that command to:</p>
<p class="InputCode">list make price mpg rep78 if price&lt;4000 // | (price&lt;5000 &amp; rep78&gt;3 &amp; rep78&lt;.) </p>
<p>When you're ready to return to the original command, just remove the comment markers.</p>
<p>Three forward slashes (<span class="InputCode">///</span>) means that the current command is continued on the next line. Think of it as commenting out the 'end-of-line' that tells Stata the command is complete. This allows you to break up commands over multiple lines for readability:</p>
<p class="InputCode">list make price mpg rep78 ///<br/>
<span class="indent3">if price&lt;4000 | (price&lt;5000 &amp; rep78&gt;3 &amp; rep78&lt;.)</span></p>
<p>From now on we'll do everything using do files.</p>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-data.htm">Working with Data</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-syntax.htm">Usage and Syntax</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>SSCC - Social Science Computing Cooperative</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This is part nine of the Stata for Researchers series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Introduction</a>. If you're new to Stata we highly recommend reading the articles in order.</em></p>
<p>Stata has a suite of tools for creating publication-quality graphs.
            	Graphs are inherently complicated objects and the syntax for
            	creating them can also get quite complicated. However, simple
            	graphs with the default settings are very easy to make.</p>
<p> This article will give you a very brief introduction to Stata's graphical capabilities. If this is a topic that interests you, you may want to skip this article and read our <a href="https://ssc.wisc.edu/sscc/pubs/4-24.htm">Introduction to Stata Graphics</a> instead (either before or after proceeding to the next article in this series, <a href="https://ssc.wisc.edu/sscc/pubs/sfr-do.htm">Do Files and Project Management</a>).</p>
<p>Load the automobile data set once again:</p>
<p class="InputCode">sysuse auto, replace</p>
<p>Then make a scatterplot of <span class="InputCode">mpg</span> versus <span class="InputCode">weight</span> by typing:</p>
<p class="InputCode">scatter mpg weight </p>
<p>If you want a line graph instead, type:</p>
<p class="InputCode">line mpg weight, sort </p>
<p>The <span class="InputCode">sort</span> option here does not mean
                  Stata should  sort the data. Rather it means that the
                  line should be drawn from the observation with the smallest value
                  of <span class="InputCode">weight</span> to the observation with
                  the next smallest, etc. Without it the line would be drawn from
                  observation one to observation two to observation three and so
                  forth, and the result would look like a scribble (try it).</p>
<p>Since graphs can be so complicated we don't suggest trying to memorize the syntax for every setting and detail. Keeping track of such things is the great strength of a point-and-click graphical
                  user interface, so this is an area where we suggest taking advantage of it. Stata will translate what you choose into a
                  Stata command which you can then put into a do file, rerun or modified.</p>
<p>To make the same basic line graph using the graphical user interface, start by clicking <span class="MenuOutput">Graphics</span>, <span class="MenuOutput">Twoway
                  graph</span> (twoway meaning a graph that
                  has an X and a Y). Then click the <span class="MenuOutput">Create</span> button
                  to create a new plot.</p>
<p>You'll then get a window where you can choose the basic properties
                  of your plot. Leave the category set to <span class="MenuOutput">Basic
                    plots</span>, set the
                  type to <span class="MenuOutput">Line</span> and choose or type <span class="InputCode">mpg</span> as
                  the <span class="MenuOutput">Y
                    variable</span> and <span class="InputCode">weight</span> as the <span class="MenuOutput">X variable</span>. Check the box that says <span class="MenuOutput">Sort
                      on x variable</span>. Then click <span class="MenuOutput">Accept</span>. </p>
<p><img alt="Creating a line graph" height="416" src="https://ssc.wisc.edu/sscc/pubs/screenshots/4-9/4-9_2.png" width="621"/></p>
<p>This will take you back to the main graphics Window. You could
                  click <span class="MenuOutput">Create</span> again to add another
                  plot, which would be overlaid on the line plot you already defined.
                  But there are several other tabs that control the properties
                  of the entire graph.</p>
<p>Select the <span class="MenuOutput">if/in</span> tab and you can
                  choose which observations are to be included. Type <span class="InputCode">price&lt;10000</span> in
                  the <span class="MenuOutput">If:</span> box (note that you shouldn't type the word <span class="InputCode">if</span>). </p>
<p><img alt="Selecting observations with if" height="346" src="https://ssc.wisc.edu/sscc/pubs/screenshots/4-9/4-9_3.png" width="481"/></p>
<p>Next click on the <span class="MenuOutput">By </span>tab. Check
                  the box <span class="MenuOutput">Draw subgraphs for unique values of variables</span> and
                  for <span class="MenuOutput">Variables</span> choose
                  or type <span class="InputCode">foreign</span>. </p>
<p><img alt="By: options" height="346" src="https://ssc.wisc.edu/sscc/pubs/screenshots/4-9/4-9_4.png" width="481"/></p>
<p>Click <span class="MenuOutput">OK</span>, and the graph will be
                  created. The command for creating it will also be placed in the
                  results window:</p>
<p class="InputCode">twoway (line mpg weight, sort) if price&lt;10000, by(foreign) </p>
<p>Note how for
                  graphs <em>by</em> is
                  an option, not a prefix like you're used to. That's because you're
                  not creating two completely separate graphs for the domestic and
                  foreign cars like you would with the standard <em>by:</em>. Instead
                  you're creating one graph with the two subpopulations next to
                  each other. </p>
<p>If you click <span class="MenuOutput">Graphics</span>, <span class="MenuOutput">Twoway
                  graph </span>again, the same settings will still be there so you
                  can refine the options you chose. Once you've
                  got the graph you want, copy the resulting command into a
                  do file. If you want to start a new graph instead, click
                  on the large <span class="MenuOutput">R</span> (reset) button in
                  the lower left of the window.</p>
<p>For much more information about creating graphs, see <a href="https://ssc.wisc.edu/sscc/pubs/4-24.htm">An
                  Introduction to Stata Graphics</a>.</p>
<h4>Exercise</h4>
<ol>
<li>Create a scatter plot of <span class="InputCode">price</span> on <span class="InputCode">weight</span>.</li>
<li>Split that scatter plot into seven plots, one for each value of <span class="InputCode">rep78</span> including missing and a total.</li>
</ol>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-projects.htm">Project Management</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-combine.htm">Combining Data Sets</a></p>
<p> </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/4-9/4-9_2.png, https://ssc.wisc.edu/sscc/pubs/screenshots/4-9/4-9_3.png, https://ssc.wisc.edu/sscc/pubs/screenshots/4-9/4-9_4.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Researchers: Working with Groups</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This is part six of the Stata for Researchers series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Introduction</a>. If you're new to Stata we highly recommend reading the articles in order.</em> </p>
<p>Tasks that  require working with groups are common and can range from the very simple ("Calculate the mean mpg of the domestic cars and the foreign cars separately") to the very complex ("Model student performance on a standardized test, taking into account that the students are grouped into classes which are grouped into schools which are grouped into districts."). Fortunately, working with groups is one of Stata's greatest strengths. In this article we'll discuss tools for working with groups, and at the same time try to give you more experience using Stata's syntax to get useful results. In the next section (<a href="https://ssc.wisc.edu/sscc/pubs/sfr-hier.htm">Hierarchical Data</a>) we'll introduce a theoretical framework for thinking about grouped data, but it will make more sense if you've had some experience working with groups first.                </p>
<p>We'll start by going through some basic tools that are used for working with groups, and some tricks for using them. In doing so we'll use one of the example data sets for this series, <span class="InputCode">households.dta</span>. Make sure you copied those files from <span class="MenuOutput">X:\SSCC Tutorials\StataResearch</span> or <a href="https://ssc.wisc.edu/sscc/pubs/files/StataResearch.zip">downloaded them</a>, and put them in a convenient location like <span class="MenuOutput">U:\StataResearch</span>. Make sure your current working directory is set to that location:</p>
<p class="InputCode">cd U:\StataResearch</p>
<p>(or wherever you put them). Then start a do file:</p>
<p class="InputCode">clear all<br/>
capture log close<br/>
set more off<br/>
log using groups1.log, replace<br/>
<br/>
use households<br/>
<br/>
log close</p>
<p>You'll want to run your do file frequently in this section. Consider keeping a data browser window open so you can easily see what the do file does to your data.</p>
<p>This data set contains information on twenty fictional people who live in six different households. This data structure is one of the most common encountered at the SSCC. One variable that may require explanation is <span class="InputCode">rel2head</span>, or "relationship to the head of household." It is a categorical variable that takes on three values, with value labels applied. Type <span class="InputCode">label list</span> to see them. This is typical of real-world data (except real data usually have many more kinds of relationships).</p>
<h2><a id="By" name="By"></a>By</h2>
<p>The most important tool for working with groups is <em>by</em>. Recall that if you put <span class="InputCode">by </span><span class="Parameter">varlist</span><span class="InputCode">:</span> before a command, Stata will first break up the data set up into one group for each value of the <em>by</em> variable (or each unique combination of the <em>by</em> variables if there's more than one), and then run the command separately for each group. For further review,  see the section on <em>by</em> in <a href="https://ssc.wisc.edu/sscc/pubs/sfr-syntax.htm#by">Usage and Syntax</a>. Here are some examples of things you can do with <em>by</em>.</p>
<h3><a id="CalculatingSummaryStatisticsOverGroups" name="CalculatingSummaryStatisticsOverGroups"></a>Calculating Summary Statistics Over Groups</h3>
<p>Find the average age of the adults in each household:</p>
<p class="InputCode">by household: sum age if age&gt;=18</p>
<p>(You could get the same results more compactly with <span class="InputCode">tab household if age&gt;=18, sum(age)</span>)                </p>
<p>Store the total household income  in a new variable:</p>
<p class="InputCode">by household: egen householdIncome=total(income)</p>
<p>Note that <span class="InputCode">householdIncome</span> is the same for all the individuals living in a given household. That's because it's a characteristic of the household, not the individual. We'll talk more about this distinction in <a href="https://ssc.wisc.edu/sscc/pubs/sfr-hier.htm">Hierarchical Data</a>.</p>
<h3><a id="IdentifyingCharacteristicsofaGroup" name="IdentifyingCharacteristicsofaGroup"></a>Identifying Characteristics of a Group</h3>
<p>Create an indicator for whether a household has children or not, regardless of number:</p>
<p class="InputCode">gen child=(age&lt;18)<br/>
                by household: egen hasChildren=max(child)</p>
<p></p>
<p></p>
<p>If a household has no children, the maximum value of <span class="InputCode">child</span> will be zero. If it has any at all, the maximum will be one.</p>
<p>In this case, <span class="InputCode">child</span> is likely to be a useful variable in its own right. But if you didn't need it, you could do the whole process in one line with:</p>
<p class="InputCode">by household: egen hasChildren=max(age&lt;18)</p>
<p>Now instead of finding the max of a variable, you're finding the max of an expression, but the result is the same: the maximum will be one for the entire household if the household has any children in it and zero otherwise.</p>
<h3><a id="CountingObservationsthatMeetaCondition" name="CountingObservationsthatMeetaCondition"></a>Counting Observations that Meet a Condition</h3>
<p>Find the number of children in each household:</p>
<p class="InputCode">                by household:egen numChildren=total(child)                </p>
<p>Here we
                  take advantage               
                of the fact that the total of an indicator variable is the number of observations for which the indicator variable is true. Again, <span class="InputCode">total(child)</span> could have been <span class="InputCode">total(age&lt;18)</span>.</p>
<h3><a id="ResultSpreading" name="ResultSpreading"></a>Result Spreading</h3>
<p>Suppose we need to store the mean age of the adults in each household as a variable. The obvious starting point would be:</p>
<p class="InputCode">by household: egen meanAdultAge=mean(age) if age&gt;=18</p>
<p>However, <span class="InputCode">meanAdultAge</span> receives a missing for all the children in the data set. That's because the <em>if</em> condition does two things in this command: it controls which which observations are used in calculating the mean to be stored in <span class="InputCode">meanAdultAge</span>, but also which observations that mean is stored in. If we need the household's <span class="InputCode">meanAdultAge</span> to be available in all the observations for that household (and we usually do), then we need to "spread" the result to the other observations.</p>
<p class="InputCode">by household: egen temp=mean(meanAdultAge)<br/>
                drop meanAdultAge<br/>
                rename temp meanAdultAge</p>
<p>All the observations in each household that have a value for <span class="InputCode">meanAdultAge</span> have the same value. Thus the <span class="InputCode">mean()</span> function returns that value—but it does so for all the observations in the household. (Recall that when <span class="InputCode">mean()</span> encounters missing values it essentially ignores them and calculates the mean of the non-missing values.) Thus the <span class="InputCode">temp</span> variable contains the proper value of <span class="InputCode">meanAdultAge</span> for all observations, adults and children. We then drop the old <span class="InputCode">meanAdultAge</span> variable and rename <span class="InputCode">temp</span> <span class="InputCode">meanAdultAge</span>. If we plan ahead we can save one line of code compared to the above:</p>
<p class="InputCode">by household: egen temp=mean(age) if age&gt;=18<br/>
  by household: egen meanAdultAge=mean(temp)<br/>
  drop temp
</p>
<p> This is sometimes called "spreading" a result: if you can find the right answer for some of the observation in a group, you can then spread it out to the others. You could do  spreading with any of several <span class="InputCode">egen</span> functions: <span class="InputCode">min()</span>, <span class="InputCode">max()</span>, etc., but <span class="InputCode">mean()</span> is perhaps the most intuitive.</p>
<h4>Exercises</h4>
<ol>
<li>Create an indicator variable for childless households using the <span class="InputCode">numChildren</span> variable you created earlier. Defend your choice whether or not to use <em>by</em> in the process. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_groups_by1.htm">Solution</a>)</li>
<li>Find the age of the youngest adult in each household at the time their first child was born. (Hint: this is a characteristic of the household, not an individual.) (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_groups_by2.htm">Solution</a>)</li>
<li>Find the mean household income of people in single-parent households and  two-parent households. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_groups_by3.htm">Solution</a>)</li>
</ol>
<h2><a id="_nand_N" name="_nand_N"></a>_n and _N</h2>
<p>Most Stata commands are actually loops: do something to observation one, then do it to observation two and so forth. As Stata works through this loop, it tracks  which observation it is working on with an internal variable called <span class="InputCode">_n</span>. You are welcome to use this variable in your commands:</p>
<p class="InputCode">l if _n==5</p>
<p>will only list observation five, because the condition <span class="InputCode">_n==5</span> is only true when Stata is working with observation five.</p>
<p><span class="InputCode">_n</span> becomes even more useful when combined with <em>by. </em>Suppose you wanted to list the first observation in each household:</p>
<p class="InputCode">by household: l if _n==1</p>
<p>It just so happens that the first observation is the head of household in every case, which is not unusual. But what if instead of having <span class="InputCode">rel2head</span> you only knew the head of household by their location in the household? Then you'd have to be very careful about sorting. Stata's default sort algorithm is not "stable," meaning that if you sort by household it may change the order of observations within the household. If the order of observations matters, you should add the <span class="InputCode">stable</span> <em>option</em> to any <span class="InputCode">sort</span> commands. That way Stata will use a different sort algorithm that is slower but will not change the order of observations within a group. But having done that you can always identify the head of household with a combination of <span class="InputCode">by household:</span> and <span class="InputCode">if _n==1</span>.</p>
<p>Another internal variable, <span class="InputCode">_N</span>, contains the number of observations in the data set. It is also the observation number of the last observation. You can use it in commands just like <span class="InputCode">_n</span>:</p>
<p class="InputCode">by household: l if _n==_N</p>
<p>This lists the last observation in each household.</p>
<h3><a id="CreatingWithinGroupIdentifiers" name="CreatingWithinGroupIdentifiers"></a>Creating Within-Group Identifiers</h3>
<p> Often you'll want to have a within-group identifier so you can always tell which observation is which, even after a mistaken sort. In this case the within-group identifier could logically be called <span class="InputCode">person</span>:</p>
<p class="InputCode">by household: gen person=_n</p>
<p>The <span class="InputCode">person</span> variable will correspond to the observation number of the person within their household in the current sort order. If you wanted a globally unique identifier, run the above command without <span class="InputCode">by household:</span>.</p>
<h3><a id="FindingtheSizeofaGroup" name="FindingtheSizeofaGroup"></a>Finding the Size of a Group</h3>
<p>Like <span class="InputCode">_n</span>, <span class="InputCode">_N</span> honors by groups. Thus <span class="InputCode">_N</span> contains the number of observations in the <em>by</em> group currently being worked on. You can easily find household size with:</p>
<p class="InputCode">by household: gen size=_N</p>
<h2><a id="Subscripts" name="Subscripts"></a>Subscripts</h2>
<p>Consider the command:</p>
<p class="InputCode">gen newIncome=income </p>
<p>In carrying it out, Stata looks at one observation at a time, and sets <span class="InputCode">newIncome</span> for that observation equal to <span class="InputCode">income</span> for the same observation. Subscripts allow you to look at the value of a variable for any observation you want. Try:</p>
<p class="InputCode">gen newIncome2=income[1]</p>
<p><span class="InputCode">income[1]</span> means "the value of income for observation 1." Thus <span class="InputCode">newIncome2</span> will be 60,000 for all observations (not that that is a useful result).</p>
<h3><a id="SpreadingCharacteristicsofaSpecialObservation" name="SpreadingCharacteristicsofaSpecialObservation"></a>Spreading Characteristics of a Special Observation</h3>
<p>Consider trying to identify the female-headed households:</p>
<p class="InputCode">by household: gen femaleHead=female[1]</p>
<p>Since the first person in each household is the head, the household has a female head if and only if the first person is female.</p>
<p>What if the head of household were last instead of first? Just change it to:</p>
<p class="InputCode">by household: gen femaleHead=female[_N]</p>
<p>What if the heads of household weren't in any particular place within the household? Use <span class="InputCode">sort</span> to make them the first person in the household:</p>
<p class="InputCode">sort household rel2head<br/>
  by household: gen femaleHead=female[1]</p>
<p>What if the code for "head of household" weren't the lowest value of <span class="InputCode">rel2head</span>? The following will always work:</p>
<p class="InputCode">gen isHead=(rel2head==1)<br/>
  sort household isHead<br/>
  by household: gen femaleHead=female[_N]<br/>
</p>
<p>What if some households don't have a head, and you need <span class="InputCode">femaleHead</span> to be missing for those households? Do the above, but add an <em>if</em> condition to the last line:</p>
<p class="InputCode">by household: gen femaleHead=female[_N] if isHead[_N]</p>
<p>This general method will work any time you need to pick out the characteristics of a special row within a group (the respondent to a survey, the month in which a subject graduated, etc.):</p>
<ol>
<li>Create an indicator variable that is one for the special row and zero for all other rows</li>
<li>Sort by the group ID and the new indicator variable</li>
<li>The special row will be last and can be accessed with <span class="InputCode">[_N]</span> as long as you start with <em>by</em></li>
</ol>
<p>If you  want the special observation to be first rather than last, you can use <span class="InputCode">gsort</span> (generalized sort):</p>
<p class="InputCode">gsort household -isHead</p>
<p>With <span class="InputCode">gsort</span> you can put a minus sign in front of a variable name and the observations will be sorted in descending order by that variable rather than ascending.</p>
<h3>Checking Whether a Variable Varies within a Group</h3>
<p>The <span class="InputCode">householdIncome</span> variable should have the same value for all the individuals within a given household. You can check that with:</p>
<p class="InputCode">sort household householdIncome<br/>
by household: assert householdIncome[1]==householdIncome[_N]</p>
<p>Because the observations within a household are sorted by <span class="InputCode">householdIncome</span>, the smallest value will be first and the largest value will be last. If the first and last values are the same, then you know all the values are the same.</p>
<h4>Exercises</h4>
<ol>
<li>How could you check that every household has one and only one head of household? (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_groups_checks1.htm">Solution</a>)</li>
<li>Create an indicator variable for whether a household's value of <span class="InputCode">age</span> varies. Use it to <span class="InputCode">browse</span> just those households whose <span class="InputCode">age</span> does vary. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_groups_checks2.htm">Solution</a>)</li>
</ol>
<h3><a id="CalculationsBasedonanObservationsNeighbors" name="CalculationsBasedonanObservationsNeighbors"></a>Calculations Based on an Observation's Neighbors</h3>
<p>Subscripts can contain mathematical expressions, including <span class="InputCode">_n</span> and <span class="InputCode">_N</span>.</p>
<p> Start a new do file that loads the data set called <span class="InputCode">schools</span>. This contains enrollment numbers for ten fictional (and not terribly plausible) schools. We'll define a student's peer group as everyone in her grade, the grade above her, and the grade below her. To find the size of each grade's peer group, type the following:</p>
<p class="InputCode">by school: gen peerGroup=students+students[_n+1]+students[_n-1]</p>
<p>The result is missing for grade one because it doesn't have a grade before it, and for grade twelve because it doesn't have a grade after it. Thus <span class="InputCode">students[_n-1]</span>or <span class="InputCode">students[_n+1]</span> give missing values for them. Fortunately Stata just returns a missing value in such cases rather than giving an "index out of bounds" error or something similar.</p>
<h4>Exercises    </h4>
<ol>
<li>What would happen if you left out <span class="InputCode">by school:</span> in:
  <p class="InputCode">by school: gen peerGroup=students+students[_n+1]+students[_n-1]</p>
<p> What would happen if some schools didn't have an observation for some grades? (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_groups_subscripts2.htm">Solution</a>)</p>
</li>
<li>Implement an extended definition of  <span class="InputCode">peerGroup</span> where the the peers of the first graders and the first and second graders, and the peers of the twelfth graders are the eleventh and twelfth graders (i.e. fill in the missing values). (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_groups_subscripts1.htm">Solution</a>)</li>
</ol>
<h2><a id="PanelData" name="PanelData"></a>Panel Data</h2>
<p>Panel data, or data with multiple individuals observed multiple times, can be treated like grouped data even though a "group" in this case is  an individual. (This is why we introduce more general terminology in <a href="https://ssc.wisc.edu/sscc/pubs/sfr-hier.htm">Hierarchical Data</a>.) Start another do file that loads a data set called <span class="InputCode">employment</span>. This consists of five people observed for twenty months, with each person's employment status recorded each month.</p>
<h3><a id="IdentifyingSpells" name="IdentifyingSpells"></a>Identifying Spells</h3>
<p>A typical person in this panel is employed for a while, then unemployed for a while, etc. Each period of continuous employment or unemployment is called a "spell" and a common first task with such data is to identify the spells.</p>
<p>Begin by identifying the months which start a new spell, i.e. the months where a person's employment status is different from what it was the previous month:</p>
<p class="InputCode">by person: gen start=(employed!=employed[_n-1])</p>
<p>For the first month  in which a person is observed, the quantity <span class="InputCode">employed[_n-1]</span> does not exist and is thus missing. Since <span class="InputCode">employed</span> is never missing (how would you check that?) this guarantees that the first month a person is observed is marked as the start of a new spell.</p>
<p>Next comes something you should add to your bag of tricks:</p>
<p class="InputCode">by person: gen spell=sum(start)</p>
<p>The <span class="InputCode">sum()</span> function finds running sums, i.e. the sum of a variable for all observations up to and including the current observation. Since <span class="InputCode">start</span> is one whenever a spell starts and zero otherwise, <span class="InputCode">sum(start)</span> for an observation is the number of spells which have started up to that point—and that serves as a splendid spell ID.</p>
<p>Once you've identified the spells, you can treat them as groups. However, these spell IDs only make sense within the context of a person (each person has their own spell number one). Thus the proper <em>by</em> is <span class="InputCode">by person spell:</span>, and the first time you use it you'll have to say <span class="InputCode">bysort</span>. But everything you've learned still applies. For example, finding the duration of a spell is exactly like finding the size of a household:</p>
<p class="InputCode">bysort person spell: gen duration=_N</p>
<h4>Exercises</h4>
<ol>
<li><p>Think back to the command:</p><p class="InputCode">by person: gen start=(employed!=employed[_n-1])</p>
<p>What would happen if you omitted the <em>by</em>? (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_groups_spell1.htm">Solution</a>)</p></li>
<li>Create variables containing the start month, start year, end month and end year for each spell. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_groups_spell2.htm">Solution</a>)</li>
<li>Find the mean spell length for each person. Make sure the mean is calculated over spells, not months. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_groups_spell3.htm">Solution</a>)</li>
</ol>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-hier.htm">Hierarchical Data</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-stats.htm"> Statistics</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Researchers: Hierarchical Data</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This is part seven of the Stata for Researchers series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Introduction</a>. If you're new to Stata we highly recommend reading the articles in order.</em></p>
<p>Hierarchical data are  data where observations fall into groups or clusters. The most common examples at the SSCC are individuals living in a household and a subject being observed multiple times, as in the data sets used in the previous section. But there are many other applications: schools within a district, courses taken by a student, or   individuals who are part of a subject's social network can all be treated as hierarchical data. Hierarchies can  have more than two levels; for example students may be grouped into classrooms which are grouped into schools which are grouped into districts.</p>
<p>This article will  introduce you to a way of describing hierarchical data that will make it easier to talk about—and think about—its structure. It was developed by the community of statisticians interested in formal Hierarchical Linear Modeling, but you don't have to be doing HLM for the concepts and terminology to be useful. We'll then introduce two commands that act directly on the structure of hierarchical data sets: <span class="InputCode">reshape</span> and <span class="InputCode">collapse</span>.</p>
<h2><a id="DescribingHierarchicalData" name="DescribingHierarchicalData"></a>Describing Hierarchical Data</h2>
<p>Since hierarchical data can describe so many different things, we need  to define terms that can apply to all of them. We'll describe the smallest unit in the data as the level one unit. In the examples mentioned above the level one unit would be an individual within the household, a particular time the subject was observed, a school within the district, a course taken by the student, or an individual within the subject's social network. A level two unit is  a group of level one units: the household in which the individuals live, the subject which is measured repeatedly, the district which contains the schools, the student who takes the courses or the subject whose social network is being described. If needed, a level three unit is  a collection of level two units, and so forth.</p>
<p>Most hierarchical data sets will include some variables which describe the level one units and some which describe the level two units. For example, a data set of individuals living in households may contain the age and sex of each individual, plus the household income of the household as a whole. Age and sex would then be level one variables while household income would be a level two variable.</p>
<p>Level two variables are easy to identify: they always have the same value for all the level one units in the same level two unit. For example, the total number of people in the household must be the same for every member of a household, or if a subject is observed multiple times he or she will  have the same birth date each time. Anything that varies within a level two unit is a level one variable: individuals within a household can obviously have different employment statuses, so employment status must be a level one variable. While it's rarely difficult to identify which of your variables are level one and which are level two, taking a moment to do so during the planning stage of your project and before writing any code can help you avoid a lot of headaches.</p>
<p>Ideally each level will have an associated  identifier: for example a household ID and an individual ID, or a subject ID and a survey wave ID. The level one identifiers only need to be unique within a level two group, and in fact the <span class="InputCode">reshape</span> command will only work if this is the case. Often data sets do not come with a usable level one identifier, but you learned how to create one in the last section (e.g. <span class="InputCode">by household: gen person=_n</span>).</p>
<h2><a id="RepresentingHierarchicalDataasaMatrix" name="RepresentingHierarchicalDataasaMatrix"></a>Representing Hierarchical Data as a Matrix</h2>
<p>Stata (like most statistical programs) stores its data in a matrix, where rows are observations and columns are variables. But when working with hierarchical data "observation" is an ambiguous term: it could mean either a level one unit or a level two unit. The purpose of the <span class="InputCode">reshape</span> command is to allow you to go back and forth between the two definitions at will, restructuring your data accordingly.</p>
<p>If an observation represents a level one unit then your data are in the long form, so named because it has more observations. In the long form, both level one and level two variables are represented by columns in the data matrix. However, level two variables will have many repeated values, since all the observations in the same level two group will share the same values of all the level two variables.</p>
<p>If, on the other hand, an observation represents a level two unit then your data are in the wide form, so named because it has more variables. In wide form, level two variables are represented by columns as usual. However, level one variables are represented by sets of columns, with each set containing a column for each level one unit. Thus the values of the level one variables for each level one unit within a level two unit are stored in the same row, but in different columns.</p>
<p>Consider the following data:</p>
<a id="long" name="long"></a>
<table cellpadding="0" cellspacing="0">
<tr>
<th>person</th>
<th>wave</th>
<th>birthdate</th>
<th>education</th>
<th>income</th>
</tr>
<tr>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">12/2/1963</td>
<td>HS Grad</td>
<td align="right">60000</td>
</tr>
<tr>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">12/2/1963</td>
<td>HS Grad</td>
<td align="right">65000</td>
</tr>
<tr>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">3/18/1966</td>
<td>Bachelor's</td>
<td align="right">90000</td>
</tr>
<tr>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">3/18/1966</td>
<td>Bachelor's</td>
<td align="right">0</td>
</tr>
<tr>
<td align="right">3</td>
<td align="right">1</td>
<td align="right">6/6/1959</td>
<td>Some College</td>
<td align="right">40000</td>
</tr>
<tr>
<td align="right">3</td>
<td align="right">2</td>
<td align="right">6/6/1959</td>
<td>Bachelor's</td>
<td align="right">110000</td>
</tr>
</table>
<p>This is panel data, with three people each observed in two survey waves. Thus a level two unit is a person, while a level one unit is a person-wave combination. A person's birthdate never changes, so it is a level two variable. Meanwhile, a person's  income clearly can change between waves, so it is  a level one variable. Education looks like it might be a level two variable at first, but person number three apparently went back to school between waves and finished a Bachelor's degree. Thus <span class="InputCode">education</span> must be treated as a level one variable.</p>
<p>Since each row represents a level one unit, the above data are in the long form. Now consider the exact same data in a different format:</p>
<a id="wide" name="wide"></a>
<p>
<table cellpadding="0" cellspacing="0">
<tr>
<th>person</th>
<th>birthdate</th>
<th>education1</th>
<th>income1</th>
<th>education2</th>
<th>income2</th>
</tr>
<tr>
<td align="right">1</td>
<td align="right">12/2/1963</td>
<td>HS Grad</td>
<td align="right">60000</td>
<td>HS Grad</td>
<td align="right">65000</td>
</tr>
<tr>
<td align="right">2</td>
<td align="right">3/18/1966</td>
<td>Bachelor's</td>
<td align="right">90000</td>
<td>Bachelor's</td>
<td align="right">0</td>
</tr>
<tr>
<td align="right">3</td>
<td align="right">6/6/1959</td>
<td>Some College</td>
<td align="right">40000</td>
<td>Bachelor's</td>
<td align="right">110000</td>
</tr>
</table>
</p>
<p>Here a row represents a level two unit, so this is the wide form. The level one variables education and income are represented by two columns each, one for each wave.</p>
<h2><a id="UsingReshape" name="UsingReshape"></a>Using Reshape</h2>
<p>Stata's <span class="InputCode">reshape</span> command allows you switch between the two forms at will. The general syntax is:</p>
<p class="InputCode">reshape <span class="Parameter">long/wide</span> <span class="Parameter">"stubs" of level 1 vars</span>, i(<span class="Parameter">level 2 ID</span>) j(<span class="Parameter">level 1 ID</span>)</p>
<p>Before talking through the syntax in detail let's do an example. Start a do file that loads the dataset <span class="InputCode">reshape1</span>.</p>
<p>Do a <span class="InputCode">list</span> and you'll see it's currently in the long form (as in <a href="#long">this table</a>). To change that, type:</p>
<p class="InputCode">reshape wide education  income, i(person) j(wave)</p>
<p>Do another <span class="InputCode">list</span> to see the results (it should look like <a href="#wide">this table</a> except for the placement of the <span class="InputCode">birthdate</span> column). To go back to long form, type: </p>
<p class="InputCode"> reshape long education  income, i(person) j(wave)</p>
<p>Referring back to the general syntax, <span class="InputCode">long</span> or <span class="InputCode">wide</span> is the form in which you want to put the data. Next comes a list of level one variables, but note that when the data set is in wide form it does not contain any variables literally called  <span class="InputCode">education</span> or <span class="InputCode">income. </span>Instead you have <span class="InputCode">education1, education2 </span>and so forth.  <span class="InputCode">birthdate</span> is not in the list, as it is a level two variable.</p>
<p> The <span class="InputCode">i()</span> option is where you give the level two identifier variable. <span class="InputCode">j()</span> is then the level one identifier—but  note again that in wide form the data set does not have a variable called <span class="InputCode">wave</span>. When reshaping from wide to long, <span class="InputCode">education  income</span> combined with <span class="InputCode">j(wave) </span>can be interpreted as "look for variable names that start with <span class="InputCode">education</span> or <span class="InputCode">income</span>, then take whatever follows those words and put it in a new variable called <span class="InputCode">wave</span>."                </p>
<h2><a id="RemovingExtraneousCases" name="RemovingExtraneousCases"></a>Removing Extraneous Cases</h2>
<p>Now consider a (fabricated) data set consisting of individuals living in households:</p>
<table align="center" border="1" cellpadding="4">
<tr>
<th scope="col">household</th>
<th scope="col">income</th>
<th scope="col">age1</th>
<th scope="col">female1</th>
<th scope="col">age2</th>
<th scope="col">female2</th>
<th scope="col">age3</th>
<th scope="col">female3</th>
</tr>
<tr>
<td>1</td>
<td>30000</td>
<td>30</td>
<td>1</td>
<td>2</td>
<td>1</td>
<td>.</td>
<td>.</td>
</tr>
<tr>
<td>2</td>
<td>90000</td>
<td>45</td>
<td>0</td>
<td>43</td>
<td>1</td>
<td>15</td>
<td>0</td>
</tr>
</table>
<p>Here the level one unit is an individual, the level two unit is a household (with the <span class="InputCode">household</span> variable as the identifier), <span class="InputCode">income</span> is a level two variable, and <span class="InputCode">age</span> and <span class="InputCode">female</span> are level one variables. Since an observation represents a household, the level two unit, this data set is in wide form.</p>
<p>Start a do file that loads this data set, called <span class="InputCode">reshape2</span>.</p>
<p>If you need a dataset of individuals, all you need to do is reshape the data into the long form:</p>
<p class="InputCode">reshape long age female, i(household) j(person)</p>
<p>Here is the result:</p>
<table align="center" border="1" cellpadding="4">
<tr>
<th scope="col">household</th>
<th scope="col">person</th>
<th scope="col">income</th>
<th scope="col">age</th>
<th scope="col">female</th>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>30000</td>
<td>30</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>30000</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>3</td>
<td>30000</td>
<td>.</td>
<td>.</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>90000</td>
<td>45</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>90000</td>
<td>43</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
<td>90000</td>
<td>15</td>
<td>0</td>
</tr>
</table>
<p>There's just one problem: person number three in household one. Note that in wide form the number of columns is determined by the household with the largest number of members: the data set must have <span class="InputCode">age</span> and <span class="InputCode">female</span> columns for all the individuals in that household. However, that means the smaller households must have those columns as well. In this data set, household one only has two people so <span class="InputCode">age3</span> and <span class="InputCode">female3</span> are missing. But the reshape command doesn't choose not to create an observation just because these variables  have missing values. Conceivably there could  be a third person in household one and we just don't know their age or sex.</p>
<p>Such agnosticism is rarely an option with real data. In big surveys the largest household tends to be very large indeed, so you could easily have twenty or more <span class="InputCode">age</span> and <span class="InputCode">female</span> variables. Converting them all to observations results in a data set consisting mostly of missing values. Thus you most likely want to drop these extraneous observations:</p>
<p class="InputCode">drop if age==. &amp; female==.</p>
<p>If you had more level one variables you would still use all of them in the <em>if</em> condition,  to be sure that you don't eliminate a real person who is only missing a few variables.</p>
<h2>Collapse</h2>
<p>Sometimes you need to remove the level one units from your data entirely, leaving a data set of level two units. If all the level two variables you need have already been created, you can do so with code like:</p>
<p class="InputCode">drop age sex <br/>
                  by household: keep if _n==1<br/>
</p>
<p>Don't put this in your do file. But if you did, the first line would drop all the individual level variables, and the second would keep just the first observation in each household. (Once the level one variables are gone, it doesn't matter which one you keep because they're all the same.)</p>
<p>But if you need to calculate some level two variables before dropping the level one units, the <span class="InputCode">collapse</span> command may be able to do both for you. <span class="InputCode">collapse</span> says it "converts the dataset in memory into a dataset of means, sums, medians, etc." Left unsaid is that it does so across level two units.</p>
<p>The basic syntax for collapse is:</p>
<p class="InputCode">collapse (<span class="Parameter">statistic1</span>) <span class="Parameter">varlist1</span> (<span class="Parameter">statistic2</span>) <span class="Parameter">varlist2</span>..., by(<span class="Parameter">level 2 ID</span>)</p>
<p>The various statistics <span class="InputCode">collapse</span> calculates can be found by typing <span class="InputCode">help collapse</span>, but some particularly useful ones are <span class="InputCode">mean</span> (the default), <span class="InputCode">count</span>, and <span class="InputCode">first</span>. By default <span class="InputCode">collapse</span> will replace the current values of each variable with the  statistic it calculates for that variable, but you can have it rename variables with <span class="Parameter">newvar</span><span class="InputCode">=</span><span class="Parameter">oldvar</span>. Just note that <span class="Parameter">oldvar</span> will be removed—as will any variables not listed somewhere in the <span class="InputCode">collapse</span> command.</p>
<p>Suppose you want to reduce the data set of individuals you have now to a data set of households, and for each household you need to know the household income (which you already have), the proportion of household members which are female, and the size of the household. You can do so with the following collapse command:</p>
<p class="InputCode">collapse (first) income (mean) propFemale=female (count) size=person, by(household)</p>
<p>Since <span class="InputCode">income</span> is already a level two variable all you need to do is carry it over into the new data set. <span class="InputCode">(first) income</span> does so by setting the  <span class="InputCode">income</span> statistic to the first value of   <span class="InputCode">income</span> for each household.</p>
<p><span class="InputCode">(mean) propFemale=female</span> takes advantage of the fact that the mean of an indicator variable is the proportion of observations which have a one for it. The statistic is calculated based on the <span class="InputCode">female</span> variable, but the result is called <span class="InputCode">propFemale</span>.</p>
<p>The <span class="InputCode">(count)</span> statistic counts how many observations have a non-missing value of the listed variable. To get the size of the household you want to count all observations, so you can have it count any variable that's never missing. Identifiers (<span class="InputCode">person</span> in this case) are good candidates because they are rarely missing, but you should always check.</p>
<h4>Exercise</h4>
<ol>
<li>Consider the data set <span class="InputCode">reshape4.dta</span>. What is a level one unit? What is a level two unit? What are the level one and level two variables? Reshape it to wide form and then go back to long form. Now convert it to a data set of just countries, with variables <span class="InputCode">meanPop</span> (mean population over the period) and <span class="InputCode">maxCGDP</span> (maximum cgdp over the period). (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_hier2.htm">Solution</a>)</li>
</ol>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-combine.htm">Combining Data Sets</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-groups.htm">Working with Groups</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Researchers: Introduction</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Stata is the most popular program for statistical analysis at
                  the SSCC, as it is extremely powerful and relatively easy
                  to learn. Its straightforward but flexible syntax makes it a
                  good choice for data management, and it implements
                  a very large number of statistical techniques. Stata
                  also has a an extensive user community which has made
                  a great deal of code available, including many
                  additional estimators. We've been quite pleased with Stata at
                  the SSCC, and we think you'll find it extremely useful.</p>
<p>The goal of Stata for Researchers (as opposed to <a href="https://ssc.wisc.edu/sscc/pubs/sfs/">Stata for Students</a>) is to give you a solid
                  foundation that you can  build on to become an expert
                  Stata user. If your goal is  to learn just enough Stata to get
                  you through a particular course you should probably read <a href="https://ssc.wisc.edu/sscc/pubs/sfs/">Stata for Students</a> instead.</p>
<p>There are two different approaches one can take to Stata. One
                  is to use it as an interactive tool: you start Stata, load your
                  data, and start typing or clicking on commands. This can be a good
                  way to explore your data, figure out what you want to do, and
                  check that your programs worked properly. It can also be useful when you're trying to figure out something new because you get immediate feedback. However, interactive
                  work cannot be easily or reliably replicated, or modified if
                  you change your mind. It's also very difficult to recover from
                  mistakes—there's no "undo"
                  command in Stata.</p>
<p>The other approach is to treat Stata as a programming language.
                  In this approach you write your programs, called do files, and
                   run them when they're complete. A do file contains the same  commands
                  you'd type in interactive Stata, but since they're written in a permanent file they can   be debugged or modified and then rerun at will. They also serve as an exact record
                  of how you obtained your results—a lab notebook for
                  the social scientist. Any work you
                  intend to publish or present should be done using do files. Thus
                  this series will for the most part ignore Stata's graphical
                  user interface and prepare you to write do files for
                  research.</p>
<h2>About This Series</h2>
<p>Stata for Researchers contains the following sections:</p>
<ol>
<li><a href="#top">Introduction</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfr-syntax.htm">Usage and Syntax</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfr-do.htm">Do Files</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfr-data.htm">Working With Data</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfr-stats.htm">Statistics</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfr-groups.htm">Working with Groups </a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfr-hier.htm">Hierarchical Data</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfr-combine.htm">Combining Data Sets</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfr-graphics.htm">Graphics</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfr-projects.htm">Project Management</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfr-learning.htm">Learning More</a></li>
</ol>
<p><a id="files" name="files"></a>Some of the articles in this series use example files. If you are on the SSCC network these files can be found in <span class="MenuOutput">X:\SSCC Tutorials\StataResearch</span>. Alternatively, you can <a href="https://ssc.wisc.edu/sscc/pubs/files/StataResearch.zip">download a zip file containing all the example files</a>. Copy these files to a convenient location like <span class="MenuOutput">U:\StataResearch</span> and make that location your current working directory whenever you're doing the examples in this series (we'll show you how shortly).</p>
<p>Each topic includes exercises, and solutions are given for most of them. While many of the exercises are short questions to test your understanding of the material, others require more work and are designed to give you experience working with Stata. If you are currently involved in a research project it may be a better use of your time to get your Stata experience by working on your project. If you get stuck on an exercise it's probably best to move on. On the other hand, you can learn from reading the solutions even if you don't do all the exercises.</p>
<h2>Running Stata at the SSCC</h2>
<p>The SSCC makes Stata available on Winstat, in our computer labs, on Linstat, and through our HTCondor flock. For details about the capabilities of the SSCC's servers see <a href="https://ssc.wisc.edu/sscc/pubs/computing_resources.htm">Computing Resources at the SSCC</a>. Most SSCC members run Stata/MP on Winstat, but some jobs require different resources.</p>
<h3>Stata/MP vs. Stata/MP16</h3>
<p>The SSCC runs Stata/MP, the multi-processor version of Stata. Most of our licenses are for the two processor version of Stata/MP, but we have a small number of the more expensive sixteen processor licenses for use on our servers. Use regular Stata/MP for day-today work, especially writing do files, but feel free to use Stata/MP16 any time you need to run a do file that will take more than a minute or two. You don't have to make any changes to your do files to run them using Stata/MP16. <a href="https://ssc.wisc.edu/sscc/pubs/stata_mp.htm">Running Stata/MP at the SSCC</a> has instructions.</p>
<h3>Windows vs. Linux</h3>
<p>Stata looks and acts the same whether it's running on Windows or Linux (or on a Mac). However, Linstat (the SSCC's Linux computing cluster) has much more memory than Winstat (the SSCC's Windows Terminal Server Farm), and is better suited for long jobs. Running Stata jobs on Linstat is probably easier than you think: read <a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a> to learn how.</p>
<h3>Next: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-syntax.htm">Usage and Syntax</a></h3>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Researchers: Learning More</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This is part eleven of the Stata for Researchers series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Introduction</a>. If you're new to Stata we highly recommend reading the articles in order.</em></p>
<p>Congratulations, you now know enough Stata to get started and do some very useful things. However, you'll almost certainly need to learn more at some point in your Stata career. Thus we'll conclude by discussing resources for doing so.</p>
<h2>Help</h2>
<p> Your first resource is the Stata help files. To see the help for a particular
                  command type <span class="InputCode">help <span class="Parameter">command</span></span>,
                  e.g.</p>
<p class="InputCode">help egen</p>
<p>You'll get a syntax diagram, a brief explanation of the various
                options, and even examples.</p>
<p>In the syntax diagram, optional elements are placed in square brackets. Thus for <span class="InputCode">egen</span> a <span class="InputCode">[type]</span> is optional (if you don't specify a variable type you'll get the default float) while a name for the new variable is mandatory. If part of a word is underlined, that is the minimum abbreviation for that word. Thus in the <span class="InputCode">anycount()</span> function, the <span class="InputCode">values()</span> option could be abbreviated as just <span class="InputCode">v()</span> or as <span class="InputCode">val()</span>, <span class="InputCode">value()</span> etc.</p>
<h2>Help on Functions</h2>
<p>To use a function you need two pieces of information: the input and the output. The inputs, or arguments, are the things that go in parentheses.</p>
<p> For <span class="InputCode">egen</span> functions the inputs will almost always be a single entity, but that entity could be a list of variables (<span class="Parameter">varlist</span>), a single variable (<span class="Parameter">varname</span>) or a mathematical expression (<span class="Parameter">exp</span>), among others. Keep in mind that a single variable counts as an expression.</p>
<p>To get help on general-use functions, type <span class="InputCode">help functions</span> and then click on the type of function you need (for example, string functions). To use these functions you need to find out how many arguments are needed and what they mean. For example, the <span class="InputCode">abbrev()</span> function is listed as <span class="InputCode">abbrev(s,n)</span>, which tells you it takes two arguments. <span class="InputCode">Domain s:     strings</span> and <span class="InputCode">Domain n:     5 to 32</span> tells you the first argument must be a string and the second must be a number between 5 and 32, but they don't have to be called  <span class="InputCode">s</span> or <span class="InputCode">n</span>. The inputs can be variables of the proper types, or quantities you type in. <span class="InputCode">Range:        strings</span> tells you the output is a string, and  <span class="InputCode">Description:  returns s, abbreviated to n characters</span>, along with the longer note below that, tells you what that string will be.</p>
<h2>Findit</h2>
<p>You'll  often know what you want to do but not the
                  name of the command that will do it. Then <span class="InputCode">findit</span> is
                  your best bet—think of it as Google for Stata. For example, suppose you want to do something
                  with Heckman selection models. If you type</p>
<p class="InputCode">findit heckman</p>
<p>you'll get a tremendous amount of information.  First Stata will
                  search the help files and point out that there is a <span class="InputCode">heckman</span> command,
                  along with related commands like <span class="InputCode">suest</span> and <span class="InputCode">treatreg</span>.
                  Then it will search the <a href="http://stata.com/support/faqs/">Frequently Asked Questions files on Stata's
                  web site</a> and the large <a href="http://www.ats.ucla.edu/stat/stata/default.htm">Stata web site at UCLA</a>. Finally
                  it will search through the user-written programs that have appeared
                  in the <a href="http://stata.com/bookstore/sjdetails.html">Stata Journal</a>, the old <a href="http://stata.com/products/stb/">Stata Technical Bulletin</a>, or in
                  the Boston College <a href="http://ideas.repec.org/s/boc/bocode.html">Statistical Software Components</a> archive. You
                can find out what these programs do by reading their help files (<span class="InputCode">.hlp</span>), and if you decide they'll be useful to you you can download and install them by clicking on the <span class="InputCode">click here to install</span> link. See <a href="https://ssc.wisc.edu/sscc/pubs/4-16.htm">Finding and Installing User-Written  		  Stata Programs</a> for more information.</p>
<p>Another useful tool for finding commands is the <span class="MenuOutput">Also see</span> section at the bottom of each help file. If you can think of a command that's close to what you want to do, call up its PDF help file and then see what's related to it.</p>
<h2>Documentation</h2>
<p>More extensive documentation is available as PDF files. For example, click on the <span class="InputCode">heckman</span> command in the <span class="InputCode">findit</span> results to see its help file, then click <span class="InputCode">[R] heckman</span> at the top. This opens the entry for <span class="InputCode">heckman</span> in the <span class="MenuOutput">Reference</span> manual (hence the <span class="InputCode">[R]</span>). This will give you a longer description of what the command does, along with worked out examples and technical information about how the command is implemented. The references  can be a good place to start if you need to learn more about the theory behind the method.</p>
<p>The PDF documentation is also good for general learning about Stata in general, especially the <span class="MenuOutput">User's Guide</span> (sections headings like this—once upon a time they were separate books—are found on the left).  You can open the PDF documentation directly by clicking <span class="MenuOutput">Help</span>, <span class="MenuOutput">PDF Documentation</span>.</p>
<h2>SSCC Resources</h2>
<p>The <a href="https://ssc.wisc.edu/sscc/pubs/stat.htm">SSCC's
                  Knowledge Base</a> has a large section on Stata, including
                  general guides like this one and discussions of specific topics like <a href="https://ssc.wisc.edu/sscc/pubs/4-27.htm">Bootstrapping
                in Stata</a> or <a href="https://ssc.wisc.edu/sscc/pubs/4-23.htm">Using Stata Graphs in Documents</a>. Once you feel confident using Stata's basic syntax, we strongly suggest reading <a href="https://ssc.wisc.edu/sscc/pubs/stata_prog1.htm">Stata Programming Essentials</a>. It will teach you things like how to do the same thing to ten different variables without having to write it out ten times. If you're interested in graphics, be sure to read <a href="https://www.ssc.wisc.edu/sscc/pubs/4-24.htm">An Introduction to Stata Graphics</a>.</p>
<p>The SSCC offer classes on Stata each semester, generally including a class based on this Stata for Researchers series, a class on Stata programming, and at least one class on some other topic—see the <a href="https://www.ssc.wisc.edu/sscc_jsp/training/index.jsp">training
                  web page</a> for details and to register.</p>
<p>Finally, the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">SSCC's statistical consultants</a> are available to assist SSCC members. We cannot write your Stata programs for you.
                  But we will be more than happy to help with planning your project,
                  figuring out the commands that will make your program
                  work, and of course finding and fixing bugs along with consulting on statistical methodology.</p>
<h2>Practice</h2>
<p>The most important resource for learning Stata is practice. If you don't use the skills and knowledge you've gained from reading this series within the next few weeks (at most) you'll lose them rapidly. If you don't have a current research project that will require you to use Stata, make one up.</p>
<p>One particular pitfall to watch out for is "I'll just do it in Excel." It may be true that you can carry out a particular task in Excel faster than you can first learn how to do it in Stata and then actually carry it out. But if you do it in Stata anyway, the next time it comes up you'll be able to do it much more quickly in Stata than in Excel (and more reproducibly, and with less likelihood of error). You'll also build up your general Stata expertise, so that soon you'll be able to do things faster in Stata even if you've never done them before. Now that you've spent the time to learn Stata, plan on never using Excel for research again.</p>
<p>This concludes the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Stata for Researchers</a> series. We hope it has been useful to you, and that your relationship with Stata will be a long and productive one.</p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-do.htm">Do Files and Project Management</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Researchers: Do Files and Project Management</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This is part ten of the Stata for Researchers series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Introduction</a>. If you're new to Stata we highly recommend reading the articles in order.</em></p>
<p>In a typical project you have a research question you want to
                  answer and some data that you think will answer it, but the data
                isn't in a form that can actually answer the question—yet. Project management is about getting from raw data to completed analysis.</p>
<h2>Simple Best Practices</h2>
<p>Books have been written about how to manage research projects properly. While we won't go into that level of detail here, we will suggest a few simple best
                  practices that can save  a tremendous amount of time 
                and reduce the probability of making serious mistakes.</p>
<h3>Master your Data Set</h3>
<p>Everything you do depends on your data set, so spend the time to get to know it well. How was it collected? What does an observation represent? What variables are available? Is there any hierarchy or other structure? Which variables are continuous, categorical, binary or text? How are they distributed? Is there missing data? How much? Is there structure to the missing data ("People who answered X to question Y then skipped to question Z")?</p>
<p>Real mastery (i.e. knowing the answers to most if not all of these questions without having look them up) will come as you're working on your project, but you should spend a significant amount of time learning about the data before you start writing code. Sometimes the answers to these questions can affect the feasibility of your research agenda. For example, crosstabs may reveal that you have too few observations in certain cells to get meaningful results. ("Not enough women with PhDs in science and engineering" can be a statistical problem as well as a social problem!)</p>
<h3>Begin with the End in Mind </h3>
<p>Before you write any code, decide out what form the data
                  needs to be in so you can analyze it. What should an observation
                  represent? What variables will each observation need to contain?
                  The answers to these questions will most likely be determined
                  by the statistical techniques you plan to use. Thinking it through ahead of time will prevent you from spending time putting the data in a form that seems natural, but doesn't actually  meet your needs.</p>
<h3>Don't Try to do Everything at Once</h3>
<p>Once the goal is clear in your mind, don't try to write one massive do file that
                  gets you there in one step, only trying to run it once it's "done."
                  If you do, the do file 
                  will most likely have a large number of bugs. Then you
                  may find that in order to make one part work, you need
                  to do something in a different way than you originally planned.
                  You'll then have to change everything that follows.</p>
<p>It's far better to write a bit of code, test and debug it, then
                  write a little more, test and debug it, and so forth. But if a do file gets too big, you waste  time rerunning old code you know is good in order to test  what you just added.  When that happens it's time to start a new do file.</p>
<h3>Split Your Code into Multiple Do Files</h3>
<p>If a do file gets too long, as you go through the write-test-debug cycle you'll find yourself spending too much time waiting for code you know is good to run so it can move on to the code you just added and need to test. More generally, you want to write do files that are short enough that while you're working on one you can remember everything it does.</p>
<p>To break up a long do file into smaller pieces, just pick a logical stopping point, have the do file save the data set at that point, then create a new do file that uses that data set as its starting point. Just remember: <strong><em>never save your output data set over your input data set.</em></strong><em> </em></p>
<h3>Put Code for Different Purposes in Different Do Files</h3>
<p>While data preparation is a linear process with each step depending on what came before (first recode, then clean...), exploratory analysis often branches out (maybe ordinary linear regression is okay, but I'll try a mixed model too...). Then when you've identified the results you want to report or publish, you want the code that produces them to be as clean, clear, and concise as possible. Thus it's best to have separate do files for each of these purposes.</p>
<p>For most projects there should be a "final" data set that's used for all  analysis. That way you can open it up interactively and try things, write do files that analyze it in different ways, and generally experiment at will without running the risk of forgetting that, for example, the do file that ran the linear regressions also did a bit more recoding.</p>
<h2>Checking your Work</h2>
<p>Programming errors can be subtle and very difficult to catch by just staring at your code. Generally it's more effective to spend your time comparing your results to what they should be. Of course this depends on having some sense of what they should be: be constantly on the lookout for information you can use to check your work.</p>
<p>Examine summary statistics and frequencies frequently as you carry out data preparation, especially when you create new variables or change the structure of your data. See if what you get is plausible. If the results change, be sure you can explain why.</p>
<p>Spend even more time looking at individual cases. Use the <span class="InputCode">browse</span> command, often with a <em>varlist</em> and an <em>if</em> condition to allow you to focus on what's currently relevant, and compare what your do file did to individual cases with what you meant it to do. If you have different types of cases, be sure to look at samples of each.</p>
<p>If you do find problems, looking at cases is the best way to solve them. What kinds of cases get the wrong answers? Which variables are wrong? Figuring out those details will point you to the particular commands that need to be corrected.</p>
<h2>Make your Project Reproducible</h2>
<p>With proper organization you should be able to reproduce your entire project at will.</p>
<p>Start with the data as you obtained it.  Your first
                  do file will  read it in, make some changes, and save the results
                  in a different file. Your second do file will read in the output
                  from the first do file, make further changes, and then save its
                  results in another separate file. Repeat until data preparation is complete. Then all your analysis do files will read the same final data set and analyze it in various ways.</p>
<p>If you discover errors or need to make changes, having a well-organized and reproducible project will save you significant amounts of time. To track down an error, run your do files one-by-one, checking the results after each, until the error appears. Then you'll know which do file needs to be fixed. Once the error is corrected or the change is made, consider whether it will affect subsequent do files. Once all the needed changes are made, simply rerun all your do files.</p>
<p>Consider writing a master do file that runs all the do files required by the project, in the proper order (recall that one do file can run another simply by running the command <span class="InputCode">do otherDoFile</span>). Also write a "readme" document to keep with the project files, containing other relevant information. This will be very valuable to anyone else who has to work with your code, but also to the future you who has to try to remember how it all worked months or years later.                </p>
<h2>Case Studies</h2>
<p>Two stories that illustrate the importance of proper project management:</p>
<p>One day a professor and her research assistant came to the SSCC's statistical consultants. They were working with census data from multiple  countries over many years, so a lot of data preparation work was required to make the various data sets compatible and then combine them. The RA had been working on this data preparation for about six months.</p>
<p>Then the the professor decided to run some basic frequencies on the data they had. The results were clearly wrong. The RA must have made a mistake at some point, and they came to us hoping we'd be able to fix the problem. After some discussion, we found that the RA had been doing all his work interactively. He had only a general recollection of what he had done, and had no do files, logs or intermediate data sets to fall back on. Since everything he had created was useless, the project had to be started again from the original data.</p>
<p>The next time we saw her, the professor had a new RA, one who was very careful to do everything using do files.</p>
<p>On a happier note, a grad student once came to the SSCC's statistical consultants because in preparing to present her research she  discovered that the values of one variable for three observations had somehow been corrupted. Three observations probably wouldn't change her results, but we didn't really know.</p>
<p>Fortunately she had done everything using do files. We got the data from the source again, checked that it was intact this time, and then she re-ran all her do files. Months of work were replicated in less than 15 minutes, and she was able to proceed with her presentation.</p>
<p>Far more could be said about project management (we haven't even mentioned collaborating with others). You might find J. Scott Long's <a href="http://stata.com/bookstore/wdaus.html">Workflow of Data Analysis Using Stata</a> helpful. </p>
<h4>Exercises</h4>
<ol>
<li>
<p>We've looked at how foreign cars and domestic cars differ, but the foreign cars include both European cars and Japanese cars and you might reasonably expect them to differ from each other as well. Classify each car as American, European or Japanese. (Hint: one way to do that would be to identify the manufacturer of each car and then classify the manufacturers.) Then analyze how <span class="InputCode">weight</span>, <span class="InputCode">price</span>, <span class="InputCode">mpg</span> and <span class="InputCode">rep78</span> differ between these categories using whatever statistical techniques you are comfortable with and think are appropriate (or use the ones discussed in <a href="https://ssc.wisc.edu/sscc/pubs/sfr-stats.htm">Basic Statistics</a>). Feel free to ignore the small sample size.</p>
<p>Use good research practices in carrying out this exercise: put all the related files in a singe directory, write at least two do files (one for data work and one for analysis), make them self sufficient, add comments  where needed, etc. For extra credit, once they're complete run them again using Condor.</p></li>
<li>
<p>Consider the data sets <span class="InputCode">finalscores</span> and <span class="InputCode">finaldemo</span>. The first contains fictional scores on standardized tests. The second contains information about the fictional students and their families. Examine how household income, whether the student lives with one parent or both parents, and the maximum education attainment of the student's parents (i.e. the educational attainment of the parent with the most education) predict test scores. Again, use good research practices in carrying out this exercise.</p>
<p>It will be easiest to first create the explanatory variables described using the demographics file, then merge it with the scores. The merge will work best if you drop the non-students first (which you can do once you've figured out what you need to know about the students in their families).</p></li>
<li>Take your current research project and think through it as described above.</li>
</ol>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-learning.htm">Learning More</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-graphics.htm">Graphics</a></p>
<h2></h2>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Researchers: Statistics</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This is part five of the Stata for Researchers series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Introduction</a>. If you're new to Stata we highly recommend reading the articles in order.</em></p>
<p>This article will teach you how to get descriptive statistics, do basic hypothesis testing, run regressions, and carry out some postestimation tasks.  This is a very small sample of Stata's capabilities, but it will give you a sense of how Stata's statistical commands work.</p>
<p>We'll use the auto data set throughout this section. Start a do file as usual:</p>
<p class="InputCode">clear all<br/>
capture log close<br/>
set more off<br/>
log using stats.log, replace<br/>
<br/>
use auto<br/>
<br/>
//real work goes here<br/>
<br/>
log close</p>
<p>Remember the code you add goes after <span class="InputCode">use auto</span> and before <span class="InputCode">log close</span>.</p>
<h2><a id="GeneralInformation" name="GeneralInformation"></a>General Information</h2>
<p>A good place to start with any new data set is <span class="InputCode">describe</span>. This gives you information about the data set, including the amount of memory it needs and a list of all its variables and their types and labels. Especially watch out for value labels. If you have a large data set and only need information about a few of them, you can give <span class="InputCode">describe</span> a <em>varlist</em>:</p>
<p class="InputCode">describe foreign</p>
<p>For more information about your variables try the <span class="MenuOutput">Properties</span> window or the <span class="MenuOutput">Variables Manager</span> (third button from the right or type <span class="InputCode">varman</span>).</p>
<h2><a id="SummaryStatistics" name="SummaryStatistics"></a>Summary Statistics</h2>
<p><span class="InputCode">summarize</span> (<span class="InputCode">sum</span>)
           	    gives you summary statistics. If you just type:</p>
<p class="InputCode">sum</p>
<p>you will get basic summary statistics for all the variables in
                  your data set. Note
                  that there is nothing for <span class="InputCode">make</span>:
                  it is a string variable so summary statistics don't make sense. Also note that for <span class="InputCode">rep78</span> the number of observations is 69 rather than 74. That's because the five missing values were ignored and the summary statistics calculated over the remaining 69. Most statistical commands take a similar approach to missing values and that's usually what you want, so you rarely have to include special handing for missing values in statistical commands.</p>
<p>All the syntax elements you learned earlier also work with statistical commands. To get summary statistics for just <span class="InputCode">mpg</span>, give <span class="InputCode">sum</span> a <em>varlist</em>:</p>
<p class="InputCode">sum mpg</p>
<p> If you want summary statistics for just the foreign cars, add an <em>if</em> condition:</p>
<p class="InputCode">sum mpg if foreign</p>
<p>If you want summary statistics of <span class="InputCode">mpg</span> for both foreign and domestic cars,  calculated separately, use <em>by</em>:</p>
<p class="InputCode">by foreign: sum mpg</p>
<p>The <span class="InputCode">detail</span> (<span class="InputCode">d</span>) <em>option</em> will give more information.
                Try:</p>
<p class="InputCode">sum mpg, d</p>
<p></p>
<p></p>
<h2><a id="Frequencies" name="Frequencies"></a>Frequencies</h2>
<p><span class="InputCode">tabulate</span> (<span class="InputCode">tab</span>)
           	    will create tables of frequencies. If you give it a <em>varlist</em> with one variable it will give you a one-way table, while if you give it two variables it will give you a two-way table (i.e. crosstabs). To get an idea of what <span class="InputCode">tab</span> does, try:</p>
<p class="InputCode">tab rep78<br/>tab rep78 foreign</p>
<p>Tables are usually easier to read if the variable with the most
                unique values comes first, so they're listed vertically.</p>
<p></p>
<p>Note that the missing values of <span class="InputCode">rep78</span> were ignored. If you'd like them to have their own entry, add the <span class="InputCode">missing</span> option:</p>
<p class="InputCode">tab rep78, missing</p>
<p> The <span class="InputCode">tab</span> command won't accept more
            	than two variables, but you can create three-way or higher tables
            	by combining <span class="InputCode">tab</span> with <em>by:</em>.</p>
<p class="InputCode">by foreign: tab headroom rep78</p>
<p></p>
<p>To get percentages, add the <span class="InputCode">row</span>, <span class="InputCode">column</span> or <span class="InputCode">cell</span> options:</p>
<p class="InputCode">tab rep78 foreign, row column cell</p>
<p>For this table, <span class="InputCode">row</span> answers the question "What percentage of the cars with a <span class="InputCode">rep78</span> of one are domestic?" while <span class="InputCode">column</span> answers "What percentage of the domestic cars have a <span class="InputCode">rep78</span> of one?" and <span class="InputCode">cell</span> answers "What percentage of all the cars are both domestic and have a <span class="InputCode">rep78</span> of one?"</p>
<p><span class="InputCode">tab</span> has an <em>option</em> called <span class="InputCode">sum</span> which
            	gives summary statistics for a given variable, calculated over the observations in each cell of the table. Try: </p>
<p class="InputCode">tab foreign, sum(mpg)</p>
<p>There's also a <span class="InputCode">chi2</span> option that
                runs a chi-squared test on a two-way table: </p>
<p class="InputCode">tab rep78 foreign, chi2</p>
<h2><a id="Correlations" name="Correlations"></a>Correlations</h2>
<p><span class="InputCode">correlate</span> (<span class="InputCode">cor</span>) calculates correlations:</p>
<p class="InputCode">cor weight length mpg</p>
<p>If you need covariances instead, add the <span class="InputCode">cov</span> option:</p>
<p class="InputCode">cor weight length mpg, cov</p>
<h2><a id="HypothesisTestsofMeans" name="HypothesisTestsofMeans"></a>Hypothesis Tests of Means</h2>
<p><span class="InputCode">ttest</span>  tests hypotheses about means. To test whether the mean of a variable is equal to a given number,  type <span class="InputCode">ttest </span><span class="Parameter">var</span><span class="InputCode">==</span><span class="Parameter">number</span>:</p>
<p class="InputCode">ttest mpg==20</p>
<p>To test whether two variables have the same mean, type <span class="InputCode">ttest </span><span class="Parameter">var1</span><span class="InputCode">==</span><span class="Parameter">var2</span>:</p>
<p class="InputCode">ttest mpg==weight</p>
<p>To test whether two subsamples of your data have the same mean for a given variable, use the <span class="InputCode">by()</span> <em>option</em>:</p>
<p class="InputCode">ttest mpg, by(foreign)</p>
<h2>Exercises</h2>
<ol>
<li>Find the mean value of <span class="InputCode">weight</span> for cars with <span class="InputCode">mpg</span> greater than 25. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_stats_desc1.htm">Solution</a>)</li>
<li>Test the hypothesis that cars with <span class="InputCode">mpg</span>&gt;25 have a lower mean weight than cars with <span class="InputCode">mpg</span>&lt;=25. You'll have to create a new variable to do so. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_stats_desc3.htm">Solution</a>)</li>
</ol>
<h2><a id="ReturnedResults" name="ReturnedResults"></a>Returned Results</h2>
<p>Most statistical commands also save their results so that you can use them in subsequent commands. You can see what is saved with the <span class="InputCode">return list</span> command. To see a typical example, try:</p>
<p class="InputCode">sum mpg<br/>
  return list</p>
<p>These saved results are often referred to as the <em>r vector</em>.</p>
<p>Suppose you want to center <span class="InputCode">mpg</span> around zero, by subtracting the mean value from all observations. Running <span class="InputCode">sum mpg</span> puts the mean of mpg in the <em>r vector</em>, and then you can create a centered version of <span class="InputCode">mpg</span> with:</p>
<p class="InputCode">gen mpgCentered=mpg-r(mean)</p>
<p>Check your results with:</p>
<p class="InputCode">sum mpgCentered</p>
<p>The mean isn't quite zero due to round-off error, but it's as close as a computer can get.</p>
<p> If you type:</p>
<p class="InputCode">return list</p>
<p>again, you'll see that the tables of the <em>r vector</em> have changed. It only contains the results of the most recent command, so if you need to use any of those results be sure to do so (or store them in variables) before running any other commands that use the <em>r vector</em>.</p>
<p>To  standardize <span class="InputCode">mpg</span> you could take <span class="InputCode">mpgCentered</span> and divide by <span class="InputCode">r(sd)</span>. However, there's an <span class="InputCode">egen</span> function called <span class="InputCode">std()</span> that will do the entire process for you.</p>
<h4>Exercise</h4>
<ol>
<li>Find the Interquartile Range of <span class="InputCode">mpg</span> (i.e. the difference between the 75th percentile and the 25th percentile). Recall that <span class="InputCode">sum</span> with the <span class="InputCode">details</span> option calculates various percentiles. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_stats_res1.htm">Solution</a>)</li>
</ol>
<p></p>
<h2><a id="Regression" name="Regression"></a>Regression</h2>
<p>Stata has many, many commands for doing various kinds of regressions, but its developers worked  hard to make them all as
            	 similar as possible. Thus if you can do a simple linear regression you can do all sorts of more complex models.</p>
<h3>Linear Regression</h3>
<p>The <span class="InputCode">regress</span> (<span class="InputCode">reg</span>) command does linear regression. It always needs a <em>varlist</em>, and it uses it in a particular way: the first variable
                  is the dependent variable, and it is regressed on all the others
                in the list plus a constant (unless you add the <span class="InputCode">noconstant</span> <span class="italic">option</span>).</p>
<p>Let's estimate how much consumers were willing to pay for good gas
                  mileage in 1978 using a naive "hedonic pricing" model (i.e., we'll presume the price depends on the characteristics of the car). Whether
                  a car is foreign or domestic seems to be important, so throw
                that in as a covariate too. Type: </p>
<p class="InputCode">regress price mpg foreign</p>
<p>This regresses <span class="InputCode">price</span> on <span class="InputCode">mpg</span> and <span class="InputCode">foreign</span>.  The negative and highly significant coefficient on <span class="InputCode">mpg</span> suggests that American
                  consumers in 1978 disliked fuel efficiency, and would pay to avoid it!</p>
<p>Like any good researcher, when our empirical results contradict
            	 our theory (or common sense) we first look for better empirical results. We might
            	possibly have some missing variable bias here; in particular it's probably
            	important to control for the size of the car by adding <span class="InputCode">weight</span> to the regression:</p>
<p class="InputCode">reg price mpg foreign weight</p>
<p>Now <span class="InputCode">mpg</span> is insignificant but <span class="InputCode">weight</span> is positive and highly significant. Looks like American consumers in 1978 liked big cars and didn't 
                  care about fuel efficiency, a much more plausible result.</p>
<h3>Logistical Regression</h3>
<p>Logistical regression is just as easy to run, but we need a binary dependent variable. Make an indicator variable <span class="InputCode">goodRep</span> which is one for cars with <span class="InputCode">rep78</span> greater than three (and missing if <span class="InputCode">rep78</span> is missing):</p>
<p class="InputCode">gen goodRep=(rep78&gt;3) if rep78&lt;.</p>
<p>Now let's examine what predicts a car's repair record. We'll include <span class="InputCode">mpg</span>, <span class="InputCode">displacement</span> and <span class="InputCode">gear_ratio</span> because they're the only technical data we have about the car's engine (the most likely thing to break), <span class="InputCode">weight</span> as a measure of load on the engine, and <span class="InputCode">price</span> and <span class="InputCode">foreign</span> just because they seem to be important characteristics of a car.</p>
<p>The <span class="InputCode">logit</span> command runs logistical regression. The syntax is identical to regress:                </p>
<p class="InputCode">logit goodRep mpg displacement gear_ratio weight price foreign</p>
<p>If you prefer odds ratios to coefficient add the <span class="InputCode">or</span> <em>option</em>. Just be sure to interpret them properly, as well discuss later. The fact that logit models are easy to run often masks the fact that they can be extremely difficult to interpret.</p>
<h3><a id="CategoricalFactorVariables" name="CategoricalFactorVariables"></a>Categorical (Factor) Variables</h3>
<p>Consider the variable <span class="InputCode">rep78</span>: it is a measure of the car's repair record and takes on the values one through five (plus a few missing values). However, these numbers only represent categories—a car with a <span class="InputCode">rep78</span> of five is not five times better  than a car with a <span class="InputCode">rep78</span> of one. Thus it would make no sense to include <span class="InputCode">rep78</span> in a regression as-is. However, you might want to include a set of indicator variables, one for each value of <span class="InputCode">rep78</span>. This is even more important for categorical variables with no underlying order, like race. Stata can create such indicator variables for you "on the fly"; in fact you can treat them as if they were always there.</p>
<p>The set of indicator variables representing a categorical variable is formed  by putting <span class="InputCode">i.</span> in front of the variable's name. This works in most (but not  all) <em>varlists</em>. To see how it works, try:</p>
<p class="InputCode">list rep78 i.rep78</p>
<p>As you see, <span class="InputCode">3.rep78</span> is one if <span class="InputCode">rep78</span> is three and zero otherwise. The other indicators are constructed in the same way. <span class="InputCode">1b.rep78</span> is a special case: it is the base category, and always set to zero to avoid the "dummy variable trap" in regressions. If <span class="InputCode">rep78</span> is missing, all the indicator variables are also missing. </p>
<p>If you want to choose a different category as the base, add <span class="InputCode">b</span> and then the number of the desired base category to the <span class="InputCode">i</span>:</p>
<p class="InputCode">list rep78 ib3.rep78</p>
<p>Now try using <span class="InputCode">i.rep78</span> in a regression:</p>
<p class="InputCode">reg price weight foreign i.rep78</p>
<p>The coefficients for each value of <span class="InputCode">rep78</span> are interpreted as the expected change in <span class="InputCode">price</span> if a car moved to that value of <span class="InputCode">rep78</span> from the base value of one. If you change the base category:</p>
<p class="InputCode">reg price weight ib3.rep78</p>
<p>the model is the same, but the coefficients are now the expected change in <span class="InputCode">price</span> if a car moves to that value of <span class="InputCode">rep78</span> from a <span class="InputCode">rep78</span> of three. You can verify that the models are equivalent by noting that the coefficients in the second model are just the coefficients of the first model minus the coefficient for <span class="InputCode">3.rep78</span> from the first model.</p>
<p>You don't have to use the full set of indicators. For example, you could pick out just the indicator for <span class="InputCode">rep78</span> is five with:</p>
<p class="InputCode">reg price weight 5.rep78</p>
<p>This has the effect of collapsing all the other categories into a single category of "not five."</p>
<p>Indicator variables are, in a sense, categorical variables. Marking them as such will not affect your regression output; you'll get the same results from:</p>
<p class="InputCode">reg price weight ib3.rep78 foreign</p>
<p>as from:</p>
<p class="InputCode">reg price weight ib3.rep78 i.foreign</p>
<p>However, the latter tells Stata that <span class="InputCode">foreign</span> is not continuous, which is very important to some postestimation commands.  However, if you're not planning to run <span class="InputCode">margins</span> or some other postestimation command that cares about this distinction, putting <span class="InputCode">foreign</span> in your model rather than <span class="InputCode">i.foreign</span> is just fine.</p>
<h3><a id="Interactions" name="Interactions"></a>Interactions</h3>
<p>You can add interactions between variables by putting two pound signs between them:</p>
<p class="InputCode">reg price weight foreign##rep78</p>
<p>The two pound signs means "include the main effects of <span class="InputCode">foreign</span> and <span class="InputCode">rep78</span> and their interactions." Two variables with one pound sign between them refers to just their interactions. It's almost always a mistake to include interactions in a regression without the main effects, but you'll need to talk about the interactions alone in some postestimation commands.</p>
<p>The variables in an interaction are assumed to be categorical unless you say otherwise. Thus the above model includes everything in:</p>
<p class="InputCode">reg price weight i.foreign i.rep78</p>
<p>What it adds is a new set of indicator variables, one for each unique combination of <span class="InputCode">foreign</span> and <span class="InputCode">rep78</span>. This allows the model to see, for example, whether the effect of having a <span class="InputCode">rep78</span> of five is different for foreign cars than for domestic cars.</p>
<p>Note that while Stata chose <span class="InputCode">rep78==1</span> for its base category, it had to drop the <span class="InputCode">rep78==5</span> category for foreign cars because no foreign cars have a <span class="InputCode">rep78</span> of one. If you'd prefer that it drop the same category for both types of cars, choose a different base category:</p>
<p class="InputCode">reg price weight foreign##ib3.rep78</p>
<p>To form interactions involving a continuous variable,  use the same syntax but put <span class="InputCode">c.</span> in front of the continuous variable's name:</p>
<p class="InputCode">reg price foreign##c.weight i.rep78</p>
<p>This allows the effect of <span class="InputCode">weight</span> on <span class="InputCode">price</span> to be different for foreign cars than for domestic cars (i.e. they can have different slopes).</p>
<p>The <span class="InputCode">##</span> symbol is an operator just like <span class="InputCode">+</span> or <span class="InputCode">-</span>, so you can use parentheses  with the usual rules:</p>
<p class="InputCode">reg price foreign##(c.weight rep78)</p>
<p>This interacts <span class="InputCode">foreign</span> with both <span class="InputCode">weight</span> and <span class="InputCode">rep78</span>. The latter is automatically treated as a categorical variable since it appears in an interaction and does not have <span class="InputCode">c.</span> in front of it.</p>
<p>Interactions are formed by multiplication: to form an indicator for "car is foreign and has a rep78 of 5" multiply an indicator for "car is foreign" by an indicator for "car has a rep78 of 5." But this is not limited to indicators:</p>
<p class="InputCode">reg price c.weight##c.weight</p>
<p>This regresses <span class="InputCode">price</span> on <span class="InputCode">weight</span> and weight squared, allowing you to consider non-linear effects of <span class="InputCode">weight</span> (at least second order Taylor series approximations to them). You could estimate the same model with:</p>
<p class="InputCode">gen weightSquared=weight^2<br/>
                  reg price weight weightSquared</p>
<p>Specifying the model using interactions is shorter, obviously. But it also (again) helps postestimation commands understand the structure of the model.</p>
<h4>Exercises</h4>
<ol>
<li>The product of <span class="InputCode">weight</span> and <span class="InputCode">mpg</span> measures how many pounds a car's engine can move one mile using one gallon of gasoline, and is thus a measure of the efficiency of the engine independent of the car it's placed in. Regress the <span class="InputCode">price</span> of a car on this product and the main effects of <span class="InputCode">weight</span> and <span class="InputCode">mpg</span>. Form the product of <span class="InputCode">weight</span> and <span class="InputCode">mpg</span> using interactions, not <span class="InputCode">gen</span>. Hint: if you get an error message, read it carefully. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_stats_cat1.htm">Solution</a>)</li>
<li>Suppose I argued that "The efficiency of an engine in terms of pound-miles per gallon is an attribute of the engine, not an interaction. Thus I don't need to include the main effects of <span class="InputCode">weight</span> and <span class="InputCode">mpg</span>." Run that model, then explain how the results of that model compared to  one that includes main effects of  <span class="InputCode">weight</span> and <span class="InputCode">mpg</span> (i.e. the model from exercise 1) show that this argument is wrong. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_stats_cat2.htm">Solution</a>)</li>
</ol>
<h2><a id="Postestimation" name="Postestimation"></a>Postestimation</h2>
<p>Estimation commands store values in the <em>e vector</em>, which can be viewed with the <span class="InputCode">ereturn list</span> command. Try:</p>
<p class="InputCode">reg price c.weight##c.weight i.foreign i.rep78 mpg displacement<br/>
  ereturn list </p>
<p>Most of these results are only of interest to advanced Stata users, with one important exception.</p>
<p>The <span class="InputCode">e(sample)</span> function tells you whether a particular observation was in the sample used for the previous regression. It is 1 (true) for observations that were included and 0 (false) for observations that were not. In this case, the five observations with missing values of <span class="InputCode">rep78</span> were excluded. <span class="InputCode">e(sample)</span> can be very useful if you think missing data may be causing problems with your model. For example, you could type:</p>
<p class="InputCode">tab foreign if e(sample)</p>
<p>to check which values of <span class="InputCode">foreign</span> actually appear in the data used in the regression. Or:</p>
<p class="InputCode">sum mpg if e(sample)<br/>
  sum mpg if !e(sample)</p>
<p>will tell you if the mean value of <span class="InputCode">mpg</span> is different for the observations used than for the observations not used, which could indicate that the data are not missing at random.</p>
<p>Regression coefficients are stored in the <span class="InputCode">e(b)</span> matrix. We won't discuss working with matrices, but they are also available as <span class="InputCode">_b[</span><span class="Parameter">var</span><span class="InputCode">]</span> (e.g. <span class="InputCode">_b[mpg]</span>). Standard errors are available as <span class="InputCode">_se[</span><span class="Parameter">var</span><span class="InputCode">]</span>.</p>
<p>Most of the time you won't use the <em>e vector</em> directly. Instead you'll use Stata's postestimation commands and let them work with the <em>e vector</em>. We'll cover just a small sample of them.</p>
<h3 id="test">Hypothesis Tests on Coefficients</h3>
<p>The <span class="InputCode">test</span> command tests hypotheses about the model coefficients. The syntax is just <span class="InputCode">test</span> plus a list of hypotheses, which are tested jointly. In setting up hypotheses, the name of a variable is taken to mean the coefficient on that variable. If you just give the name of a variable without comparing it to something, <span class="InputCode">test</span> will assume you want to test the hypothesis that that variable's coefficient is zero. The command:</p>
<p class="InputCode">test mpg displacement</p>
<p>tests the hypothesis that the coefficients on <span class="InputCode">mpg</span> and<span class="InputCode"> displacement </span>are jointly zero. If you want to jointly test more complicated hypotheses, put each hypothesis in parentheses:</p>
<p class="InputCode">test (mpg==-50) (displacement==5)</p>
<p>For factor variables, indicate which level you want to test by putting the number before the variable, followed by a period:</p>
<p class="InputCode">test 1.foreign=3000</p>
<p>For interactions, use the variable name itself to refer to the main effect, and  the interaction specified with one pound sign for the interaction term:</p>
<p class="InputCode">test weight c.weight#c.weight</p>
<p>You can have variables on both sides of the equals sign:</p>
<p class="InputCode">test weight=mpg</p>
<p>This is equivalent to (and will be recast as):</p>
<p class="InputCode">test weight-mpg==0</p>
<h3 id="predict">Predicted Values</h3>
<p>The <span class="InputCode">predict</span> command puts the model's predicted values in a variable:</p>
<p class="InputCode">predict phat</p>
<p>("hat" refers to the circumflex commonly used to denote estimated values). You can calculate residuals with the <span class="InputCode">residuals</span> <em>option</em>:                </p>
<p class="InputCode">predict res, residuals</p>
<p> You can change your data between running the model and making the predictions, which means you can look at counterfactual scenarios like "What if all the  cars were foreign?" See <a href="https://ssc.wisc.edu/sscc/pubs/4-22.htm">Making
       			Predictions with Counter-Factual Data in Stata</a> for some examples. However, it's usually easier to do that kind of thing using <span class="InputCode">margins</span>.</p>
<h3 id="margins">Margins</h3>
<p>The <span class="InputCode">margins</span> command is a very useful tool for exploring what your regression results mean.</p>
<p>If you just type:</p>
<p class="InputCode">margins</p>
<p>all by itself, Stata will calculate the predicted value of the dependent variable for each observation, then report the mean value of those predictions (along with the standard error, t-statistic, etc.).</p>
<p>If margins is followed by a categorical variable, Stata first identifies all the levels of the categorical variable. Then, for each value it calculates what the mean predicted value of the dependent variable <em>would be</em> if all observations had that value for the categorical variable. All other variables are left unchanged. Thus:</p>
<p class="InputCode">margins foreign</p>
<p>first asks, "What would the mean price be if all the cars were domestic?" (but still had their existing weights, displacements, etc.) and then asks "What would the mean price be if all the cars were foreign?"</p>
<p class="InputCode">margins rep78</p>
<p>does the same for all five values of <span class="InputCode">rep78</span>, but since there are so many of them it's a good candidate for a graphical presentation. The <span class="InputCode">marginsplot</span> command takes the results of the previous <span class="InputCode">margins</span> command and turns them into a graph:</p>
<p class="InputCode">marginsplot</p>
<p>For continuous variables <span class="InputCode">margins</span> obviously can't look at all possible values, but you can specify which values you want to examine with the <span class="InputCode">at</span> option:</p>
<p class="InputCode">margins, at(weight=(2000 4000))</p>
<p>This calculates the mean predicted value of <span class="InputCode">price</span> with <span class="InputCode">weight</span> set to 2000 pounds, and then again with <span class="InputCode">weight</span> set to  4000 pounds. Think of each value as a "scenario"—the above scenarios are very simple, but you can make much more complicated scenarios by listing multiple variables and values in the <span class="InputCode">at</span> option. The <span class="InputCode">margins</span> output first assigns a number to each scenario, then gives their results by number.</p>
<p> The values are specified using a <em>numlist</em>. A <em>numlist</em> is a list of numbers just like a <em>varlist</em> is a list of variables and, like a <em>varlist,</em> there are many different ways to define a <em>numlist</em>. Type <span class="InputCode">help numlist</span> to see them all. The simplest method is just to list the numbers you want, as above. We'll learn one more version, which is <span class="Parameter">start</span><span class="InputCode"> (</span><span class="Parameter">interval</span><span class="InputCode">)</span><span class="Parameter"> end</span>:</p>
<p class="InputCode">margins, at(weight=(1500 (500) 5000))</p>
<p>This calculates the mean predicted value of <span class="InputCode">price</span> with <span class="InputCode">weight</span> set to 1500,  2000, 2500, etc. up to 5000. (The actual weights range from 1760 to 4840.) Again, this is a good candidate for a graphic:</p>
<p class="InputCode">marginsplot</p>
<p>If you want to look at the marginal effect of a covariate, or the derivative of the mean predicted value with respect to that covariate, use the <span class="InputCode">dydx</span> option:</p>
<p class="InputCode">margins, dydx(mpg)</p>
<p>In this simple case, the derivative is just the coefficient on<span class="InputCode"> mpg</span>, which will always be the case for a linear model. But consider changing <span class="InputCode">weight</span>: since the model includes both <span class="InputCode">weight</span> and weight squared you have to take into account the fact that both change. This case is particularly confusing (but not unusual) because the coefficient on <span class="InputCode">weight</span> is negative but the coefficient on weight squared is positive. Thus the  net effect of changing <span class="InputCode">weight</span> for any given car will very much depend on its starting weight.</p>
<p>The <span class="InputCode">margins</span> command can very easily tell you the mean effect:</p>
<p class="InputCode">margins, dydx(weight)</p>
<p>What <span class="InputCode">margins</span> does here is take the numerical derivative of the  expected <span class="InputCode">price</span> with respect to <span class="InputCode">weight</span> for each car, and then calculates the mean. In doing so, <span class="InputCode">margins</span> looks at the actual data. Thus it considers the effect of changing the Honda Civic's weight from 1,760 pounds as well as changing the Lincoln Continental's from 4,840 (the weight squared term is more important with the latter than the former). It then averages  them along with all the other cars to get its result of 2.362865, or that each additional pound of <span class="InputCode">weight</span> increases the mean expected <span class="InputCode">price</span> by $2.36.</p>
<p>To see how the effect of <span class="InputCode">weight</span> changes as <span class="InputCode">weight</span> changes, use the <span class="InputCode">at</span> option again and then plot the results:</p>
<p class="InputCode">margins, dydx(weight) at(weight=(1500 (500) 5000))<br/>
marginsplot</p>
<p>This tells us that for low values of weight (less than about 2000), increasing weight actually reduces the price of the car. However, for most cars increasing weight increases price.</p>
<p>The <span class="InputCode">dydx</span> option also works for binary variables:</p>
<p class="InputCode">margins, dydx(foreign)</p>
<p>However, because <span class="InputCode">foreign</span> was entered into the model as <span class="InputCode">i.foreign</span>, <span class="InputCode">margins</span> knows that it cannot take the derivative with respect to <span class="InputCode">foreign</span> (i.e. calculate what would happen if all the cars became slightly more foreign). Thus it reports the difference between the scenario where all the cars are foreign and the scenario where all the cars are domestic. You can verify this by running:</p>
<p class="InputCode">margins foreign</p>
<p>and doing the subtraction yourself.</p>
<h3 id="marginslogit">Binary Outcome Models and Predicted Probabilities</h3>
<p>The <span class="InputCode">margins</span> command becomes even more useful with binary outcome models because they are always nonlinear. Clear the <span class="InputCode">auto</span> data set from memory and then load <span class="InputCode">grad</span>:</p>
<p class="InputCode">clear<br/>
                  use grad
                </p>
<p>This is a fictional data set consisting of 10,000 students. Exactly one half of them are "high socioeconomic status" (<span class="InputCode">highSES</span>) and one half are not. Exactly one half of each group was given an intervention, or "treatment" (<span class="InputCode">treat</span>) designed to increase the probability of graduation. The <span class="InputCode">grad</span> variable tells us whether they did in fact graduate. Your goals are to determine 1) whether the treatment made any difference, and 2) whether the effect of the treatment differed by socioeconomic status (SES).</p>
<p>You can answer the first question with a simple logit model:</p>
<p class="InputCode">logit grad treat highSES</p>
<p>The coefficient on <span class="InputCode">treat</span> is positive and significant, suggesting the intervention did increase the probability of graduation. Note that <span class="InputCode">highSES</span> had an even bigger impact.</p>
<p>Next examine whether the effect depends on SES by adding an interaction between the two:</p>
<p class="InputCode">logit grad treat##highSES</p>
<p>The coefficient on <span class="InputCode">treat#highSES</span> is not significantly different from zero. But does that really mean the treatment had exactly the same effect regardless of SES?</p>
<p>Binary outcomes are often interpreted in terms of odds ratios, so repeat the previous regression with the <span class="InputCode">or</span> <em>option</em> to see them:</p>
<p class="InputCode">logit grad treat##highSES, or</p>
<p>This tells us that the odds of graduating if you are treated are approximately 2.83 times the odds of graduating if you are not treated, regardless of your SES. Researchers sometimes confuse odds ratios with probability ratios; i.e. they say you are 2.83 times more "likely" to graduate if you are treated. This is incorrect.</p>
<p>If you ask <span class="InputCode">margins</span> to examine the interaction between two categorical variables, it will create scenarios for all possible combinations of those variables. You can use this to easily obtain the predicted probability of graduation for all four possible scenarios (high SES/low SES, treated/not treated):</p>
<p class="InputCode">margins highSES#treat</p>
<p>For low SES students, treatment increases the predicted probability of graduation from about .49 to about .73. For high SES students, treatment increases the predicted probability of graduation from about .96 to about .98. Now, if you plug those probabilities  into the formula for calculating the odds ratio, you will find that the odds ratio is 2.83 in both cases (use the full numbers from the <span class="InputCode">margins</span> output, not the two digit approximations given here). Treatment adds the same amount to the linear function that is passed through the logistic function in both cases. But recall the <em>shape</em> of the logistic function:</p>
<p><img alt="Graph of logistic function, with four possible scenarios marked" height="446" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfr/logit.png" width="631"/></p>
<p>The treatment has a much smaller effect on the probability of graduation for high SES students because their probability is already very high—it can't get much higher. Low SES students are in the part of the logistic curve that slopes steeply, so  changes in the linear function have much larger effects on the predicted probability.</p>
<p>The <span class="InputCode">margins</span> command can most directly answer the question "Does the effect of the treatment vary with SES?" with a combination of <span class="InputCode">dydx()</span> and <span class="InputCode">at()</span>:</p>
<p class="InputCode">margins, dydx(treat) at(highSES=(0 1))</p>
<p></p>
<p>(You can also do this with <span class="InputCode">margins highSES, dydx(treat)</span>.) Once again, these are the same numbers you'd get by subtracting the levels obtained above. We suggest always looking at levels as well as changes—knowing where the changes start from gives you a much better sense of what's going on.</p>
<p>What if you just ran:</p>
<p class="InputCode">margins, dydx(treat)</p>
<p>This examines the change in predicted probability due to changing the <span class="InputCode">treat</span> variable, but <span class="InputCode">highSES</span> is not specified so margins uses the actual values of <span class="InputCode">highSES</span> in the data and takes the mean across observations. Since our sample is about one half high SES and one half low, the mean change is 1/2 times the change for highSES students plus 1/2 times the change for low SES students. But if a sample had a different proportion of high and low SES students, this number would be very different. Any time the <span class="InputCode">margins</span> command does not specify values for all the variables in the underlying regression model, the result will only be valid for populations that are similar to the sample.</p>
<p>It's a general rule that it's easiest to change the predicted probability for  subjects who are "on the margin;" i.e. those whose predicted probability starts near 0.5. However, this is a property of the logistic function, not the data. It is an assumption you make when you choose to run a logit model.</p>
<h4>Exercises</h4>
<ol>
<li>Try regressing <span class="InputCode">price</span> on <span class="InputCode">weight</span>, <span class="InputCode">foreign</span> and <span class="InputCode">rep78</span>, ignoring the fact that <span class="InputCode">rep78</span> is a categorical variable. Then regress <span class="InputCode">price</span> on <span class="InputCode">weight</span>, <span class="InputCode">foreign</span> and <span class="InputCode">i.rep78</span>. Use the second model to test the hypothesis that the first model is right. (Hint: if it is right, what should the coefficients on the <span class="InputCode">i.rep78</span> indicator variables in the second model be?) (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_stats_reg1.htm">Solution</a>)</li>
<li>Consider the final example of students and the treatment intended to increase the probability of graduation. Assume that these are the results from the first year of the program, and you are now deciding what to do in the second year. You can only give the treatment to one half of all the students, but you can choose which ones. If you are the superintendent of schools and will be evaluated based on your students' graduation rate, who do you want to give the treatment to? If you are the person administering the treatment program and will be evaluated based on the graduation rate of the students you treat, who do you want to give the treatment to? If you are the parent of a child in the district, who do you want to give the treatment to?</li>
</ol>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-groups.htm">Working with Groups</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-data.htm">Working With Data</a></p>
<h2></h2>
<p></p>
<h2></h2>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/sfr/logit.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Researchers: Usage and Syntax</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This is part two of the Stata for Researchers series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Introduction</a>. If you're new to Stata we highly recommend reading the articles in order.</em></p>
<p>This article will introduce Stata's user interface and teach you its basic syntax. Understanding Stata's syntax is the key to becoming an expert Stata user.</p>
<h2>Running Stata</h2>
<p>To start Stata on Winstat or another Windows computer, click the Windows logo button, <span class="MenuOutput">All Programs</span>, <span class="MenuOutput">Stata 14</span> and then <span class="MenuOutput">Stata MP 14</span>. On Linstat, type <span class="InputCode">xstata</span>.                </p>
<h2>Stata's User Interface</h2>
<p>When you start up Stata, the first thing you'll see is the main user interface window. </p>
<table border="0" class="noBorder">
<tr>
<td><img alt="" height="478" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfr/ui2.png" width="768"/></td>
</tr>
</table>
<p>Most of it is self-explanatory. A few tricks that will make you more efficient:</p>
<ul>
<li>Press <span class="InputCode">Page Up</span> to retrieve your last command; press it more than once to retrieve earlier commands.</li>
<li>Click on a command in the <span class="MenuOutput">Review</span> window and it will be pasted into the <span class="MenuOutput">Command</span> window for editing. Double click on a command and it will be executed again.</li>
<li>If you decide something you did interactively was useful enough to preserve, right-click on the commands in the <span class="MenuOutput">Review</span> window, choose <span class="MenuOutput">Send selected to Do-file Editor</span>, edit as needed, and then save.</li>
<li>If you start typing the name of a variable and then press <span class="InputCode">Tab</span>, Stata will fill in the rest of the variable name if you've typed in enough for Stata to identify it.</li>
<li>Click on a variable name in the <span class="MenuOutput">Variables</span> window and it will be pasted into the <span class="MenuOutput">Command</span> window at the current location of the cursor.</li>
<li>Press <span class="InputCode">q</span> or click on the circled-X button at the top to interrupt a command in progress (the button turns red when something is running)</li>
<li>Use the <span class="MenuOutput">Properties</span> window do learn about your data set, the individual variables it contains, and how much memory Stata is using. Stata must load your entire data set into memory, but if you try to use more memory than your computer has Windows will use disk space as memory and Stata will become extremely slow.</li>
</ul>
<p>Start up Stata on the computer you're using. You should be seeing 
                the graphical user interface just like the picture above. 
                </p>
<h2>Directories and Files</h2>
<p>Stata always has exactly one data set in memory, and  the commands you issue will act on it. To open a data set you may be tempted to click <span class="MenuOutput">File</span>, <span class="MenuOutput">Open</span>, but you can't write that into a do file. Thus we'll stick to typing commands.</p>
<p>Stata always keeps track of what it calls the "current working directory." Think of it as where you "are" in your computer's file system. Any commands that work with files will assume that the files are in the current working directory unless you specify otherwise. You  set the current working directory with the <span class="InputCode">cd</span> (change directory) command. The syntax is simply:</p>
<p class="InputCode">cd <span class="Parameter">directory</span></p>
<p>with one caveat: if the directory name has any spaces in it the entire directory name must go in quotes so Stata understands it's just one entity.</p>
<p>If the directory name starts with a drive letter (or in Linux if it starts with "/") then Stata will go directly to that location no matter what the current working directory is. If you placed the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm#files">Stata for Researchers example files</a> in <span class="InputCode">U:\StataResearch</span> make that the current working directory by typing:</p>
<p class="InputCode">cd U:\StataResearch</p>
<p>If you placed it in a different directory, type that instead. Don't forget that if you put spaces in the name you need to put quotes around it (e.g. <span class="InputCode">cd "U:\Stata Research"</span>). Note that in Windows file and directory names are not case sensitive (i.e. you could have typed <span class="InputCode">cd u:\stataresearch</span>) but in Linux they are.</p>
<p>You can also specify directories relative to the current directory. For example, .. means "up one level from the current directory." Assuming you're now in <span class="InputCode">U:\StataResearch</span>, typing:</p>
<p class="InputCode">cd ..</p>
<p>will put you in <span class="InputCode">U:\</span>. </p>
<p>If the directory in your <span class="InputCode">cd</span> command does not start with a drive letter ("/" in Linux) then it is assumed to be inside the current directory. Type:</p>
<p class="InputCode">cd StataResearch</p>
<p>to move from the <span class="InputCode">U:\</span> drive to <span class="InputCode">U:\StataResearch</span>.</p>
<p>Next see what's here using the <span class="InputCode">ls</span> (list) command. Type:</p>
<p class="InputCode">ls</p>
<p>The file you want is called <span class="InputCode">auto.dta</span> (<span class="InputCode">.dta</span> is the standard extension
                  for  Stata data sets).  To load it type:</p>
<p class="InputCode">use auto</p>
<p>You don't have to type the <span class="InputCode">.dta</span>;
                  Stata will assume it.</p>
<p>You can specify the full location of a data set in the <span class="InputCode">use</span> command, e.g.:</p>
<p class="InputCode">use U:\StataResearch\auto</p>
<p>With this method you don't need to use <span class="InputCode">cd</span> to set the current directory, but you have to specify the full location of every file you work with. You can also use relative paths in commands: if the current working directory had a subdirectory called <span class="InputCode">data</span> you could type <span class="InputCode">use data\mydataset</span> to load a data set inside it.</p>
<p>Our suggestion is that you make a directory for each project you're working on, and  keep all the data files, do files, log files and any other files related to the project in its directory. Make that directory the current working directory whenever you're working on that project. If you double-click on a data set or do file in Windows Explorer, Stata will start with the current working directory already set to the location of the file. Then in your programs you can refer to files simply by name without having to specify any locations. This is quicker than typing out the location of each file and reduces opportunities for error. It also makes your project portable: you can move the entire directory to a different computer (even from Windows to Linux) or zip it up and send it to someone else, and all your programs will still work.</p>
<p> If you're inclined to create subdirectories to organize your files, consider using Stata's Project Manager instead. The Project Manager allows you to define groups and place files in them without actually changing their location on disk. That way you can reorganize your files without changing the programs that use them. We won't discuss the Project Manager, but it's very easy to use.</p>
<h2>The 'auto' Example Data Set</h2>
<p>The 'auto' data set contains information about 1978 cars and has been included with Stata for many, many years. Every Stata user has access to it so it is frequently used for examples, just as we'll use it today. To see what's in it, type:</p>
<p class="InputCode">browse</p>
<p>or click the fourth button from the right in the toolbar at the top. This opens Stata's <span class="MenuOutput">Data Editor</span>, which shows you your data set in a spreadsheet-like form. You can also invoke the <span class="MenuOutput">Data Editor</span> by typing <span class="InputCode">edit</span> or clicking the fifth button from the right, and then it will allow you to make changes. Since you should <em><strong>never</strong></em> change your data interactively, get in the habit of using <span class="InputCode">browse</span> so you don't make changes by accident. Before proceeding there are a few things you should note about this data set.</p>
<h3>Numbers vs. Strings</h3>
<p>Most of the variables in this data set are numbers, like <span class="InputCode">price</span> and <span class="InputCode">mpg</span>. The variable <span class="InputCode">make</span> contains words or, as Stata calls them, "strings" (as in strings of characters). Obviously you can't do math with words, but Stata can do many other useful things with string variables. </p>
<h3>Missing Values</h3>
<p>Several cars have dots in the <span class="InputCode">rep78</span> column rather than numbers. These indicate missing values. A Stata data set is a rectangular matrix, so every observation must have something for every variable. If no actual data are available, Stata stores a  code for "missing."</p>
<p>Missing values often require special handling, and it's easy to write code which works fine with complete data but gives wrong answers if there are any missing values. The worst part about missing values is there's no single right way to deal with them—it depends on what you're trying to do.  How to handle missing data will be a recurring theme in this series.</p>
<p>While this data set just uses "generic" missing values, there are 26 others you can use:  <span class="InputCode">.a</span> through <span class="InputCode">.z</span>. Stata treats them all the same, but you can assign meanings to them. For example, if you were working with a survey  you might decide to code "the question did not apply" as <span class="InputCode">.a</span> and "the respondent refused to answer" as <span class="InputCode">.b</span>.</p>
<h3>Value Labels</h3>
<p>The <span class="InputCode">foreign</span> variable appears to contain text, like <span class="InputCode">make</span>. But note that it's a different color, and if you click on a cell in that column what appears at the top of the window is a <span class="InputCode">0</span> or a <span class="InputCode">1</span>. This tells you <span class="InputCode">foreign</span> is really an numeric variable with a set of value labels applied. Comparing the 
                numbers at the top with the words in the table, you'll see that this set of value labels associates the number <span class="InputCode">0</span> with the word <span class="InputCode">Domestic</span> and the number <span class="InputCode">1</span> with the word <span class="InputCode">Foreign</span>. We'll talk about creating value labels in <a href="https://ssc.wisc.edu/sscc/pubs/sfr-data.htm">Working with Data</a>. But for now, the important thing to remember is that if you write code referring to the <span class="InputCode">foreign</span> variable, it must use the real values <span class="InputCode">0</span> and <span class="InputCode">1</span>, not the labels <span class="InputCode">Domestic</span> and <span class="InputCode">Foreign</span>. This frequently confuses people who are starting out with a new data set, so it's worth checking to see which variables have associated value labels. In addition to opening the data browser and looking for columns in blue, you can look at the <span class="MenuOutput">Properties</span> window (after selecting the variable of interest in the <span class="MenuOutput">Variables</span> window) or type:</p>
<p class="InputCode">describe</p>
<p>(or just <span class="InputCode">d</span>). This will give you information about all the variables in your data set, including a column that tells you which ones have value labels. You can get the same information and more by opening the <span class="MenuOutput">Variables Manager</span> window (third button from the right or type <span class="InputCode">varman</span>). You can see what the labels are by typing:</p>
<p class="InputCode">label list</p>
<h2>Syntax Elements</h2>
<p>Almost all Stata commands rely on the same set of syntax elements. These elements give you a tremendous amount of control over the commands you run. Very complicated instructions can be expressed relatively simply by the proper combination of syntax elements.</p>
<p>We'll discuss four elements:</p>
<ul>
<li><em>varlists</em></li>
<li><em>if</em></li>
<li><em>options</em></li>
<li><em>by</em></li>
</ul>
<p>These elements always go in the same order:</p>
<p class="InputCode">[by varlist:] command [varlist] [if condition] [, options]</p>
<p>In order to see these elements in action, we'll use a very simple command:</p>
<p class="InputCode"> list</p>
<p>(<span class="InputCode">list</span> can  also be abbreviated as just <span class="InputCode">l</span>.) This  prints your data on the screen—think of it as a <span class="InputCode">browse</span> you can use in do files. However, <span class="InputCode">list</span> all by itself produces so much output that it's hard to find what you want. By learning to use these syntax elements you'll learn to <span class="InputCode">list</span> just the information you want—and in the process learn to control what any Stata command does.</p>
<h3><a id="Varlists" name="Varlists"></a>Varlists</h3>
<p><em>Varlists</em> allows you to control which variables (columns) a command will act on. A <em>varlist</em> is simply a list of variables separated by spaces, and it goes right after the command itself.  Type:</p>
<p class="InputCode">list make</p>
<p>This
  lists just the <span class="InputCode">make</span> of each car rather than all the variables. </p>
<p> As the name suggests, a <span class="italic"><em>varlist</em></span> can
  include multiple variables. Try typing: </p>
<p class="InputCode">list make price mpg</p>
<p><em>Varlists</em> can get quite long, so there are several shortcuts for writing them. If you put a dash between two variables, all the variables between them (as defined by the order they're listed in the <span class="MenuOutput">Variables</span> window) will be included in the variable list. Thus:</p>
<p class="InputCode">list make-mpg</p>
<p>includes <span class="InputCode">price</span>, because the first three variables in the data set are <span class="InputCode">make</span>, <span class="InputCode">price</span> and <span class="InputCode">mpg</span>.</p>
<p>You can also use wildcard characters. A <span class="InputCode">*</span> matches any number of characters, so </p>
<p class="InputCode">list m*</p>
<p>gives you both <span class="InputCode">make</span> and <span class="InputCode">mpg</span>. It would also include a variable just called <span class="InputCode">m</span> if there were one in the data set. A <span class="InputCode">?</span> matches any one character, but it must be exactly one. Thus:</p>
<p class="InputCode">list x?</p>
<p>would list (if our data set had such variables) <span class="InputCode">x1</span>, <span class="InputCode">x2</span>, and <span class="InputCode">x3</span>, but not <span class="InputCode">x</span>, <span class="InputCode">x10</span> or <span class="InputCode">xenophobia</span>.</p>
<p>Wildcards can go in any location. For example,</p>
<p class="InputCode">list *t</p>
<p>lists all variables that end in t (<span class="InputCode">weight</span> and <span class="InputCode">displacement</span>) while</p>
<p class="InputCode">list t*n*</p>
<p>lists all variables that start with <span class="InputCode">t</span> and then have an <span class="InputCode">n</span> in any other position (<span class="InputCode">trunk</span> and <span class="InputCode">turn</span>).</p>
<p>You can  mix shortcut types:</p>
<p class="InputCode">list m* weight-displacement *n
</p>
<p></p>
<h4>Exercises</h4>
<ol>
<li>What is the most concise varlist that would include all the variables in this data set? (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_syntax_varlists_1.htm">Solution</a>)</li>
<li>Suppose your data set included  variables <span class="InputCode">x1</span> through <span class="InputCode">x20</span> plus many others, including one called <span class="InputCode">xenophobia</span>. What varlist would select <span class="InputCode">x1</span> through <span class="InputCode">x20</span> but not those other variables, in particular not <span class="InputCode">xenophobia</span>? Assume the variables are intermingled so <span class="InputCode">x1-x20</span> will not work. (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_syntax_varlists_2.htm">Solution</a>)</li>
</ol>
<h3>If</h3>
<p><em>If</em> conditions allow you to control which observations (rows) a command acts on. An <em>if</em> condition consists of the  word <span class="InputCode">if</span> followed by some condition that is either true or false. It comes after the <em>varlist</em> if there is one (if not it goes directly after the command). The command will only act on those observations where the condition is true. Type:</p>
<p class="InputCode">list make mpg if mpg==25</p>
<p>This gives you a list containing the <span class="InputCode">make</span> and <span class="InputCode">mpg</span> of just those cars which get exactly 25 miles per gallon.</p>
<p>Make sure you type two equals signs. Stata, like most computer languages, understands two different
            	meanings for "equals." One equals sign is for assignment: <span class="InputCode">mpg=25</span> means "Make mpg 25." Two equals signs is a question: <span class="InputCode">mpg==25</span> asks
            	"Is mpg  25?" This will drive you crazy
            	for about a week and then  become second nature. The following are the "relational operators" used to form conditions:</p>
<table border="0">
<tr>
<td>==</td>
<td><p>Equal</p></td>
</tr>
<tr>
<td>&gt;</td>
<td>Greater than</td>
</tr>
<tr>
<td>&lt;</td>
<td>Less than</td>
</tr>
<tr>
<td>&gt;=</td>
<td>Greater than or equal to</td>
</tr>
<tr>
<td>&lt;=</td>
<td>Less than or equal to</td>
</tr>
<tr>
<td>!=</td>
<td>Not equals</td>
</tr>
</table>
<p>The exclamation point also means "not" more generally. For example,
            	try:</p>
<p class="InputCode">  list make mpg if !(mpg&gt;25)</p>
<p>"Not" can  be thought of as reversing the
   condition that follows it: changing false to true and true to false.</p>
<h4>Combining Conditions</h4>
<p>You can  combine two conditions with "logical and" (<span class="InputCode">&amp;</span>) or "logical or" (<span class="InputCode">|, </span> called the "pipe" and created by pressing <span class="InputCode">Shift-\</span>). With "logical and" the result is true if and only if both conditions are true, while with "logical or" the result is true if either condition is true, or both. In terms of set theory, "logical and" is the intersection, while "logical or" is the union.</p>
<p>Thus:</p>
<p class="InputCode">list make price mpg if mpg&gt;25 &amp; price&lt;5000</p>
<p>will give you a list of cars that both get good gas mileage and are relatively cheap (remember these are 1978 dollars), while:</p>
<p class="InputCode">list make price mpg if mpg&gt;25 | price&lt;5000</p>
<p>will give you a list of cars that either get good gas mileage or are relatively cheap or both, a much larger list.</p>
<p>Once you get past two conditions, the order in which they're evaluated can  change the result. There are set precedence rules, but we suggest using parentheses liberally to ensure Stata will evaluate conditions in the order you think it should.</p>
<h4>Indicator Variables</h4>
<p>While we've talked about conditions being true or false, in reality Stata uses numbers: one is true and zero is false. You can take advantage of this to write very natural <em>if</em> conditions with indicator variables:</p>
<p class="InputCode">list make if foreign</p>
<p>Part of what makes this work is the variable name: the variable <span class="InputCode">foreign</span> tells us whether or not a car is in fact foreign. Now consider a variable called <span class="InputCode">gender</span>: does a one indicate that a person is male or that a person is female? You can't tell without checking your codebook (or value labels). But if the variable were called <span class="InputCode">female</span> it would be obvious that a one means this person is female.</p>
<p>Be careful however: more generally, any number other than zero is considered true—even missing.  If <span class="InputCode">foreign</span> were missing for some cars, <span class="InputCode">list make if foreign</span> would treat those cars as if they were known to be foreign. This leads some people to suggest that it's better to always use code like:</p>
<p class="InputCode">list make if foreign==1</p>
<p>But this treats cars with a missing value for <span class="InputCode">foreign</span> as if they were known <em>not</em> to be foreign. Which  one is appropriate—or whether you need to do something else entirely—depends on what exactly you're trying to do.</p>
<h4>Missing Values and Inequalities</h4>
<p>Internally, Stata stores the missing values <span class="InputCode">.</span>, <span class="InputCode">.a</span>, <span class="InputCode">.b</span> ... <span class="InputCode">.z</span> as the 27 largest possible numbers of each variable type, and in that order. It's very important to keep this in mind when dealing with inequalities: think of missing values as essentially "positive infinity."</p>
<p>Consider making a list of cars with "good" repair records, defined as <span class="InputCode">rep78</span> greater than three:</p>
<p class="InputCode">l make rep78 if rep78&gt;3</p>
<p>Cars with a missing value for <span class="InputCode">rep78</span> are included, because infinity is much greater than three.</p>
<p>Whether that's a problem or not depends on your goal in making this list. If you want a list of cars which are not known to have poor repair records,  that code is entirely correct. But if you want a list of cars which are known to have good repair records then you need to add a second condition:</p>
<p class="InputCode">l make rep78 if rep78&gt;3 &amp; rep78!=.</p>
<p>Now cars with missing repair records are specifically excluded. However, note that this would not exclude the other missing values: <span class="InputCode">.a</span>, <span class="InputCode">.b</span>, etc. Thus veteran Stata programmers will use:</p>
<p class="InputCode">l make rep78 if rep78&gt;3 &amp; rep78&lt;.</p>
<p>The generic <span class="InputCode">.</span> is the smallest of the missing values, so <span class="InputCode">rep78&lt;.</span> will be true for all valid values and false for all missing values.</p>
<p>An alternative that's  longer to type but easier to read is:</p>
<p class="InputCode">l make rep78 if rep78&gt;3 &amp; !missing(rep78)</p>
<p>The <span class="InputCode">missing</span> function takes a variable name as input, and returns true if that variable is missing and false if it is not. (Alternatively you can give it a list of variables separated by commas and it will return true if any of them are missing.) The exclamation point  reverses the result, making it effectively "not missing."</p>
<p>Since the "missing is infinity" rule is not  intuitive, it's easy to forget. But doing so can be disastrous. Consider trying to identify senior citizens with the condition <span class="InputCode">if age&gt;=65</span>: anyone whose age is missing would be called a senior citizen. Different rules for handling missing values have been proposed, but they  just make the disasters occur under different circumstances. There's no alternative to checking for missing values and handling them properly where they exist.</p>
<p>Fortunately the checking is easy to do. Just type:</p>
<p class="InputCode">misstable sum</p>
<p>This is an example of a command with a subcommand. The <span class="InputCode">misstable</span> command can do many things, so the second word (or in this case abbreviation since <span class="InputCode">sum</span> is short for <span class="InputCode">summarize)</span> tells Stata you want it to give you a summary of the variables that have missing values. Since <span class="InputCode">rep78</span> is the only variable listed, you now know that you have to worry about missing values when working with <span class="InputCode">rep78</span>, but can ignore them with all the other variables—as long as the data set doesn't change.</p>
<p>If you will be working with many data sets or data sets that do change, you can build a test for missing values right into your do files. The <span class="InputCode">assert</span> command checks to see whether a given condition is true or not for all observations. For example:</p>
<p class="InputCode">assert mpg&lt;.</p>
<p>checks to see if <span class="InputCode">mpg</span> is always non-missing. Since it is, nothing happens. However, try:</p>
<p class="InputCode">assert rep78&lt;.</p>
<p>Now you get an error message (along with information about how often the condition is violated). If you had been running a do file it would have come to a screeching halt. This is good: if your  code was written  on the assumption that <span class="InputCode">rep78</span> is never missing, it's far better for that code to crash than to continue running and give you wrong answers.</p>
<p><span class="InputCode">assert</span> is useful for far more than checking for missing values. With clever programming you can use it to check all sorts of assumptions about your data ("Each value of <span class="InputCode">ID</span> is associated with just one person", "Every household has a head of household", etc.). Doing so can save you a lot of headaches.</p>
<h4>Exercises</h4>
<ol>
<li>A shipping company would like to ship cars from other countries to the US. Its ships can handle cargoes up to 200 inches in length and weighing up to 4,000 pounds. Doing so is only profitable for cars costing at least $5,000. Which cars should it consider shipping? (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_syntax_if_2.htm">Solution</a>)</li>
<li>Suppose I want to buy a car. I'm willing to pay up to $4,000 for most cars, but I'll go up to $5,000 if the car is known to be reliable (<span class="InputCode">rep78</span>&gt;3) and gets good gas mileage (<span class="InputCode">mpg</span>&gt;25). Which cars should I look at? (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_syntax_if_1.htm">Solution</a>)</li>
<li>Recall that we earlier typed <span class="InputCode">list make mpg if !(mpg&gt;25)</span>. Now try <span class="InputCode">list make mpg if !mpg&gt;25</span>. What's going on? (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_syntax_if_3.htm">Solution</a>)</li>
</ol>
<h3><a id="Options" name="Options"></a>Options</h3>
<p><em>Options</em> control how a command runs. They go at the end of the command after a comma.  There can be any number of options (all following a single comma) and they can go in any order. If an option needs more information, like a variable to act on, that information goes in parentheses immediately following the option. To see an option in action, type:</p>
<p class="InputCode">list make foreign</p>
<p>and then</p>
<p class="InputCode">list make foreign, nolabel</p>
<p>The <span class="InputCode">nolabel</span> option can be used with many commands. It tells the command to ignore value labels and show the actual values of the variable. Other options may only be used by a single command.</p>
<p>The <span class="InputCode">list</span> command has a <span class="InputCode">header</span> option that prompts it to repeat the header row containing variable names. This can make it easier to keep track of what the columns mean in long lists. However, it needs to know how how many observations should go between each repetition of the header. As additional information, this number goes in parentheses after the word <span class="InputCode">header</span>:</p>
<p class="InputCode">list make-mpg, header(20)</p>
<h3></h3>
<h3><a id="by" name="by"></a>By</h3>
<p><em>by</em> is used to run a command separately across 
  groups. For example, list the domestic cars and the foreign cars
  separately by typing:</p>
<p class="InputCode">by foreign: l make foreign </p>
<p>Note how the list is broken into two parts. The first one says <span class="MenuOutput">foreign=Domestic</span> at the top, the second says <span class="MenuOutput">foreign=Foreign</span>. <span class="italic"><em>by</em></span> splits the data set up into 
  groups, one group for each unique value of the <span class="italic"><em>by</em></span> variable, then executes the command  for each group independent of the others.</p>
<p>Since <span class="italic"><em>by</em></span> takes a <span class="italic">varlist</span>,
  you can work by more than one variable at a time. Try: </p>
<p class="InputCode">by foreign rep78: l make</p>
<p>You'll get the message</p>
<p class="MenuOutput"><span class="Red">not sorted</span><br/>
<span class="Blue">r(5); </span></p>
<p>Stata can only use <span class="italic"><em>by</em></span> if the data
  set is sorted in the order of the <em>by</em> variables. This
  data set started out sorted by <span class="InputCode">foreign</span>,
  but not by <span class="InputCode">rep78</span>. Type:</p>
<p class="InputCode">sort foreign rep78</p>
<p>and Stata will sort the data and allow you to execute:</p>
<p class="InputCode"> by
  foreign rep78: l make</p>
<p> successfully. As you can see it breaks
  the data set into one group for each unique combination
  of <span class="InputCode">foreign</span> and <span class="InputCode">rep78</span> and then carries out the
  command. Note that some combinations (foreign cars with a <span class="InputCode">rep78</span> of one, for example) do not occur in the data and  are not listed.</p>
<p> Users got  tired of forgetting to sort before using <em>by</em>, so Stata added <span class="InputCode">bysort</span>:</p>
<p class="InputCode">bysort foreign rep78: l make</p>
<p>This will first sort the data by <span class="InputCode">foreign</span> and <span class="InputCode">rep78</span>, then carry out the rest
  of the command.</p>
<p>A caution about sorting: Stata's default sort algorithm is not <em>stable</em>, meaning that it may change the order of the observations even if it doesn't have to. For example, if you have data consisting of individuals grouped into households, running <span class="InputCode">sort household</span> may change the order of individuals within a household. If the order is important, add the <span class="InputCode">stable</span> option to the <span class="InputCode">sort</span> command (e.g. <span class="InputCode">sort household, stable</span>) and Stata will switch to a  slower algorithm that is stable.</p>
<h4>Exercise</h4>
<ol>
<li><span class="InputCode">make</span>  appears to be a unique identifier in this data set (i.e. each car has a unique value of <span class="InputCode">make</span>). If so, what would it look like if you did a list "by make"? Do the list; is it what you expected? What would it look like if <span class="InputCode">make</span> were not in fact a unique identifier? (<a href="https://ssc.wisc.edu/sscc/pubs/sfr/soln_syntax_by.htm">Solution</a>)</li>
</ol>
<p>We'll do much more with <em>by</em> in <a href="https://ssc.wisc.edu/sscc/pubs/sfr-groups.htm">Working with Groups</a>.</p>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-do.htm">Do Files</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Introduction</a></p>
<p> </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/sfr/ui2.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>We demonstrated appending in order to create the long form of this data set:</p>
<p class="InputCode">clear<br/>
use panel2007<br/>
gen year=2007<br/>
save panel2007_append<br/>
use panel2008<br/>
gen year=2008<br/>
append using panel2007_append</p>
<p> Now all you need to do is reshape:</p>
<p class="InputCode">reshape wide score, i(id) j(year)</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Again the first step is to append the data sets:</p>
<p class="InputCode">clear<br/>
use panel2007<br/>
gen year=2007<br/>
save panel2007_append<br/>
use panel2008<br/>
gen year=2008<br/>
append using panel2007_append</p>
<p>You can observe that there is a person who only appears once with <span class="InputCode">duplicates report</span>:</p>
<p class="InputCode">duplicates report id</p>
<p>If you want to figure out who it is and examine their data, you can follow the procedure for identifying duplicates. Just keep in mind that in this case everyone should have two copies, and anything else is a problem:</p>
<p class="InputCode"> bysort id: gen copies=_N<br/>
                l if copies==1</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Two notes before diving into the details:</p>
<ol>
<li>It's probably worth your time to try to combine these files before fixing all the errors so you can see what the result looks like. When it comes to programming, "experience" often comes down to having made a mistake before so you recognize it faster when you make it again.</li>
<li>Given that you have two files to fix and Stata only works with one file at a time, the efficient way to do it is to load one, fix all the problems in it, save the results, and then move on to the other. But for clarity we'll discuss fixing one kind of error at a time in both files and omit the implied <span class="InputCode">save</span> and <span class="InputCode">use</span> commands. We'll put everything together and in the proper order at the end. </li>
</ol>
<p>Begin by doing a <span class="InputCode">describe</span> on both data sets:</p>
<p class="InputCode">                  use error2007<br/>
                  d<br/>
                  use error2008<br/>d</p>
<p>The first problem is the variable names: in <span class="InputCode">error2007</span> the identifier variable is called <span class="InputCode">studentID</span> while in <span class="InputCode">error2008</span> it is called <span class="InputCode">id</span>. In <span class="InputCode">error2007</span> the teacher identifier is  called <span class="InputCode">teacher</span>, while in <span class="InputCode">error2008</span> it is called <span class="InputCode">teacherID</span>. Meanwhile the student's score is called <span class="InputCode">testScore</span> in <span class="InputCode">error2007</span> and simply <span class="InputCode">score</span> in <span class="InputCode">error2008</span>. It doesn't matter what the variables are called, but they must be consistent. We'll go with <span class="InputCode">id</span>, <span class="InputCode">teacher</span> and <span class="InputCode">score</span>:</p>
<p class="InputCode">rename studentID id<br/>
                  rename testScore score<br>
                  rename teacherID teacher                  <br/>
</br></p>
<p>Second, in <span class="InputCode">error2007</span> the <span class="InputCode">id</span> variable (formerly <span class="InputCode">studentID</span>)  is a string while in <span class="InputCode">error2008</span> it is a number. Strings are nice for identifiers because you never have to worry about rounding, so we'll convert the <span class="InputCode">id</span> in <span class="InputCode">error2008</span> to a string. However, there's an additional complication: the string identifiers in <span class="InputCode">error2007</span> have leading zeroes for if they are less than ten ("<span class="InputCode">01</span>", "<span class="InputCode">02</span>" etc.). One option would be to tell the <span class="InputCode">string</span> function to use a format that includes leading zeroes when converting the numbers to strings. But rather than look up the proper format I'd suggest a straightforward <span class="InputCode">replace</span>:</p>
<p class="InputCode">gen temp=string(id)<br/>
                  replace temp="0"+temp if id&lt;10
                  <br/>
                  drop id<br/>
                rename temp id</p>
<p>The third problem is duplicate observations. You can examine them with:</p>
<p class="InputCode">duplicates report id<br/>
                  bysort id: gen copies=_N<br/>
                  l if copies&gt;1</p>
<p>This reveals that in <span class="InputCode">error2007</span> you have two student 41's, and they're different. There's just one student 41 in <span class="InputCode">error2008</span> and you have no idea which it should match with, so you'll have to drop both student 41's from <span class="InputCode">error2007</span>. You could drop student 41 from <span class="InputCode">error2008</span> as well, but you'll take care of that when you do the final merge by only keeping observations that match.</p>
<p class="InputCode">drop if id=="41"</p>
<p>(Remember we converted id to a string, so the number 41 must go in quotes.) </p>
<p>Meanwhile in <span class="InputCode">error2008</span> we have two student 37's and two observations with missing values for <span class="InputCode">id</span>. <span class="InputCode">error2007</span> has no observations with missing values for <span class="InputCode">id</span>, so they won't match with anything and will be deleted automatically. The two student 37's on the other hand, turn out to be the same person--their data are identical. Thus all you need to do is drop one:</p>
<p class="InputCode">duplicates drop id, force</p>
<p>Now we've fixed the errors, but we still have to keep track of which year is which. To put things in the wide form that means adding the year to the end of all the level one variable names:</p>
<p class="InputCode">rename score score2007<br/>
                  rename race race2007<br/>
                  rename teacher teacher2007<br/>
                rename teacherRace teacherRace2007 </p>
<p>And similar for 2008.</p>
<p>Now you're finally ready to merge. For now keep everything whether it matches or not:</p>
<p class="InputCode">merge 1:1 id using fixed2007</p>
<p>You'll see that despite your best efforts, some observations did not match. Examine the problem observations with:</p>
<p class="InputCode">browse if _merge!=3</p>
<p>The observations with the id's "<span class="InputCode">41</span>" and "<span class="InputCode">.</span>" were dealt with previously and you expected them not to match. However, "<span class="InputCode">40</span>", "<span class="InputCode">20</span>", "<span class="InputCode">55</span>" and "<span class="InputCode">60</span>" are unexpected. But they do not indicate mistakes: if you go back to the original files, you'll see that <span class="InputCode">error2008</span> has no student 40, and <span class="InputCode">error2007</span> has no students 20,55 or 60. Thus you've done the best that can be done.</p>
<p>You can eliminate the unmatched observations (assuming they're no use to you without both years' data) with:</p>
<p class="InputCode">drop if _merge!=3</p>
<p>Alternatively you can go back and chance the merge command to:</p>
<p class="InputCode">merge 1:1 id using fixed2007, keep(match)</p>
<p>But note that if you did that from the beginning you couldn't check your results.</p>
<p>Following is the complete code, in the proper order and including all the <span class="InputCode">use</span> and <span class="InputCode">save</span> commands:</p>
<p class="InputCode">use error2007<br/>
                d<br/>
                rename studentID id<br/>
                rename testScore score<br/>
<br/>
                duplicates report id<br/>
                bysort id: gen copies=_N<br/>
                l if copies&gt;1<br/>
                drop if id=="41"<br/>
<br/>
                rename score score2007<br/>
                rename race race2007<br>
                rename teacher teacher2007<br/>
                rename teacherRace teacherRace2007<br/>save fixed2007, replace<br/>
<br/>
                use error2008<br/>
                d<br/>
                rename teacherID teacher<br/>
<br/>
                gen temp=string(id)<br/>
                replace temp="0"+temp if id&lt;10<br/>
                drop id<br/>
                rename temp id<br/>
<br/>
                duplicates report id<br/>
                bysort id: gen copies=_N<br/>
                l if copies&gt;1<br/>
                duplicates drop id, force<br/>
<br/>
rename score score2008<br/>
                rename race race2008<br/>
                rename teacher teacher2008<br/>
                rename teacherRace teacherRace2008<br/>
                save fixed2008, replace<br/>
<br/>
                merge 1:1 id using fixed2007<br/>
                  browse if _merge!=3<br/>
                  drop if _merge!=3
                  <br/>
</br></p>
<p>Moving on to appending the data, you'll find that Stata will append the two data sets as-is without any complaints:</p>
<p class="InputCode">use error2007<br/>
                append using error2008</p>
<p>The result is unusable, but <span class="InputCode">browse</span> and see why. The <span class="InputCode">merge</span> command is much more likely to crash than the <span class="InputCode">append</span> command, but that's a good thing--it brings problems to your attention that would have caused trouble eventually anyway.</p>
<p>You'll need to do a bit of fixing just to see the more interesting errors with <span class="InputCode">append</span>:</p>
<p class="InputCode">use error2007<br/>
                  rename studentID id<br/>
                  save fixed2007b<br/>
                  use error2008<br/>
                  gen temp=string(id)<br/>
                  replace temp="0"+temp if id&lt;10<br/>
                  drop id<br/>
                  rename temp id<br/>
                append using fixed2007b</p>
<p>To identify the duplicate observations you can follow the same procedure as before, but note that each ID should have two observations:</p>
<p class="InputCode">duplicates report id<br/>
                  bysort id: gen copies=_N<br/>
                browse if copies!=2</p>
<p>You'll see the same suspects as before. Alternatively, if you had created a year variable (as you'd need to if you actually wanted to use this data) you could have included it in your <span class="InputCode">duplicates report</span> and <span class="InputCode">bysort</span> commands and then the expected result would be one observation per id/year combination.</p><!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>When you're starting out, it's best to break things up into little pieces. So start with the first component of cost, $1.50 per pound of weight:</p>
<p class="InputCode">gen cost=1.5*weight</p>
<p>Next add the $0.25 per pound to ship for foreign cars:</p>
<p class="InputCode">replace cost=cost+.25*weight if foreign</p>
<p>And finally the $100 for cars with a <span class="InputCode">rep78</span> of 5:</p>
<p class="InputCode">replace cost=cost+100 if rep78==5</p>
<p>Then the profit is price minus cost:</p>
<p class="InputCode">gen profit=price-cost</p>
<p>But once you're confident of what you're doing you can make it much more compact:</p>
<p class="InputCode">gen profit2=price-(1.5*weight + .25*weight*foreign + 100*(rep78==5))</p>
<p>This relies on two tricks: that true/false is equivalent to one/zero, and that adding something multiplied by zero is equivalent to not adding it. Thus <span class="InputCode">.25*weight</span> is only added for foreign cars, and 100 is only added for cars where <span class="InputCode">rep78==5</span>.</p>
<p>You can verify that these commands are equivalent with:</p>
<p class="InputCode">assert profit==profit2</p>
<p>Complete do file:</p>
<p class="InputCode">clear all<br/>
                  set more off<br/>
                  capture log close<br/>
                  log using data_ex1.log, replace<br/>
                  use auto<br/>
<br/>
gen cost=1.5*weight<br/>
replace cost=cost+.25*weight if foreign<br/>
replace cost=cost+100 if rep78==5<br/>
gen profit=price-cost<br/>
<br/>
gen profit2=price-(1.5*weight + .25*weight*foreign + 100*(rep78==5))<br/>
assert profit==profit2<br/>
list make profit*
<br/>
<br/>
log close
<br/>
</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>To find the amount of time that has passed between any two dates you subtract them, but the years have to be converted to months by multiplying by twelve:</p>
<p class="InputCode">gen ageInMonths=(interviewYear-birthYear)*12 + (interviewMonth-birthMonth)</p>
<p>To find  age in whole years you need to divide by 12 and drop the fractional part. Stata will drop the fractional part automatically if you declare your new variable to be an <span class="InputCode">int</span>:</p>
<p class="InputCode">gen int age=ageInMonths/12</p>
<p>Complete do file:</p>
<p class="InputCode">clear all<br/>
                  set more off<br/>
                  capture log close<br/>
                  log using data_ex2.log, replace<br/>
                  use interviews<br/>
<br/>
  gen ageInMonths=(interviewYear-birthYear)*12 + (interviewMonth-birthMonth)<br/>
  gen int age=ageInMonths/12<br/>
  list
  <br/>
<br/>
                  log close <br/>
</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>The easy way to find the manufacturer is to use the <span class="InputCode">word()</span> function. It takes two arguments: the first is the string you want to extract a word from and the second is the number of the word you want. Since the manufacturer is always the first word of <span class="InputCode">make</span>, all you need is:</p>
<p class="InputCode">gen manufacturer=word(make,1)</p>
<p>There are several ways to extract <span class="InputCode">manufacturer</span> from <span class="InputCode">make</span>, some of which will work in a wider variety of situations.</p>
<p> One alternative is the oddly-named <span class="InputCode">egen</span> function <span class="InputCode">ends()</span>, with the <span class="InputCode">head</span> option. This will give you the first word of the string:</p>
<p class="InputCode">egen manufacturer2=ends(make), head</p>
<p>The <span class="InputCode">last</span> option would give you the last word, and the <span class="InputCode">tail</span> option would give you all but the first word. But the advantage of <span class="InputCode">ends()</span> over <span class="InputCode">word() </span>is that <span class="InputCode">ends()</span> has a <span class="InputCode">punct()</span> option which lets you divide strings into "words" based on characters other than spaces. Thus if you had a variable <span class="InputCode">fullname</span> containing <span class="InputCode">Dimond,Russell</span> you could do:</p>
<p class="InputCode">egen firstname=ends(fullname), punc(",") last<br/>
                egen lastname=ends(fullname), punc(",") head                </p>
<p>The most flexible method uses  <span class="InputCode">substr()</span>, but, as usual, flexibility implies complexity. <span class="InputCode">substr()</span> takes three arguments: the string you want to extract a substring from, the location where the substring should start, and the number of characters it should contain. Since we want the first part of  <span class="InputCode">make</span>, the starting location is just 1. The trick is that the length of each manufacturer is different. However, we know we've hit the end of the manufacturer when we see a space, and we can use the <span class="InputCode">strpos()</span> function to find the space. <span class="InputCode">strpos()</span> takes two strings as arguments and returns the location of the second string within the first--or zero if the second string is not in the first, which can also be useful. Thus to find manufacturer using <span class="InputCode">substr()</span> you would type:</p>
<p class="InputCode">gen manufacturer3=substr(make,1,strpos(make," "))</p>
<p>This gives you one missing value, the car whose <span class="InputCode">make</span> is just <span class="InputCode">Subaru</span>. While <span class="InputCode">word()</span> and <span class="InputCode">ends()</span> interpreted <span class="InputCode">Subaru</span> as the first word, it confused our <span class="InputCode">substr()</span> method: <span class="InputCode">strpos(make," ")</span> returns zero because <span class="InputCode">Subaru</span> doesn't contain a space, and when <span class="InputCode">substr()</span> is asked to make a substring of zero length it responds with missing.</p>
<p>The moral of this story: use <span class="InputCode">word()</span> if you can, because it's so easy. But if you need to extract data from a complex piece of text (say, the HTML source code of a web page) <span class="InputCode">substr()</span> and <span class="InputCode">strpos()</span> may be your only hope.</p>
<p>Complete do file:</p>
<p class="InputCode">clear all<br/>
                  set more off<br/>
                  capture log close<br/>
                  log using data_ex3.log, replace<br/>
                  use auto<br/>
<br/>
                  gen manufacturer=word(make,1)<br/>
                  list make manufacturer                  <br/>
<br/>
                  log close
<br/>
</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Since the state ID becomes the hundreds place of the new ID, just multiply it by 100 and add the county ID:</p>
<p class="InputCode">gen id1=state*100+county</p>
<p>Making string versions of the variables is easy:</p>
<p class="InputCode">gen stateString=string(state)<br/>
                  gen countyString=string(county)</p>
<p>Combining them is also easy. With strings, tacking one string to the end of the other is just addition:</p>
<p class="InputCode">gen id2=stateString+countyString</p>
<p>Unfortunately it's also wrong. Do a list and you'll note that the leading zero you were asked to create is not there. Even worse, the first ten counties don't have a zero after the state, so you can't tell state 1, county 11 from state 11, county 1 (both have an <span class="InputCode">id2</span> of <span class="InputCode">111</span>). </p>
<p>One way to fix this problem is to detect cases that need leading zeros and add them:</p>
<p class="InputCode">replace stateString="0"+stateString if state&lt;10<br/>
                replace countyString="0"+countyString if county&lt;10</p>
<p>Then you can combine the modified strings and get the proper result:</p>
<p class="InputCode">gen id3=stateString+countyString</p>
<p>A more elegant method gives the <span class="InputCode">string()</span> function a second argument, the format the number should be put in when converting it to a string. We won't discuss formats, but since it is a better solution here are the commands:</p>
<p class="InputCode">gen goodStateString=string(state,"%02.0f")<br/>
                gen goodCountyString=string(county,"%02.0f")                </p>
<p>Type <span class="InputCode">help format</span> if you'd like to learn more about them.</p>
<p>Complete do file:</p>
<p class="InputCode">clear all<br/>
                  set more off<br/>
                  capture log close<br/>
                  log using data_ex4.log, replace<br/>
                  use statecounty<br/>
<br/>
                  gen id1=state*100+county<br/>
<br/>
gen stateString=string(state)<br/>
gen countyString=string(county)<br/>
gen id2=stateString+countyString<br/>
list if state==1<br/>
<br/>
replace stateString="0"+stateString if state&lt;10<br/>
replace countyString="0"+countyString if county&lt;10<br/>
gen id3=stateString+countyString<br/>
list
if state==1<br/>
<br/>
                  log close<br/>
</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Stata has no objection to value labels that happen to start with the number they label and then add some description. There's also no rule that says every value has to have a label—if a value has no label the value itself will be listed as usual. Thus the following will define the label you need:</p>
<p class="InputCode">label define mpgLabel 12 "12 (Lowest MPG)" 41 "41 (Highest MPG)"</p>
<p>Now apply that mapping to the values of the <span class="InputCode">mpg</span> variable:</p>
<p class="InputCode">label values mpg mpgLabel</p>
<p>Do a list to see the results:</p>
<p class="InputCode">l make mpg</p>
<p>Complete do file:</p>
<p class="InputCode">clear all<br/>
set more off<br/>
capture log close<br/>
log using data_ex1.log, replace<br/>
use auto<br/>
<br/>
label define mpgLabel 12 "12 (Lowest MPG)" 41 "41 (Highest MPG)"<br/>
label values mpg mpgLabel<br/>
l make mpg<br/>
<br/>
log close</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Given the <span class="InputCode">numChildren</span> variable, all you need to do to identify childless households is look for households where the number of children is zero:</p>
<p class="InputCode">gen childless=(numChildren==0)</p>
<p>There's no need to use <em>by</em> because this command doesn't look across observations in any way. You had to look across the observations in the household to construct <span class="InputCode">numChildren</span>, but at this point each observation has its own copy of the result.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Your first task is to find the age of the youngest adult in each household. You can do that with:</p>
<p class="InputCode">by household: egen ageYoungestAdult=min(age) if age&gt;=18</p>
<p>Next, find the age of the oldest child:</p>
<p class="InputCode">by household: egen ageFirstChild=max(age) if rel2head==3</p>
<p>(Yes, <span class="InputCode">if age&lt;18</span> would work too for this data. In real data sets you'd have to consider the possibility of adult children still living at home, and instead of "youngest adult" you'd have to think about "youngest parent," which could be hard to identify. But never mind all that for now.)</p>
<p>In principle, all you need is <span class="InputCode">ageYoungestAdult</span>-<span class="InputCode">ageFirstChild</span>. The trouble is, the first is only defined for adults and the second is only defined for children. Thus some result spreading is required.</p>
<p class="InputCode">by household: egen ageYoungestAdult2=mean(ageYoungestAdult)<br/>
                by household: egen ageFirstChild2=max(ageFirstChild)</p>
<p>The second command gives three missing values: the three people living in households with no children. Now we're ready to find the answer:</p>
<p class="InputCode">gen ageYoungestAdultAtFirstBirth= ageYoungestAdult2-ageFirstChild2</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Begin by  thinking carefully about what defines a single-parent household and a two-parent household. First, in order to have parents at all a household must have at least one child. Second, a two-parent household must have a spouse, while a single-parent household must not have a spouse. (This assumes that every household has a head, which is the case here but worth checking in real-world data. Real-world data will also include partners that are not spouses.)</p>
<p>If you've been following along, your do file will already have code to create a variable called <span class="InputCode">hasChildren</span>. If not, create it with:</p>
<p class="InputCode">gen child=(age&lt;18)<br/>
by household: egen hasChildren=max(child)</p>
<p>Next we need a variable for whether a household has a spouse or not. Recall that spouses have a 2 for <span class="InputCode">rel2head</span>. Thus we can type:</p>
<p class="InputCode">by household: egen hasSpouse=max(rel2head==2)</p>
<p>This command finds the maximum not of a variable, but of the expression <span class="InputCode">rel2head==2</span>. That expression will be 1 (true) for spouses and 0 (false) for everyone else. Thus its maximum value over a household will be 1 if there is a spouse in the household and 0 otherwise.                </p>
<p>Now you're ready to identify the single-parent and two-parent households. </p>
<p class="InputCode">gen singleParent=hasChildren &amp; !hasSpouse<br/>
                gen twoParent=hasChildren &amp; hasSpouse<br/>
</p>
<p>There's no need for <span class="InputCode">by household:</span> because neither command looks across observations.</p>
<p>With those indicators in hand, you're ready to look at incomes. Again, if you were following along you already have code to create a <span class="InputCode">householdIncome</span> variable, but if not create it with:</p>
<p class="InputCode">by household: egen householdIncome=total(income)</p>
<p>Now you can compare mean household incomes with:</p>
<p class="InputCode">sum householdIncome if singleParent<br/>
                sum householdIncome if twoParent</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="InputCode">by household: egen numHeads=total(rel2head==1)<br/>
                  assert numHeads==1
                </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="InputCode">sort household age<br/>
                  by household: gen ageVaries=age[1]!=age[_N]<br/>
                  browse if ageVaries</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Without the <span class="InputCode">by person:</span>, Stata won't know when the data for one person ends and the next person begins. Thus it will compare the first month for any given person with the last month of the person before, and only if their unemployment statuses differ will it mark it as the beginning of a new spell. The result could be a "spell" that is shared by two people!</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Since the months are still in order, to get information about the first and last month of each spell we just need to work <span class="InputCode">by person spell:</span> and then look at observations <span class="InputCode">[1]</span> and <span class="InputCode">[_N]</span>. Thus:</p>
<p class="InputCode">by person spell: gen startMonth=month[1]<br/>
                by person spell: gen startYear=year[1]<br/>
                by person spell: gen endMonth=month[_N]<br/>
                by person spell: gen endYear=year[_N]                <br/>
</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>It's tempting to do something like:</p>
<p class="InputCode">by person: egen meanDuration=mean(duration)</p>
<p>But this would be the mean across months, not spells. (For example, person five has two spells, one 18 months long and one 2 months long. The mean duration we want is 10. However, the mean across months is 16.4 since the 18 months with duration 18 count for more than the 2 months with duration 2.)</p>
<p>One easy way to get a mean across spells is to only consider one observation per spell. Since the <span class="InputCode">start</span> variable is one for just the first observation in each spell, you can do this with:</p>
<p class="InputCode">by person: egen meanDuration=mean(duration) if start</p>
<p>Depending on what you needed to do with this variable you might have to do some result spreading.</p>
<p>If you didn't have start defined already, you could create it with something like:</p>
<p class="InputCode">by person spell: gen start=(_n==1)</p>
<p>However, there's a egen function called <span class="InputCode">tag()</span> that does the same thing:</p>
<p class="InputCode">egen start=tag(person spell)</p>
<p>The <span class="InputCode">tag()</span> function gives a one to the first observation in each group defined by the variables it's given and a zero to all others. That first observation is thus "tagged" as the one to be included in calculations.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="InputCode">replace peerGroup=students+students[_n+1] if grade==1<br/>
                replace peerGroup=students[_n-1]+students if grade==12</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Consider grade twelve of school one and grade one of school two. If you specify <span class="InputCode">by school:</span> Stata understands that the first is the end of a school's data and the second is the beginning of a different school's data. But without <span class="InputCode">by school:</span> Stata sees them as adjacent observations. Thus the command:</p>
<p class="InputCode">gen peerGroup=students+students[_n+1]+students[_n-1]</p>
<p>would count the first graders in school two among the peers of the twelfth graders in school one.</p>
<p>This code is written on the assumption that adjacent observations represent "adjacent" grades. If some schools do not have some observations for some grades, that assumption is violated. For example, if a school did not have an observation for grade three, <span class="InputCode">students[_n+1]</span> for the second graders would be the fourth graders, and thus the fourth graders would be considered peers of the second graders.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>This data set contains data about three countries over three years. The level two unit is thus a country, and the level one unit is a country-year combination. The level two variables are <span class="InputCode">country</span> and <span class="InputCode">area</span>, while the level one variables are <span class="InputCode">year</span>, <span class="InputCode">pop</span> and <span class="InputCode">cgdp</span>. <span class="InputCode">country</span> is the level two identifier and <span class="InputCode">year</span> the level one identifier. Note that countries do occasionally change in area. If your panel included such an event (say, the United States in 1803) then you'd have to treat <span class="InputCode">area</span> as a level one variable throughout.                </p>
<p>To reshape this data to wide form the command is:</p>
<p class="InputCode">reshape wide pop cgdp, i(country) j(year)</p>
<p>To go back to long:</p>
<p class="InputCode">reshape long pop cgdp, i(country) j(year)</p>
<p>To collapse to a data set of countries with variables <span class="InputCode">meanPop</span> and <span class="InputCode">maxCGDP</span>:</p>
<p class="InputCode">collapse meanPop=pop (max) maxCGDP=cgdp, by(country)</p>
<p>Note that <span class="InputCode">area</span> disappeared. If you wanted to keep <span class="InputCode">area</span> (which you could, since it's a country-level variable) you'd need to add it to the command, probably using the <span class="InputCode">(first)</span> statistic.</p>
<p></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>The regression command is:</p>
<p class="InputCode">reg price c.weight##c.mpg</p>
<p>This includes <span class="InputCode">weight</span> and <span class="InputCode">mpg</span> as well as their product by treating them as main effects in the interaction between <span class="InputCode">weight</span> and <span class="InputCode">mpg</span>.</p>
<p>If you forget the <span class="InputCode">c.</span> in front of <span class="InputCode">weight</span> and <span class="InputCode">mpg</span>, Stata will assume they're both categorical variables and try to form an indicator for each possible combination of them. Fortunately the resulting error message gives several possible solutions, and the third one is correct.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>First review the results of the model including both main and interaction effects:</p>
<p class="InputCode">reg price c.weight##c.mpg</p>
<p>The coefficients on <span class="InputCode">weight</span> and <span class="InputCode">mpg</span> are both significant and positive, but the coefficient on their product is significant and negative.</p>
<p>To run the model without main effects, replace <span class="InputCode">##</span> with <span class="InputCode">#</span>:</p>
<p class="InputCode">reg price c.weight#c.mpg</p>
<p>First note that the R-squared of this model is essentially zero, as is its F-statistic: this model can't predict its way out of a paper bag. In addition, the coefficient on the product is now zero—and the standard error is quite small. What happened?</p>
<p>Since <span class="InputCode">c.weight#c.mpg</span> is made up of <span class="InputCode">weight</span> and <span class="InputCode">mpg</span>, you can't change it without changing one or both of its components. The first model suggests this is a complicated affair: increasing <span class="InputCode">weight</span> and/or <span class="InputCode">mpg</span> increases the expected <span class="InputCode">price</span> through its main effect, but decreases the expected <span class="InputCode">price</span> through the product. The second model, since it does not include the main effects, has to attribute the entire change to the effect of the product, and the combined effect turns out to be zero.</p>
<p>Having main and interaction effects cancel each other out so precisely is unusual. But it's even more unusual for main effects not to matter at all. If you leave them out, the model will have to attribute their effects to the interaction term. This might increase its coefficient or decrease it, but the important thing is that it will be wrong. The bottom line is that you should always include the main effects whenever you include an interaction.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="InputCode">sum weight if mpg&gt;25</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>First create an indicator variable for whether a car has <span class="InputCode">mpg</span>&gt;25:</p>
<p class="InputCode">gen highMPG=mpg&gt;25</p>
<p>Then test whether the subsample with <span class="InputCode">highMPG</span>=1 has a different mean from the subsample with <span class="InputCode">highMPG</span>=0:</p>
<p class="InputCode">ttest weight, by(highMPG)</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Ignoring the fact that <span class="InputCode">rep78</span> is a categorical variable gives:</p>
<p class="InputCode">reg price weight foreign rep78</p>
<p>The coefficient on <span class="InputCode">rep78</span> is about <span class="InputCode">150</span>, though with a 95% confidence interval of <span class="InputCode">-492</span> to <span class="InputCode">792</span> it's statistically indistuinguishable from zero.</p>
<p>That suggests that the contribution of <span class="InputCode">rep78</span> to a car's price is <span class="InputCode">150</span> times its value of <span class="InputCode">rep78</span>, i.e. for cars with a <span class="InputCode">rep78</span> of one it contrubutes <span class="InputCode">150</span>, for cars with a <span class="InputCode">rep78</span> of two it contributes <span class="InputCode">300</span>, etc. </p>
<p>Now run the regression with <span class="InputCode">i.rep78</span>:</p>
<p class="InputCode">reg price weight foreign i.rep78</p>
<p>The coefficient on each value of <span class="InputCode">i.rep78</span> represents its change from the base level of one. If the first model is right, we'd thus expect the coefficient on <span class="InputCode">2.rep78</span> to be <span class="InputCode">150</span> (a <span class="InputCode">rep78</span> of two contributes <span class="InputCode">300</span>, but we have to subtract the <span class="InputCode">150</span> contributed by a <span class="InputCode">rep78</span> of one), <span class="InputCode">3.rep78</span> to be <span class="InputCode">300</span>, etc. We can test the hypothesis that all those values are correct with:</p>
<p class="InputCode">test (2.rep78=150) (3.rep78=300) (4.rep78=450) (5.rep78==600)</p>
<p>The result does not reject this hypothesis, however that probably has more to do with the fact that we can't say much of anything about the effect of <span class="InputCode">rep78</span> than it actually being linear.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>You can find the values of the quartiles by adding the details option to sum:</p>
<p class="InputCode">sum mpg, d</p>
<p>Now look at the <em>r vector</em> to see where the numbers you want are stored:</p>
<p class="InputCode">return list</p>
<p>You numbers you want are called <span class="InputCode">r(p75)</span> and <span class="InputCode">r(p25)</span>. To calculate their difference, type:</p>
<p class="InputCode">gen iqr=r(p75)-r(p25)</p>
<p>You can see the value by typing:</p>
<p class="InputCode">tab iqr</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>If you do <span class="InputCode">by make:</span>, and <span class="InputCode">make</span> indeed uniquely identifies a car, then each <em>by</em> group will have exactly one car in it. That is in fact the case:</p>
<p class="InputCode">bysort make: l make</p>
<p>If there were two cars with the same value of <span class="InputCode">make</span> they'd be in the same <em>by</em> group. Thus in that group (and only that group, assuming no other duplicates) there would be an observation two--we'll take advantage of that fact in <a href="https://ssc.wisc.edu/sscc/pubs/sfr-groups.htm">Working with Groups</a>.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>The cars I should look at are:</p>
<pre>     +--------------------------------------+<br/>     | make             price   mpg   rep78 |<br/>     |--------------------------------------|<br/>  3. | AMC Spirit       3,799    22       . |<br/> 14. | Chev. Chevette   3,299    29       3 |<br/> 18. | Chev. Monza      3,667    24       2 |<br/> 19. | Chev. Nova       3,955    19       3 |<br/> 20. | Dodge Colt       3,984    30       5 |<br/>     |--------------------------------------|<br/> 24. | Ford Fiesta      4,389    28       4 |<br/> 29. | Merc. Bobcat     3,829    22       4 |<br/> 34. | Merc. Zephyr     3,291    20       3 |<br/> 43. | Plym. Champ      4,425    34       5 |<br/> 57. | Datsun 210       4,589    35       5 |<br/>     |--------------------------------------|<br/> 62. | Honda Civic      4,499    28       4 |<br/> 63. | Mazda GLC        3,995    30       4 |<br/> 65. | Renault Le Car   3,895    26       3 |<br/> 66. | Subaru           3,798    35       5 |<br/> 68. | Toyota Corolla   3,748    31       5 |<br/>     +--------------------------------------+
</pre>
<p>I can generate this list with the following command:</p>
<p class="InputCode">l make price mpg rep78 if price&lt;4000 | (price&lt;5000 &amp; rep78&gt;3 &amp; rep78&lt;. &amp; mpg&gt;25)</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>The cars it should ship are:</p>
<pre>
     +----------------------------------------------------+
     | make            foreign   length   weight    price |
     |----------------------------------------------------|
 53. | Audi 5000       Foreign      189    2,830    9,690 |
 54. | Audi Fox        Foreign      174    2,070    6,295 |
 55. | BMW 320i        Foreign      177    2,650    9,735 |
 56. | Datsun 200      Foreign      170    2,370    6,229 |
 58. | Datsun 510      Foreign      170    2,280    5,079 |
     |----------------------------------------------------|
 59. | Datsun 810      Foreign      184    2,750    8,129 |
 61. | Honda Accord    Foreign      172    2,240    5,799 |
 64. | Peugeot 604     Foreign      192    3,420   12,990 |
 67. | Toyota Celica   Foreign      174    2,410    5,899 |
 69. | Toyota Corona   Foreign      175    2,670    5,719 |
     |----------------------------------------------------|
 70. | VW Dasher       Foreign      172    2,160    7,140 |
 71. | VW Diesel       Foreign      155    2,040    5,397 |
 73. | VW Scirocco     Foreign      156    1,990    6,850 |
 74. | Volvo 260       Foreign      193    3,170   11,995 |
     +----------------------------------------------------+
</pre>
<p>This list was generated with the following command:</p>
<p class="InputCode">l make foreign length weight price if foreign &amp; length&lt;=200 &amp; weight&lt;=4000 &amp; price&gt;=5000</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>First of all, the reason you get no output is that no observation fulfills the <em>if</em> condition. But how can that be, given that many cars get  25 miles per gallon or less?</p>
<p> The trouble is that, once you apply the proper order of operations, this condition has nothing to do with "25 miles per gallon or less." The original version,</p>
<p class="InputCode">l make mpg if !(mpg&gt;25)</p>
<p>first checks to see if <span class="InputCode">mpg</span> is greater than 25 or not, then reverses the result. But precedence rules say the not operator (<span class="InputCode">!</span>) is evaluated before the greater than operator (<span class="InputCode">&gt;</span>). Thus this version,</p>
<p class="InputCode">l make mpg if !mpg&gt;25</p>
<p>is actually equivalent to:</p>
<p class="InputCode">l make mpg if (!mpg)&gt;25</p>
<p>The quantity <span class="InputCode">!mpg</span> is evaluated first, using the rule "zero is false and anything else is true." Since <span class="InputCode">mpg</span> is never zero, <span class="InputCode">mpg</span> by itself is always true. That means <span class="InputCode">!mpg</span> is always false.</p>
<p> Stata then evaluates the greater than condition. False is zero, and zero is not greater than 25. Thus the final result is always false. Actually, it doesn't matter whether <span class="InputCode">!mpg</span> is true or false, since true (one) isn't greater than 25 either.</p>
<p>This particular example may be less confusing if you think like Stata: always use 1 and 0 instead of true and false, and think of the <span class="InputCode">!</span> and <span class="InputCode">&gt;</span> operators as functions. <span class="InputCode">!x</span> is defined as 1 if x=0 and 1 otherwise, and <span class="InputCode">x&gt;y</span> is defined as 1 if x&gt;y and 0 otherwise. But regardless of how you think about it, the moral of this story is to always use parentheses to control the order things are evaluated in.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>The most concise varlist that would include all the variables in any data set is simply a star, all by itself:</p>
<p class="InputCode">l *</p>
<p>Of course there's no point in using <span class="InputCode">*</span> with <span class="InputCode">list</span>, since that's what it does with no <em>varlist</em> at all. But you might use it with other commands.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Solution</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>The <em>varlist</em></p>
<p class="InputCode">x? x??</p>
<p>will select all variables that start with x and then contain either one or two additional characters. <span class="InputCode">x1</span> through <span class="InputCode">x20</span> fit this pattern but <span class="InputCode">xenophobia</span> does not.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Stata for Students is designed for undergraduate students taking methodology classes in the social sciences at UW-Madison, but it will be useful to students taking similar classes elsewhere or anyone looking for a basic introduction to Stata. Graduate students and other researchers, and those who hope to someday be graduate students or researchers, should start with <a href="https://ssc.wisc.edu/sscc/pubs/intro_stata/intro_stata1.htm">Introduction to Stata</a> and then read <a href="https://ssc.wisc.edu/sscc/pubs/dws/data_wrangling_stata1.htm">Data Wrangling in Stata</a>.</p>
<p>Stata for Students divided into short articles that cover a single subject. You should read all the articles in the <strong>Stata Basics</strong> section before you do anything else. We also recommend reading the articles in the <strong>Understanding Stata</strong> section, as they will help everything else make  sense and make you a more efficient Stata user. After that you can read just the articles that correspond to the material covered in your class.</p>
<p>You will learn more if you actually carry out the steps described in these articles. All of the articles include examples you can do yourself. They use a subsample from the 2014 General Social Survey, which you'll download by doing the example in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>. (The <a href="http://gss.norc.org/">General Social Survey</a> (GSS) is a project of the independent research organization <a href="http://www.norc.org/">NORC</a> at the University of Chicago, with principal funding from the National Science Foundation.) If you have a  homework assignment to work on you may prefer to just read the articles and then immediately apply what you've learned to your assignment. In that case you can the ignore the specific instructions for the examples.</p>
<h2>Stata Basics</h2>
<ul>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-where.htm">Where You Can Use Stata</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a></li>
</ul>
<h2>Understanding Stata</h2>
<ul>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ui.htm">Stata's User Interface</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-data.htm">Stata Data Sets</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-syntax.htm">How Stata Commands Work</a><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ui.htm"></a></li>
</ul>
<h2>Other Topics</h2>
<ul>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-comments.htm">Comments and Other Tools for Making Do Files Readable</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-vars.htm">Creating Variables and Labels</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-graphs.htm">Using Graphs</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-import.htm">Reading Data from a Spreadsheet or CSV File</a> </li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-qualtrics.htm">Downloading Data from Qualtrics and Importing it into Stata</a></li>
</ul>
<h2>Statistical Commands by Class</h2>
<ul>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-soc357.htm">Sociology 357</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-soc360.htm">Sociology 360</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-econ310.htm">Economics 310</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-econ410.htm">Economics 410</a></li>
</ul>
<h2 id="topic">Statistical Commands by Topic                </h2>
<h3 id="desc">Descriptive Statistics</h3>
<ul>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-describe.htm"><span class="InputCode">describe</span>: Information about a data set and what it contains</a></li>
<li>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#oneway">Frequencies for a Single Categorical Variable</a></p>
<p>For a variable that describes  categories (like sex or race) rather than quantities (like income) frequencies tell you how many observations are in each category. These are examples of univariate statistics, or statistics that describe a single variable.</p>
<p>Categorical variables are also sometimes called factor variables. Indicator variables (also called binary or dummy variables) are just categorical variables with two categories. Frequency tables for a single variable are sometimes called one-way tables.</p>
</li>
<li>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#sum">Summary Statistics for a Single Quantitative Variable</a></p>
<p>For a variable that describes quantities (like income) the mean tells you what the expected value of the variable is, and the standard deviation tells you how much it varies. However, the median and percentiles often give you a better sense of how the variable is distributed, especially for variables that are not symmetric (like income, which often has a few very high values). These are also univariate statistics.</p>
<p>Quantitative variables are often called continuous variables. Means are often called averages, and variance is just the standard deviation squared. The median is also the 50th percentile.</p>
</li>
<li>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#twoway">Frequencies for Two Categorical Variables</a></p>
<p>For two categorical variables, frequencies tell you how many observations fall in each combination of the two categorical variables (like black women or hispanic men) and can give you a sense of the relationship between the two variables. These are examples of bivariate statistics, or statistics that describe the joint distribution of the two variables.</p>
<p>Tables of frequencies for two variables are often called two-way tables, contingency tables, or crosstabs.</p>
</li>
<li>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#tabsum">Summary Statistics for One Quantitative Variable over One Categorical Variable</a></p>
<p>For a  quantitative variable and a categorical variable, the mean value of the quantitative variable for those observations that fall in each category of the categorical variable can give you a sense of how the two variables are related. Of then the question of interest is whether the distribution of the quantitative variable is different for different categories. These are also examples of bivariate statistics.</p>
</li>
<li>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#threeway">Frequencies for Three or More Categorical Variables</a></p>
<p>For three or more categorical variables, frequencies <a href="#threeway"></a>will tell you how many observations fall in each combination of the variables and give you a sense of their relationships just like they did with two categorical variables. These are examples of multivariate statistics.<br/>
</p>
</li>
<li>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#twoway_sum">Summary Statistics for One Quantitative Variable over Two or More Categorical Variables</a></p>
<p>For a quantitative variable and two or more categorical variables, the  the mean value of the quantitative variable for those observations in each combination of the categorical variables can give you a sense of how the variables are related just like they did with a quantitative variable and one categorical variable. These are examples of multivariate statistics.</p>
</li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-cor.htm"><span class="InputCode">correlate</span>: Correlations between variables</a></li>
</ul>
<h3>Estimates and Hypothesis Tests</h3>
<ul>
<li><span class="InputCode"><a class="InputCode" href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ci.htm">mean</a></span><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ci.htm"> or <span class="InputCode">ci mean</span>: Estimate the population mean and its confidence interval for a variable</a></li>
<li><span class="InputCode"><a class="InputCode" href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ttest.htm">ttest</a></span><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ttest.htm">: Test hypotheses about means</a></li>
<li><span class="InputCode"><a class="InputCode" href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-prtest.htm">prtest</a></span><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-prtest.htm">: Test hypotheses about proportions</a></li>
</ul>
<h3 id="graphs">Graphs</h3>
<ul>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-hist.htm"><span class="InputCode">histogram</span>: Graphical representation of a variable's distribution</a></li>
<li><span class="InputCode"><a class="InputCode" href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-bargraph.htm">graph bar</a></span><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-bargraph.htm">: Bar graph representing summary statistics</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-scatter.htm"><span class="InputCode">scatter</span>: Scatterplot of two variables</a></li>
</ul>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Bar Graphs</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Bar graphs are a very useful tool for presenting summary statistics because the reader can instantly grasp the relationships between the various values. This is especially useful for non-technical audiences. In this article we'll discuss two simple bar graphs:</p>
<ul>
<li><a href="#mean">Mean of a Quantitative Variable Across a Categorical Variable</a></li>
<li><a href="#freq">Frequencies of a Categorical Variable</a></li>
</ul>
<p>You can build on what you learn here to create much more complex graphs.</p>
<h2>Setting Up</h2>
<p>If you plan to carry out the examples in this article, make sure you've downloaded the GSS sample to your U:\SFS folder as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>. Then create a do file called <span class="InputCode">bargraph.do</span> in that folder that loads the GSS sample as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a>. If you plan on applying what you learn directly to your homework, create a similar do file but have it load the data set used for your assignment.</p>
<h2 id="mean">Mean of a Quantitative Variable Across a Categorical Variable</h2>
<p>In the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#tabsum">Descriptive Statistics</a> section, one of the examples was:</p>
<p class="InputCode">tab class, sum(edu)</p>
<p>Which gives the following output:</p>
<pre class="InputCode"> SUBJECTIVE |
      CLASS |  Summary of HIGHEST YEAR OF SCHOOL
IDENTIFICAT |              COMPLETED
        ION |        Mean   Std. Dev.       Freq.
------------+------------------------------------
  LOWER CLA |        11.5   3.5630959          24
  WORKING C |   12.570248   3.1247038         121
  MIDDLE CL |    14.71134   3.0171688          97
  UPPER CLA |        15.2   3.4253954          10
------------+------------------------------------
      Total |   13.396825   3.3473052         252</pre>
<p>A few seconds spent examining this table will show that mean education increases with subjective class identification.</p>
<p>To make a bar graph of the same information, use the command <span class="InputCode">graph bar</span> followed by the quantitative variable whose means you want to see (in this case, <span class="InputCode">edu</span>). The variable that defines the categories (in this case, <span class="InputCode">class</span>) goes in an option called <span class="InputCode">over</span>:</p>
<p class="InputCode">graph bar edu, over(class)<br/>
</p>
<p><img alt="" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/bar1.png" width="600"/></p>
<p>Now the relationship is immediately obvious.</p>
<p>Many people prefer horizontal bar graphs because they better match the eye's natural left-to-right, top-to-bottom reading pattern (western eyes, anyway). They're especially good if the category names are long. You can convert this graph to a horizontal bar graph by changing the command from <span class="InputCode">graph bar</span> to <span class="InputCode">graph hbar</span>:</p>
<p class="InputCode">graph hbar edu, over(class)</p>
<p><img alt="" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/bar2.png" width="600"/></p>
<p>While this graph makes it easy to see the relationship between the two variables, it's hard to read off the values of the means. You can fix that, at the price of adding some clutter to your graph, by putting a label on each bar that gives the height of the bar. This is done by adding the  <span class="InputCode">blabel</span> (bar label) option with <span class="InputCode">bar</span> (bar height) in the parentheses:</p>
<p class="InputCode">graph hbar edu, over(class) blabel(bar)</p>
<p><img alt="" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/bar3.png" width="600"/></p>
<p>Some of the labels have more significant digits than are useful. You can tell Stata how to format the labels by putting a <span class="InputCode">format</span> option inside the <span class="InputCode">blabel</span> option with the format you want. The format <span class="InputCode">%9.1f</span> means "format the number such that it fits in no more than nine total spaces (more than enough) with one digit after the decimal point, following the general rules for floating point numbers" but you don't really need to memorize all that.</p>
<p class="InputCode">graph hbar edu, over(class) blabel(bar, format(%9.1f))</p>
<p><img alt="" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/bar4.png" width="600"/></p>
<h2 id="freq">Frequencies of a Categorical Variable</h2>
<p>Creating a bar graph to show the frequencies of a categorical variable is done in exactly the same way; just replace the first variable with <span class="InputCode">(count)</span>.</p>
<p class="InputCode">graph bar (count), over(class)</p>
<p><img alt="" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/bar5.png" width="600"/></p>
<p>Note how this is essentially a histogram, just with space between the bars and better labels (compare with <span class="InputCode">histogram class, discrete frequency</span>).</p>
<p>All the tools you learned in the previous section can apply here as well (but no need to worry about decimal places with frequencies).</p>
<p class="InputCode">graph hbar (count), over(class) blabel(bar)</p>
<p><img alt="" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/bar6.png" width="600"/></p>
<p>There is much more that can be done with bar graphs, such as changing labels and titles, and working with more than one categorical variable. If you're interested, click <span class="MenuOutput">Graphics</span>, <span class="MenuOutput">Bar chart</span> in Stata, and start experimenting.</p>
<h2 id="dofile">Complete Do File</h2>
<p>The following is a complete do file for this section:</p>
<p class="InputCode">capture log close<br/>
log using bargraph.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
<br/>
tab class, sum(edu)<br/>
<br/>
graph bar edu, over(class)<br/>
graph hbar edu, over(class)<br/>
<br/>
graph hbar edu, over(class) blabel(bar)<br/>
 graph hbar edu, over(class) blabel(bar, format(%9.1f))<br/>
<br/>
graph bar (count), over(class)<br/>
graph hbar (count), over(class) blabel(bar)<br/>
<br/>
log close</p><!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/sfs/bar1.png, https://ssc.wisc.edu/sscc/pubs/sfs/bar2.png, https://ssc.wisc.edu/sscc/pubs/sfs/bar3.png, https://ssc.wisc.edu/sscc/pubs/sfs/bar4.png, https://ssc.wisc.edu/sscc/pubs/sfs/bar5.png, https://ssc.wisc.edu/sscc/pubs/sfs/bar6.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Means and Confidence Intervals</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>In principle, estimating the mean value of a variable in a population and calculating the mean value of a variable in a sample are very different tasks. In practice, this distinction is obscured by the fact that most of the time the sample mean is the best estimate for the population mean. In this section we'll discuss two commands that estimate the mean value of a variable for a population and give you a 95% confidence interval for that estimate.</p>
<h2>Setting Up</h2>
<p>If you plan to carry out the examples in this article, make sure you've downloaded the GSS sample to your U:\SFS folder as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>. Then create a do file called <span class="InputCode">ci.do</span> in that folder that loads the GSS sample as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a>. If you plan on applying what you learn directly to your homework, create a similar do file but have it load the data set used for your assignment.</p>
<h2>Mean in a Sample</h2>
<p>The <span class="InputCode">summarize</span> command gives you the sample mean, as described in the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#sum">Descriptive Statistics</a> section:</p>
<p class="InputCode">sum educ</p>
<p>Produces:</p>
<pre class="InputCode">    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
        educ |        254    13.38583    3.336343          0         20</pre>
<h2>Mean in a Population</h2>
<p>The <span class="InputCode">mean</span> command estimates the population mean:</p>
<p class="InputCode">mean educ</p>
<p>Produces:<br/>
</p>
<pre class="InputCode">Mean estimation                   Number of obs   =        254

--------------------------------------------------------------
             |       Mean   Std. Err.     [95% Conf. Interval]
-------------+------------------------------------------------
        educ |   13.38583   .2093408      12.97355     13.7981
--------------------------------------------------------------</pre>
<p>Note how the estimated mean is exactly the same as that produced by <span class="InputCode">sum</span>. However, <span class="InputCode">mean</span> gives you a 95% confidence interval for that estimate.</p>
<p>You can get the  same results using the <span class="InputCode">ci</span> (confidence interval) command while specifying that you want the mean:</p>
<p class="InputCode">ci mean educ</p>
<p>This produces:</p>
<pre class="InputCode">    Variable |        Obs        Mean    Std. Err.       [95% Conf. Interval]
-------------+---------------------------------------------------------------
        educ |        254    13.38583    .2093408        12.97355     13.7981</pre>
<p>The  <span class="InputCode">mean</span> and <span class="InputCode">ci</span> commands can do a variety of other things, but for this purpose they produce the exact same results so which you use is purely a matter of taste—most likely your instructor's taste.</p>
<h2>Complete Do File</h2>
<p>The following is a complete do file for this section.</p>
<p class="InputCode">capture log close<br/>
log using ci.log, replace<br>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
<br/>
sum educ<br/>
mean educ<br/>
ci mean educ<br/>
<br/>
log close </br></p>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Comments and Other Readability Tools for Do Files</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Do files need to be readable by humans as well as Stata. In this article we'll talk about a few tools that can make it much easier for humans, like yourself, to read your do files.</p>
<h2>Blank Lines</h2>
<p>Stata doesn't care about blank lines in your code, but they can make it  easier for you to read. Put blank lines in between logical sections of your code, just like paragraphs in regular text.</p>
<p>Compare this do file:</p>
<p class="InputCode">                  capture log close<br/>
                  log using example1.log, replace<br/>
                  clear all<br/>
                  set more off<br/>
                  use gss_sample<br/>
                  sum age<br/>
                  log close<br/>
</p>
<p>To this one:</p>
<p class="InputCode">capture log close<br/>
                  log using example1.log, replace<br/>
<br/>
                  clear all<br/>
                  set more off<br/>
<br/>
                  use gss_sample<br/>
<br/>
                  sum age<br/>
<br/>
                log close</p>
<h2>Breaking up Long Lines</h2>
<p>Normally a do file has one command per line—in fact Stata uses the end of the line to know when the command is complete. However, if you put three slashes at the end of a line (<span class="InputCode">///</span>) then the command can continue on the next line. Use this to make long lines more readable. Graph commands can get very long very quickly:</p>
<p class="InputCode">graph hbar, over(life) blabel(bar, format(%5.1f)) ytitle(% of Respondents) title(Life is...) note(N=181)</p>
<p>This will be easier to read if you turn it into:</p>
<p class="InputCode">graph hbar, over(life) blabel(bar, format(%5.1f)) ///<br/>
<span class="indent3">                ytitle(% of Respondents) title(Life is...) note(N=181)</span></p>
<p>Indenting the second line makes it visually obvious that it's part of the previous line.</p>
<h2>Comments</h2>
<p>Comments are bits of text Stata will ignore. You can use them to explain your do file to other readers, or for notes to yourself. Your instructor might ask you to put your name in a comment so it appears in your log file.</p>
<p>Two slashes (<span class="InputCode">//</span>) means "the rest of this line is a comment." Alternatively, you can start a comment with <span class="InputCode">/*</span> and then it will continue until you type <span class="InputCode">*/</span>. Here are some examples of ways to use comments:</p>
<p class="InputCode">/* Create a set of indicator variables
for whether the respondent<br/>
answered the scientific knowledge questions correctly. */<br/>
<br/>
 gen bigbang_right=(bigbang==1) if bigbang&lt;.<br/>
gen electron_right=(electron==1) if electron&lt;.<br/>
// Correct answer for laser is 2, not 1<br/>
gen laser_right=(laser==2) if laser&lt;. </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Correlations</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section</em>.</p>
<p>                Correlations are a measure of how strongly related  two quantitative variables are. It can only perfectly measure linear relationships, but a linear relationship will serve as a first approximation to many other kinds of relationships. You can calculate correlations for categorical variables and the results you get will sometimes point you in the right direction, but there are <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm">better ways to describe relationships involving categorical variables</a>.</p>
<p>Correlation coefficients range from -1 to 1. A positive correlation coefficient means the two variables tend to move together: an observation which has a high value for one variable is likely to have a high variable for the other, and vice versa. The larger the coefficient the stronger the relationship. A negative correlation coefficient means they tend to move in opposite directions: observations with a high value for one variable are likely to have a low value for the other. Variables which are independent will have a correlation of zero, but variables which are related but not in a linear way can also have a correlation of zero.</p>
<h2>Setting Up</h2>
<p>If you plan to carry out the examples in this article, make sure you've downloaded the GSS sample to your U:\SFS folder as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>. Then create a do file called <span class="InputCode">cor.do</span> in that folder that loads the GSS sample as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a>. If you plan on applying what you learn directly to your homework, create a similar do file but have it load the data set used for your assignment.</p>
<h2>Calculating Correlations</h2>
<p>The <span class="InputCode">correlate</span> command, often abbreviated <span class="InputCode">cor</span>, calculates correlations. List the variables you want correlations for after the command.</p>
<p class="InputCode">cor sei10 educ height weight</p>
<p>This gives you the correlations between the respondent's socioeconomic status, years of education, height, and weight. They are given in the form of a matrix, but only half of the matrix is shown because it is symmetric:</p>
<pre class="InputCode">(obs=114)

             |    sei10     educ   height   weight
-------------+------------------------------------
       sei10 |   1.0000
        educ |   0.6205   1.0000
      height |   0.2466   0.1868   1.0000
      weight |   0.1048  -0.0224   0.5282   1.0000</pre>
<p>This shows that the correlation between socioeconomic status and education is .6205, which is fairly high. The correlation between socioeconomic status and height, .2466, is weaker, but it's interesting that its positive at all. Keep in mind that <a href="https://xkcd.com/552/">correlation does not imply causation</a>. We cannot tell from these results whether high socioeconomic status causes people to grow taller or being tall causes people to have higher socioeconomic status (both can be true, and there's  evidence for both theories), or if something else causes people to both grow taller and have higher socioeconomic status.</p>
<p>The correlation between weight and education is essentially zero, but the negative number indicates that people with higher levels of education are likely to have lower levels of weight. It's just a very small effect. On the other hand, given that education and height are positively correlated and height and weight are strongly positively correlated, this raises the possibility that education and weight might have a stronger negative relationship if we could control for height. Multivariate regression  allows us to explore that possibility.</p>
<h2>Calculating Covariances</h2>
<p>If you want covariances instead, add the <span class="InputCode">cov</span> option:</p>
<p class="InputCode">cor sei10 educ height weight, cov</p>
<pre class="InputCode">(obs=114)

             |    sei10     educ   height   weight
-------------+------------------------------------
       sei10 |  510.103
        educ |  43.4237  9.59983
      height |  22.7511  2.36376  16.6884
      weight |  99.2858 -2.91236  90.4648  1757.94</pre>
<p>Covariances are not bound to fall in the range of -1 to 1, and depend on both how much the variables vary together and how much they vary overall. But the interpretations of positive and negative numbers are similar. The diagonal of the matrix gives you the variance of each variable, or its standard deviation squared.</p>
<h2>Complete Do File</h2>
<p class="InputCode">capture log close<br/>
log using cor.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
<br/>
cor sei10 educ height weight<br/>
cor sei10 educ height weight, cov<br/>
<br/>
log close
<br/>
</p>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Stata Data Sets</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>In this section we'll take a look at two Stata data sets and see how they're put together.</p>
<p>Start up Stata, then type:</p>
<p class="InputCode">sysuse auto</p>
<p>This will load an example data set of 1978 cars that comes with Stata. Next either type:</p>
<p class="InputCode">browse</p>
<p>or click the button at the top that looks like a magnifying glass looking at a spreadsheet. This will open the data browser and let you look at the data set you've loaded.</p>
<table border="0" class="noBorder">
<tr>
<td>
<img alt="Stata data browser" height="400" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/browse_auto.png" width="739"/><br/>
</td></tr></table>
<p>As you see, a Stata data set looks a lot like a spreadsheet, only more structured. The rows are always represent observations, though it's not always obvious what an "observation" is in a given data set. In this data set an observation represents a kind of car, but just looking at it you might wonder if it represented individual cars. Always be sure you know what an observation is in your data set.</p>
<p>The columns represent variables. There are two main kinds of variables: numbers and text (Stata generally calls text variables "strings"). In this data set the <span class="InputCode">make</span> variable is a text variable and all the others are numbers.</p>
<table border="0" class="noBorder">
<tr>
<td>
<img alt="Stata data browser" height="400" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/browse_auto2.png" width="739"/>
</td></tr></table>
<p>What about the <span class="InputCode">foreign</span> variable? (Scroll right to see it.) It looks like text, but note that the text is blue instead of red. This tells us that it is a numeric variable that has value labels associated with it. The value labels tell Stata that 0 means "Domestic" (i.e. built in the United States) and 1 means "Foreign." You'll learn how to create value labels in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-vars.htm">Creating Variables</a>. Value labels are very useful, but they're only for your benefit: Stata commands that refer to the values of the <span class="InputCode">foreign</span> variable need to use the numbers 0 and 1, not the text "Domestic" or "Foreign."</p>
<p>By convention, 0 means false and 1 means true. Thus a 1 for a variable called <span class="InputCode">foreign</span> means "this car is foreign" and 0 means "this car is not foreign." If you always name binary variables after the "true" state then you almost don't need labels.</p>
<table border="0" class="noBorder">
<tr>
<td>
<img alt="Stata data browser" height="400" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/browse_auto3.png" width="739"/>
</td></tr></table>
<p>Next note the value of <span class="InputCode">rep78</span> (car's repair record in 1978, on a five-point scale) for the third observation, the AMC Spirit. Repair record  data weren't available for this car, so Stata stores a period, or dot, meaning that the value is missing. Surveys often need to store not just that a value is missing, but why (for example, the question didn't apply vs. the respondent refused to answer) so Stata can also use <span class="InputCode">.a</span>, <span class="InputCode">.b</span>, <span class="InputCode">.c</span>, up through <span class="InputCode">.z</span> for missing. Then data set creators can assign the different kinds of missing different meanings.</p>
<p>Internally, Stata stores <span class="InputCode">.</span> as a really big number and <span class="InputCode">.a</span>, <span class="InputCode">.b</span>, etc. as numbers that are even bigger than that. Just think of them all as positive infinity. That means that conditions like <span class="InputCode">x&gt;3</span> will be true if x is missing. On the other hand, <span class="InputCode">x&lt;.</span> will be true for all actual values of x and false for all missing values of x, including <span class="InputCode">.a</span> through <span class="InputCode">.z</span>. You'll learn how to use conditions like this in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-syntax.htm">How Stata Commands Work</a>.                </p>
<h2>The 2014 General Social Survey</h2>
<p>Next let's look at the 2014 General Social Survey. Close Stata. Go to the folder you created in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a> and double-click on <span class="MenuOutput">gss_sample.dta</span>. Then either type <span class="InputCode">browse</span> or click on the browse button.</p>
<table border="0" class="noBorder">
<tr>
<td>
<img alt="Stata Data Browser" height="400" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/browse_gss.png" width="739"/>
</td></tr></table>
<p> This is a much larger data set, in terms of both observations and variables—the Properties window in the bottom right has a Data section that will tell you just how big. Almost all the variables in this data set are in blue, meaning they have value labels. Some of these are like the value labels you saw before. For example, the <span class="InputCode">sex</span> variable has 1 labeled as "male" and 2 labeled as "female."</p>
<p> However, most of the value labels only label the missing values. For the <span class="InputCode">prestg10</span> variable (respondent's occupational prestige score in 2010), the values for the first eight observations really are just the numbers you see. For observation nine, the value <span class="InputCode">.a</span> has been labeled "IAP,DK,NA" (inapplicable, don't know, or no answer). Other variables use multiple kinds of missing and assign different labels to them: for <span class="InputCode">actlaw</span>, <span class="InputCode">.a</span> is "iap", <span class="InputCode">.b</span> is "CANT CHOOSE" [sic], and <span class="InputCode">.c</span> has no label assigned. The GSS, like many real-world data sets, has some missing values for a lot of variables and a lot of missing values for some variables.</p>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/browse_auto.png, https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/browse_auto2.png, https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/browse_auto3.png, https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/browse_gss.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Describe</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>The <span class="InputCode">describe</span> command gives you a variety of useful information about your data set.</p>
<h2>Setting Up</h2>
<p>If you plan to carry out the examples in this article, make sure you've downloaded the GSS sample to your U:\SFS folder as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>. Then create a do file called <span class="InputCode">desc.do</span> in that folder as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a> and start with the following code:</p>
<p class="InputCode">capture log close<br/>
                  log using desc.log, replace<br/>
<br/>
                  clear all<br/>
                  set more off<br/>
<br/>
                  use gss_sample<br/>
<br/>
                  // do work here<br/>
<br/>
                  log close</p>
<p>If you plan on applying what you learn directly to your homework, create a similar do file but have it load the data set used for your assignment.</p>
<h2>Using <span class="InputCode">describe</span></h2>
<p>If you run describe all by itself, you'll get a description of all the variables in the data set:</p>
<p class="InputCode">describe</p>
<p>Produces the output:</p>
<pre class="InputCode">Contains data from U:\sfs\gss_sample.dta
  obs:           254                          
 vars:           895                          22 Jun 2016 15:52
 size:       277,622                          
-----------------------------------------------------------------------------------------------------------------
              storage   display    value
variable name   type    format     label      variable label
-----------------------------------------------------------------------------------------------------------------
prestg10        byte    %8.0g      LABA       Rs occupational prestige score (2010)
sppres10        byte    %8.0g      LABA       Spouse occupational prestige score (2010)
papres10        byte    %8.0g      LABA       Father's occupational prestige score (2010)
mapres10        byte    %8.0g      LABA       Mother's occupational prestige score (2010)
prestg105plus   byte    %8.0g      LABA       Rs occupational prestige score using threshold method (2010)
sppres105plus   byte    %8.0g      LABA       Spouse occupational prestige score using threshold method (2010)
papres105plus   byte    %8.0g      LABA       Father's occupational prestige score using threshold method (2010)
mapres105plus   byte    %8.0g      LABA       Mother's occupational prestige score using threshold method (2010)
sei10           double  %12.0g     LABB       R's socioeconomic index (2010)
spsei10         double  %12.0g     LABB       R's spouse's socioeconomic index (2010)
pasei10         double  %12.0g     LABB       R's father's socioeconomic index (2010)
masei10         double  %12.0g     LABB       R's mother's socioeconomic index (2010)
sei10educ       double  %12.0g     LABB       Percentage of some college educ in OCC10 based on ACS 2010
spsei10educ     double  %12.0g     LABB       Percentage of some college educ in SPOCC10 based on ACS 2010
pasei10educ     double  %12.0g     LABB       Percentage of some college educ in PAOCC10 based on ACS 2010
masei10educ     double  %12.0g     LABB       Percentage of some college educ in MAOCC10 based on ACS 2010</pre>
<p>This is just the first page. With 895 variables, the <span class="InputCode">describe</span> output for the GSS is very long. Remember you can press 'q' or click on the red stop sign button to have Stata quit what it is doing.</p>
<p>A few highlights of this output:</p>
<ul>
<li>This data set has 254 observations, which in this case means 254 people who responded to the General Social Survey. It is a subset of the complete GSS results.</li>
<li>It has 895 variables.</li>
<li>The variable name is what you need to use in your commands.</li>
<li>The variable label can help you understand what each variable means, though it's no substitute for the complete GSS documentation.</li>
<li>All of these variables have something in the value label column. Commands like <span class="InputCode">tab</span> will show you the value labels by default, but code must refer to the actual values.</li>
</ul>
<p></p>
<p>If you want information about a specific variable, put its name right after describe:</p>
<p class="InputCode">describe sex</p>
<p>Produces:</p>
<pre class="InputCode">              storage   display    value
variable name   type    format     label      variable label
------------------------------------------------------------------
sex             byte    %8.0g      SEX        RESPONDENTS SEX</pre>
<p>With so many variables, it can be hard to find what you need in the GSS. One useful trick:</p>
<p class="InputCode">describe *edu*</p>
<p>This will describe all variables that contain "edu" anywhere in their name. The output is:</p>
<pre class="InputCode">              storage   display    value
variable name   type    format     label      variable label
------------------------------------------------------------------------------------------------------------
sei10educ       double  %12.0g     LABB       Percentage of some college educ in OCC10 based on ACS 2010
spsei10educ     double  %12.0g     LABB       Percentage of some college educ in SPOCC10 based on ACS 2010
pasei10educ     double  %12.0g     LABB       Percentage of some college educ in PAOCC10 based on ACS 2010
masei10educ     double  %12.0g     LABB       Percentage of some college educ in MAOCC10 based on ACS 2010
coneduc         byte    %8.0g      LABAB      CONFIDENCE IN EDUCATION
educ            byte    %8.0g      LABAJ      HIGHEST YEAR OF SCHOOL COMPLETED
immeduc         byte    %8.0g      IMMEDUC    LEGAL IMMIGRANTS SHOULD HAVE SAME EDUCATION AS AMERICANS
inteduc         byte    %8.0g      INTEDUC    INTERESTED IN LOCAL SCHOOL ISSUES
maeduc          byte    %8.0g      LABAJ      HIGHEST YEAR SCHOOL COMPLETED, MOTHER
nateduc         byte    %8.0g      LABBL      IMPROVING NATIONS EDUCATION SYSTEM
nateducy        byte    %8.0g      LABBL      EDUCATION -- VERSION Y
paeduc          byte    %8.0g      LABAJ      HIGHEST YEAR SCHOOL COMPLETED, FATHER
sexeduc         byte    %8.0g      SEXEDUC    SEX EDUCATION IN PUBLIC SCHOOLS
speduc          byte    %8.0g      LABAJ      HIGHEST YEAR SCHOOL COMPLETED, SPOUSE
usedup          byte    %8.0g      USEDUP     HOW OFTEN DURING PAST MONTH R FELT USED UP</pre>
<p>This is not a complete list of variables related to education, and includes one variable that is not related to education, <span class="InputCode">usedup</span>. But if you're interested in looking at education issues using the GSS it's a start.</p>
<h2>Complete Do File</h2>
<p>The following is a complete do file for this section.</p>
<p class="InputCode">capture log close<br/>
log using desc.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
<br/> 
describe<br/>
describe sex<br/>
describe *edu*
<br/>
<br/>
log close</p>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: tabulate</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>Descriptive statistics give you a basic understanding one or more variables and how they relate to each other.</p>
<h2>Topics Covered in this Section</h2>
<h3><a href="#oneway">Frequencies for a Single Categorical Variable</a></h3>
<p>For a variable that describes  categories (like sex or race) rather than quantities (like income) frequencies tell you how many observations are in each category. These are examples of univariate statistics, or statistics that describe a single variable.</p>
<p>Categorical variables are also sometimes called factor variables. Indicator variables (also called binary or dummy variables) are just categorical variables with two categories. Frequency tables for a single variable are sometimes called one-way tables.</p>
<h3><a href="#sum">Summary Statistics for a Single Quantitative Variable</a></h3>
<p>For a variable that describes quantities (like income) the mean tells you what the expected value of the variable is, and the standard deviation tells you how much it varies. However, the median and percentiles often give you a better sense of how the variable is distributed, especially for variables that are not symmetric (like income, which often has a few very high values). These are also univariate statistics.</p>
<p>Quantitative variables are often called continuous variables. Means are often called averages, and variance is just the standard deviation squared. The median is also the 50th percentile. </p>
<h3><a href="#twoway"> Frequencies for Two Categorical Variables</a></h3>
<p>For two categorical variables, frequencies tell you how many observations fall in each combination of the two categorical variables (like black women or hispanic men) and can give you a sense of the relationship between the two variables. These are examples of bivariate statistics, or statistics that describe the joint distribution of the two variables.</p>
<p>Tables of frequencies for two variables are often called two-way tables, contingency tables, or crosstabs.</p>
<h3><a href="#tabsum">Summary Statistics for One Quantitative Variable over One Categorical Variable</a></h3>
<p>For a  quantitative variable and a categorical variable, the mean value of the quantitative variable for those observations that fall in each category of the categorical variable can give you a sense of how the two variables are related. Of then the question of interest is whether the distribution of the quantitative variable is different for different categories. These are also examples of bivariate statistics.</p>
<h3><a href="#threeway">Frequencies for Three or More Categorical Variables</a></h3>
<p>For three or more categorical variables, frequencies <a href="#threeway"></a>will tell you how many observations fall in each combination of the variables and give you a sense of their relationships just like they did with two categorical variables. These are examples of multivariate statistics.</p>
<h3><a href="#twoway_sum">Summary Statistics for One Quantitative Variable over Two or More Categorical Variables</a></h3>
<p>For a quantitative variable and two or more categorical variables, the  the mean value of the quantitative variable for those observations in each combination of the categorical variables can give you a sense of how the variables are related just like they did with a quantitative variable and one categorical variable. These are examples of multivariate statistics.</p>
<h3>Commands Used</h3>
<p>All of these tasks can be carried out using just two Stata commands: <span class="InputCode">tabulate</span> (or <span class="InputCode">tab</span>) and <span class="InputCode">summarize</span> (or <span class="InputCode">sum</span>). Getting them to do all these things is simply a matter of applying Stata syntax, so so if you've read <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-syntax.htm">How Stata Commands Work</a> this section will have no surprises for you.</p>
<p>Some  commonly used options  can change what the tables produced by <span class="InputCode">tab</span> look like, as described in the sections below:</p>
<ul>
<li><a href="#perc">Adding percentages</a></li>
<li><a href="#nolabel">Viewing values instead of labels</a></li>
<li><a href="#miss">Viewing missing values</a> </li>
</ul>
<h2>Setting Up</h2>
<p>If you plan to carry out the examples in this article, make sure you've downloaded the GSS sample to your U:\SFS folder as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>. Then create a do file called <span class="InputCode">descriptives.do</span> in that folder as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a> and start with the following code:</p>
<p class="InputCode">capture log close<br/>
log using descriptives.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
<br/>
// do work here<br/>
<br/>
log close</p>
<p>If you plan on applying what you learn directly to your homework, create a similar do file but have it load the data set used for your assignment.</p>
<h2 id="oneway">Frequencies for a Single Categorical Variable</h2>
<p>The <span class="InputCode">tabulate </span>command, or just <span class="InputCode">tab</span>, creates tables of frequencies. To have it give  you frequencies for a single categorical variable simply tell it which variable you want it to act on:</p>
<p class="InputCode">tab sex</p>
<p>This produces the following output:</p>
<pre class="InputCode">RESPONDENTS |
        SEX |      Freq.     Percent        Cum.
------------+-----------------------------------
       male |        110       43.31       43.31
     female |        144       56.69      100.00
------------+-----------------------------------
      Total |        254      100.00</pre>
<p>This tells us that in the GSS sample, 110 of the respondents are male (43.31%) and 144 of the respondents are female (56.69%), for a total of 254 respondents.</p>
<h2 id="sum">Summary Statistics for a Single Quantitative Variable</h2>
<p>The <span class="InputCode">summarize</span> command, or just <span class="InputCode">sum</span>, creates tables of summary statistics. To have it give you summary statistics for a single variable, simply tell it which variable you want it to act on:</p>
<p class="InputCode">sum educ</p>
<p>This produces the following output:</p>
<pre class="InputCode">    Variable |        Obs        Mean    Std. Dev.       Min        Max
-------------+---------------------------------------------------------
        educ |        254    13.38583    3.336343          0         20</pre>
<p>This tells us that the mean years of education of the respondents in our GSS sample is 13.4 years.</p>
<p>If you want to see percentiles, add the <span class="InputCode">detail</span> option:</p>
<p class="InputCode">sum educ, detail</p>
<p>This produces the following output:</p>
<pre class="InputCode">              HIGHEST YEAR OF SCHOOL COMPLETED
-------------------------------------------------------------
      Percentiles      Smallest
 1%            5              0
 5%            7              2
10%           10              5       Obs                 254
25%           12              6       Sum of Wgt.         254

50%           13                      Mean           13.38583
                        Largest       Std. Dev.      3.336343
75%           16             20
90%           18             20       Variance       11.13118
95%           19             20       Skewness      -.3988663
99%           20             20       Kurtosis       3.899598</pre>
<p>The median, 13, is in the table as the 50th percentile. Note how the 25th percentile is 12, just one year lower than the median, while the 75th percentile is four years higher at 16. This shows that the distribution of <span class="InputCode">educ</span> is asymmetric. A histogram (<span class="InputCode">hist educ </span>or <span class="InputCode">hist educ, discrete</span>) would be a good tool to understand its distribution.</p>
<h2 id="twoway">Frequencies for Two Categorical Variables</h2>
<p>To have tab give you the joint distribution of two categorical variables, tell it which two variables you want it to act on:</p>
<p class="InputCode">tab class sex</p>
<p>This produces the following output:</p>
<pre class="InputCode">   SUBJECTIVE |
        CLASS |
IDENTIFICATIO |    RESPONDENTS SEX
            N |      male     female |     Total
--------------+----------------------+----------
  LOWER CLASS |        10         14 |        24 
WORKING CLASS |        57         64 |       121 
 MIDDLE CLASS |        37         60 |        97 
  UPPER CLASS |         5          5 |        10 
--------------+----------------------+----------
        Total |       109        143 |       252 </pre>
<p>This tells us that in the GSS sample 57 of the respondents are  males who consider themselves working class while 60 are females who consider themselves middle class. If you want percentages, see <a href="#perc">Adding Percentages to <span class="InputCode">tab</span> Output</a>.</p>
<p>The first variable you list will be placed in rows and the second in columns. The table will usually be easier to read if the variable with the most unique values is listed first. On the other hand, if you're thinking of the two variables as a dependent variable and an independent variable, the dependent variable is usually listed first so it goes in the rows.</p>
<h2 id="tabsum">Summary Statistics for One Quantitative Variable over One Categorical Variable</h2>
<p>If you start with a <span class="InputCode">tab</span> command and then add the <span class="InputCode">sum()</span> option, with the name of a continuous variable in the parentheses, Stata will add summary statistics for that variable to each cell of the table:</p>
<p class="InputCode">tab class, sum(edu)</p>
<p>Gives:</p>
<pre class="InputCode"> SUBJECTIVE |
      CLASS |  Summary of HIGHEST YEAR OF SCHOOL
IDENTIFICAT |              COMPLETED
        ION |        Mean   Std. Dev.       Freq.
------------+------------------------------------
  LOWER CLA |        11.5   3.5630959          24
  WORKING C |   12.570248   3.1247038         121
  MIDDLE CL |    14.71134   3.0171688          97
  UPPER CLA |        15.2   3.4253954          10
------------+------------------------------------
      Total |   13.396825   3.3473052         252</pre>
<p>This tells us that the 24 respondents who consider themselves lower class have an average of 11.5 years of education, while the 10 respondents who consider themselves upper class have an average of 15.2 years of education. Examination of the table as a whole suggests  a relationship between formal education and class, which should surprise no one.</p>
<h2 id="threeway">Frequencies for Three or More Categorical Variables</h2>
<p>You cannot give <span class="InputCode">tab</span> a list of three variables to act on. However, you can use <em>by</em> to create separate tables for each value of a categorical variable:</p>
<p class="InputCode">bysort sex: tab class race</p>
<p>This produces:</p>
<pre class="InputCode">-----------------------------------------------------------------
-&gt; sex = male

   SUBJECTIVE |
        CLASS |
IDENTIFICATIO |        RACE OF RESPONDENT
            N |     white      black      other |     Total
--------------+---------------------------------+----------
  LOWER CLASS |         6          1          3 |        10 
WORKING CLASS |        41          8          8 |        57 
 MIDDLE CLASS |        30          3          4 |        37 
  UPPER CLASS |         3          2          0 |         5 
--------------+---------------------------------+----------
        Total |        80         14         15 |       109 


------------------------------------------------------------------
-&gt; sex = female

   SUBJECTIVE |
        CLASS |
IDENTIFICATIO |        RACE OF RESPONDENT
            N |     white      black      other |     Total
--------------+---------------------------------+----------
  LOWER CLASS |         7          5          2 |        14 
WORKING CLASS |        49         12          3 |        64 
 MIDDLE CLASS |        45         10          5 |        60 
  UPPER CLASS |         3          1          1 |         5 
--------------+---------------------------------+----------
        Total |       104         28         11 |       143</pre>
<p>This tells us that the sample includes 6 respondents who are male, white, and identify as lower class, as well as 10 respondents who are female, black, and identify as middle class.</p>
<p>You can add as many variables as you need to the <em>by</em> part of the command:</p>
<p class="InputCode">bysort sex divorce: tab class race</p>
<p>However, the amount of output you'll get can become cumbersome quickly.</p>
<h2 id="twoway_sum">Summary Statistics for One Quantitative Variable over Two or More Categorical Variables</h2>
<p>The <span class="InputCode">sum()</span> option works exactly the same for tables with two or more categorical variables as it does with <a href="#sum">one categorical variable</a>.</p>
<p class="InputCode">tab class sex, sum(edu)</p>
<p>Produces:</p>
<pre class="InputCode">
                Means, Standard Deviations and Frequencies
                    of HIGHEST YEAR OF SCHOOL COMPLETED

SUBJECTIVE |
     CLASS |
IDENTIFICA |   RESPONDENTS SEX
      TION |      male     female |     Total
-----------+----------------------+----------
 LOWER CLA |      11.7  11.357143 |      11.5
           | 4.5227818   2.871803 | 3.5630959
           |        10         14 |        24
-----------+----------------------+----------
 WORKING C | 12.719298    12.4375 | 12.570248
           | 3.1495713  3.1212279 | 3.1247038
           |        57         64 |       121
-----------+----------------------+----------
 MIDDLE CL | 14.513514  14.833333 |  14.71134
           | 3.2966449  2.8532863 | 3.0171688
           |        37         60 |        97
-----------+----------------------+----------
 UPPER CLA |      15.2       15.2 |      15.2
           | 3.0331502  4.1472883 | 3.4253954
           |         5          5 |        10
-----------+----------------------+----------
     Total | 13.348624  13.433566 | 13.396825
           | 3.4490368  3.2793838 | 3.3473052
           |       109        143 |       252</pre>
<p>This tells us that the 37 males in our sample who identify as middle class have an average of 14.5 years of education, while the 60 females who identify as middle class have an average of 14.8 years of education.</p>
<p>If you need to consider three or more categorical variables, <a href="#threeway">use <em>by</em> as described above</a>.</p>
<h2 id="perc">Adding Percentages to <span class="InputCode">tab</span> Output</h2>
<p>By default Stata only shows percentages for tables with one variable. If you want percentages for other tables, you need to tell it which percentages you want by adding the appropriate option.</p>
<p>Consider the table of sex and class we created earlier:</p>
<p class="InputCode">tab class sex</p>
<pre class="InputCode">   SUBJECTIVE |
        CLASS |
IDENTIFICATIO |    RESPONDENTS SEX
            N |      male     female |     Total
--------------+----------------------+----------
  LOWER CLASS |        10         14 |        24 
WORKING CLASS |        57         64 |       121 
 MIDDLE CLASS |        37         60 |        97 
  UPPER CLASS |         5          5 |        10 
--------------+----------------------+----------
        Total |       109        143 |       252 </pre>
<p>If we add the <span class="InputCode">row</span> option, Stata will tell us what percentage of each class is male and what percentage is female in our sample:</p>
<p class="InputCode">tab class sex, row</p>
<pre class="InputCode">+----------------+
| Key            |
|----------------|
|   frequency    |
| row percentage |
+----------------+

   SUBJECTIVE |
        CLASS |
IDENTIFICATIO |    RESPONDENTS SEX
            N |      male     female |     Total
--------------+----------------------+----------
  LOWER CLASS |        10         14 |        24 
              |     41.67      58.33 |    100.00 
--------------+----------------------+----------
WORKING CLASS |        57         64 |       121 
              |     47.11      52.89 |    100.00 
--------------+----------------------+----------
 MIDDLE CLASS |        37         60 |        97 
              |     38.14      61.86 |    100.00 
--------------+----------------------+----------
  UPPER CLASS |         5          5 |        10 
              |     50.00      50.00 |    100.00 
--------------+----------------------+----------
        Total |       109        143 |       252 
              |     43.25      56.75 |    100.00 </pre>
<p>If we add the <span class="InputCode">column</span> (or <span class="InputCode">col</span>) option, Stata will tell us what percentage of the males are in each class and what percentage of the females are in each class:</p>
<p class="InputCode">tab class sex, col</p>
<pre class="InputCode">+-------------------+
| Key               |
|-------------------|
|     frequency     |
| column percentage |
+-------------------+

   SUBJECTIVE |
        CLASS |
IDENTIFICATIO |    RESPONDENTS SEX
            N |      male     female |     Total
--------------+----------------------+----------
  LOWER CLASS |        10         14 |        24 
              |      9.17       9.79 |      9.52 
--------------+----------------------+----------
WORKING CLASS |        57         64 |       121 
              |     52.29      44.76 |     48.02 
--------------+----------------------+----------
 MIDDLE CLASS |        37         60 |        97 
              |     33.94      41.96 |     38.49 
--------------+----------------------+----------
  UPPER CLASS |         5          5 |        10 
              |      4.59       3.50 |      3.97 
--------------+----------------------+----------
        Total |       109        143 |       252 
              |    100.00     100.00 |    100.00 </pre>
<p>If we add the <span class="InputCode">cell</span> option, Stata will tell us what percentage each combination of class and sex is of the total sample.</p>
<p class="InputCode">tab class sex, cell</p>
<pre class="InputCode">+-----------------+
| Key             |
|-----------------|
|    frequency    |
| cell percentage |
+-----------------+

   SUBJECTIVE |
        CLASS |
IDENTIFICATIO |    RESPONDENTS SEX
            N |      male     female |     Total
--------------+----------------------+----------
  LOWER CLASS |        10         14 |        24 
              |      3.97       5.56 |      9.52 
--------------+----------------------+----------
WORKING CLASS |        57         64 |       121 
              |     22.62      25.40 |     48.02 
--------------+----------------------+----------
 MIDDLE CLASS |        37         60 |        97 
              |     14.68      23.81 |     38.49 
--------------+----------------------+----------
  UPPER CLASS |         5          5 |        10 
              |      1.98       1.98 |      3.97 
--------------+----------------------+----------
        Total |       109        143 |       252 
              |     43.25      56.75 |    100.00 </pre>
<p>Which one you want depends on what question you're asking.</p>
<h2 id="nolabel">Viewing Values Instead of Labels</h2>
<p>By default <span class="InputCode">tab</span> shows  value labels for any variable that has them. If you need to see the actual values, add the <span class="InputCode">nolabel</span> option:</p>
<p class="InputCode">tab sex, nolabel</p>
<pre class="InputCode">RESPONDENTS |
        SEX |      Freq.     Percent        Cum.
------------+-----------------------------------
          1 |        110       43.31       43.31
          2 |        144       56.69      100.00
------------+-----------------------------------
      Total |        254      100.00</pre>
<h2 id="miss">Viewing Missing Values</h2>
<p>By default <span class="InputCode">tab</span> does not include missing values in its tables, which makes it easy to forget about them. Add the <span class="InputCode">missing</span> (or <span class="InputCode">miss</span>) option to see them:</p>
<p class="InputCode">tab class, miss</p>
<pre class="InputCode">   SUBJECTIVE |
        CLASS |
IDENTIFICATIO |
            N |      Freq.     Percent        Cum.
--------------+-----------------------------------
  LOWER CLASS |         24        9.45        9.45
WORKING CLASS |        121       47.64       57.09
 MIDDLE CLASS |         97       38.19       95.28
  UPPER CLASS |         10        3.94       99.21
           .b |          1        0.39       99.61
           na |          1        0.39      100.00
--------------+-----------------------------------
        Total |        254      100.00</pre>
<p>"<span class="InputCode">na</span>", i.e. "Not Applicable", is the value label applied to <span class="InputCode">.c</span> (as you can see if you add the <span class="InputCode">nolabel</span> option). The value <span class="InputCode">.b</span> also means missing, but has no label to say why it's missing. Whenever you use the <span class="InputCode">class</span> variable you should keep in mind that it is missing for two respondents.</p>
<h2 id="dofile">Complete Do File</h2>
<p>The following is a complete do file for this section:</p>
<p class="InputCode">capture log close<br/>
log using descriptives.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
<br/>
tab sex<br/>
<br/>sum educ<br/>
sum educ, detail<br/>
<br/>
tab class sex<br/>
<br/>
tab class, sum(educ)<br/>
<br/>
bysort sex: tab class race<br/>
bysort sex divorce: tab class race

<br/>
<br/>
tab class sex, sum(edu)<br/>
<br/>
tab class sex<br/>
tab class sex, row<br/>
tab class sex, col<br/>
tab class sex, cell<br/>
<br/>
tab sex, nolabel<br/>
<br/>
tab class, miss<br/>
<br/>
log close </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Doing Your Work Using Do Files</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>A do file is is just a list of Stata commands. When you tell Stata to "do" the do file, it will carry out all the commands in order. By putting all your commands in a do file, you can re-run them at any time. You can do part of a homework assignment on one day and then pick right up where you left off on the next. If it turns out you made a mistake, all you need to do is fix the part of the do file that's wrong and run it again—no need to start over. We strongly recommend you do all your work using do files. This is especially true if you plan on using Stata for research in the future.</p>
<h2></h2>
<p>One thing that often confuses new Stata users is that Stata works with three things at the same time: your <em>data</em>, your <em>commands</em>, and your <em>results</em>. A properly written do file will manage all three: it will create a <span class="InputCode">.log</span> file to store its results, load a <span class="InputCode">.dta</span> file containing the relevant data, and then run the commands that do the actual work.</p>
<h2>Creating a Do File</h2>
<p>If you are doing our example assignment, use Windows Explorer to open the U:\SFS folder you created in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>. If you're going straight to your homework, open the folder you created for it, making sure any data files you need are there.</p>
<p> Right-click on a blank spot inside the folder and choose <span class="MenuOutput">New</span>, <span class="MenuOutput">Text Document</span>. This will create a file in that folder called <span class="MenuOutput">New Text Document.txt</span>. (If <span class="MenuOutput">Text Document</span> is not an option on your computer, click <span class="MenuOutput">Microsoft Word Document</span> instead and you'll get <span class="MenuOutput">New Word Document.docx</span>.) If you're doing our example, change the name to <span class="InputCode">example1.do</span>. If you're doing a homework assignment, call it something logical like <span class="InputCode">homework1.do</span>.  Make sure you change the <span class="InputCode">.txt</span> (or <span class="InputCode">.docx</span>) part of the filename to <span class="InputCode">.do</span>, so Windows knows this will be a do file. If you don't see <span class="InputCode">.txt</span> or <span class="InputCode">.docx</span> at the end of the file name, revisit the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm#ViewingFileExtensions">instructions for making file extensions visible</a> in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>.</p>
<h2>Editing a Do File</h2>
<p>To edit a do file, go to the folder it is stored in and double-click on it. That will open the do file in Stata's do file editor and set Stata's working folder to the folder that it is stored in. If your data file(s) and log file(s) are or will be in the same folder, then you can just refer to them by name without specifying a location and Stata will find them automatically.</p>
<h2>Writing a Do File</h2>
<p>Almost all do files carry out the same basic steps.</p>
<h3>Create a Log File to Store Results</h3>
<p>The first thing your do file should do is set up a log file which will store its results. Make sure that no previous log files are still open with:</p>
<p class="InputCode">capture log close</p>
<p>Then open a new log file. We suggest giving a log file the same name as the do file it records, so either:</p>
<p class="InputCode">log using example1.log, replace</p>
<p>or something like:</p>
<p class="InputCode">log using homework1.log, replace
                  <br/>
</p>
<p>The <span class="InputCode">replace</span> option tells Stata it's okay to replace previous versions of that file.</p>
<h3>Clear Stata's Memory</h3>
<p>You always want to start a do file with a blank slate, so the next command should be:</p>
<p class="InputCode">clear all</p>
<p>This clears out any data or stored results from whatever you were doing before running this do file.</p>
<h3>Open a Data Set</h3>
<p>The command to open a Stata data set is <span class="InputCode">use</span>. If you're doing our example, type:</p>
<p class="InputCode">use gss_sample</p>
<p>If you're doing a homework assignment, replace <span class="InputCode">gss_sample</span> with the data set you're using. You don't need to type <span class="InputCode">.dta</span> at the end of the file name, but it won't hurt.</p>
<p>If the data set you want to work with is not in Stata format, you'll need the <span class="InputCode">import</span> command instead of <span class="InputCode">use</span>. You can click on <span class="MenuOutput">File</span>, <span class="MenuOutput">Import</span> in the main Stata window and then use the graphical user interface to set up the right options for reading in your data set, but be sure to copy the resulting command into your do file.</p>
<h3>Do Your Work</h3>
<p>You're now ready to do your work. If you're doing our example, type:</p>
<p class="InputCode">sum age</p>
<p>This will give you the mean age of the 2014 GSS respondents, along with other summary statistics. If you're doing homework, add whatever commands you need to do your assignment. Do files written for research may have hundreds of commands at this point.</p>
<h3>Finish Up</h3>
<p>Most homework assignments do not require you to save any changes to your data set. But if you have made changes to the data, like creating a new variable, and you want those changes to be available in the future, use the <span class="InputCode">save</span> command to save the modified data set:</p>
<p class="InputCode">save gss_sample2, replace</p>
<p>Again, the <span class="InputCode">replace</span> option means Stata can replace old versions of that file. However, note that the file name in the <span class="InputCode">save</span> command is not the same as in the earlier <span class="InputCode">use</span> command. <strong>Never save a modified data set over your original data file</strong>. If you do, and it turns out you made a mistake, you will have to get fresh copy of the data from its source. But if you keep the original data set intact, all you have to do is correct the mistake in your do file and run it again.</p>
<p>When you're all done, close your log file:</p>
<p class="InputCode">log close</p>
<p>That will normally be the last command in your do file.</p>
<h2>A Complete Do File</h2>
<p>Here is the complete do file described in the previous steps:</p>
<p class="InputCode">capture log close<br/>
                  log using example1.log, replace<br/>
<br/>
                  clear all<br/>
<br/>
                  use gss_sample<br/>
<br/>
                  sum age<br/>
<br/>
                  log close
                </p>
<h2>Running a Do File</h2>
<p>You can run a do file by pressing <span class="InputCode">Ctrl-D</span> or by clicking the button on the far right of the top menu that looks like a "play" button. If you select part of the do file, pressing Ctrl-D or clicking play will only run that part.</p>
<h2>Using Your Log</h2>
<p>The results of your do file will appear in the Results window, but they'll also be stored in your log file. Go back to the window showing your project's folder and the log file should have appeared there. Double-click on it and it will open in Notepad. Your professor may want you to send them this file directly or copy some or all of its contents into a Word document.</p>
<p>If you copy Stata results into Word, change the font for those results to Courier or something similar. Courier uses the same amount of space for each letter (<span class="InputCode">like this</span>) so the columns will line up properly.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Economics 310</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>This page contains links to articles describing the statistical topics covered in Economics 310 at UW-Madison. The articles assume you're already familiar with the basics of Stata, especially <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a> and <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a>.</p>
<p> <em>SSCC staff try to keep this list up-to-date, but you instructor may add to or take away from it at any time and information you receive from him or her about what material you are responsible for always takes priority.</em></p>
<ul>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-describe.htm"><span class="InputCode">describe</span>: Information about a data set and what it contains</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-hist.htm"><span class="InputCode">histogram</span>: Graphical representation of a variable's distribution</a></li>
<li>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#sum">Summary Statistics for a Single Quantitative Variable</a></p>
<p>For a variable that describes quantities (like income) the mean tells you what the expected value of the variable is, and the standard deviation tells you how much it varies. However, the median and percentiles often give you a better sense of how the variable is distributed, especially for variables that are not symmetric (like income, which often has a few very high values). These are also univariate statistics.</p>
<p>Quantitative variables are often called continuous variables. Means are often called averages, and variance is just the standard deviation squared. The median is also the 50th percentile.</p>
</li>
<li><span class="InputCode"><a class="InputCode" href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ci.htm">mean</a></span><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ci.htm"> or <span class="InputCode">ci mean</span>: Estimate the population mean and its confidence interval for a variable</a></li>
<li><span class="InputCode"><a class="InputCode" href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ttest.htm">ttest</a></span><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ttest.htm">: Test hypotheses about means</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-cor.htm"><span class="InputCode">correlate</span>: Correlations between variables</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-scatter.htm"><span class="InputCode">scatter</span>: Scatterplot of two variables</a><br/>
<br/>
</li>
</ul>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Economics 310</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>This page contains links to articles describing the statistical topics covered in Economics 410 at UW-Madison. The articles assume you're already familiar with the basics of Stata, especially <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a> and <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a>.</p>
<p> <em>SSCC staff try to keep this list up-to-date, but you instructor may add to or take away from it at any time and information you receive from him or her about what material you are responsible for always takes priority.</em></p>
<ul>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-describe.htm"><span class="InputCode">describe</span>: Information about a data set and what it contains</a></li>
<li>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#sum">Summary Statistics for a Single Quantitative Variable</a></p>
<p>For a variable that describes quantities (like income) the mean tells you what the expected value of the variable is, and the standard deviation tells you how much it varies. However, the median and percentiles often give you a better sense of how the variable is distributed, especially for variables that are not symmetric (like income, which often has a few very high values). These are also univariate statistics.</p>
<p>Quantitative variables are often called continuous variables. Means are often called averages, and variance is just the standard deviation squared. The median is also the 50th percentile.</p>
</li>
<li><span class="InputCode"><a class="InputCode" href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ci.htm">mean</a></span><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ci.htm"> or <span class="InputCode">ci mean</span>: Estimate the population mean and its confidence interval for a variable</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-cor.htm"><span class="InputCode">correlate</span>: Correlations between variables</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-scatter.htm"><span class="InputCode">scatter</span>: Scatterplot of two variables</a><br/>
<br/>
</li>
</ul>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Managing Stata Files</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>The easiest way to manage Stata files is to put all the files related to a given project, including files you download from Learn@UW, in a single folder. If that's something you're comfortable doing, you may be able to skim or completely skip this article. But if you usually just save things in the default location of the program you're using,  you may find a review of managing files helpful.</p>
<p>If you're using Winstat or one of the SSCC's Lab PCs, you should store your files on the U: drive, which is your personal disk space on the SSCC network. The U: drive is private (only you can access it), available from anywhere by logging into Winstat, and backed up five times a day. If you have installed Stata on your own computer, you can store your files on your local hard drive,  but we recommend doing some sort of backups regularly. This article will describe storing files on U:, but if you're storing files on a local drive just replace U: with the name of your drive.</p>
<h2>Windows Explorer</h2>
<p><img alt="The folder icon for Windows Explorer" height="38" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/explorer_icon.PNG" style="float: left; padding:5px;" width="60"/>The main program Windows uses to manage files is Windows Explorer (which is not the same as Internet Explorer). You'll use Windows Explorer to move files, create files, and start Stata by double-clicking on Stata files. Whenever you click on <span class="MenuOutput">Documents</span> or <span class="MenuOutput">Computer</span> or the folder icon on the task bar at the bottom of the screen, you're using Windows Explorer. Start Windows Explorer now. </p>
<h2 id="ViewingFileExtensions">Viewing File Extensions</h2>
<p>Windows thinks  you don't need to know about file name endings like <span class="InputCode">.dta</span>, <span class="InputCode">.do</span>, and <span class="InputCode">.log</span>, so it hides them from you by default. Dealing with Stata files will be much less confusing if you tell it you want to see these file name endings, or "extensions."</p>
<p>Press <span class="InputCode">Alt</span>. A new menu will appear near the top of the Windows Explorer window.</p>
<p><img alt="Press Alt and a new menu appears." height="372" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/new_menu.png" width="497"/></p>
<p> Click <span class="MenuOutput">Tools</span>, <span class="MenuOutput">Folder Options</span>, then the <span class="MenuOutput">View</span> tab. Uncheck the box that says <span class="MenuOutput">Hide extensions for known file types</span> and click <span class="MenuOutput">OK</span>. You will only need to do this once on each computer where you run Stata (including Winstat).</p>
<p><img alt="" height="481" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/uncheck.png" width="396"/></p>
<h2>Creating a Folder on the U: Drive</h2>
<p>Next click on <span class="MenuOutput">Computer</span> on the left. This will give you a list of drives available to your computer, including network drives. If you're using Winstat or a Lab PC, double-click on the drive with your name on it, <span class="MenuOutput"><em>Username</em> (\\sscwin\dfsroot\USERS) (U:)</span>. This is your U: drive, your space for storing files on the SSCC network.</p>
<p><img alt="The U: drive" height="422" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/u_drive.png" width="645"/></p>
<p>Right-click on a blank space inside the U: drive and choose <span class="MenuOutput">New</span>, <span class="MenuOutput">Folder</span>. This is the folder where you'll put all the Stata files for your current project. If you're going to do the examples we've created, call the new folder <span class="InputCode">SFS</span> (Stata for Students). If you're going to go straight to your class work, name the folder after the class you're taking (<span class="InputCode">Soc357</span>, <span class="InputCode">Econ310</span>, etc.).</p>
<p>If you're going to run Stata on your own computer you can put the new folder wherever  makes sense to you on your local hard drive.</p>
<h2>Downloading Files</h2>
<p>UW-Madison instructors frequently make files available through Learn@UW, including Stata data sets to be used in homework assignments. Stata can't read files from Learn@UW directly, so you'll need to download them and put them in the folder you've created.</p>
<p>Go to <a href="http://learnuw.wisc.edu/">Learn@UW</a> and  log in. Find the class you're taking and then locate the files associated with the assignment. (If you have any difficulties finding them, speak with your instructor or TA.) Click on the file you want, and then click on the <span class="MenuOutput">Download</span> button.</p>
<p>If the data set you need is on a different web site, the web site may have a process you need to follow to obtain the data set, or you may be able to download it like any other file. Your instructor or TA will be able to tell you more if you're getting the file for a class assignment. Some data sets will come "zipped" or otherwise compressed. If you double-click on a compressed file Windows will generally show you what it contains, but you'll need to actually extract (or "unzip") the data set before Stata can use it. The details of how to do that will depend on what software your computer uses to handle compressed files.</p>
<p>If you plan to do our examples in Stata for Students, <a href="https://ssc.wisc.edu/sscc/pubs/sfs/gss_sample.dta">click here to download a subsample of the 2014 General Social Survey</a>. (You can get the full data set from the <a href="http://gss.norc.org/Get-The-Data">GSS web site</a>.)</p>
<h3>Moving Downloaded Files to the U: Drive</h3>
<p>When your file has finished downloading it will be located in your Downloads folder. The next step is to move it from there to the U: drive. Go back to Windows Explorer, and click on <span class="MenuOutput">Downloads</span> on the left. Locate the file you just downloaded, right-click on it, and choose <span class="MenuOutput">Cut</span>.</p>
<p><img alt="Find the file in Downloads and Cut" height="398" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/file_cut.png" width="574"/> </p>
<p>Click the back button (the arrow pointing left in the upper left corner of Windows Explorer), and you should be back in the folder you just created. If the back button doesn't take you straight there, click on <span class="MenuOutput">Computer</span> on the left, then the <span class="MenuOutput">U:</span> drive, and then folder you made. Right-click on a blank space on the right and select <span class="MenuOutput">Paste</span>. The data file should appear in that folder.</p>
<p><img alt="Go to the folder you want to use and paste" height="398" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/file_paste.png" width="574"/></p>
<h2>Working With Your Files</h2>
<p>When you want to work with your files in the future, open Windows Explorer and go to <span class="MenuOutput">Computer</span>, <span class="MenuOutput">U:</span> drive, and then your folder. Double-click on a Stata data set or  do file and it will open in Stata automatically. This will also make the folder they're located in Stata's working folder, so you can use files in that folder without having to tell Stata where to find them.</p>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a><br/>
</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/explorer_icon.PNG, https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/new_menu.png, https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/uncheck.png, https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/u_drive.png, https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/file_cut.png, https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/file_paste.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Using Graphs</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>We'll talk about how to create various graphs in the statistical sections of Stata for Students, but in this article we'll discuss what to do with a graph once you've created it. The answer will depend on what your instructor asks you to turn in.</p>
<p>As an example, go to the U:\SFS folder you created in  <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a> and create a new do file called <span class="InputCode">usegraphs.do</span> as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a>. Open it, and start with:</p>
<p class="InputCode">capture log close<br/>
log using usegraphs.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
<br/>
histogram educ, discrete percent<br/>
<br/>
log close</p>
<p> This will create a histogram of the <span class="InputCode">educ</span> (years of education) variable. The options used tell Stata that <span class="InputCode">educ</span> is a discrete variable and thus the histogram should have a bin for each value, and that the y-axis should be labeled with percentages. The <span class="InputCode">histogram</span> command is discussed in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-hist.htm">Histograms</a>.</p>
<p><img alt="" height="442" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/educ_hist.png" width="510"/></p>
<p>If this were a homework assignment, your next task would be to get this graph to your instructor.</p>
<h2>Printing a Graph</h2>
<p>If your instructor asks you to print the graph and hand in the paper copy, click the button that looks like a printer at the top of the graph. If you're working in the SSCC computer lab you'll need to use <a href="http://ssc.wisc.edu/sscc/pubs/goprint.htm">GoPrint</a> to pay for your printing.</p>
<h2>Copying a Graph into a Word Document</h2>
<p>If your instructor asks you to put your graph in a Word document, right-click on the graph and choose <span class="MenuOutput">Copy</span>, then open your Word document and paste it in the proper location.</p>
<h2>Turning a Graph into a File</h2>
<p>If you just click the save button on the graph window, the graph will be saved as a Stata <span class="InputCode">.gph</span> file but other programs won't be able to use it. You can save the graph in a variety of standard image formats using <span class="InputCode">graph export</span>:</p>
<p class="InputCode">graph export  educ_hist.emf, replace</p>
<p>Stata will figure out what kind of file you want from the extension you put at the end of the file name. If you just want to send someone the graph itself, a <span class="InputCode">.pdf</span> file (Portable Document Format) is probably ideal. If you want to put the graph in a Word document, use <span class="InputCode">.emf</span> (Enhanced MetaFile). You can then go to Word and click <span class="MenuOutput">Insert</span>, <span class="MenuOutput">Picture</span> to add it to your document. Using <span class="InputCode">graph export</span> to save your graph as a file allows you to put the entire graph creation process in a do file.</p>
<h2>Complete Do File</h2>
<p>The following is a complete do file for this article, including saving the graph as an <span class="InputCode">.emf</span> file:</p>
<p class="InputCode">capture log close<br/>
log using usegraphs.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
<br/>
histogram educ, discrete percent<br/>
graph export  educ_hist.emf, replace<br/>
<br/>
log close</p>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/sfs/educ_hist.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Histograms</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>Histograms are a very useful graphical tool for understanding the distribution of a variable. They can be used for both categorical and quantitative variables. This section will teach you how to make histograms; <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-graphs.htm">Using Graphs</a> discusses what you can do with a graph once you've made it, such as printing it, adding it to a Word document, etc.</p>
<h2>Setting Up</h2>
<p>If you plan to carry out the examples in this article, make sure you've downloaded the GSS sample to your U:\SFS folder as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>. Then create a do file called <span class="InputCode">hist.do</span> in that folder as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a> and start with the following code:</p>
<p class="InputCode">capture log close<br/>
                  log using hist.log, replace<br/>
<br/>
                  clear all<br/>
                  set more off<br/>
<br/>
                  use gss_sample<br/>
<br/>
                  // do work here<br/>
<br/>
                  log close</p>
<p>If you plan on applying what you learn directly to your homework, create a similar do file but have it load the data set used for your assignment.</p>
<h2>Creating Histograms</h2>
<p>The command to create a histogram is just <span class="InputCode">histogram</span>, which can be abbreviated <span class="InputCode">hist</span>. It is followed by the name of the variable you want it to act on:</p>
<p class="InputCode">hist educ</p>
<p>This produces:</p>
<p><img alt="Basic histogram of educ" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/hist1.png" width="600"/></p>
<p>The y-axis is labeled as Density because Stata likes to think of a histogram as an approximation to a probability density function. You can change the Y-axis to count the number of observations in each bin with the <span class="InputCode">frequency</span> (or <span class="InputCode">freq</span>) option:</p>
<p class="InputCode">hist educ, freq</p>
<p><img alt="Histogram of educ with Y axis denoting frequencies" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/hist2.png" width="600"/></p>
<p>Percentages (<span class="InputCode">percent</span>) is another popular option. Note how the shape of the histogram is the same no matter how the Y-axis is labeled.</p>
<p>You can control how many "bins" the data are divided into with the <span class="InputCode">bin()</span> option, putting the desired number of bins in the parentheses. Compare the above with:</p>
<p class="InputCode">hist educ, freq bin(8)                </p>
<p><img alt="" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/hist3.png" width="600"/></p>
<p>You can miss features of the data by not using enough bins. For example, with the default 15 bins we can see that people are more likely to drop out of college in the first half of their college career than the second, but this is not visible with 8 bins.</p>
<p>For categorical variables, or quantitative variables that are integers and take on a fairly small number of values (<span class="InputCode">educ</span> qualifies with 20 values), the ideal is often to have one bin for each value. You can do this with the <span class="InputCode">discrete</span> option:</p>
<p class="InputCode">hist educ, freq discrete</p>
<p><img alt="" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/hist4.png" width="600"/></p>
<p>This further clarifies that what's really happening is that people are less likely to drop out in their last year of college.</p>
<p>There are many, many options you can set for histograms, such as titles and colors. The easy way to find all these options is to click <span class="MenuOutput">Graphics</span>, <span class="MenuOutput">Histogram</span>. Tweak the settings there until you get the graph you want, then copy the resulting command into your do file.                  </p>
<h2>Complete Do File</h2>
<p>The following is a complete do file for this section.</p>
<p class="InputCode">capture log close<br/>
log using hist.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
<br/>
hist educ<br/>
hist educ, freq<br/>
hist educ, freq bin(8)<br/>
hist educ, freq discrete<br/>
<br/>
log close</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/sfs/hist1.png, https://ssc.wisc.edu/sscc/pubs/sfs/hist2.png, https://ssc.wisc.edu/sscc/pubs/sfs/hist3.png, https://ssc.wisc.edu/sscc/pubs/sfs/hist4.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Reading Data from a Spreadsheet or Text File</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>Stata can use many kinds of data files. In this section we'll talk about how to import two of the most common kinds of data files: Excel spreadsheets and CSV (comma-separated variable) files.</p>
<p>If you want to carry out the examples for this section, click on the following links to download a <a href="https://ssc.wisc.edu/sscc/pubs/sfs/gss2014.xls">GSS sample in Excel format</a> and a <a href="https://ssc.wisc.edu/sscc/pubs/sfs/gss2014.csv">GSS sample in CSV</a> format, then move them to your U:\SFS folder as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>.  Note that these files are subsets of the full GSS results. You can get the full data set from the <a href="http://gss.norc.org/Get-The-Data">GSS web site</a>.</p>
<h2>Importing Excel Spreadsheets</h2>
<p>Normally you tell Stata what data set you want to use with the <span class="InputCode">use</span> command, but if the data set is an Excel spreadsheet, use <span class="InputCode">import excel</span> instead. Here's an example do file:</p>
<p class="InputCode">capture log close<br/>
log using imp.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
import excel using gss2014, firstrow<br/>
<br/>
 save gss2014_from_excel, replace<br/>
<br/>
log close </p>
<p>When you give the filename of the spreadsheet you do not need to include <span class="InputCode">.xls</span> or <span class="InputCode">.xlsx</span>, but if you do it needs to be the right one.</p>
<p></p>
<p>The <span class="InputCode">firstrow</span> option tells Stata that the first row of the spreadsheet contains the names of the variables. Otherwise it will name the variables A, B, C, etc.</p>
<p>There are other options that let you specify which which worksheet to read, or to only read in part of a spreadsheet so you can skip titles or notes that aren't really data. If you have a complicated spreadsheet you might click <span class="MenuOutput">File</span>, <span class="MenuOutput">Import Excel</span>, tweak the options in the dialog box you get until it can read the spreadsheet successfully, then copy the resulting command into your do file.</p>
<h2>Importing CSV Files</h2>
<p>A CSV file is really just a text file, but structured so that each line of text represents one observation and each variable is separated by a comma. Hence the name, comma-separated variable file. Text files that put a specific character between variables are also known as delimited files, and the Stata command to read them is <span class="InputCode">import delimited</span>.</p>
<p class="InputCode">capture log close<br/>
log using imp_csv.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
import delimited using gss2014<br/>
<br/>
 save gss2014_from_csv, replace<br/>
<br/>
log close
                </p>
<p>The <span class="InputCode">import delimited</span> command will try to figure out whether the first row contains variable names or data, and usually succeeds. If it gets it wrong, you can specify that the first row contains variable names with the <span class="InputCode">varnames(1)</span> option.</p>
<p>Importing an Excel spreadsheet or CSV file takes longer than loading a Stata data set, and there's no need to repeat that process every time you analyze the data. That's why these do files simply import a data set and save it as a Stata data set. You can then write a separate do file that loads the Stata data set and carries out  your analysis.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Proportion Tests</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>Proportion tests allow you to test hypotheses about proportions in a population, such as the proportion of the population that is female or the proportion that answers a question in a given way. Conceptually they are very similar to t-tests.  The command to run one is simply <span class="InputCode">prtest</span>, but the syntax will depend on the hypothesis you want to test. In this section we'll discuss the following types of tests:</p>
<h3><a href="#onesample">The Proportion in the Population is Equal to Some Specified Value</a></h3>
<p>One type of hypothesis simply asks whether the population proportion of a variable is equal to some particular value of interest.</p>
<h3><a href="http://ssc.wisc.edu/sscc/pubs/sfs/sfs-ttest.htm#paired">The Population Proportions for Two Variables are the Same</a></h3>
<p>Another type of hypothesis looks at whether two variables have the same proportions.</p>
<h3><a href="#twosample">The Population Proportions for Two Subsamples are the Same</a></h3>
<p>The final type of hypothesis we'll consider is whether two groups have the same proportions for a single variable.</p>
<p>For all these tests we've described the null hypothesis. Usually the null hypothesis is the opposite of what you're really interested in. For example, if you're investigating differences between men and women in the proportion that have earned a bachelor's degree, your null hypothesis will usually be that the proportions are the same. Your alternative hypothesis could then be one of the following: that the proportion of women with a bachelor's degree is higher than the proportion of men with a bachelor's degree, that the proportion of women with a bachelor's degree is different than the proportion of men with a bachelor's degree, or the proportion of women with a bachelor's degree is lower than the proportion of men with a bachelor's degree.</p>
<p>Stata will report results for all three alternative hypotheses, but you should choose which one you're interested in ahead of time. Looking at the results and then picking the alternative hypothesis that matches what you'd like to see will increase the probability of drawing the wrong conclusion from the test.</p>
<p>We will discuss the interpretation of the proportion test in detail for the first type of hypothesis (that the proportion is equal to a specified value) but the discussion applies to all the hypotheses a t-test can test.</p>
<h2>Setting Up</h2>
<p>If you plan to carry out the examples in this article, make sure you've downloaded the GSS sample to your U:\SFS folder as described in <a href="http://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>. Then create a do file called <span class="InputCode">prtests.do</span> in that folder that loads the GSS sample as described in <a href="http://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a>. If you plan on applying what you learn directly to your homework, create a similar do file but have it load the data set used for your assignment.</p>
<h2>Preparing Variables for Proportion Tests</h2>
<p>The <span class="InputCode">prtest</span> command assumes that the variables it will act on are binary (0/1) variables and the proportion of interest is the proportion of 1's. The GSS codes most of its binary variables as 1/2, so we'll need to create some new variables and change others to match what <span class="InputCode">prtest</span> is expecting. We'll use the following four variables in the examples for this section:</p>
<p><span class="InputCode">sex</span> is coded 1 for male, 2 for female. Create a variable called <span class="InputCode">female</span>  coded 0/1 (1 meaning "yes, this person is female") with:</p>
<p class="InputCode">gen female=(sex==2)</p>
<p>Recall that if you set a variable equal to a condition, the variable gets 1 if the condition is true and 0 if it is false.</p>
<p><span class="InputCode">evolved</span> (SCI KNOWLEDGE:HUMAN BEINGS DEVELOPED FROM ANIMALS) is coded 1/2 with 1 meaning "True" (the correct answer) and 2 meaning "False". Recode it to 0/1 with 1 meaning "Yes, the respondent said humans evolved from animals" by changing the 2's to 0's with:</p>
<p class="InputCode">recode evolved (2=0)</p>
<p><span class="InputCode">electron</span> (SCI KNOWLEDGE:ELECTRONS ARE SMALLER THAN ATOMS) is coded 1/2 with 1 meaning "True" (the correct answer) and 2 meaning "False". Recode it to 0/1 with 1 meaning "Yes, the respondent said electrons are smaller than atoms" by changing the 2's to 0's with:</p>
<p class="InputCode">recode electron (2=0)</p>
<p><span class="InputCode">relpersn</span>  (R[espondent] CONSIDER SELF A RELIGIOUS PERSON) is coded 1-4, but create a binary variable with:</p>
<p class="InputCode">gen religious=(relpersn&lt;3)  if relprsn&lt;.</p>
<p>This creates a variable <span class="InputCode">religious</span> which is 1 if the respondent described themselves as moderately (<span class="InputCode">relpersn</span>=2) or very (<span class="InputCode">relpersn</span>=1) religious and 0 otherwise. The <em>if</em> condition ensures that if <span class="InputCode">relpersn</span> is missing (the respondent didn't answer the question) then <span class="InputCode">religious</span> is also missing.</p>
<p>For more examples of code like this, see <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-vars.htm">Creating Variables</a>. It also discusses creating  labels, which is left as an exercise for the reader.</p>
<h2>Hypothesis: The Proportion is Equal to Some Specified Value</h2>
<p>The Census Bureau reports that proportion of females in the US population is 0.508 (50.8%), but the proportion female in our sample is .567 (56.7%). Is this difference significant? To test,  the syntax is:</p>
<p class="InputCode">prtest female=0.508</p>
<p>This gives the following output:</p>
<pre class="InputCode">One-sample test of proportion                 female: Number of obs =      254
------------------------------------------------------------------------------
    Variable |       Mean   Std. Err.                     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      female |   .5669291   .0310905                       .505993    .6278653
------------------------------------------------------------------------------
    p = proportion(female)                                        z =   1.8786
Ho: p = 0.508

    Ha: p &lt; 0.508               Ha: p != 0.508                 Ha: p &gt; 0.508
 Pr(Z &lt; z) = 0.9698         Pr(|Z| &gt; |z|) = 0.0603          Pr(Z &gt; z) = 0.0302</pre>
<p>Formal evaluation compares the null hypothesis (<span class="InputCode">Ho</span>), that the proportion (<span class="InputCode">p</span>) is 0.508, with one of three alternative hypotheses (<span class="InputCode">Ha</span>): that the proportion is less than 0.508, that the proportion is not equal to 0.508 but could be bigger or smaller, and that the proportion is greater than 0.508. You must pick the alternative hypothesis you're interested in testing before running the test.</p>
<p>First consider <span class="InputCode">Ha: p &lt; 0.508</span>. If the proportion female in the population is 0.508, the probability of drawing a sample of 254 observations with a proportion female less than 0.566921, which is what we observe in the sample, is 0.9698 (i.e. it's very likely). So if your alternative hypothesis is that the GSS population has a lower proportion female than the US population, then you should accept the null hypothesis, that they are the same, instead.</p>
<p>Next consider <span class="InputCode">Ha: p != 0.508</span>. If the proportion female in the population is 0.508, the probability of drawing a sample of 254 observations where the proportion female is at least 0.5669291-0.508=0.0589291 away from that in either direction is 0.0603. This is still above the conventional threshold for significance of 0.05, so if your alternative hypothesis is that the proportion is not 0.508 you should reject it in favor of the null hypothesis again.</p>
<p>Finally consider <span class="InputCode">Ha: p &gt; 0.508</span>. If the proportion female in the population is 0.508, the probability of drawing a sample of 254 observations with a proportion female of 0.5669291 or greater is 0.0302, i.e. it's not very likely. Since this is below the usual threshold of 0.05, if your alternative hypothesis is that the proportion female in the population is greater than 0.508, then you should reject the null hypothesis and accept the alternative instead.</p>
<p>Does this mean the GSS sample is not drawn from the US population? No, but it does suggest females may be more likely to respond to the GSS than males, which could bias any analysis done with this GSS sample. This is a very important issue in survey research and statistics in general, but techniques for correcting that bias, like weighting the data, are beyond the scope of  Stata for Students.</p>
<h2>Hypothesis: Two Variables have the Same Proportion</h2>
<p>Now consider the variables <span class="InputCode">evolved</span> and <span class="InputCode">electron</span>. One possible research hypothesis is that the relative  sizes of electrons and atoms is a  more obscure issue than evolution, so the proportion getting the <span class="InputCode">evolved</span> question right should be larger than the proportion getting the  <span class="InputCode">electron</span> question right. Another possible research hypothesis is that some respondents are aware of the scientific consensus on evolution but choose not to respond "true" to the evolution question for religious reasons, and thus the proportion giving the correct answer for <span class="InputCode">evolved</span> will be lower than the proportion giving the correct answer for <span class="InputCode">electron</span> (because <span class="InputCode">electron</span> does not raise similar issues). You can test both with: </p>
<p class="InputCode">prtest evolved=electron</p>
<pre class="InputCode">Two-sample test of proportions               evolved: Number of obs =      105
                                            electron: Number of obs =       83
------------------------------------------------------------------------------
    Variable |       Mean   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
     evolved |    .552381   .0485265                      .4572708    .6474911
    electron |   .7108434   .0497639                      .6133079    .8083788
-------------+----------------------------------------------------------------
        diff |  -.1584624   .0695073                     -.2946943   -.0222306
             |  under Ho:   .0712048    -2.23   0.026
------------------------------------------------------------------------------
        diff = prop(evolved) - prop(electron)                     z =  -2.2254
    Ho: diff = 0

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(Z &lt; z) = 0.0130         Pr(|Z| &gt; |z|) = 0.0261          Pr(Z &gt; z) = 0.9870</pre>
<p>Keep in mind that Stata is comparing the proportion of 1's for the two variables. It is up to you to ensure that this makes sense: in this case both variables are coded so that a 1 means the respondent gave the correct answer.</p>
<p>Stata calculated the difference (<span class="InputCode">diff</span>) between the two proportions as <span class="InputCode">prop(evolved) - prop(electron)</span>, so the alternative hypothesis <span class="InputCode">Ha: diff &lt; 0</span> is also the hypothesis that the proportion giving the right answer for <span class="InputCode">evolved</span> is smaller than the proportion giving the right answer for <span class="InputCode">electron</span>, while <span class="InputCode">Ha: diff &gt; 0</span> is the hypothesis that the proportion giving the right answer for <span class="InputCode">electron</span> is greater than <span class="InputCode">evolved</span>.</p>
<p>If your research hypothesis is that more people know about evolution than the size of electrons, the relevant alternative hypothesis is <span class="InputCode">Ha: diff &gt; 0</span>, and the very large p-value suggests you should reject the alternative and accept the null hypothesis (no difference). This finding would  not support your research hypothesis.</p>
<p>If your research hypothesis is that some people choose not to answer "true" to the <span class="InputCode">evolved</span> question for religious reasons, then the relevant alternative hypothesis is <span class="InputCode">Ha: diff &lt; 0</span> and the low p-value suggests you should reject the null hypothesis and accept the alternative. This finding is consistent with your research hypothesis.</p>
<h2>Hypothesis: Two Subsamples have the Same Proportion</h2>
<p>But if we think people are choosing not to answer "true" to the evolve question for religious reasons, we should see a difference in the proportion responding "true" between religious respondents and non-religious respondents. We can test that with the following syntax:</p>
<p class="InputCode">prtest evolve, by(religious)</p>
<pre class="InputCode">Two-sample test of proportions                     0: Number of obs =       48
                                                   1: Number of obs =       57
------------------------------------------------------------------------------
    Variable |       Mean   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           0 |   .7291667   .0641422                      .6034503    .8548831
           1 |   .4035088   .0649817                       .276147    .5308706
-------------+----------------------------------------------------------------
        diff |   .3256579   .0913063                      .1467008     .504615
             |  under Ho:   .0974115     3.34   0.001
------------------------------------------------------------------------------
        diff = prop(0) - prop(1)                                  z =   3.3431
    Ho: diff = 0

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(Z &lt; z) = 0.9996         Pr(|Z| &gt; |z|) = 0.0008          Pr(Z &gt; z) = 0.0004</pre>
<p>Stata calculates the difference (<span class="InputCode">diff</span>) as <span class="InputCode">prop(0) - prop(1)</span>, or proportion of non-religious people who answered true minus proportion of religious people who answered true. Thus the hypothesis that religious people are less likely to answer true is <span class="InputCode">Ha: diff &gt; 0</span> and the very low p-value associated with it suggests we should reject the null and accept that alternative hypothesis.</p>
<p>On the other hand, it's possible that that religious people simply know less about science. If that were the case, we would expect the proportion of religious people who respond correctly to <span class="InputCode">electron</span> to be lower than the proportion of non-religious people:</p>
<p class="InputCode">prtest electron, by(religious)</p>
<pre class="InputCode">Two-sample test of proportions                     0: Number of obs =       36
                                                   1: Number of obs =       47
------------------------------------------------------------------------------
    Variable |       Mean   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           0 |   .6944444   .0767737                      .5439707    .8449182
           1 |   .7234043   .0652476                      .5955214    .8512871
-------------+----------------------------------------------------------------
        diff |  -.0289598   .1007544                     -.2264348    .1685152
             |  under Ho:   .1004136    -0.29   0.773
------------------------------------------------------------------------------
        diff = prop(0) - prop(1)                                  z =  -0.2884
    Ho: diff = 0

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(Z &lt; z) = 0.3865         Pr(|Z| &gt; |z|) = 0.7730          Pr(Z &gt; z) = 0.6135
</pre>
<p>The high p-value associated with <span class="InputCode">Ha: diff &gt; 0</span> suggests you should accept the null hypothesis (no difference) instead. In fact the proportion of religious people who answered electron correctly is slightly higher than the proportion of non-religious people, but the difference is not significant (no matter which specific alternative hypothesis you choose to test).</p>
<p> While it is certainly not conclusive, this combination of results supports the research hypothesis that some religious people choose not to answer "true" to the evolved question for religious reasons despite likely being aware of the scientific consensus on the issue. (On the other hand, note that 40% of religious people did answer "true" while 27% of non-religious people answered "false.")</p>
<h2>Saving the Data?</h2>
<p>In order to carry out this analysis you had to create two variables (<span class="InputCode">female</span> and <span class="InputCode">religious</span>) and recode two others (<span class="InputCode">evolve</span> and <span class="InputCode">electron</span>). Should you save the modified data set?</p>
<p>If this is the end of your analysis you don't need to. The commands to create and recode those variables are stored in the do file, so it will load the original GSS sample, create the variables it needs, and then carry out the analysis any time you run it.</p>
<p>If you want to carry out more analysis using these variables, you could save the data set with a command like:</p>
<p class="InputCode">save gss2, replace</p>
<p>You could then write a new do file that starts by loading gss2, and it will be able to use the new and modified variables immediately.</p>
<p>What you should <strong>not</strong> do is save the modified data set with the same name as the original data set (gss_sample) so that it overwrites the original data. If you do that, your do file will not work because  the variables <span class="InputCode">female</span> and <span class="InputCode">religious</span> will already exist and Stata won't allow you to create them again. Worse, if it turns out that you made a mistake, you'll need to download the data set again to fix it rather than being able to just fix your do file and run it again.</p>
<p> For research work, we recommend putting data preparation (e.g. creating and recoding variables) and analysis in separate do files. That way you can be sure that all your analysis is based on the same data.</p>
<h2>Complete Do File</h2>
<p>The following is a complete do file for this section.</p>
<p class="InputCode">capture log close<br/>
log using prtests.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
gen female=(sex==2)<br/>
recode evolved (2=0)<br/>
recode electron (2=0)<br/>
gen religious=(relpersn&lt;3) if relpersn&lt;.<br/>
<br/>
prtest female=0.508<br/>
<br/>
prtest evolved=electron<br/>
<br/>
prtest evolve, by(religious)<br/>
prtest electron, by(religious)<br/>
<br/>
save gss2,replace<br/>
log close </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Downloading Data from Qualtrics and Importing it into Stata</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em><br/>
</p>
<p>This article will teach you how to download data from a survey you've created using Qualtrics and import it into Stata. We'll assume you've already learned to use Qualtrics, created a survey, and collected data using it.</p>
<h2>Downloading the Data</h2>
<p>Begin by <a href="https://uwmadison.co1.qualtrics.com/ControlPanel/">logging into Qualtrics</a>, and opening your survey. Then go to <span class="MenuOutput">Data &amp; Analysis,</span> click the <span class="MenuOutput">Export &amp; Import</span> button, and choose <span class="MenuOutput">Export Data...</span></p>
<table border="1" class="noBorder" width="100%">
<tbody>
<tr>
<td align="center"><img alt="Dialog for downloading data from Qualtrics." height="518" src="https://ssc.wisc.edu/sscc/pubs/sfs/qualtrics_download.PNG" width="569"/></td>
</tr>
</tbody>
</table>
<p>Choose <span class="MenuOutput">CSV</span>, select <span class="MenuOutput">Use numeric values</span> and then <span class="MenuOutput">Download</span>. A CSV, or Comma-Separated Values file, is a text file containing data with one observation per line and a comma between each value. Many computers treat CSV files like Excel files, but they're really just text.</p>
<p><em>Note: for work that is not a class assignment it's usually easier to download an SPSS file and convert it to Stata format using Stat/Transfer, as it will come with  variable and value labels already defined. If your instructor told you to download a CSV file (as is typical in Soc 357) it's to give you an opportunity to practice preparing a data set.</em></p>
<p> Qualtrics will give you a zip file containing the CSV file you actually want to work with. Usually if you tell your browser to open the zip file you'll be able to see the CSV file.</p>
<table border="1" class="noBorder" width="100%">
<tbody>
<tr>
<td align="center"><img alt="Your CSV file, seen inside the Zip file." height="351" src="https://ssc.wisc.edu/sscc/pubs/sfs/zip.PNG" width="570"/></td>
</tr>
</tbody>
</table>
<p>You'll need to put the file in a permanent location, most likely wherever you normally put files associated with your class. On the SSCC network, the U: drive is a good choice. One way to do that is to right click on the file, choose <span class="MenuOutput">Copy</span>, go to the permanent location, and choose <span class="MenuOutput">Paste</span>.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Create a do file in that location</a> and double-click on it to start Stata. Have your do file create a log file and set up the Stata environment <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">as usual</a>. When it comes time to load your data, you'll need to import it, and Qualtrics files need a bit of special attention.</p>
<h2>Importing the Data</h2>
<p>The easy way to import a CSV file is to click <span class="MenuOutput">File</span>, <span class="MenuOutput">Import</span>, <span class="MenuOutput">Text Data</span>. This will open an import window with the various settings you can choose and a preview of how the data will be interpreted with the current settings. Thus you can tweak the settings until the preview makes sense and then click <span class="MenuOutput">OK</span> to actually import the data. Just be sure to copy the resulting command into your do file so you don't have to go through that process every time. You'll start with something like the following:</p>
<table border="1" class="noBorder" width="100%">
<tbody>
<tr>
<td align="center"><img alt="Importing the data. At first there will be rows and columns you don't need." height="624" src="https://ssc.wisc.edu/sscc/pubs/sfs/import1.PNG" width="564"/></td>
</tr>
</tbody>
</table>
<p>The CSV file Qualtrics gives you  contains some variables you almost certainly don't care about, like the date and  time the respondent started the survey, and some rows that don't actually represent observations. Instead they contain "metadata" or information about the data. Most of that metadata cannot be used by Stata, and if you tell Stata to treat those rows as observations it will be very confused. The key to importing Qualtrics data into Stata is to use the <span class="MenuOutput">Set range</span> button to only import the part of the data that you want and can use.</p>
<p>Scroll right until you find the actual questions in your survey. In this example, they start in column 18:</p>
<table border="1" class="noBorder" width="100%">
<tbody>
<tr>
<td align="center"><img alt="Importing the data 2: finding the actual data." height="624" src="https://ssc.wisc.edu/sscc/pubs/sfs/import2.PNG" width="564"/></td>
</tr>
</tbody>
</table>
<p>Note how the actual responses begin in row 5. Now you're ready to click <span class="MenuOutput">Set range</span>:</p>
<table border="1" class="noBorder" width="100%">
<tbody>
<tr>
<td align="center"><img alt="The dialog for setting the rows and columns to be read." height="179" src="https://ssc.wisc.edu/sscc/pubs/sfs/import3.PNG" width="403"/></td>
</tr>
</tbody>
</table>
<p>Under <span class="MenuOutput">Rows</span>, check <span class="MenuOutput">First</span> and set it to <span class="InputCode">5</span>. Under <span class="MenuOutput">Columns</span> check <span class="MenuOutput">First</span> and set it to <span class="InputCode">18</span> (or the corresponding numbers for your data set). When you click OK, the preview window will look quite different:</p>
<table border="1" class="noBorder" width="100%">
<tbody>
<tr>
<td align="center"><img alt="" height="624" src="https://ssc.wisc.edu/sscc/pubs/sfs/import4.PNG" width="564"/></td>
</tr>
</tbody>
</table>
<p>With the metadata rows gone, Stata should recognize that the file contains variable names (<span class="InputCode">q1</span>, <span class="InputCode">q2</span>, etc.) and use them automatically. It will also recognize that the variables are numeric rather than text, so they'll be black instead of red. Click <span class="MenuOutput">OK</span> and you'll get a usable data set. Be sure to copy the command Stata runs into your do file so that in the future this whole process will happen automatically. It will look something like:</p>
<p class="InputCode">import delimited "U:\357\357 Example_March 7, 2018_09.38.csv", rowrange(5) colrange(18)</p>
<h2>Preparing the Data</h2>
<p>While the resulting data set can be used as-is, the variable names are not very informative, and variable and value labels would be very helpful (and possibly required for your class). Variable labels can only be 80 characters long, so you may need to abbreviate your questions. You may also want to create indicator variables for yes/no questions rather than using Qualtrics's default 1/2 coding. Instructions for doing all these things can be found in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-vars.htm">Stata for Students: Creating Variables and Labels</a>. We won't repeat them here, but the following do file is an example of their use. You may need to refer to your survey in Qualtrics to get details about the questions and possible responses.</p>
<p class="InputCode">capture log close<br/>
log using prepdata.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
import delimited "U:\357\357 Example_March 7, 2018_09.38.csv", rowrange(5) colrange(18)<br/>
<br/>
rename q1 difficult<br/>
label variable difficult "Using Stata for assignments in this class was difficult for me."<br/>
label define agree 1 "Strongly Agree" 2 "Somewhat Agree" 3 "Neither Agree Nor Disagree" 4 "Somewhat Disagree" 5 "Strongly Disagree"<br/>
label values difficult agree<br/>
<br/>
gen everProgram=(q2==1) if q2&lt;.<br/>
label variable everProgram "Before this class, had you ever written a computer program?"<br/>
<br/>

gen class=(q3==1) if q3&lt;.
<br/>
label variable class "Before this class, had you ever taken a programming class (HS or College)?"<br/>
<br/>

gen taught=(q4==1) if q4&lt;.<br/>
label variable taught "Were you ever taught to program before high school?"<br/>
<br/>

label define yn 1 "Yes" 0 "No"<br/>
label values everProgram class taught yn

<br/>
<br/>
drop q2 q3 q4<br/>
<br/>
rename q5 device<br/>
label variable device "What kind computing device have you spent the most time using?"<br/>
 rename q7 entDevice //Note how the variables were not numbered sequentially by Qualtrics. Watch for that.<br/>
label variable entDevice "What kind computing device have you spent the most time using for entertainment?"<br/>
<br/>

label define device 1 "Windows Computer" 2 "Apple Computer" 3 "Smartphone or Tablet" 4 "Gaming Console" 5 "Other Device / Does not apply"<br/>
label values device entDevice device<br/>
<br/>
save projectdata, replace<br/>
log close
                </p>
<p> </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/sfs/qualtrics_download.PNG, https://ssc.wisc.edu/sscc/pubs/sfs/zip.PNG, https://ssc.wisc.edu/sscc/pubs/sfs/import1.PNG, https://ssc.wisc.edu/sscc/pubs/sfs/import2.PNG, https://ssc.wisc.edu/sscc/pubs/sfs/import3.PNG, https://ssc.wisc.edu/sscc/pubs/sfs/import4.PNG</img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Scatterplots</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>A scatterplot is an excellent tool for examining the relationship between two quantitative variables. One variable is designated as the Y variable and one as the X variable, and a point is placed on the graph for each observation at the location corresponding to its values of those variables. If you believe there is a causal relationship between the two variables, convention suggests you make the cause X and the effect Y, but a scatterplot is  useful even if there is no such relationship.</p>
<p>This section will teach you how to make scatterplots; <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-graphs.htm">Using Graphs</a> discusses what you can do with a graph once you've made it, such as printing it, adding it to a Word document, etc.</p>
<h2>Setting Up</h2>
<p>If you plan to carry out the examples in this article, make sure you've downloaded the GSS sample to your U:\SFS folder as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>. Then create a do file called <span class="InputCode">scatter.do</span> in that folder that loads the GSS sample as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a>. If you plan on applying what you learn directly to your homework, create a similar do file but have it load the data set used for your assignment.</p>
<h2>Creating Scatterplots</h2>
<p>To create a scatterplot, use the <span class="InputCode">scatter</span> command, then list the variables you want to plot. The first variable you list will be the Y variable and the second will be the X variable.</p>
<p class="InputCode">scatter weight height </p>
<p>This creates:<br/>
<img alt="Scatter plot of height vs weight" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/scatter.png" width="600"/></p>
<p>The distribution of the points suggests a positive relationship between height and weight (i.e. tall people tend to weigh more).</p>
<h2>Adding a Regression Line</h2>
<p>Regression attempts to find the line that best fits these points. You can plot a regression line or "linear fit" with the <span class="InputCode">lfit</span> command followed, as with <span class="InputCode">scatter</span>, by the variables involved. To add a linear fit plot to a scatterplot, first specify the scatterplot, then put two "pipe" characters (what you get when you press shift-Backslash) to tell Stata you're now going to add another plot, and then specify the linear fit.</p>
<p class="InputCode">scatter weight height || lfit weight height</p>
<p><img alt="scatterplot of height and weight with a fit line" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/lfit.png" width="600"/></p>
<h2>Plotting Subsamples</h2>
<p>You can use similar code to plot subsamples in different colors:</p>
<p class="InputCode">                scatter weight height if sex==1 || scatter weight height if sex==2</p>
<p><img alt="scatter plot of height and weight with men in blue and women in red." height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/sub1.png" width="600"/></p>
<p>Unfortunately, the default legend at the bottom is now completely useless, so you'll need to specify what it should say. You can do so with the <span class="InputCode">legend</span> option, which then contains the <span class="InputCode">order</span> option. Within that you give a list of plot numbers and associated labels much like a list of value labels. The first plot you specify is plot number 1, the second number 2, etc. </p>
<p class="InputCode">scatter weight height if sex==1 || scatter weight height if sex==2, ///<br/>
legend(order(1 "Males" 2 "Females"))</p>
<p><img alt="scatter plot of height and weight with men in blue and women in red with a much mure useful legend" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/sub2.png" width="600"/></p>
<p>An alternative way to plot create this plot is to start with the separate command.</p>
<p class="InputCode">separate weight, by(sex)</p>
<p>This creates two variables: a <span class="InputCode">weight1</span> which only exists for males (i.e. it's missing for females and thus won't be plotted) and a <span class="InputCode">weight2</span> which only exists for females. You can create a scatterplot that plots both of these variables with:</p>
<p class="InputCode">scatter weight1 weight2 height</p>
<p><img alt="" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/sub3.png" width="600"/></p>
<p>The default legend for this version is more informative, but you'd still probably want to replace it (and add a title for the Y axis).</p>
<h2>Plotting Multiple Variables</h2>
<p>You can use similar syntax to plot multiple variables in the same scatterplot. Just list them after the <span class="InputCode">scatter</span> command. The last variable will always be the X variable and any other variables you list will be Y variables. For example:</p>
<p class="InputCode">scatter weight age height</p>
<p><img alt="" height="400" src="https://ssc.wisc.edu/sscc/pubs/sfs/multi.png" width="600"/></p>
<p>This plot suggests that while weight is positively related to height, age and height have a very weak relationship if any.</p>
<p>If  you run <span class="InputCode">tab height weight</span> (and sift through the rather large amount of output it creates) you'll find a weakness of these plots: sometimes two people have the same height and weight. </p>
<p>Stata dutifully plots two points, but the second one completely covers up the first so that you can only see one. In the subsample graphs, a male (blue) point will be covered up by a female (red) point just because the graph for females was the second one specified.</p>
<p>This can distort the understanding you get of the distribution of the two variables. In this case it probably doesn't make much difference, but it would be a major problem if you tried to make a scatterplot of two categorical variables. (The underlying problem here is that many respondents seem to have rounded their weight to a multiple of five, making weight act somewhat like a categorical variable.)</p>
<p>There are many, many more options you can set for scatterplots, such as titles and colors. The easy way to find all these options is to click <span class="MenuOutput">Graphics</span>, <span class="MenuOutput">Twoway graph</span>, and then <span class="MenuOutput">Create</span>. Tweak the settings there until you get the graph you want, then copy the resulting command into your do file. Read <a href="https://ssc.wisc.edu/sscc/pubs/4-24.htm">An Introduction to Stata Graphics</a> if you want to learn more about making scatterplots.</p>
<h2>Complete Do File</h2>
<p class="InputCode">capture log close<br/>
log using scatter.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
<br/>
scatter height weight<br/>
<br/>
 scatter height weight || lfit height weight<br/>
<br/>
 scatter height weight if sex==1 || scatter height weight if sex==2<br/>
<br/>
 scatter height weight if sex==2 || scatter height weight if sex==1, ///<br/>
<span class="indent3">legend(order(1 "Males" 2 "Females"))</span><br/>
<br/>
 separate weight, by(sex)<br/>
 scatter weight1 weight2 height<br/>
<br/>
 scatter weight age height<br/>
<br/>
log close<br/>
</p>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/sfs/scatter.png, https://ssc.wisc.edu/sscc/pubs/sfs/lfit.png, https://ssc.wisc.edu/sscc/pubs/sfs/sub1.png, https://ssc.wisc.edu/sscc/pubs/sfs/sub2.png, https://ssc.wisc.edu/sscc/pubs/sfs/sub3.png, https://ssc.wisc.edu/sscc/pubs/sfs/multi.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Sociology 357</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>This page contains links to articles describing the statistical topics covered in Sociology 357 at UW-Madison. The articles assume you're already familiar with the basics of Stata, especially <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a> and <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a>.</p>
<p> <em>SSCC staff try to keep this list up-to-date, but your instructor may add to or take away from it at any time and information you receive from him or her about what material you are responsible for always takes priority.</em></p>
<ul>
<li>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#oneway">Frequencies for a Single Categorical Variable</a></p>
<p>For a variable that describes  categories (like sex or race) rather than quantities (like income) frequencies tell you how many observations are in each category. These are examples of univariate statistics, or statistics that describe a single variable.</p>
<p>Categorical variables are also sometimes called factor variables. Indicator variables (also called binary or dummy variables) are just categorical variables with two categories. Frequency tables for a single variable are sometimes called one-way tables.</p>
</li>
<li>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#sum">Summary Statistics for a Single Quantitative Variable</a></p>
<p>For a variable that describes quantities (like income) the mean tells you what the expected value of the variable is, and the standard deviation tells you how much it varies. However, the median and percentiles often give you a better sense of how the variable is distributed, especially for variables that are not symmetric (like income, which often has a few very high values). These are also univariate statistics.</p>
<p>Quantitative variables are often called continuous variables. Means are often called averages, and variance is just the standard deviation squared. The median is also the 50th percentile.</p>
</li>
<li>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#twoway">Frequencies for Two Categorical Variables</a></p>
<p>For two categorical variables, frequencies tell you how many observations fall in each combination of the two categorical variables (like black women or hispanic men) and can give you a sense of the relationship between the two variables. These are examples of bivariate statistics, or statistics that describe the joint distribution of the two variables.</p>
<p>Tables of frequencies for two variables are often called two-way tables, contingency tables, or crosstabs.</p>
</li>
<li>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#tabsum">Summary Statistics for One Quantitative Variable over One Categorical Variable</a></p>
<p>For a  quantitative variable and a categorical variable, the mean value of the quantitative variable for those observations that fall in each category of the categorical variable can give you a sense of how the two variables are related. Of then the question of interest is whether the distribution of the quantitative variable is different for different categories. These are also examples of bivariate statistics.</p>
</li>
<li>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#threeway">Frequencies for Three or More Categorical Variables</a></p>
<p>For three or more categorical variables, frequencies <a href="#threeway"></a>will tell you how many observations fall in each combination of the variables and give you a sense of their relationships just like they did with two categorical variables. These are examples of multivariate statistics.</p>
</li>
<li>
<p><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#twoway_sum">Summary Statistics for One Quantitative Variable over Two or More Categorical Variables</a></p>
<p>For a quantitative variable and two or more categorical variables, the  the mean value of the quantitative variable for those observations in each combination of the categorical variables can give you a sense of how the variables are related just like they did with a quantitative variable and one categorical variable. These are examples of multivariate statistics.</p>
</li>
</ul>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Sociology 357</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>This page contains links to articles describing the statistical topics covered in Sociology 360 at UW-Madison. The articles assume you're already familiar with the basics of Stata, especially <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a> and <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a>.</p>
<p> <em>SSCC staff try to keep this list up-to-date, but your instructor may add to or take away from it at any time and information you receive from him or her about what material you are responsible for always takes priority.</em></p>
<ul>
<li><span class="InputCode"><a class="InputCode" href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ttest.htm">ttest</a></span><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ttest.htm">: Test hypotheses about means</a></li>
<li><span class="InputCode"><a class="InputCode" href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-prtest.htm">prtest</a></span><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-prtest.htm">: Test hypotheses about proportions</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-hist.htm"><span class="InputCode">histogram</span>: Graphical representation of a variable's distribution</a></li>
<li><span class="InputCode"><a class="InputCode" href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-bargraph.htm">graph bar</a></span><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-bargraph.htm">: Bar graph representing summary statistics</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-scatter.htm"><span class="InputCode">scatter</span>: Scatterplot of two variables</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-cor.htm"><span class="InputCode">correlate</span>: Correlations between variables</a><br/>
<br/>
</li>
</ul>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: How Stata Commands Work</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>Stata tries very hard to make all its commands work the same way. Spending a little time learning the syntax itself will make it much easier to use commands later.</p>
<p>To carry out the examples in this section, you'll need to have created an SFS folder and downloaded the gss_sample data set as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>. Create a new do file in that folder called <span class="InputCode">syntax.do</span>, as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a>. To start with it should contain:</p>
<p class="InputCode">capture log close<br/>
                  log using syntax.log, replace<br/>
<br/>
                clear all<br/>
                set more off<br/>
<br/>
                use gss_sample<br/>
<br/>
                // work will go here<br/>
<br/>
                log close
                </p>
<p>The example commands will go after <span class="InputCode">use gss_sample </span>and before <span class="InputCode">log close</span>. Add the example commands to this do file as you go, and  run it frequently to see the results.</p>
<h2>Commands</h2>
<p>Most Stata commands are verbs. They tell Stata to do something: <span class="InputCode">summarize</span>, <span class="InputCode">tabulate</span>, <span class="InputCode">regress</span>, etc. Normally the command itself comes first and then you tell Stata the details of what you want it to do after.</p>
<p>Many commands can be abbreviated: <span class="InputCode">sum</span> instead of <span class="InputCode">summarize</span>, <span class="InputCode">tab</span> instead of <span class="InputCode">tabulate</span>, <span class="InputCode">reg</span> instead of <span class="InputCode">regress</span>. Commands that can destroy data, like <span class="InputCode">replace</span>, cannot be abbreviated.</p>
<h2>Variable Lists</h2>
<p>A list of variables after a command tells the command which variables to act on. First try <span class="InputCode">sum</span> (summarize) all by itself, and then followed by age:</p>
<p class="InputCode">sum<br/>
                  sum age
                  <br/>
</p>
<p>If you don't specify which variables <span class="InputCode">sum</span> should act on it will give you summary statistics for all the variables in the data set. In this case that's a pretty long list. Putting <span class="InputCode">age</span> after <span class="InputCode">sum</span> tells it to only give you summary statistics for the <span class="InputCode">age</span> variable.</p>
<p>If you list more than one variable, the command will act on all of them:</p>
<p class="InputCode">sum age yearsjob prestg10</p>
<p>This gives you summary statistics for age, years on the job, and a rating of the respondent's job's prestige.</p>
<h2>If Conditions</h2>
<div>
<p>An <em>if condition</em> tell a command which observations it should act on. It will only act on those observations where the condition is true. This allows you to do things with subsets of the data. An if condition comes after a variable list:</p>
<p class="InputCode">sum yearsjob if sex==1</p>
<p>This gives you summary statistics for years on the job for just the male respondents (in the GSS 1 is male and 2 is female).</p>
<p>Note the two equals signs! In Stata you use one equals sign when you're setting something equal to something else (see <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-vars.htm">Creating Variables</a>) and two equals signs when you're asking if two things are equal. Other operators you can use are:</p>
<table border="0">
<tr>
<td>==</td>
<td>Equal</td>
</tr>
<tr>
<td>&gt;</td>
<td>Greater than</td>
</tr>
<tr>
<td>&lt;</td>
<td>Less than</td>
</tr>
<tr>
<td>&gt;=</td>
<td>Greater than or equal to</td>
</tr>
<tr>
<td>&lt;=</td>
<td>Less than or equal to</td>
</tr>
<tr>
<td>!=</td>
<td>Not equals</td>
</tr>
</table>
<p>! all by itself means "not" and reverses whatever condition follows it.                  </p>
<h2>Combining Conditions</h2>
<p>You can combine conditions with <span class="InputCode">&amp;</span> (logical and) or <em class="InputCode">|</em> (logical or). The character used for logical or is called the "pipe" character and you type it by pressing <span class="InputCode">Shift-Backslash</span>, the key right above <span class="InputCode">Enter</span>. Try:                  </p>
<p class="InputCode">sum yearsjob if sex==1 &amp; income&gt;=9<br/>
                  sum yearsjob if sex==1 | income&gt;=9</p>
<p>The first gives you summary statistics for years on the job for respondents who are male <em>and</em> have a household income of $10,000 or more. The second gives you summary statistics for years on the job for respondents who are  male <em>or</em> have a household income of $10,000 or more, a very different group.</p>
<p>Any conditions you combine must be complete. If you want summary statistics for years on the job for respondents who are either black (race==2) or "other" (race==3) you can <em>not</em> use:</p>
<p class="InputCode">sum yearsjob if race==2 | 3 // don't do this</p>
<p>(What this does and why is left as an exercise for the reader, but it's not what you want.) Instead you should use:</p>
<p class="InputCode">sum yearsjob if race==2 | race==3 // do this instead</p>
<h2>Missing Values</h2>
<p>If you have missing values in your data, you need to keep them in mind when writing if conditions. Recall that the generic missing value (<span class="InputCode">.</span>) acts like positive infinity, and the extended missing values (<span class="InputCode">.a</span>, <span class="InputCode">.b</span>, etc.) are even bigger. So if you type:</p>
<p class="InputCode">sum yearsjob if age&gt;65</p>
<p>you are not just getting summary statistics for years on the job for respondents who are older than 65. Anyone with a missing value for age is also included. Assuming you're interested in people who are known to be older than 65, you should exclude the people with missing values for <span class="InputCode">age</span> with a second condition:</p>
<p class="InputCode">sum yearsjob if age&gt;65 &amp; age&lt;.</p>
<p>It makes a difference!</p>
<p>Why <span class="InputCode">age&lt;.</span> rather than <span class="InputCode">age!=.</span>? For the <span class="InputCode">age</span> variable, the GSS uses <span class="InputCode">.c</span> for missing and <span class="InputCode">age!=. </span>would not exclude <span class="InputCode">.c</span>. Other variables use different extended missing values, and some use more than one. Using <span class="InputCode">age&lt;.</span> guarantees you're excluding all missing values, even if you don't know ahead of time which ones the data set uses.</p>
<h2>Binary Variables</h2>
<p>If you have a binary variable coded as 0 or 1, you can take advantage of the fact that to Stata 1 is true and 0 is false. Imagine that instead of a variable called <span class="InputCode">sex</span> coded 1/2, you had a variable called <span class="InputCode">female</span> coded 0/1. Then you could do things like:</p>
<p class="InputCode">sum yearsjob if female<br/>
                    sum yearsjob if !female
                  // meaning "not female"</p>
<p>Just one thing to be careful of: to Stata everything except 0 is true, including missing. If <span class="InputCode">female</span> had missing values you would need to use:</p>
<p class="InputCode">sum yearsjob if female &amp; female&lt;. // exclude missing values</p>
<p>or:</p>
<p class="InputCode">sum yearsjob if female==1 // automatically excludes missing values</p>
<p>Unfortunately the GSS does not code its binary variables 0/1 so you can't actually run these four commands. But many data sets data sets do, and if you have to create your own binary variables you can make them easy to use by coding them 0/1.</p>
<h2>Options</h2>
<p>Options change how a command works. They go after any variable list or if condition, following a comma. The comma means "everything after this is options" so you only type one comma no matter how many options you're using.</p>
<p>The <span class="InputCode">detail</span> option tells <span class="InputCode">summarize</span> to calculate percentiles (including the 50th percentile, or median) and some additional moments.</p>
<p class="InputCode">sum yearsjob, detail</p>
<p>Many options can be abbreviated like commands can be—in this case just <span class="InputCode">d</span> would do.</p>
<p>Some options require additional information, like the name of a variable or a number. Any additional information an option needs goes in parentheses directly after the option itself.</p>
<p> Recall that when we did <span class="InputCode">sum</span> all by itself and it gave us summary statistics for all the variables, it put a separator line after every five variables. You can change that with the <span class="InputCode">separator</span> (or just <span class="InputCode">sep</span>) option:</p>
<p class="InputCode">sum, sep(10)</p>
<p>The <span class="InputCode">(10)</span> in parentheses tells the separator option to put a separator between every ten variables. You'll learn more useful options that need additional information in the articles on statistical commands.</p>
<h2>By</h2>
<p><em>By</em> allows you to execute a command separately for subgroups within your data. Try:</p>
<p class="InputCode">bysort sex: sum yearsjob</p>
<p></p>
<p> This gives you summary statistics for years on the job for both males and females, calculated separately.</p>
<p><em>By </em>is a prefix, so it comes before the command itself. It's followed by the variable (or variables) that identifies the subgroups of interest, then a colon. The data must be sorted for <em>by</em> to work, so <span class="InputCode">bysort</span> is a shortcut that first sorts the data and then executes the by command. Now that the data set is sorted by <span class="InputCode">sex</span>, you can just use <span class="InputCode">by</span> in subsequent commands:</p>
<p class="InputCode">by sex: sum prestg10</p>
<h2>Complete Do File</h2>
<p>The following is a do file containing all the example commands in this section:</p>
<p class="InputCode">capture log close<br/>
log using syntax.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
<br/>
sum<br/>
sum age<br/>
sum age yearsjob
prestg10<br/>
<br/>
sum yearsjob if sex==1<br/>
sum yearsjob if sex==1 &amp; income&gt;=9<br/>
sum yearsjob if sex==1 | income&gt;=9<br/>
<br/>
sum yearsjob if race==2 | 3 // don't do this<br/>
sum yearsjob if race==2 | race==3 // do this instead<br/>
<br/>
sum yearsjob if age&gt;65<br/>
sum yearsjob if age&gt;65 &amp; age&lt;. // exclude missing values<br/>
<br/>
/* Things you could do if you had female coded 0/1<br/>
<span class="indent3"> instead of sex coded 1/2:</span><br/>
sum yearsjob if female<br/>
sum yearsjob if !female // meaning "not female"<br/>
sum yearsjob if female &amp; female&lt;. // exclude missing values<br/>
sum yearsjob if female==1 // automatically excludes missing values<br/>
*/
<br/>
<br/>
sum yearsjob, detail<br/>
sum, sep(10)<br/>
<br/>
bysort sex: sum yearsjob<br/>
by sex: sum prestg10<br/>
<br/>
log close                </p>
</div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: t-tests</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>t-tests are frequently used to test hypotheses about the population mean of a variable. The command to run one is simply <span class="InputCode">ttest</span>, but the syntax will depend on the hypothesis you want to test. In this section we'll discuss the following types of tests:</p>
<h3><a href="#onesample">The Population Mean is Equal to Some Specified Value</a></h3>
<p>One type of hypothesis simply asks whether the population mean of a variable is equal to some particular value of interest. This is called a single-sample t-test, because you look at the entire sample at once.</p>
<h3> <a href="#paired">The Population Means for Two Variables are the Same</a></h3>
<p>Another type of hypothesis looks at whether two variables have the same population mean. This is called a paired-sample t-test, because the test assumes that the values of the two variables for the same observation go together (i.e. the value of X for observation 1 has a relationship to the value of Y for observation 1 that does not exist between the value of X for observation 1 and the value of Y for observation 2).</p>
<h3><a href="#twosample">The Population Means for Two Subsamples are the Same</a></h3>
<p>The final type of hypothesis we'll consider is whether two groups have the same population mean for a single variable. This is called a two-sample t-test, and is  the most common.</p>
<p>For all these tests we've described the null hypothesis. Usually the null hypothesis is the opposite of what you're really interested in. For example, if you're investigating differences between men and women in the mean education level, your null hypothesis will usually be that they are the same. Your alternative hypothesis could then be one of the following: that the mean education level of women is higher than the mean education level of men, that the mean education level of men is higher than the mean education level of women, or that the mean levels of education are different regardless of which is higher.</p>
<p> Stata will report results for all three alternative hypotheses, but you should choose which one you're interested in ahead of time. Looking at the results and then picking the alternative hypothesis that matches what you'd like to see will increase the probability of drawing the wrong conclusion from the test.</p>
<p>We will discuss the interpretation of the t-test in detail for the first type of hypothesis (that the mean is equal to a specified value) but the discussion applies to  all the hypotheses a t-test can test.                </p>
<h2>Setting Up</h2>
<p>If you plan to carry out the examples in this article, make sure you've downloaded the GSS sample to your U:\SFS folder as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>. Then create a do file called <span class="InputCode">ttests.do</span> in that folder that loads the GSS sample as described in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a>. If you plan on applying what you learn directly to your homework, create a similar do file but have it load the data set used for your assignment.</p>
<h2 id="onesample">Hypothesis: The Population Mean is Equal to Some Specified Value</h2>
<p>Suppose you want to test the hypothesis that the population mean of <span class="InputCode">educ</span> is 14 years. The syntax is simply:</p>
<p class="InputCode">ttest educ=14</p>
<p>This gives the output:</p>
<pre class="InputCode">One-sample t test
------------------------------------------------------------------------------
Variable |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
    educ |     254    13.38583    .2093408    3.336343    12.97355     13.7981
------------------------------------------------------------------------------
    mean = mean(educ)                                             t =  -2.9338
Ho: mean = 14                                    degrees of freedom =      253

    Ha: mean &lt; 14               Ha: mean != 14                 Ha: mean &gt; 14
 Pr(T &lt; t) = 0.0018         Pr(|T| &gt; |t|) = 0.0037          Pr(T &gt; t) = 0.9982</pre>
<p>The mean of <span class="InputCode">educ</span> in the sample<span class="InputCode">,</span> which is also the best estimate of the population mean, is 13.38. But in order to evaluate the hypothesis that mean is really 14, you have to consider the uncertainty about that estimate. The 95% confidence interval ranges from 12.97 to 13.80, which does not include 14, so it's not looking good for our null hypothesis.</p>
<p>Formal evaluation compares the null hypothesis (<span class="InputCode">Ho</span>), that the mean is 14, with one of three alternative hypotheses (<span class="InputCode">Ha</span>): that the mean is less than 14, that the mean is not equal to 14 but could be bigger or smaller, and that the mean is greater than 14. You must pick the alternative hypothesis you're interested in testing before running the test.</p>
<p>First consider <span class="InputCode">Ha: mean &lt; 14</span>. If the population mean is 14, then the probability of drawing a sample with a mean of 13.38 or less, given the number of observations we have and the standard deviation we observe, is 0.0018 (i.e. it's extremly unlikely). This is less than .05, so we reject the null hypothesis that the mean is 14 in favor of the alternative that the mean is less than 14.</p>
<p>Next consider <span class="InputCode">Ha: mean != 14</span>. If the population mean is 14, then the probability of drawing a sample that is at least 14 - 13.38 = 0.62 away from that mean in either direction is 0.0037 (again, given the number of observations we have and the standard deviation we observe). This is exactly twice the probability of the previous hypothesis, though this is obscured by rounding. The previous hypothesis was a one-tail test (i.e. looking at the probability that the outcome is out in one of the "tails" of the probability distribution) while this is a two-tail test (i.e. looking at the probability that the outcome is in either tail of the distribution). Again the probability is less than 0.05, so we reject the null hypothesis that the mean is 14 in favor of the alternative hypothesis that the mean is something other than 14.</p>
<p>Finally consider <span class="InputCode">Ha: mean &gt; 14</span>. If the population mean is 14, then the probability of drawing a sample with a mean that is 13.38 or greater is 0.9982 (i.e. it's almost certain). This probability is nowhere near less than 0.05, so in this case we accept the null hypothesis that the mean is 14 rather than the alternative that the mean is greater than 14.</p>
<h3>Changing the Confidence Level</h3>
<p>If you want to consider a different confidence level, use the <span class="InputCode">level()</span> option with the desired confidence level in the parentheses:</p>
<p class="InputCode">ttest educ=14, level(90)</p>
<p>This produces:</p>
<pre class="InputCode">One-sample t test
------------------------------------------------------------------------------
Variable |     Obs        Mean    Std. Err.   Std. Dev.   [90% Conf. Interval]
---------+--------------------------------------------------------------------
    educ |     254    13.38583    .2093408    3.336343    13.04023    13.73143
------------------------------------------------------------------------------
    mean = mean(educ)                                             t =  -2.9338
Ho: mean = 14                                    degrees of freedom =      253

    Ha: mean &lt; 14               Ha: mean != 14                 Ha: mean &gt; 14
 Pr(T &lt; t) = 0.0018         Pr(|T| &gt; |t|) = 0.0037          Pr(T &gt; t) = 0.9982</pre>
<p>The only change is that you are given a 90% confidence interval rather than a 95% confidence interval. The true mean will fall into this interval 90% of the time rather than 95% of the time like in the prior results, so this interval is slightly smaller.</p>
<h2 id="paired">Hypothesis: The Population Means for Two Variables are the Same</h2>
<p>Suppose you wanted to test the hypotheses that the population mean for the respondent's father's education  (<span class="InputCode">paeduc</span>) is the same as the population mean for the respondent's mother's education (<span class="InputCode">maeduc</span>). This is a paired sample test because the mother and father of the same respondent are related. To do this, run:</p>
<p class="InputCode">ttest paeduc=maeduc</p>
<p>This produces:</p>
<pre class="InputCode">Paired t test
------------------------------------------------------------------------------
Variable |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
  maeduc |     172    11.94767    .2895882    3.797913    11.37605     12.5193
  paeduc |     172    11.98256    .3293803    4.319782    11.33238    12.63273
---------+--------------------------------------------------------------------
    diff |     172   -.0348837    .2189349    2.871305   -.4670468    .3972794
------------------------------------------------------------------------------
     mean(diff) = mean(maeduc - paeduc)                           t =  -0.1593
 Ho: mean(diff) = 0                              degrees of freedom =      171

 Ha: mean(diff) &lt; 0           Ha: mean(diff) != 0           Ha: mean(diff) &gt; 0
 Pr(T &lt; t) = 0.4368         Pr(|T| &gt; |t|) = 0.8736          Pr(T &gt; t) = 0.5632</pre>
<p>Stata calculated the difference (<span class="InputCode">diff</span>) between the two means as <span class="InputCode">maeduc - paeduc</span>, so the alternative hypothesis <span class="InputCode">mean(diff) &lt; 0</span> is  also the hypothesis that <span class="InputCode">paeduc</span> is greater than <span class="InputCode">maeduc</span>. In this case the probabilities associated with all three alternative hypotheses are well above 0.05, so no matter which alternative hypothesis you chose to test you would accept the null hypothesis that the means are the same. More precisely, we do not have sufficient evidence to reject the hypothesis that they are same. It's possible we could reject that hypothesis if we had more observations, for example.</p>
<h2 id="twosample">Hypothesis: The Population Means for Two Subsamples are the Same</h2>
<p>Suppose you wanted to test the hypothesis that the population mean of <span class="InputCode">educ</span> is the same for men and women. To do this, run:</p>
<p class="InputCode">ttest educ, by(sex)</p>
<pre class="InputCode">Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
    male |     110    13.33636    .3275703    3.435586    12.68713     13.9856
  female |     144    13.42361    .2725067     3.27008    12.88495    13.96227
---------+--------------------------------------------------------------------
combined |     254    13.38583    .2093408    3.336343    12.97355     13.7981
---------+--------------------------------------------------------------------
    diff |           -.0872475    .4232854               -.9208752    .7463803
------------------------------------------------------------------------------
    diff = mean(male) - mean(female)                              t =  -0.2061
Ho: diff = 0                                     degrees of freedom =      252

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.4184         Pr(|T| &gt; |t|) = 0.8369          Pr(T &gt; t) = 0.5816</pre>
<p><span class="InputCode">diff</span> is defined as <span class="InputCode">mean(male) - mean(female)</span>, so the alternative hypothesis <span class="InputCode">diff &lt; 0</span> is also the hypothesis that the mean of <span class="InputCode">educ</span> for females is greater than the mean of <span class="InputCode">educ</span> for males. All the probabilities are well above 0.05, so once again no matter which alternative hypothesis you chose to test you will not reject the null hypothesis that the mean level of education for males and females is the same.</p>
<p>Note that this test assumed that the population variance of <span class="InputCode">educ</span> was the same for males and females. We can see from the output that the standard deviation (which is the square root of the variance) is slightly higher for males in the sample. If we think that difference is real, we can tell the <span class="InputCode">ttest</span> command to take it into account by adding the <span class="InputCode">unequal</span> option:</p>
<p class="InputCode">ttest educ, by(sex) unequal</p>
<p>In this case it makes very little difference.</p>
<h2>Complete Do File</h2>
<p>The following is a complete do file for this section.</p>
<p class="InputCode">capture log close<br/>
log using ttests.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
<br/>
ttest educ=14<br/>
ttest educ=14, level(90)<br/>
<br/>
ttest paeduc=maeduc<br/>
<br/>
ttest educ, by(sex)<br/>
ttest educ, by(sex) unequal<br/>
<br/>
log close </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Stata's User Interface</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>In this section, we'll give you a brief introduction to Stata's user interface, focusing on the parts you'll use to run do files.</p>
<table border="0" class="noBorder">
<tr>
<td><img alt="" height="478" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfr/ui2.png" width="768"/></td>
</tr>
</table>
<p>Stata's main user interface is made up of five windows. The big one in the middle is the <span class="MenuOutput">Results</span> windows, where you'll see the results of your analysis. Underneath it is the <span class="MenuOutput">Command</span> window. You can type a command here, press <span class="InputCode">Enter</span>, and immediately see its results. This is useful for exploring and experimenting, but for real work you should use a <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">do file</a>.</p>
<p>One the left is the <span class="MenuOutput">Review</span> window, which contains a list of commands you've run previously. You can click on one to paste it into the <span class="MenuOutput">Command</span> window and run it again (or just press <span class="InputCode">Page Up</span> until you get the command you want<span class="InputCode">)</span>. </p>
<p>On the right, the <span class="MenuOutput">Variables</span> window lists the variables in your current data set. Underneath it, the <span class="MenuOutput">Properties</span> window gives you additional information about the variable selected in the <span class="MenuOutput">Variables</span> window and about the data set as a whole. If you click twice on a variable name in the <span class="MenuOutput">Variables</span> window, the name will be pasted into the <span class="MenuOutput">Command</span> window. You can also start typing a variable name in the <span class="MenuOutput">Command</span> window and  press <span class="InputCode">Tab</span>, and Stata will try go guess which variable you want.</p>
<p>A few key buttons across the top:</p>
<p>The button that looks like a pencil writing in a notebook opens the <span class="MenuOutput">Do File Editor</span>. We'll talk about it in <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a>.</p>
<p>The button that looks like pencil writing in a spreadsheet opens the <span class="MenuOutput">Data Editor</span>, and the button that looks like a magnifying glass looking at a spreadsheet opens the <span class="MenuOutput">Data Browser</span>. Both let you see the data set itself, which is very useful. The difference is that the <span class="MenuOutput">Data Editor</span> will let you change the data and the <span class="MenuOutput">Data Browser</span> will not. You don't want to risk changing your data by accident so you should generally use the <span class="MenuOutput">Data Browser</span>. You should only use the <span class="MenuOutput">Data Editor</span> if you need to enter brand new data for a class assignment.</p>
<p>The button that looks like an octagon with a small 'x' inside will turn stop-sign red if Stata is working on something (including when Stata pauses because the <span class="MenuOutput">Results</span> window is full). You can  click that button to tell Stata to quit whatever it is doing. Pressing <span class="InputCode">q</span> will do the same thing.</p>
<p>One button you should <em>not</em> click is the button that looks like a floppy disk. This button will save the data currently in memory, including any changes you've made, over the original data file. <em>Always save modified data sets with a new name so you keep the original data intact.</em><br/>
</p>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/sfr/ui2.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Creating Variables and Labels</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>In this article you'll learn how to create new variables and change existing variables.</p>
<p>Assuming you created an SFS folder while reading <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a>, go to that folder and create a new do file called <span class="InputCode">newvars.do</span>. Start with the usual setting up (see <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a>):</p>
<p class="InputCode">capture log close<br/>
log using newvars.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
<br/>
// do work here<br/>
<br/>
log close</p>
<h2>Generate and Replace</h2>
<p>You create a new variable in Stata using the <span class="InputCode">generate</span> command, usually abbreviated <span class="InputCode">gen</span>. You can change the value of an existing variable using <span class="InputCode">replace</span>. Since <span class="InputCode">replace</span> can destroy data, it has no abbreviation. The basic syntax is the same for both commands:</p>
<p class="InputCode">gen <span class="Parameter">variable</span>=<span class="Parameter">something</span><br/>
                  replace <span class="Parameter">variable</span>=<span class="Parameter">something</span><br/>
</p>
<p>The something you're setting the variable to will be the result of some math, but it can be really simple math, like a single number.</p>
<p>The <span class="InputCode">gen</span> and <span class="InputCode">replace</span> commands will often have <em>if</em> conditions. With <span class="InputCode">gen</span>, an observation that doesn't meet the <em>if</em> condition will not get a value for the new variable—it will be missing instead. With <span class="InputCode">replace</span>, an observation that doesn't meet the <em>if</em> condition is left unchanged.</p>
<h2>Recoding with Generate and Replace</h2>
<p>Let's turn  the <span class="InputCode">educ</span> variable ("HIGHEST YEAR OF SCHOOL COMPLETED") into a categorical variable <span class="InputCode">edu_cat</span>, with the categories "Less than High School", "High School", "Some College", "Bachelors", and "Advanced". You'll need an initial <span class="InputCode">gen</span> command to create the new variable and handle one of the categories, and a <span class="InputCode">replace</span> command for each of the remaining categories. <em>if</em> conditions ensure that each respondent gets the right value of <span class="InputCode">edu_cat</span> based on its value of <span class="InputCode">educ</span>.</p>
<p class="InputCode">gen edu_cat=1 if educ&lt;12<br/>
                  replace edu_cat=2 if educ==12<br/>
                  replace edu_cat=3 if educ&gt;12 &amp; educ&lt;16<br/>
                  replace edu_cat=4 if educ==16<br/>
                replace edu_cat=5 if educ&gt;16 &amp; educ&lt;. </p>
<p>If <span class="InputCode">educ</span> is missing then <span class="InputCode">edu_cat</span> will be missing because a missing value does not meet any of the <em>if</em> conditions in these commands.</p>
<h2>The Recode Command</h2>
<p>You can also do this task using the <span class="InputCode">recode</span> command, which is easier to use but  not as flexible as <span class="InputCode">gen</span> and <span class="InputCode">replace</span>. With <span class="InputCode">recode</span> you specify a list of rules in the form <span class="InputCode">(</span><span class="Parameter">old values</span><span class="InputCode">=</span><span class="Parameter">new value</span><span class="InputCode">)</span>. The old values can be a single number, a list of numbers, or a range of numbers which you describe with <span class="Parameter">start</span><span class="InputCode">/</span><span class="Parameter">end</span>:</p>
<p class="InputCode">recode educ (0/11=1) (12=2) (13 14 15=3) (16=4) (17/20=5) ///<br/>
<span class="indent3">                , gen(edu_cat2)</span></p>
<p>The <span class="InputCode">gen</span> option tells <span class="InputCode">recode</span> to create a new variable (<span class="InputCode">edu_cat2</span>) to store the results. If you don't include a <span class="InputCode">gen</span> option, <span class="InputCode">recode</span> will change the original variable. <span class="InputCode">edu_cat2</span> will be missing if <span class="InputCode">educ</span> is missing  because none of the <span class="InputCode">recode</span> rules say to change missing values to anything else.</p>
<h2>Labels</h2>
<p>Variable labels can tell you more about the variable itself, like the actual question asked. You can set them with the<span class="InputCode"> label variable</span> command:</p>
<p class="InputCode">label variable edu_cat "Education Category"</p>
<p>Value labels tell you what the individual values of the variable mean. To set them, you first define the labels and then apply them to a variable:</p>
<p class="InputCode">label define edcats 1 "Less than HS" 2 "HS" 3 "Some College" ///<br/>
<span class="indent3">                  4 "Bachelors" 5 "Advanced"</span><br/>
                label values edu_cat edcats </p>
<p>If you look in the data browser at the <span class="InputCode">edu_cat</span> variable after running these commands, you'll see the text labels rather than the raw numbers.</p>
<h2>Rename</h2>
<p>You can change the name of a variable with the <span class="InputCode">rename</span> command. Changing meaningless variable names (like Q26 for "answer to question 26") to descriptive variable names can make it much easier to keep track of your variables. The GSS uses descriptive variable names, which is good, but they're very short and sometimes cryptic. For example, age of the respondent at the time their first child was born is <span class="InputCode">agekdbrn</span>. You could change it with:</p>
<p class="InputCode">rename agekdbrn age_at_1st_birth</p>
<h2>Indicator (Binary) Variables</h2>
<p>A variable  can  be set to the result of a condition. If the condition is true the variable will get a 1, and if it is false the variable will get a 0. This makes it very easy to create indicator or binary variables, which tell you if something is true or not.</p>
<p>Consider the questions <span class="InputCode">bigbang</span> ("THE UNIVERSE BEGAN WITH A HUGE EXPLOSION"), <span class="InputCode">electron</span> ("ELECTRONS ARE SMALLER THAN ATOMS"), and <span class="InputCode">laser</span> ("LASERS WORK BY FOCUSING SOUND WAVES"). They are true/false questions, with "true" coded as 1 and "false" coded as 2. They are designed to measure the scientific knowledge of the respondent. The correct answer to the first two questions is "true," but the correct answer to the third question is "false" (lasers are coherent light, not focused sound). Many respondents have missing values for these questions.</p>
<p>You can create corresponding indicator variables for "respondent got this question right" with the following commands:</p>
<p class="InputCode">gen bigbang_right=(bigbang==1) if bigbang&lt;.<br/>
gen electron_right=(electron==1) if electron&lt;.<br/>
gen laser_right=(laser==2) if laser&lt;.</p>
<p>The new <span class="InputCode">bigbang_right</span> variable will get a 1 if <span class="InputCode">bigbang</span> is 1 (i.e. the condition <span class="InputCode">(bigbang==1)</span> is true). It will get a 0 otherwise, unless <span class="InputCode">bigbang</span> is missing. In that case the <span class="InputCode">if bigbang&lt;.</span> condition takes over and says <span class="InputCode">bigbang_right</span> should be missing. Note that without that <em>if</em> condition, respondents with a missing value for <span class="InputCode">bigbang</span> would get 0 for <span class="InputCode">bigbang_right</span>, as if they had answered the question and gotten it wrong.</p>
<p>The variable names make these variables easy to understand: if <span class="InputCode">bigbang_right</span> is 1, or true, that means "Yes, this person got the big bang question right" while if <span class="InputCode">bigbang_right</span> is 0, or false, that means "No, this person did not get the big bang question right."</p>
<h2>Creating a Scale (Index)</h2>
<p>Next create a scale or index that measures the respondent's overall scientific knowledge:</p>
<p class="InputCode">gen sci_know=bigbang_right+electron_right+laser_right</p>
<p>The resulting scale will be the number of questions the respondent got right. It will be missing if the respondent didn't answer all of the questions, which is good: again, we do not want to treat not answering a question the same as answering it but getting it wrong.                </p>
<h2>Variables Based on Statistics</h2>
<p>The <span class="InputCode">egen</span> ("extended generate") command lets you create variables containing statistics based on your data. For example:</p>
<p class="InputCode">egen mean_sci_know=mean(sci_know)<br/>
</p>
<p>This creates a variable containing the mean  of <span class="InputCode">sci_know</span>. To see all the things <span class="InputCode">egen</span> can do, type <span class="InputCode">help egen</span>.</p>
<h2>Statistics for Groups</h2>
<p>If you want to calculate statistics for groups rather than the entire data set, use <em>by</em> to tell Stata to run <span class="InputCode">egen</span> separately for each group.</p>
<p class="InputCode">bysort edu_cat: egen edu_mean_sci_know=mean(sci_know)                </p>
<p>This calculates the mean of <span class="InputCode">sci_know</span> for each education category. To see the results, we'll jump ahead a bit and use the <span class="InputCode">tab</span> command with the <span class="InputCode">sum</span> option.</p>
<p class="InputCode">tab edu_cat, sum(mean_sci_know_edu)</p>
<p>The results show that the average of <span class="InputCode">sci_know</span> is higher at higher levels of education, as we'd expect. If you just wanted to see those means, not store them in a variable, you could run:</p>
<p class="InputCode">tab edu_cat, sum(sci_know)</p>
<p>This is an example of <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-descriptives.htm#tabsum">Summary Statistics for One Quantitative Variable over One Categorical Variable</a>.</p>
<h2>Complete Do File</h2>
<p>The following is a complete do file for this section:</p>
<p class="InputCode">capture log close<br/>
log using newvars.log, replace<br/>
<br/>
clear all<br/>
set more off<br/>
<br/>
use gss_sample<br/>
<br/>
gen edu_cat=1 if educ&lt;12<br/>
replace edu_cat=2 if educ==12<br/>
replace edu_cat=3 if educ&gt;12 &amp; educ&lt;16<br/>
replace edu_cat=4 if educ==16<br/>
replace edu_cat=5 if educ&gt;16 &amp; educ&lt;.<br/>
<br/>
recode educ (0/11=1) (12=2) (13 14 15=3) (16=4) (17/20=5) ///<br/>
<span class="indent3"> , gen(edu_cat2)</span><br/>
<br/>
label variable edu_cat "Education Category"

<br/>
<br/>
label define edcats 1 "Less than HS" 2 "HS" 3 "Some College" ///<br/>
<span class="indent3"> 4 "Bachelors" 5 "Advanced"
</span><br/>
label values edu_cat edcats<br/>
<br/>
rename agekdbrn age_at_1st_birth<br/>
<br/>
gen bigbang_right=(bigbang==1) if bigbang&lt;.<br/>
gen electron_right=(electron==1) if electron&lt;.<br/>
gen laser_right=(laser==2) if laser&lt;.<br/>
<br/>
gen sci_know=bigbang_right+electron_right+laser_right<br/>
<br/>
egen mean_sci_know=mean(sci_know)<br/>
<br/>
bysort edu_cat: egen mean_sci_know_edu=mean(sci_know)<br/>
<br/>
tab edu_cat, sum(mean_sci_know_edu)<br/>
 tab edu_cat, sum(sci_know)<br/>
<br/>
log close</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata for Students: Running Stata</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This article is part of the <a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm">Stata for Students</a> series. If you are new to Stata we strongly recommend reading all the articles in the Stata Basics section.</em></p>
<p>Students at UW-Madison have several options for using Stata:</p>
<ul>
<li>You can log into <a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">Winstat</a> from your computer (no matter where you are) and run Stata there</li>
<li>You can come to the <a href="https://ssc.wisc.edu/sscc/infrastructure/labs.htm">SSCC Computer Labs</a>, especially 4218 Sewell Social Sciences Building, and run Stata on the Lab PCs</li>
<li>You can download Stata from the <a href="https://software.wisc.edu">Campus Software Library</a> and install it on your own computer</li>
</ul>
<p>While the Campus Software Library is available to all UW-Madison students, you'll need an SSCC account to use Winstat or the Lab. If your class is using SSCC resources you should have received an account for use during that class. If not, visit the <a href="http://ssc.wisc.edu/sscc/accounts/new.htm">account request</a> page to see if you're eligible for one.</p>
<p>If you use Winstat or the Computer Lab, you'll have access to your SSCC home directory, the U: drive. Files on U: are available from anywhere by logging into Winstat and backed up five times a day. The instructions in Stata for Students will assume you're storing your files on the U: drive. If you are running Stata on your own computer, you can use a folder on your computer's hard drive instead. Just change references to the U: drive to the folder you're using.</p>
<p>Stata on a Mac (or Linux computer) is essentially identical to Stata on Windows. The instructions will assume you're using Windows, but Mac users will need to make very few changes, mostly related to using files. Alternatively, you can log into Winstat from your Mac and run Stata for Windows there.</p>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Using Silo</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Silo is the SSCC's secure computing enclave. It consists of secure  servers and data storage for working with data covered by HIPAA and other sensitive data. Silo contains Windows-based servers (WinSilo), Linux based servers (LinSilo and LinSiloBig) and an HTCondor pool (CondorSilo). WinSilo acts as the gateway to all of Silo: when you log in, you'll start on WinSilo and can log into the other servers from there.</p>
<p>Keep reading to learn how to access Silo and use the Windows servers in the Silo environment. Or you can skip ahead for information on:</p>
<ul>
<li><a href="#data">Silo's file system and getting data in and out of Silo</a></li>
<li><a href="#Linux">Linux servers in Silo</a></li>
<li><a href="#CondorSilo">Silo's HTCondor pool</a></li>
</ul>
<h2>Getting Access</h2>
<p>If you are interested in using Silo, please contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">SSCC Help Desk</a>. Depending on the nature of your data you may need to get approval from your IRB, the UW-Madison Office of Cybersecurity, or other relevant authorities. Using Silo will expedite that process because it has already had a formal risk assessment by the Office of Cybersecurity and was found to be low risk, and many of the relevant authorities are already familiar with it.</p>
<p>Connecting to Silo requires multifactor authentication using Duo, the same system used for your UW-Madison NetID. Most people use the Duo app on their smartphone, but you can also use  a separate hardware token. When you contact the Help Desk about using Silo please mention which method you prefer. Instructions for obtaining and using a hardware token can be found <a href="#token">here</a>.                </p>
<h2>Installing the Citrix Workspace App</h2>
<p>To use Silo you'll need to have the Citrix Workspace App installed on your computer. Just click on the appropriate link below and then run the installer after it finishes downloading. If you've already installed the Citrix Workspace App on your computer in order to use Winstat you do not need to install it again.</p>
<ul>
<li><a href="https://ssc.wisc.edu/sscc/receiver/CitrixWorkspaceApp.exe">Citrix Workspace App for Windows</a></li>
<li><a href="https://ssc.wisc.edu/sscc/receiver/Citrix WorkspaceApp-SSCC.dmg">Citrix Workspace App for Mac</a></li>
</ul>
<p>See <a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">Using Winstat</a> for more information about using the Citrix Workspace App.                </p>
<h2>Logging In</h2>
<p>To log in to Silo, you will need go to the web site <a href="https://silo.ssc.wisc.edu">silo.ssc.wisc.edu</a>. If you're asked to give permission for programs to run, do so.</p>
<img alt="silo login screen" class="CenterImage" height="334" src="https://ssc.wisc.edu/sscc/pubs/screenshots/silo/silo1.png" width="750"/>
<p>At the login screen, first give your SSCC username and password as usual. If it is your first time logging into Silo, you'll be prompted to follow the instructions on the screen to set up Duo on your smartphone. You'll be able to use the same Duo app for both Silo and your NetID.</p>
<h2 id="data">The Silo File System</h2>
<p>Silo has an isolated file system that is separate from SSCC's primary file system, but they have similar structures. All files are available using either Windows or Linux. The key locations are:</p>
<table align="center" border="1" cellpadding="5">
<tr>
<th scope="col"> </th>
<th scope="col">Linux Name</th>
<th scope="col">Windows Name</th>
</tr>
<tr>
<td>Home Directory (Private Space) </td>
<td><span class="InputCode">~</span></td>
<td><span class="MenuOutput">Z:</span> Drive</td>
</tr>
<tr>
<td>Project Directories (Shared Space) </td>
<td class="InputCode">/project</td>
<td><span class="MenuOutput">V:</span> Drive </td>
</tr>
<tr>
<td>SMPH Project Directories (Shared Space)</td>
<td class="InputCode">/smph</td>
<td><span class="MenuOutput">S:</span> Drive</td>
</tr>
</table>
<p>Home directories are primarily meant for configuration files, installed packages, and other small files. They have a quota of 20GB, which can be expanded on request to 40GB. Research data should be stored in Project directories, which have no quotas and are shared with the other members of your research group. SMPH researchers will be given project space on the S: drive, which is SMPH's space in DoIT's RestrictedDrive service. </p>
<h2 id="MovingDataToandFromSilo">Moving Data To and From Silo</h2>
<p>To move sensitive data into Silo, contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">SSCC Help Desk</a> and we'll work with you to find the most convenient way to transfer your data. We are working with popular data providers to try to automate this process.</p>
<p>To move non-sensitive files into Silo and  to get results out you'll use SSCC's primary file system as a staging area. The easy way to access SSCC's primary file system is to log into Winstat, which you'll see when you log into Silo. Winstat is very similar to WinSilo but, not being a high-security server, it can communicate with the local hard drive of your computer. After logging into Winstat, you'll see a drive called <span class="InputCode">Local Disk (C: on </span><span class="Parameter">{your computer}</span><span class="InputCode">)</span>. You can drag files to and from this drive to move them between your computer and SSCC's primary file system. You're also welcome access SSCC's primary file system by mapping a drive to it (<a href="https://ssc.wisc.edu/sscc/pubs/5-26.htm">Windows</a>/<a href="https://ssc.wisc.edu/sscc/pubs/diskfrommac.htm">MacOS</a>) or using <a href="https://ssc.wisc.edu/sscc/pubs/1-11.htm">FTP</a>.</p>
<p>To move non-sensitive files into Silo,  put them in a folder on your Z: drive in the primary SSCC file system and then contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">SSCC Help Desk</a> and ask that that folder be copied to Silo.                </p>
<p>Moving data off of Silo's file system is simpler. We have created a folder called <span class="InputCode">silosync</span> in the Z: drive of each Silo user. Every five minutes, an automated script copies anything placed in this folder to a corresponding folder in your Z: drive on  SSCC's primary file system.  You can then access it using Winstat. Similar folders can be created within projects. (<span class="InputCode">silosync</span> does not automatically copy files from the primary SSCC file system to Silo.) It is your responsibility to ensure any data you place in the <span class="InputCode">silosync</span> folder can be appropriately stored on the SSCC's primary file system and do not require the additional security Silo provides.</p>
<h2>Using WinSilo</h2>
<p>Once you've logged in, WinSilo behaves just like a regular Windows server, with a few important exceptions:</p>
<ul>
<li>Silo cannot access the Internet. This can affect programs in unexpected ways: for example, Stata's <span class="InputCode">findit</span> command takes much longer to run than usual and then only gives partial results, because it tries to reach Stata's web server and does not display any results until that attempt times out. Fortunately the results it does give are the ones you're most likely to need.</li>
<li>You can install R packages from CRAN and Bioconductor, Stata packages from SSC, and Python packages from PyPI. If you need to install packages from other sources contact the Help Desk.</li>
<li>You cannot copy and paste between Silo and your own computer.</li>
<li>Silo cannot access disk space on your computer.</li>
<li>You cannot print from Silo.</li>
</ul>
<h2>Silo Downtime </h2>
<p>Silo has a downtime from 7:00am-9:00am the first Wednesday of the month for security updates. </p>
<p>If you don't anticipate using Silo's Linux servers, you can stop reading at this point. Welcome to Silo!</p>
<h2 id="Linux">Silo Linux Servers</h2>
<p>Silo has three kinds of Linux servers. To use them, first sign into the Silo environment, which will put you on WinSilo, and then you can log into them from there.</p>
<p><strong>LinSilo</strong> is a cluster of three servers (<span class="InputCode">linsilo001</span>, <span class="InputCode">linsilo002</span>, <span class="InputCode">linsilo003</span>) with 44 cores and 384GB of memory each. When you log into LinSilo, you'll be automatically directed to the least busy server. If you start a long job on a server, you'll need to go back to the same server to manage it. You can switch to a different server with the <span class="InputCode">ssh</span> command; e.g. to get to <span class="InputCode">linsilo001</span> type:</p>
<p class="InputCode"> ssh linsilo001</p>
<p><strong>LinSiloBig</strong> is a cluster of two servers (<span class="InputCode">linsilobig001</span>, <span class="InputCode">linsilobig002</span>) with 80 cores and 768GB of memory each. Again, when you log into LinSiloBig you'll be the directed to the least busy server, but you can switch with <span class="InputCode">ssh</span>. In fact, using LinSiloBig is so similar to using LinSilo that you can assume instructions for using LinSilo apply to LinSiloBig unless we say otherwise.</p>
<p>Jobs that cannot run without the additional memory LinSiloBig provides should have first priority on LinSiloBig. Jobs that can take full advantage of the additional cores it provides are second priority. Please do not use LinSiloBig for jobs that could run just as well on LinSilo or CondorSilo.</p>
<p><strong>CondorSilo</strong> is a cluster of nine servers with 44 cores and 384GB of RAM each. It runs jobs submitted via HTCondor.</p>
<p>The Linux servers in the Silo environment were funded by SMPH. Other researchers are welcome to use them, but SMPH researchers have priority.</p>
<h2>Logging into LinSilo</h2>
<p>To log into LinSilo, click on the Windows logo button and find the LinSilo folder in the programs list. Then click on the LinSilo or LinSiloBig icon. This will start a program called X-Win32. The first thing you'll see is a utility window that you can ignore (but don't close it or it will close the entire program—minimize it instead). The login prompt will come up shortly thereafter, and then a terminal window once you log in.</p>
<p>If you'll use these frequently, you can right-click on them and pin them so that they'll come up as soon as you click the Windows logo button.</p>
<p>If you don't need graphics, you can also log into LinSilo using SecureCRT.</p>
<h2></h2>
<h2>Running Programs on LinSilo</h2>
<p>LinSilo has a wide variety of software installed, including both general-purpose statistical software and specialized software for biomedical research.</p>
<p>SSCC has used <span class="InputCode">tcsh</span> as its default Linux shell for more than 20 years, but <span class="InputCode">bash</span> has become more popular. (If you google how to do something in Linux the solution you find will probably be written for <span class="InputCode">bash</span>, but most of the time it will work in <span class="InputCode">tcsh</span> too since they're not that different.) Many SMPH researchers have a great deal of experience using <span class="InputCode">bash</span>, so we have made it the default shell for members from SMPH. If you'd like to switch shells (in either direction) contact the<a href="https://ssc.wisc.edu/sscc/helpdesk.htm"> Help Desk</a>.</p>
<p> Here are the commands to run a few selected programs on LinSilo. In the "Command to run a long job" column, the command  is given in the form needed by <span class="InputCode">bash</span>. <span class="InputCode">tcsh</span> users should omit the <span class="InputCode">nohup</span> at the beginning of the command.</p>
<table border="1" width="100%">
<tbody>
<tr>
<th>Program</th>
<th>Command to run it interactively</th>
<th>Command to run a long job that will continue after you log out (<span class="InputCode">bash</span> version)</th>
</tr>
<tr>
<td>R</td>
<td class="InputCode">R</td>
<td class="InputCode">nohup R CMD BATCH myprogram.R &amp;</td>
</tr>
<tr>
<td>Python 3.7 (command line)</td>
<td class="InputCode">python</td>
<td class="InputCode">nohup python myprogram.py &amp;</td>
</tr>
<tr>
<td>Python 2.7 (command line)</td>
<td class="InputCode">python2</td>
<td class="InputCode">nohup python2 myprogram.py &amp;</td>
</tr>
<tr>
<td>Spyder (Python IDE)</td>
<td class="InputCode">spyder</td>
<td class="InputCode"> </td>
</tr>
<tr>
<td>Jupyter Notebook</td>
<td class="InputCode">jupyter notebook</td>
<td class="InputCode"> </td>
</tr>
<tr>
<td>Stata</td>
<td class="InputCode">xstata</td>
<td class="InputCode">nohup stata -b do mydofile &amp;</td>
</tr>
<tr>
<td>SAS</td>
<td class="InputCode">sas</td>
<td class="InputCode">nohup sas myprogram.sas &amp;</td>
</tr>
</tbody>
</table>
<p>Of course there are many ways to run these programs, and many more programs!</p>
<p>LinSilo is very similar to Linstat, SSCC's general-purpose Linux cluster, so you may find <a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a> and <a href="https://ssc.wisc.edu/sscc/pubs/linstat_jobs.htm">Managing Jobs on Linstat</a> helpful.</p>
<h2>Running RStudio on LinSilo</h2>
<p>To run RStudio on LinSilo, go to the LinSilo folder in the programs list and double-click on the <span class="MenuOutput">LinSilo RStudio Server</span> or <span class="MenuOutput">LinSiloBig RStudio Server </span>icon. (Again, if you'll use these frequently you can pin them.) This will open a web browser on the Windows server containing an RStudio interface that connects to R running on LinSilo or LinSiloBig. Jobs run in RStudio will continue to run even if you log out.</p>
<h2 id="CondorSilo">CondorSilo  </h2>
<p>CondorSilo runs HTCondor, developed by the UW-Madison Computer Science Department. HTCondor is designed to let you run multiple jobs on multiple servers efficiently: when you submit jobs to an HTCondor queue, HTCondor will find available servers to run them. <a href="https://research.cs.wisc.edu/htcondor/manual/">General documentation for using HTCondor can be found here</a>. CondorSilo differs from a standard HTCondor installation in three important ways:</p>
<ol>
<li>It shares the Silo file system with the other Silo servers, so there's no need to transfer the files needed by CondorSilo jobs to the CondorSilo servers.</li>
<li>It does not checkpoint or terminate jobs.</li>
<li>It cannot send you email when a job finishes because it is in the isolated Silo environment. You'll have to check the status of your jobs.</li>
</ol>
<p>CondorSilo does not have the simple scripts for submitting jobs that SSCC's primary Condor flock has (this is something of an experiment). Instead, you will need to create a submit file for each job, telling CondorSilo how to run it. This will give you more control over how the job is run and allow CondorSilo to allocate jobs more efficiently. We'll provide some examples you can copy shortly.</p>
<p>A submit file will specify the program to run and the arguments needed to run it, but also tell CondorSilo how many cores and how much memory it needs. The core requirement is used in deciding where to run a job, but does not limit the number of cores the job can actually use. For example, if your submit file tells CondorSilo your job needs 30 cores (i.e. the submit file includes <span class="InputCode">request_cpus = 30</span>) and CondorSilo sees that a server is only running one job which requires a single core, it may put your job on that server. However, your job can try to use 44 cores and it will get 43 of them, and that's fine. If the single-core job finishes, your job will then use all of the 44 cores in the server. But if your submit file said the job required 44 cores, CondorSilo would not assign it to that server until after the single-core job finished. Meanwhile, if someone else submits a job that requires 30 cores, CondorSilo will not assign it to your server until your job is finished. You might think that it would be nicer to share the server, but a server running two jobs that can use all of its cores will take longer to finish both jobs than if they were run sequentially. If your job can take advantage of all of a server's cores, the best way to share the server with others is for your job to get done as quickly as possible and get out of the way. We thus suggest that if your job can take advantage of many cores, you tell CondorSilo you need 30.</p>
<p>Memory is different from cores, in that a job can only use as much memory as was requested in the submit file. Be sure to request as much as you need! For most statistical software, start by seeing how big your data set is, then estimate how big it's going to be by the time you're done, then add a 25-50% safety margin to that. Even better, run a single instance of the job <span class="InputCode"></span> on LinSilo and monitor its memory usage with <span class="InputCode">top</span>. If you don't specify how much memory you need, you'll get a fraction of the server's memory equal to the fraction of the server's cores you requested, roughly  8.8GB/core.</p>
<h2>Submitting Jobs to CondorSilo</h2>
<p>To submit a job to CondorSilo, create a submit file, and then run:</p>
<p class="InputCode">condor_submit <span class="Parameter">my_submit_file</span></p>
<p>where  <span class="Parameter">my_submit_file</span> should be replaced by the actual name of your submit file.</p>
<p>A submit file is just a text file. However, it must use Linux line endings (&lt;Line Feed&gt;), not Windows line endings (&lt;Carriage Return&gt; &lt;Line Feed&gt;) or Mac line endings (&lt;Carriage Return&gt;). If you use a Linux text editor like emacs or xemacs to write submit files that won't be an issue. You can use a Windows text editor like Notepad++, which is available on WinSilo, but you may need to change the line endings by clicking <span class="MenuOutput">Edit</span>, <span class="MenuOutput">EOL Conversion</span>. Regular Notepad will not work.</p>
<p>Creating a submit file for a given program often takes some close reading of the program's documentation and some trial and error. HTCondor jobs run in the background with no user interface ("headless")  and the documentation for your program is likely to have instructions for how to do that. Often it will refer to running jobs in batch mode.</p>
<p>The most common components of a submit file are listed below. Some of them will always be needed, like <span class="InputCode">executable</span>; others should be used when needed.</p>
<p class="InputCode">universe = vanilla</p>
<p>This tells HTCondor what context to run your job in. It's unlikely you'll need anything other than <span class="InputCode">vanilla</span>.</p>
<p class="InputCode">executable = <span class="Parameter">program to run</span></p>
<p>Replace <span class="Parameter">program to run</span> with actual program to run, including the path to find it. You can identify the path  to a program with <span class="InputCode">which</span>. For example, running <span class="InputCode">which R</span> will return <span class="InputCode">/software/R/bin/R</span>. To submit an R job to CondorSilo, you would put <span class="InputCode">executable = /software/R/bin/R</span> in your submit file.</p>
<p class="InputCode">arguments = <span class="Parameter">arguments for your program</span></p>
<p>Replace <span class="Parameter">arguments for your program</span> with the arguments (things you type after the command) for your program. For many programs, the arguments will tell the program what script to run as well as how to run it. For example, to submit an R script called <span class="InputCode">example.R</span> and save the output to <span class="InputCode">example.out</span>, use <span class="InputCode">arguments = CMD BATCH example.R example.out</span>. This corresponds to running <span class="InputCode">R CMD BATCH example.R example.out</span> at the command line, a standard way to run an R job in batch mode.</p>
<p class="InputCode">input = <span class="Parameter">input file</span></p>
<p class="InputCode">output = <span class="Parameter">output file</span></p>
<p class="InputCode">error = <span class="Parameter">error file</span></p>
<p>Linux has standard places for programs to get input and send output and error messages, called <span class="InputCode">stdin</span>, <span class="InputCode">stdout</span>, and <span class="InputCode">stderr</span>. These optional lines tell CondorSilo to use files for these purposes. Not all programs use them but  Matlab, for example, will run scripts sent to <span class="InputCode">stdin</span>, so you can run a Matlab script called <span class="InputCode">example.m</span> with <span class="InputCode">input = example.m</span>.</p>
<p class="InputCode">request_cpus = <span class="Parameter">number of cores</span><br/>
                request_memory = <span class="Parameter">amount of RAM</span> GB</p>
<p>Replace <span class="Parameter">number of cores</span> and <span class="InputCode"><span class="Parameter">amount of RAM</span></span> with what you need. As discussed above, for cores you're just setting the minimum your job will accept, while for memory you're also setting the maximum your job will be able to use.</p>
<p class="InputCode">environment = "name=value"</p>
<p>The environment line allows you to set system environment variables for your job. For example, Python jobs need <span class="InputCode">PYTHONHOME</span> to be set to the location where Python is installed, so you need to include <span class="InputCode">environment = "PYTHONHOME=/software/anaconda37"</span>. Note that there can be no spaces between the name and value.<span class="InputCode"></span></p>
<p class="InputCode">accounting_group = smph</p>
<p>SMPH researchers have priority on CondorSilo (since SMPH funded the servers), and the <span class="InputCode">accounting_group</span> line tells CondorSilo this is an SMPH job. Non-SMPH researchers should omit the <span class="InputCode">accounting_group</span> line.</p>
<p class="InputCode">queue</p>
<p>The queue line goes at the end and tells CondorSilo to actually put the job in the queue. You can put multiple jobs in queue with one submit file: <span class="InputCode">queue 10</span> will put ten jobs in the queue, for example. Each job will have a process number (ten jobs would be numbered 0 through 9), and you can use <span class="InputCode">$(Process)</span> elsewhere in the submit file to refer to that number. For example, to queue ten Matlab scripts called <span class="InputCode">example0.m</span> through <span class="InputCode">example9.m</span> you'd use <span class="InputCode">input = example$(Process).m</span>, or to pass the process number  to a Stata do file as an argument it can use internally you'd use <span class="InputCode">arguments = -b do example.do $(Process)</span>.</p>
<h2>Example Submit Files</h2>
<p>The following are example submit files for popular statistical software. Because the COVID-19 pandemic has put hiring on hold, SSCC has not yet been able to hire the Biomedical Research Computing Facilitator who will be able to provide similar examples for biomedical research software. But we'll help you develop them as best we can, and will be very happy to add working submit files to our library of examples.</p>
<p>R, Python, and Matlab will only use multiple cores if you are using code that's been written to do so. If you are, we suggest you tell your program to ask for 44 cores but put in your submit file that you'll accept 30 (<span class="InputCode">request_cpus = 30</span>).</p>
<p>If you only request one core you'll get about 8.8GB of memory. If you needed 50GB, for example, you'd request it with <span class="InputCode">request_memory = 50 GB</span></p>
<h3>R</h3>
<p class="InputCode">universe = vanilla<br/>
  executable = /software/R/bin/R<br/>
  arguments = CMD BATCH exmaple.R example.output<br/>
  error = example.error<br/>
  request_cpus = 1<br/>
  queue </p>
<h3>Python</h3>
<p class="InputCode">universe = vanilla<br/>
  environment = "PYTHONHOME=/software/anaconda37"<br/>
  executable = /software/anaconda37/bin/python3<br/>
  arguments = example.py<br/>
  output = example.output<br/>
  error = example.error<br/>
  request_cpus = 1<br/>
  queue
</p>
<h3>Matlab</h3>
<p class="InputCode">universe = vanilla<br/>
executable = /software/matlab/bin/matlab<br/>
arguments = -nodisplay -nojvm<br/>
input = test.m<br/>
output = test.output<br/>
error = test.error<br/>
request_cpus = 1<br/>
queue </p>
<h3>Stata</h3>
<p class="InputCode">universe = vanilla<br/>
  executable = /software/stata/stata<br/>
  arguments = -b do example.do<br/>
  request_cpus = 32<br/>
  queue </p>
<p>CondorSilo runs Stata MP, licensed for 32 cores. Note that if you tell Stata to run <span class="InputCode">example.do</span> in batch mode it will put all output and error messages in <span class="InputCode">example.log</span> regardless of what you specify in <span class="InputCode">output =</span> or <span class="InputCode">error =</span> lines.</p>
<h2>Logging in to Silo Using a Hardware Token                </h2>
<p>If you would like to use a token to log into Silo and have one already, please contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a> and include the serial number printed on the back of your token in your email. The token must be black and white colored, with the words "OTP c100" printed on the front - we cannot use the blue and green tokens that say "Duo" on the front. If you do not have a token, please let us know and we will issue you one.</p><img alt="Silo token types" class="CenterImage" height="190" src="https://ssc.wisc.edu/sscc/pubs/screenshots/silo/tokens.png" width="500"/>
<p>Log in by going to <a href="https://silo.ssc.wisc.edu">silo.ssc.wisc.edu</a> and giving your SSCC username and password as usual. Then click <span class="MenuOutput">Enter a Passcode</span> and press the button on your token. Enter the 6-digit number from your token and click <span class="MenuOutput">Log In</span>.</p><img alt="" class="CenterImage" height="334" src="https://ssc.wisc.edu/sscc/pubs/screenshots/silo/silo2.png" width="750"/>
<p>If later you wish to add a smartphone app to your Silo account so you can authenticate with either the app or a token, click <span class="MenuOutput">Add a new device</span> under the SSCC logo and follow the onscreen instructions.</p>
<p>If you have any questions about using Silo, feel free to contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a>.</p>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/silo/silo1.png, https://ssc.wisc.edu/sscc/pubs/screenshots/silo/tokens.png, https://ssc.wisc.edu/sscc/pubs/screenshots/silo/silo2.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Installing New Software using Software Center</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>If you use a Windows PC that logs into the SSCC's PRIMO domain, you can use Software Center to easily install new software on your PC. This article will show you how.</p>
<p>Click in the search box next to the Windows logo button, start typing <span class="InputCode">software</span>, and Software Center will appear. Alternatively, click on the Windows logo button, <span class="MenuOutput">All Programs</span>, <span class="MenuOutput">Microsoft System Center</span>, and then <span class="MenuOutput">Software Center</span>. (If <span class="MenuOutput">Software Center</span> does not appear contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a>.)</p>
<p>You'll be shown a list of software that is available:</p>
<img alt="" class="CenterImage" height="645" src="https://ssc.wisc.edu/sscc/pubs/screenshots/software_center/software_center_2019.PNG" width="750"/>
<p>Click on the program you wish to install, then click the <span class="MenuOutput">Install</span> button. Software Center will install your new software automatically. If the installation process requires rebooting your computer, Software Center will prompt you to do so. Once the <span class="MenuOutput">Status</span> of the program changes to <span class="MenuOutput">Installed </span>you can close Software Center and use the program. If you have to reboot, the program will be ready for use after rebooting.                </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/software_center/software_center_2019.PNG</img_base_url>
</kb_document>
<kb_document>
<kb_title>Running SPSS Jobs on Linux</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<div id="TOC">
<ul>
<li><a href="#overview-and-documentation">Overview and Documentation</a></li>
<li><a href="#running-spss-jobs">Running SPSS Jobs</a></li>
<li><a href="#some-spss-details">Some SPSS Details</a><ul>
<li><a href="#output-format">Output Format</a></li>
<li><a href="#data-format">Data Format</a></li>
</ul></li>
<li><a href="#linux-details">Linux Details</a></li>
<li><a href="#an-example">An Example</a></li>
</ul>
</div>
<div class="section level2" id="overview-and-documentation">
<h2>Overview and Documentation</h2>
<p>SPSS for Linux does not include a graphical user interface like the Windows version, but has most of the same capabilities. Instead, SPSS runs syntax with a command from the linux prompt, which SPSS refers to as "batch facility" processing.</p>
<p><a href="http://public.dhe.ibm.com/software/analytics/spss/support/Stats/Docs/19.0/Server/User_Manuals/English/IBM_SPSS_Statistics_Batch_Facility_Users_Guide.pdf">Batch Facility User's Guide</a></p>
<p><a href="http://ssc.wisc.edu/sscc_jsp/spssdocs.jsp">Full documentation of SPSS 19 for Linux</a> is available on our web server. If you are in the SSCC's domain (e.g. in the Social Science building) you will be able to access it. If you need to access it remotely, you should use VPN to connect to SSCC.</p>
</div>
<div class="section level2" id="running-spss-jobs">
<h2>Running SPSS Jobs</h2>
<p>The basic linux syntax for running an SPSS job is:</p>
<pre><code>&gt; spssb -f filename.sps -out filename.log</code></pre>
<p>where <em>filename</em> is the name of your SPSS syntax file. The file extensions (.sps, .log) don't matter, but it is a good idea to be consistent.</p>
</div>
<div class="section level2" id="some-spss-details">
<h2>Some SPSS Details</h2>
<div class="section level3" id="output-format">
<h3>Output Format</h3>
<p>By default, <strong>spssb</strong> gives you output in text ("draft") format. Not only is this ugly to work with, but you will not be able to produce graphs. Html output (web output) is easier to work with, and you can produce it by using the <strong>-type</strong> option</p>
<pre><code>&gt; spssb -f filename.sps -type html -out filename.html</code></pre>
</div>
<div class="section level3" id="data-format">
<h3>Data Format</h3>
<p>You can use the same *.sav data files in both linux and Windows.</p>
</div>
</div>
<div class="section level2" id="linux-details">
<h2>Linux Details</h2>
<p>The usual job management tools work just fine with SPSS jobs, such as putting them in the background, terminating them, etc.</p>
<p>To run SPSS batch facility jobs in linux batch mode, use</p>
<pre><code>&gt; spssb -f filename.sps -type html -out filename.html &amp;</code></pre>
<p>See <a href="https://ssc.wisc.edu/sscc/pubs/linstat_jobs.htm">Managing Jobs on Linstat</a> for more information.</p>
</div>
<div class="section level2" id="an-example">
<h2>An Example</h2>
<p>Given a short syntax file, <a class="uri" href="https://ssc.wisc.edu/sscc/pubs/spss/Linux/carlinux.sps">carlinux.sps</a> process it with the SPSS batch facility with the linux command</p>
<pre><code>&gt; spssb -f carlinux.sps -out carlinux.log &amp;</code></pre>
<p>and you get the default text output, <a class="uri" href="https://ssc.wisc.edu/sscc/pubs/spss/Linux/carlinux.log">carlinux.log</a>.</p>
<p>For nicer output, change <strong>-type</strong> to html</p>
<pre><code>&gt; spssb -f carlinux.sps -type html -out carlinux.log &amp;</code></pre>
<p>and you get output, <a class="uri" href="https://ssc.wisc.edu/sscc/pubs/spss/Linux/carlinux.html">carlinux.html</a>, suitable for the web or use in Word.</p>
<p>Last Revised: 7/29/2016</p>
</div>

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>SPSS Extension Bundles in the SSCC</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<div id="TOC">
<ul>
<li><a href="#background">Background</a></li>
<li><a href="#download-the-extension-bundle">Download the Extension Bundle</a></li>
<li><a href="#locations-to-install-extension-bundles">Locations to Install Extension Bundles</a></li>
<li><a href="#setting-up-environment-variables">Setting Up Environment Variables</a></li>
<li><a href="#install-the-extension-bundle">Install the Extension Bundle</a></li>
</ul>
</div>
<div class="section level2" id="background">
<h2>Background</h2>
<p>It has long been possible to extend the capabilities of SPSS through the use of various other scripting languages. In recent years much of the development of these capabilities has centered on the Python and R scripting languages. IBM themselves have added many features to SPSS that rely on these languages. In SPSS 23, many items you find in the SPSS menus are actually implemented using R or Python.</p>
<p>These extended capabilities can generally be used through either syntax or the SPSS menus. Users familiar with the Python or R languages can call these programs fairly directly from within SPSS syntax by including the other language within a block of <code>PROGRAM</code> - <code>END PROGRAM</code> syntax.</p>
<p>Of broader utility to end users, programmers can create SPSS-like syntax and SPSS-like dialog boxes that call programs written in these other languages. The familiarity of the SPSS interface makes it much easier for end users to get up to speed using algorithms based in other languages. This combination of SPSS syntax/dialog and an algorithm in another language is what SPSS calls an <em>extension bundle</em>.</p>
<p>To use an extension bundle, you must be working on a computer with the bundle installed. On the SSCC's Winstat servers and lab computers, this may require you to <strong><em>download</em></strong> the bundle from somewhere, to set up several <strong><em>environment variables</em></strong>, and then to <strong><em>install</em></strong> the bundles in <strong><em>your own file space</em></strong> (i.e. the U: drive). This is very simple, as long as you are aware you need to do something!</p>
</div>
<div class="section level2" id="download-the-extension-bundle">
<h2>Download the Extension Bundle</h2>
<p>Many extension bundles are hosted at IBM's SPSS Community website. With SPSS 23, extension bundles hosted by SPSS can be downloaded, installed, and updated using the SPSS menus - <strong><em>however, you will first need to set up directories where they can be installed, and some Windows environment variables that point to those directories</em></strong> (see the next two sections).</p>
<p>For extension bundles not hosted by SPSS, and for older versions of SPSS, you will need to download them manually (usually through a web browser). If they are packaged as zip files, you will need to unzip them manually as well.</p>
<p>I'd suggest putting bundle downloads near where they will eventually be installed, perhaps in u:\spss\extensions (see the next section).</p>
</div>
<div class="section level2" id="locations-to-install-extension-bundles">
<h2>Locations to Install Extension Bundles</h2>
<p>On Winstat or a lab computer, create two (or three) folders on your U:\ drive where you can install your SPSS extensions. For example</p>
<p><code>U:\SPSS\extensions\bin</code>, and</p>
<p><code>U:\SPSS\extensions\lib</code></p>
<p>These are for syntax and dialog extensions, respectively. If you are installing a bundle that uses R packages beyond base R, you will also need a folder where you can install these. (This should <strong><em>NOT</em></strong> be the same place you install R packages if you are an R user! On SSCC computers, SPSS uses a different version of R, currently 3.1.2 on Winstat.) If you are not sure, go ahead and set this up. For instance</p>
<p><code>U:\SPSS\extensions\rpackages</code></p>
</div>
<div class="section level2" id="setting-up-environment-variables">
<h2>Setting Up Environment Variables</h2>
<p>On Winstat, set up two environment variables. These tell the operating system where to look for syntax and dialog extensions, in the folders you just created. Click <strong>Start - Control Panel - User Accounts</strong></p>
<p><img alt="User Account dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/Windows/Extension_bundle_screenshots/UserAccountdialog.JPG"/></p>
<p>At the bottom left, click <strong>Change my environment variables</strong>.</p>
<p>The new environment variables will be</p>
<table>
<thead>
<tr class="header">
<th align="left"><strong><em>Variable name:</em></strong></th>
<th align="left"><strong><em>Variable value:</em></strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><em>SPSS_EXTENSIONS_PATH</em></td>
<td align="left">U:\SPSS\extensions\bin</td>
</tr>
<tr class="even">
<td align="left"><em>SPSS_CDIALOGS_PATH</em></td>
<td align="left">U:\SPSS\extensions\lib</td>
</tr>
</tbody>
</table>
<p>Click the <strong>New</strong> button, once for each variable, and fill in the variable name and variable value for each new variable.</p>
<p><img alt="New Environment Variable dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/Windows/Extension_bundle_screenshots/NewEnvVardialog.JPG"/></p>
<p>For additional R packages, you need a third environment variable</p>
<table>
<thead>
<tr class="header">
<th align="left"><strong><em>Variable name:</em></strong></th>
<th align="left"><strong><em>Variable value:</em></strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><em>SPSS_RPACKAGES_PATH</em></td>
<td align="left">U:\SPSS\extensions\rpackages</td>
</tr>
</tbody>
</table>
<p>Click OK a couple of times, and you are done.</p>
<p>Like creating folders, this only needs to be done once on Winstat. (If you are working on the lab computers, however, you may need to set up environment variables on each lab computer you use.)</p>
</div>
<div class="section level2" id="install-the-extension-bundle">
<h2>Install the Extension Bundle</h2>
<p>To install or update bundles from the SPSS Community website, start up SPSS, then click <strong>Utilities - Extension Bundles - Download and Install Extension Bundles</strong>. Find your bundle(s) in the list, and click the selection box on the right. Click <strong>OK</strong>, then in the "Terms of Use" dialog box, change the selection to "I accept" and click <strong>OK</strong>.</p>
<p>To install a downloaded bundle, start up SPSS, then click <strong>Utilities - Extension Bundles - Install Local Extension Bundles</strong>, and navigate to where you saved the downloaded bundle (an *.spe file). Select the file and click <strong>Open</strong>.</p>
<p><img alt="Extension Bundle Installation File" src="https://ssc.wisc.edu/sscc/pubs/spss/Windows/Extension_bundle_screenshots/ExtBundleInst.JPG"/></p>
<p>You should get one or more dialog boxes to pop up, telling you the installation was a success.</p>
<p>We have encountered some "extension bundles" that are set up somewhat differently, for example, Hayes' PROCESS extension. If your bundle has an <code>spd</code> file, but no <code>spe</code> file, install it by clicking <strong>Utilities - Custom Dialogs - Install Custom Dialog</strong>, and navigate to the <code>spd</code> file.</p>
<p>If you are using an R extension, and it requires additional packages, they should be automatically downloaded as you install. If there is an error reported during this download, contact our <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a>. If you are familiar with R and installing R packages, you might try starting up R 3.1.2, setting the .libPath to the SPSS folder you are using for R packages, and manually installing any packages mentioned (that's what we'll do!).</p>
<p>You should be able to use the extension right away. You may need to restart SPSS in order for syntax highlighting to work properly.</p>
<p>Last Revised: 7/29/2016</p>
</div>

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/spss/Windows/Extension_bundle_screenshots/UserAccountdialog.JPG, https://ssc.wisc.edu/sscc/pubs/spss/Windows/Extension_bundle_screenshots/NewEnvVardialog.JPG, https://ssc.wisc.edu/sscc/pubs/spss/Windows/Extension_bundle_screenshots/ExtBundleInst.JPG</img_base_url>
</kb_document>
<kb_document>
<kb_title>SPSS Syntax</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<div id="TOC">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#commands">Commands</a></li>
<li><a href="#help-on-command-syntax">Help on Command Syntax</a></li>
<li><a href="#keywords-special-symbols-and-variable-names">Keywords, Special Symbols, and Variable Names</a></li>
<li><a href="#spacing-in-syntax">Spacing in Syntax</a></li>
<li><a href="#capitalization">Capitalization</a></li>
<li><a href="#comments-in-syntax">Comments in Syntax</a></li>
<li><a href="#further-reading">Further Reading</a></li>
</ul>
</div>
<div class="section level2" id="overview">
<h2>Overview</h2>
<p>SPSS, like all general purpose statistical software, is built around a programming language. Working directly with the programming language gives you access to many options that do not appear in the graphical user interface. Syntax also makes repetitive tasks quicker and less err0r-prone, ensures that you can repeat all the steps in your analysis, and makes troubleshooting quicker and more precise.</p>
<p>Syntax pasted from the graphical user interface is very useful as a memory aid - the dialog boxes include pointers to many more options than I can usually remember. You can also copy-and-paste syntax from the Output Viewer. However, automatically generated syntax is verbose, almost always including keywords for unnecessary default options. This can make it difficult to spot the crucial parts of a given command. If you use pasted syntax, I recommend editing it as you generate it, to ensure that you understand your code and to make it easier to read later.</p>
</div>
<div class="section level2" id="commands">
<h2>Commands</h2>
<p>The main unit of work in SPSS is the <strong><em>command</em></strong>. Each command begins with an SPSS keyword (also referred to as the "command" or "command name") and ends with a period before a line break, the SPSS <strong><em>command terminator</em></strong>. For example, a <code>GET</code> command might look like this:</p>
<pre><code>get file = "Y:\spss\data\cars.sav".</code></pre>
<p>Most commands have additional options and <strong><em>subcommands</em></strong>. Subcommands begin with a forward slash and a keyword. For example, a <code>GET</code> command that opens a working data set with only two of its original variables uses a <code>KEEP</code> subcommand, and might look like this:</p>
<pre><code>get file = "Y:\spss\data\cars.sav"
  /keep=mpg weight.</code></pre>
</div>
<div class="section level2" id="help-on-command-syntax">
<h2>Help on Command Syntax</h2>
<p>For details of what options and subcommands are available and how they work, you will want to look at the on-line Help files. There are two versions of these, in either HTML or PDF form. The easiest to access are the HTML help files: in any SPSS window click <strong>Help - Topics</strong>. You can also quickly get help on a specific command by typing or pasting the command name in a syntax window, and then pressing the F1 key - using the F1 key with any command in the syntax editor brings up the relevant Help page.</p>
<p>If you find it easier to use Help in book form, the entire SPSS Syntax Reference Manual is on-line as a PDF. Click <strong>Help - Command Syntax Reference</strong>. Each command is essentially a chapter in the printed Reference Manual.</p>
<p>Each chapter begins with a syntax diagram. For example, the chapter on the <code>DESCRIPTIVES</code> command begins with a diagram similar to this:</p>
<pre><code>DESCRIPTIVES VARIABLES= varname [(zname)] [varname...]
  [/MISSING= {<strong>VARIABLE**</strong>} [INCLUDE]]
              {LISTWISE }
  [/SAVE]
  [/STATISTICS= [<strong>DEFAULT**</strong>] [<strong>MEAN**</strong>] [<strong>MIN**</strong>] [SKEWNESS]]
                [<strong>STDDEV**</strong> ] [SEMEAN] [<strong>MAX**</strong>] [KURTOSIS]
                [VARIANCE ] [SUM   ] [RANGE] [ALL]
  [/SORT=[{<strong>MEAN</strong>    }] [ {<strong>(A)</strong>}]]
          {SMEAN   }    {(D)}
          {STDDEV  }
          {VARIANCE}
          {KURTOSIS}
          {SKEWNESS}
          {RANGE   }
          {MIN     }
          {MAX     }
          {SUM     }
          {NAME    }</code></pre>
<p>The square brackets, "<strong>[ ]</strong>", indicate optional specifications. This particular command requires at least the keywords <code>DESCRIPTIVES</code> and <code>VARIABLES=</code>, as well as the name of at least one variable to be analyzed, everything else is optional. For example, a minimal specification for <code>DESCRIPTIVES</code> might look like this:</p>
<pre><code>descriptives variables=mpg.</code></pre>
<p>Options that may be specified repeatedly are indicated with ellipses. For example, you may specify more than one variable name:</p>
<pre><code>descriptives variables=mpg weight.</code></pre>
<p>Keywords in <strong>bold</strong> in a syntax diagram represent two types of default options. Those marked with a double asterisk, "<strong>**</strong>", show you options that will have effect if no subcommand is specified. For example, these commands produce the same output:</p>
<pre><code>descriptives variables=mpg.
  /statistics=default.

descriptives variables=mpg.</code></pre>
<p>Keywords in bold, but without asterisks, are the default only when the optional subcommand is specified. For example, the following two commands present your output in different order:</p>
<pre><code>descriptives variables=all.

descriptives variables=all
/sort.</code></pre>
<p>(The syntax diagram for DESCRIPTIVES in the SPSS 23 documentation is wrong - the explanation given further into the chapter is correct - the diagram in SPSS 22, shown here, is correct.)</p>
<p>Many commands have lists of alternative options. The alternatives are indicated by curly braces, "<strong>{ }</strong>" For example, when sorting <code>DESCRIPTIVES</code> output, you could sort your output by either mean or variance, among many options.</p>
<pre><code>descriptives variables=all
  /sort=mean.

descriptives variables=all
  /sort=variance.</code></pre>
</div>
<div class="section level2" id="keywords-special-symbols-and-variable-names">
<h2>Keywords, Special Symbols, and Variable Names</h2>
<p>Commands are composed of keywords, special symbols like the "equals" symbol or parentheses, and user-supplied "words". User-supplied parts of commands are typically things like data set names, variable name, or data values. In SPSS documentation (and in pasted syntax) it is conventional for SPSS keywords to be indicated in ALL CAPS, while user-supplied "words" are given in lower case. However, the SPSS interpreter ignores case. For example, in the <code>DESCRIPTIVES</code> syntax above, the only specifications that are not SPSS keywords are variables names and standardized-variable names.</p>
</div>
<div class="section level2" id="spacing-in-syntax">
<h2>Spacing in Syntax</h2>
<p>The rules for how to put SPSS syntax on the page vary, depending on the source (run from a window or from a file), mode of execution (interactive or batch), and even the operating system of the computer you are using. The guidelines I will give you here should work in any context, but if you work with SPSS syntax long enough, you will eventually see exceptions to many of these recommendations!</p>
<ul>
<li><p>Begin each command in column one.</p></li>
<li><p>End each command with a period at the end of a line.</p></li>
<li><p>Commands may be written on more than one line. Continuations should be indented at least one space.</p></li>
<li><p>You may use blank lines between commands, but not within commands.</p></li>
<li><p>Words and keywords must be separated by spaces or special symbols. Where one space is allowed, multiple spaces may be used.</p></li>
</ul>
<p>For example, these work equally well:</p>
<pre><code>compute kpl1=mpg/(0.621371*3.78541).

compute   kpl2 =   mpg / (0.621371 * 3.78541) .
execute.</code></pre>
</div>
<div class="section level2" id="capitalization">
<h2>Capitalization</h2>
<p>Capitalization does not matter in keywords or in variable names. It does matter in data values, and may matter in file names, depending on the operating system you are working on (case matters in linux, not Windows).</p>
<p>SPSS will use the capitalization you supply for things like new variable names, variable labels, and value labels, which will affect how these are displayed in SPSS windows and in output. However, subsequent syntax use of the variable name can be in any case: to SPSS the variables "Salary" and "salary" are the same thing.</p>
</div>
<div class="section level2" id="comments-in-syntax">
<h2>Comments in Syntax</h2>
<p>A <em>comment</em> is any text which is to be ignored by the command processor. These are generally used two ways: to add explanatory notes to a command file, and to disable parts of our code.</p>
<p>In SPSS, comments work at two levels: as a whole "command" (begins with a keyword/symbol, ends with a period), or within a line.</p>
<p>A command level comment begins with the keyword <code>COMMENT</code>, or with an asterisk, "<strong>*</strong>". It ends with a period at the end of a line.</p>
<p>A within-line comment begins with a forward slash-asterisk, "<strong>/*</strong>", and ends at the end of the line or at an asterisk-slash, "<strong>*/</strong>", whichever comes first. These do not continue over more than one line. A line of syntax with only a within-line comment is treated as a blank line (so it is not allowed within a command).</p>
<p>Here are all three forms of comment:</p>
<pre><code>* pounds/(pounds/kilogram).
compute kilos=weight/2.20462.

comment "kpl" is kilometers per liter. This is
  calulated as 
  (miles/gallon) / ((miles/kilometers) * (liters/gallon)).
compute kpl = mpg / (0.621371 * 3.78541) .
execute.

* Note: Correlation is unchanged by change of scale.
correlations variables= kilos kpl.
graph /scatterplot = kilos with kpl.
correlations variables= /*kilos kpl*/ weight mpg.
graph /scatterplot = weight with mpg.</code></pre>
</div>
<div class="section level2" id="further-reading">
<h2>Further Reading</h2>
<p>See the <strong>Universals</strong> chapter in the <strong><em>Command Syntax Reference</em></strong>, the sub-section "Commands" (page 37 in the SPSS 23 manual).</p>
<p>For a more accurate description of the default options for many commands, see the <a href="ftp://public.dhe.ibm.com/software/analytics/spss/documentation/statistics/22.0/en/client/Manuals/IBM_SPSS_Statistics_Command_Syntax_Reference.pdf"><strong><em>SPSS 22 Command Syntax Reference</em></strong></a></p>
<p>Last Revised: 7/13/2016</p>
</div>

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>SPSS for the Classroom: the Basics</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<div id="TOC">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#starting-spss-statistics">Starting SPSS Statistics</a></li>
<li><a href="#the-spss-windows-and-files">The SPSS Windows and Files</a><ul>
<li><a href="#data-editor-.sav-files">Data Editor (.sav files)</a></li>
<li><a href="#output-viewer-.spv-files">Output Viewer (.spv files)</a></li>
<li><a href="#syntax-editor-.sps-files">Syntax Editor (.sps files)</a></li>
</ul></li>
<li><a href="#issuing-commands">Issuing Commands</a><ul>
<li><a href="#dialog-boxes">Dialog Boxes</a></li>
</ul></li>
<li><a href="#working-with-the-data-editor">Working with the Data Editor</a><ul>
<li><a href="#data-view">Data View</a></li>
<li><a href="#variable-view">Variable View</a></li>
</ul></li>
<li><a href="#working-with-the-output-viewer">Working with the Output Viewer</a></li>
<li><a href="#working-with-the-syntax-editor">Working with the Syntax Editor</a></li>
<li><a href="#learning-more">Learning More</a></li>
</ul>
</div>
<div class="section level2" id="overview">
<h2>Overview</h2>
<p>IBM SPSS Statistics is software for managing data and calculating a wide variety of statistics. This document is intended for students taking classes that use SPSS Statistics or anyone else who is totally new to the SPSS software. Those who plan on doing more involved research projects using SPSS should follow up this brief intro with more in-depth training.</p>
<p>For information about SSCC lab accounts, the labs, Winstat and more see <a href="https://ssc.wisc.edu/sscc/instruction/labusers.htm">Information for SSCC Instructional Lab Users</a>.</p>
<p>The SPSS software is built around the SPSS programming language. The good news for beginners is that you can accomplish most basic data analysis through menus and dialog boxes without having to actually learn the SPSS language. Menus and dialog boxes are useful because they give you visual reminders of (most of) your options with each step of your analysis. However, some tasks cannot be accomplished from the menus, and others are more quickly carried out by typing a few key words than by working through a long series of menus and dialogs. As a beginner, it will be strategic to learn a bit of both SPSS programming and the menus.</p>
<p>In the long run, you will want to learn to just work directly in the programming language, because this is how you document your work, and good documentation is key to both trouble-shooting and replicating complicated projects. For now, we assume you are just carrying out very simple tasks.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/spss/classintro/spss_students2.html">Part two</a> discusses common statistics, regression, and graphs.</p>
</div>
<div class="section level2" id="starting-spss-statistics">
<h2>Starting SPSS Statistics</h2>
<p>The SSCC has SPSS installed in our computer labs (4218 and 3218 Sewell Social Sciences Building) and on some of the <a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">Winstats</a>. If you work on a University-owned computer you can also go to DoIT's Campus Software Library, and download and install SPSS on that computer (this requires a NetID, and administrator priviledges).</p>
<p>To run SPSS, log in and click <strong>Start - Programs - IBM SPSS Statistics - IBM SPSS Statistics 23</strong>.</p>
<p>When SPSS is first started you are presented with a dialog box asking you to open a file. Pick a recently opened file or pick "Open another file" from the list on the left.</p>
<p><img alt="Initial Dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS01InitialDialog.jpg"/></p>
<p>Typically you start your SPSS session by opening the data file that you need to work with.</p>
</div>
<div class="section level2" id="the-spss-windows-and-files">
<h2>The SPSS Windows and Files</h2>
<p>SPSS Statistics has three main windows, plus a menu bar at the top. These allow you to (1) see your data, (2) see your statistical output, and (3) see any programming commands you have written. Each window corresponds to a separate type of SPSS file.</p>
<div class="section level3" id="data-editor-.sav-files">
<h3>Data Editor (.sav files)</h3>
<p>The Data Editor lets you see and manipulate your data. You will always have at least one Data Editor open (even if you have not yet opened a data set). When you open an SPSS data file, what you see is a working copy of your data. Changes you make to your data are not permanent until you save them (click <strong>File - Save</strong> or <strong>Save As</strong>). Data files are saved with a file type of <strong>.sav</strong>, a file type that most other software cannot work with. When you close your last Data Editor you are shutting down SPSS and you will be prompted to save all unsaved files.</p>
<p><img alt="Data Editor" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS02DataEditor.jpg"/></p>
<p>To open a different data set, click <strong>File - Open - Data</strong>. (It is also possible to open some non-SPSS data files by this method, such as Excel, Stata, or SAS files.) SPSS lets you have many data sets open simultaneously, and the data set that you are currently working with, the <em>active</em> data set, is always marked with a tiny red "plus" sign on the title bar. In order to avoid confusion it is usually a good strategy to close out any Data Editors you're done using.</p>
</div>
<div class="section level3" id="output-viewer-.spv-files">
<h3>Output Viewer (.spv files)</h3>
<p>As you ask SPSS to carry out various computations and other tasks, the results can show up in a variety of places. New data values will show up in the Data Editor. Statistical results will show up in the Output Viewer.</p>
<p><img alt="Output Viewer" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS03OutputViewer.jpg"/></p>
<p>The Output Viewer shows you tables of statistical output and any graphs you create. By default it also show you the programming language for the commands that you issued (called <em>syntax</em> in SPSS jargon), and most error messages will also appear here. The Output Viewer also allows you to edit and print your results. The tables of the Output Viewer are saved (click <strong>File - Save</strong> or <strong>Save As</strong>) with a file type of <strong>.spv</strong>, which can only be opened with SPSS software.</p>
<p>As with Data Editors, it is possible to open more than one Output Viewer to look at more than one output file. The <em>active</em> Viewer, marked with a tiny blue plus sign, will receive the results of any commands that you issue. If you close all the Output Viewers and then issue a new command, a fresh Output Viewer is started.</p>
</div>
<div class="section level3" id="syntax-editor-.sps-files">
<h3>Syntax Editor (.sps files)</h3>
<p>If you are working with the SPSS programming language directly, you will also open a Syntax Editor.</p>
<p><img alt="Syntax Editor" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS04SyntaxEditor.jpg"/></p>
<p>The Syntax Editor allows you to write, edit, and run commands in the SPSS programming language. If you are also using the menus and dialog boxes, the <strong>Paste</strong> button automatically writes the syntax for the command you have specified into the active Syntax Editor. These files are saved as plain text and almost any text editor can open them, but with a file extension of <strong>.sps</strong>.</p>
<p>As with the other types of windows, you can have more than one Syntax Editor open and the <em>active</em> window is marked with a tiny orange plus sign. When you paste syntax from dialog boxes, it goes to the active Syntax Editor. If you close out all your Syntax Editors and then paste a command, a fresh Syntax Editor is opened.</p>
</div>
</div>
<div class="section level2" id="issuing-commands">
<h2>Issuing Commands</h2>
<p>Unless you command SPSS to do something, it just sits there looking at you. In general commands may be issued either through menus and dialog boxes that invoke the programming language behind the scenes, or by typing the programming language in a Syntax Editor and <em>running</em> the commands.</p>
<div class="section level3" id="dialog-boxes">
<h3>Dialog Boxes</h3>
<p>Although each dialog box is unique, they have many common features. A fairly typical example is the dialog box for producing frequency tables (tables with counts and percents). To bring up this dialog box from the menus, click on <strong>Analyze - Descriptive Statistics - Frequencies</strong>.</p>
<p><img alt="Dialog Box" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS05FrequenciesDialog.jpg"/></p>
<p>On the left is a variable <em>selection list</em> with all of the variables in your data set. If your variables have variable labels, what you see is the beginning of the variable label. To see the full label as well as the variable name [in square brackets], hold your cursor over the label beginning. Select the variables you want to analyze by clicking on them (you may have to scroll through the list). Then click the arrow button to the right of the selection list, and the variables are moved to the <em>analysis list</em> on the right. If you change your mind about a variable, you can select it in the list on the right and then click the arrow button to move it back out of the analysis list. On the far right of the dialog are several buttons that lead to further dialog boxes with options for the frequencies command. At the bottom of the dialog box, click <strong>OK</strong> to issue your command to SPSS, or <strong>Paste</strong> to have the command written to a Syntax Editor.</p>
<p>If you return to a dialog box you will find it opens with all the specifications you last used. This can be handy if you are trying a number of variations on your analysis, or if you are debugging something. If you'd prefer to start fresh you can click the <strong>Reset</strong> button.</p>
</div>
</div>
<div class="section level2" id="working-with-the-data-editor">
<h2>Working with the Data Editor</h2>
<p>The main use of the Data Editor is to show you (a portion of) the data values you are working with. It can also be used to redefine the characteristics of variables (change the type, add labels, define missing values, etc.), create new variables, and enter data by hand.</p>
<p>The Data Editor gives you two views of your data set: a <em>Data View</em> and a <em>Variable View</em>, selected by clicking on the appropriate tab in the lower left corner of the window.</p>
<p><img alt="Data View" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS06DataView.jpg"/></p>
<p><img alt="Variable View" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS07VariableView.jpg"/></p>
<div class="section level3" id="data-view">
<h3>Data View</h3>
<p>In the Data View, the data are laid out in the standard rectangular format for statistical software. Each row represents a unit of observation, sometimes also referred to as a <em>record</em> or in SPSS as a <em>case</em>. The case (observation) number in the leftmost column is assigned automatically and is not saved as data. Each column represents a variable. All of the data in a column must be of the same <em>type</em>, either <em>numeric</em> or <em>string</em> (also called character).</p>
<p>Each data cell holds a data value. If data are missing, they are displayed as a period (".") or as a blank (" "). Data values may be displayed as either the actual value or as a <em>formatted</em> value. For example, a data value about a person's income might be 15000, while its formatted value might be shown as $15,000. Formats can also take the form of value labels, for instance, data recorded as 1's and 2's might be labeled as "Male" and "Female." While formatting makes it easier to interpret results, it is important to remember that the data values are what SPSS actually processes. In particular, when you set up a command that requires you to specify one or more data values, you use values and not formatted values.</p>
<p>You can switch the Data View between formatted and unformatted data by clicking on the <strong>Value Labels</strong> button on the Toolbar, the fourth button from the right when in the Data View. With value labels on you can also see the actual values for a given variable by clicking on a cell and then looking at the bar just above the data. The box to the left indicates the observation number and variable selected, e.g. <em>1:gender</em>, while the center box shows you the actual value, e.g. <em>m</em>.</p>
<p>Data values can be edited or added by typing them directly into the Data View. To enter data, type in the actual data value. However, aside from very small data sets for class exercises, you should almost never need to do this.</p>
</div>
<div class="section level3" id="variable-view">
<h3>Variable View</h3>
<p>In the Variable View you can see and edit the information that defines each variable (sometimes called <em>meta-data</em>) in your data set: each column of the Data View is described by a row of the Variable View.</p>
<p>The first attribute of each variable is its <strong>Name</strong>. The variable name is how the data column is identified in the programming language, and in order for the programming language to work gracefully variable names have to abide by certain restrictions: names must begin with a letter, and may be made up of characters, numerals, non-punctuation characters, and the period. Capitalization is ignored. Variable names may be up to 64 characters long. Other restrictions may apply - no coupons please. Variable names may be added or changed simply by typing them in.</p>
<p>The basic variable types are either <em>numeric</em> or <em>string</em>. However, just to make things confusing, SPSS allows you to select among several different standard formats for displaying numeric data (e.g. scientific notation, comma formatting, currencies) and calls this <strong>Type</strong>. You set the variable type by clicking in the column, then clicking on the gray button that appears and working in a dialog box.</p>
<p>The <strong>Label</strong> attribute allows you to give each variable a longer description that is displayed in place of the variable name, analogous to value labels for data values. Both variable labels and value labels are useful for giving you more intelligible output.</p>
<p>The <strong>Values</strong> attribute allows you to create a list of value labels. Often several variables will share a common set of value labels, and in this window you can copy and paste value label sets. Variable labels are set by simply typing them in, value labels work through a dialog box.</p>
<p>The <strong>Missing</strong> attribute is a place for you to designate certain data values that you want SPSS to ignore when it calculates statistics. For instance, in survey data it is common practice to record a data value of <em>8</em> when a respondent says "I don't know" in response to a question, and you can have SPSS treat the 8's in a variable as if they were missing data.</p>
<p>The other attributes, <strong>Width</strong>, <strong>Decimals</strong>, <strong>Columns</strong>, <strong>Align</strong>, <strong>Measure</strong>, and <strong>Role</strong>, are minor settings related to data display. Although Measure (level of measurement) is statistically a very important concept, it has little meaning within the SPSS software.</p>
</div>
</div>
<div class="section level2" id="working-with-the-output-viewer">
<h2>Working with the Output Viewer</h2>
<p>The Output Viewer collects your statistical tables and graphs, and gives you the opportunity to edit them before you save or print them. The Output Viewer is divided into two main sections, an outline pane on the left, and a tables pane on the right. When you print your output, it is the tables pane that is printed.</p>
<p><img alt="Selected Output" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS08SelectedOutput.jpg"/></p>
<p>When SPSS creates output (tables, syntax, error messages, etc.) it adds them to the tables pane as <em>objects</em>, and each object is noted in the outline pane. Individual objects may be opened and edited, deleted, hidden, rearranged, or printed. To select an object to work with, you can either click on it in the tables pane, or click on the corresponding entry in the outline pane. A red arrow appears next to the object in both panes.</p>
<p><strong>To edit objects</strong>, double-click on them in the tables pane. Depending on whether you are trying to edit a simple object like a title (which is just a box with some text in it), or something more complicated like a table or a graph, you may be able to simply change the object in the Output Viewer, or another window may open. Except for editing the look of graphs, it will often be easier to edit your output by exporting it to Microsoft Word first, but in principle you can change anything you can see in your output, down to deleting columns and changing numbers. (But if your intent is to fake your results, you should attend our Simulations workshop for better methods of doing this.)</p>
<p><strong>To delete objects</strong>, select them in either pane and use the <strong>Delete</strong> key.</p>
<p><strong>To hide objects</strong>, double-click on the icon for each object in the outline pane. To make them visible, just double-click again. You can hide a whole section of the outline by clicking on the minus sign to the left of the group in the outline pane. Hidden objects are not printed, but are saved with the output file.</p>
<p><strong>To rearrange objects</strong>, select the object (or group of objects) in either pane, and drag them until the red arrow points to the object below which you want them to appear.</p>
<p><strong>To export your output</strong>, you go through a special procedure. In the Output Viewer click <strong>File - Export</strong> to invoke the Export dialog box. There are three main settings to look at. First, pick the type of file to which you want to export: useful file types include Excel, PDF, PowerPoint, or Word. Next, check that you are exporting as much of your output as you want, the <strong>Objects to Export</strong> at the top of the dialog. If you have a part of your output selected, this option will default to exporting just your selection, otherwise you typically will export all your visible output. Finally, change the default file name to something meaningful, and save your file to a location where you will be able to keep it, like your U:\ drive.</p>
<p>Once your options are set, click <strong>OK</strong>.</p>
<p><img alt="Export Output" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS09ExportOutput.jpg"/></p>
</div>
<div class="section level2" id="working-with-the-syntax-editor">
<h2>Working with the Syntax Editor</h2>
<p>Learning SPSS programming syntax is a separate topic; the fundamentals are addressed in our SSCC training workshops. But you don't have to memorize a whole new language in order to paste and run SPSS syntax.</p>
<p>The fundamental unit of work in the SPSS language is the command: think of commands as analogous to well-formed sentences. In this language, commands begin with a keyword and end with a period. Commands should begin in the leftmost column in the editor. If they are wrapped onto more than one line, the continuing lines should begin with a blank space. Capitalization does not matter. The Syntax Editor displays syntax that SPSS cannot interpret in red type.</p>
<p>Like the Output Editor, the Syntax Editor has two panes. The tables pane on the right is what is actually saved in the <strong>.sps</strong> file.</p>
<p><img alt="Selected Syntax" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS09SelectedSyntax.jpg"/></p>
<p><strong>Running syntax</strong>. To have SPSS actually carry out your command(s), you must <em>run</em> them. Click <strong>Run</strong>, and then one of the menu options. There is also an icon on the Toolbar to run your program, a right-facing triangle ("play"). You can run all the commands in the editor, or select a group of commands and run just that (be careful that you highlight full commands, from the first keyword through the final period). You can also run the <em>current</em> command, which is whatever command the cursor is located within.</p>
<p><strong>Pasting and running</strong>. From most dialog boxes you have the option of <em>pasting</em> commands instead of simply running them. SPSS then writes the command into a Syntax Editor. The syntax tends to be verbose, specifying many options that are the defaults - syntax you write yourself tends to be much shorter and simpler. After you have pasted a command, you still need to run it to get any output.</p>
</div>
<div class="section level2" id="learning-more">
<h2>Learning More</h2>
<p>Now that you understand the basics of using the SPSS windows, you can learn how to carry out statistical tasks by reading <a href="https://ssc.wisc.edu/sscc/pubs/spss/classintro/spss_students2.html">part two of SPSS for Students</a>. It covers common statistics, regression, and graphs.</p>
<p>To learn more about the SPSS user interface, you can look at the on-line tutorial that comes with the software: click <strong>Help - Tutorial</strong>.</p>
<p>To learn more about specific data management or statistical tasks, you should try the on-line Help files. Click <strong>Help - Topics</strong> and you can read about a variety of basic SPSS topics, or search the index.</p>
<p>Your instructor and/or TA are your best resource for class-specific tasks.</p>
<p>If you are at UW-Madison, <a href="mailto:dehemken@wisc.edu">Doug Hemken</a>, a statistical consultant for the SSCC, is available to help with SPSS projects. See <a href="https://ssc.wisc.edu/sscc/statconsult.htm">Stat Consulting</a> for details.</p>
<p>Last Revised: 7/5/2016</p>
</div>

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS01InitialDialog.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS02DataEditor.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS03OutputViewer.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS04SyntaxEditor.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS05FrequenciesDialog.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS06DataView.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS07VariableView.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS08SelectedOutput.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS09ExportOutput.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students1/SPSS09SelectedSyntax.jpg</img_base_url>
</kb_document>
<kb_document>
<kb_title>SPSS for the Classroom: Statistics and Graphs</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<div id="TOC">
<ul>
<li><a href="#frequencies-counts-and-percents">Frequencies: Counts and Percents</a></li>
<li><a href="#descriptives-means-and-standard-deviations">Descriptives: Means and Standard Deviations</a></li>
<li><a href="#histograms">Histograms</a></li>
<li><a href="#crosstabs-counts-by-group">Crosstabs: Counts by Group</a></li>
<li><a href="#means-by-group">Means by Group</a></li>
<li><a href="#bar-charts">Bar Charts</a></li>
<li><a href="#boxplots">Boxplots</a></li>
<li><a href="#correlation">Correlation</a></li>
<li><a href="#scatter-plots">Scatter Plots</a></li>
<li><a href="#t-tests">T-tests</a></li>
<li><a href="#chi-square-tests">Chi-square Tests</a></li>
<li><a href="#anova-tables-and-tests">ANOVA Tables and Tests</a></li>
<li><a href="#regression">Regression</a></li>
<li><a href="#learning-more">Learning More</a></li>
</ul>
</div>
<p>This document is intended for students taking classes that use SPSS Statistics. Those who plan on doing more involved research projects using SPSS should attend our <a href="https://ssc.wisc.edu/sscc_jsp/training/index.jsp">workshop series</a>.</p>
<p>If you are not already familiar with the SPSS windows (the Data Editor, Output Viewer, and Syntax Editor), please read <a href="https://ssc.wisc.edu/sscc/pubs/spss/classintro/spss_students1.html">SPSS for the Classroom: The Basics</a>.</p>
<p>The examples that follow are based on the sample data in <code>C:\Program Files\IBM\SPSS\Statistics\23\Samples\English\Employee data.sav</code></p>
<div class="section level2" id="frequencies-counts-and-percents">
<h2>Frequencies: Counts and Percents</h2>
<p>Counts and percents are wonderful statistics because they are easy to explain and quickly grasped. Frequencies also form the very foundation of most explanations of probability. They are an excellent place to begin understanding any data you may work with.</p>
<div class="section level3" id="menu-and-dialog-box">
<h3>Menu and Dialog Box:</h3>
<p><strong>Analyze - Descriptive Statistics - Frequencies</strong></p>
<p><img alt="Frequencies dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS10Freq.jpg"/></p>
<p>Select one or more variables in the selection list on the left, and move them into the analysis list on the right by clicking on the arrow in between. Then click <strong>OK</strong>.</p>
</div>
<div class="section level3" id="syntax">
<h3>Syntax:</h3>
<pre><code>frequencies variables = gender minority.</code></pre>
</div>
<div class="section level3" id="output">
<h3>Output:</h3>
<p><img alt="Frequencies Output" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS11FreqOut.jpg"/></p>
<p>Note that this is one of the few tables where missing values (whether system missing "." or user designated missing) show up in the default output table (however, not in this particular example).</p>
</div>
</div>
<div class="section level2" id="descriptives-means-and-standard-deviations">
<h2>Descriptives: Means and Standard Deviations</h2>
<p>The mean and standard deviation of a variable are such fundamental quantities in statistics, that there are many SPSS commands that will report them to you. The most straightforward command to use is <strong>Descriptives</strong>.</p>
<p>Two other useful commands are <strong>Frequencies</strong> (in the dialog box, click on the <strong>Statistics</strong> button), when you want to see counts as well as means and standard deviations (perhaps for Likert scales), and <strong>Explore</strong>, which gives you such additional statistics as the median and interquartile range as well as a variety of graphs.</p>
<div class="section level3" id="menu-and-dialog-box-1">
<h3>Menu and Dialog Box:</h3>
<p><strong>Analyze - Descriptive Statistics - Descriptives</strong></p>
<p><img alt="Descriptives dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS12Desc.jpg"/></p>
<p>Select one or more variables in the selection list on the left, and move them into the analysis list on the right by clicking on the arrow in between. Then click <strong>OK</strong>.</p>
</div>
<div class="section level3" id="syntax-1">
<h3>Syntax:</h3>
<pre><code>descriptives variables=educ salary.</code></pre>
</div>
<div class="section level3" id="output-1">
<h3>Output:</h3>
<p><img alt="Descriptives Output" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS13DescOut.jpg"/></p>
</div>
</div>
<div class="section level2" id="histograms">
<h2>Histograms</h2>
<p>SPSS has three different sets of commands for producing graphs. The easiest to learn and use are the oldest "legacy" graphing commands. They give you graphs with a default visual style (colors used, weight of lines, size of type, etc) that can be customized by hand.</p>
<p>Histograms are vexing because they can be alternately informative or deceptive, depending upon how the bins (the bar boundaries) are chosen. They are useful and popular because they are conceptually very simple, easy to draw and interpret, and if drawn well they can give a good visual representation of the distribution of values of a variable.</p>
<div class="section level3" id="menu-and-dialog-box-2">
<h3>Menu and Dialog Box:</h3>
<p><strong>Graphs - Legacy Dialogs - Histogram</strong></p>
<p><img alt="Histogram dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS14Hist.jpg"/></p>
<p>The basic histogram command works with one variable at a time, so pick one variable from the selection list on the left and move it into the <strong>Variable</strong> box. (A useful option if you expect your variable to have a normal distribution is to <strong>Display normal curve</strong>.)</p>
</div>
<div class="section level3" id="syntax-2">
<h3>Syntax:</h3>
<pre><code>graph /histogram(normal) = prevexp.</code></pre>
</div>
<div class="section level3" id="output-2">
<h3>Output:</h3>
<p><img alt="Histogram output" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS14HistOut.jpg"/></p>
<p>In this example, the distribution of the data is nothing like a normal distribution!</p>
<p>To edit colors, titles, scales, etc. double-click on the graph in the Output Viewer, then double-click on the graph element you want to change.</p>
</div>
</div>
<div class="section level2" id="crosstabs-counts-by-group">
<h2>Crosstabs: Counts by Group</h2>
<p>The basic crosstabs command just gives you counts by default. Typically it is useful to also look at either row-percents or column-percents, which must be specified as options.</p>
<div class="section level3" id="menu-and-dialog-box-3">
<h3>Menu and Dialog Box:</h3>
<p><strong>Analyze - Descriptive Statistics - Crosstabs</strong></p>
<p>Select one variable as the rows, another variable as the columns. Conventionally you might put an independent variable in the rows and a dependent variable in the columns, although mathematically it doesn't really matter. To get percents in your output, click on the <strong>Cells</strong> button and specify the kind of percents you want to see.</p>
<p><img alt="Crosstabs dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS15Cross.jpg"/></p>
</div>
<div class="section level3" id="syntax-3">
<h3>Syntax:</h3>
<pre><code>crosstabs
  /tables=jobcat by minority
  /cells=count row.</code></pre>
<p>In this command syntax (and the next one, <code>MEANS</code>), you see the key word <code>BY</code> used to specify a categorical variable that divides the data into groups.</p>
</div>
<div class="section level3" id="output-3">
<h3>Output:</h3>
<p><img alt="Crosstabs output" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS16CrossOut.jpg"/></p>
</div>
</div>
<div class="section level2" id="means-by-group">
<h2>Means by Group</h2>
<div class="section level3" id="menu-and-dialog-box-4">
<h3>Menu and Dialog Box:</h3>
<p><strong>Analyze - Compare Means - Means</strong></p>
<p>Select the variable(s) that you want means of, and move it to the <strong>Dependent List</strong>. Select the variable that divides the data into subsets (the "grouping" or "by" variable) and move it to the <strong>Independent List</strong>. You may have more than one variable in either/both lists, and SPSS processes them in pairs and produces separate tables.</p>
<p><img alt="Means dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS17GroupMeans.jpg"/></p>
</div>
<div class="section level3" id="syntax-4">
<h3>Syntax:</h3>
<pre><code>means tables=salary by minority.</code></pre>
</div>
<div class="section level3" id="output-4">
<h3>Output:</h3>
<p><img alt="Means output" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS18GroupMeansOut.jpg"/></p>
</div>
</div>
<div class="section level2" id="bar-charts">
<h2>Bar Charts</h2>
<p>Similar to a histogram, the x axis is treated as a categorical variable, and the y axis represents one of a variety of summary statistics: counts (a.k.a. a histogram!), means, sums, etc.</p>
<div class="section level3" id="menu-and-dialog-box-5">
<h3>Menu and Dialog Box:</h3>
<p><strong>Graphs - Legacy Dialogs - Bar</strong></p>
<p>This takes you through an initial dialog box, where you choose among several basic schemas for making bar charts,</p>
<p><img alt="Bar charts dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS19Bars.jpg"/></p>
<p>and then to the main dialog box. To graph means by groups, select <strong>Other statistic</strong> for what the bars represent, the variable for which you want to calculate means in the <strong>Variable</strong> box (means will be the default statistic), and the group in the <strong>Category Axis</strong> box.</p>
<p><img alt="Simple bar chart dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS20BarChart.jpg"/></p>
</div>
<div class="section level3" id="syntax-5">
<h3>Syntax:</h3>
<pre><code>graph /bar=mean(salary) by jobcat.</code></pre>
</div>
<div class="section level3" id="output-5">
<h3>Output:</h3>
<p><img alt="Simple bar chart" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS21BarChartOut.jpg"/></p>
</div>
</div>
<div class="section level2" id="boxplots">
<h2>Boxplots</h2>
<div class="section level3" id="menu-and-dialog-box-6">
<h3>Menu and Dialog Box:</h3>
<p><strong>Graphs - Legacy Dialogs - Boxplot</strong></p>
<p>As with bar charts, you first choose a specific boxplot schema from an initial dialog box,</p>
<p><img alt="Boxplots dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS22Boxes.jpg"/></p>
<p>and then choose the analytical variable (the one you want to see medians and interquartile ranges for, the y axis), and the categorical variable (the x axis).</p>
<p><img alt="Simple boxplot dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS23BoxPlot.jpg"/></p>
</div>
<div class="section level3" id="syntax-6">
<h3>Syntax:</h3>
<pre><code>examine variables=salary by jobcat
  /plot=boxplot
  /statistics=none
  /nototal.</code></pre>
</div>
<div class="section level3" id="output-6">
<h3>Output:</h3>
<p><img alt="Simple boxplot" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS24BoxPlotOut.jpg"/></p>
</div>
</div>
<div class="section level2" id="correlation">
<h2>Correlation</h2>
<div class="section level3" id="menu-and-dialog-box-7">
<h3>Menu and Dialog Box:</h3>
<p><strong>Analyze - Correlate - Bivariate</strong></p>
<p>SPSS calculates bivariate correlations (the Pearson's r) for all pairs of variables in the list.</p>
<p><img alt="Correlation dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS25Corr.jpg"/></p>
</div>
<div class="section level3" id="syntax-7">
<h3>Syntax:</h3>
<pre><code>correlations /variables=educ salary prevexp.</code></pre>
</div>
<div class="section level3" id="output-7">
<h3>Output:</h3>
<p><img alt="Correlation output" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS25CorrOut.jpg"/></p>
</div>
</div>
<div class="section level2" id="scatter-plots">
<h2>Scatter Plots</h2>
<p>Both simple scatter plots and scatter plot matrixes are pretty easy to produce.</p>
<div class="section level3" id="menu-and-dialog-box-8">
<h3>Menu and Dialog Box:</h3>
<p><strong>Graphs - Legacy Dialogs - Scatter/Dot</strong></p>
<p>Takes you through two dialog boxes. First you choose the scatter plot schema you want to work with,</p>
<p><img alt="Scatter Plots" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS26Scatters.jpg"/></p>
<p>And then you specify the variables with the x and y coordinates of the points you wish to plot.</p>
<p><img alt="Simple scatter plot dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS27ScatPlot.jpg"/></p>
</div>
<div class="section level3" id="syntax-8">
<h3>Syntax:</h3>
<pre><code>graph /scatterplot=salary with salbegin.

graph /scatterplot(matrix)=salary salbegin prevexp.</code></pre>
</div>
<div class="section level3" id="output-8">
<h3>Output:</h3>
<p><img alt="Simple scatter plot output" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS28ScatPlotOut.jpg"/></p>
<p><img alt="Scatter plot matrix output" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS30ScatMatOut.jpg"/></p>
</div>
</div>
<div class="section level2" id="t-tests">
<h2>T-tests</h2>
<p>T-test can be used in a variety of ways, and SPSS gives you quick access to three of them (univariate, grouped, and paired) through the <strong>Compare Means</strong> menu. They all access the same <code>t-test</code> command.</p>
<div class="section level3" id="menu-and-dialog-box-9">
<h3>Menu and Dialog Box:</h3>
<p><strong>Analyze - Compare Means - Independent-Samples T Test</strong></p>
<p>When setting up an independent-samples (grouped) t-test, you not only specify the variable being tested and the grouping variable, but you also have to specify which data values represent the two groups you want compared (because in general the grouping variable might have an arbitrary number of categories, not just two). Use the <strong>Define Groups</strong> button, and type in the data values (not the value labels) that define the groups being compared.</p>
<p><img alt="T-test dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS31Ttest.jpg"/></p>
<p>If you type in an invalid data value for any of the groups, SPSS will not catch your mistake until you actually run the command. You need to know what your data look like before you get to this dialog box, because SPSS will not let you browse your data set while a dialog box is open.</p>
<p><img alt="T-test define groups dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS32Tgroups.jpg"/></p>
</div>
<div class="section level3" id="syntax-9">
<h3>Syntax:</h3>
<pre><code>t-test groups=gender('f' 'm')
  /variables=educ.</code></pre>
</div>
<div class="section level3" id="output-9">
<h3>Output:</h3>
<p><img alt="T-test output" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS32TOut.jpg"/></p>
</div>
</div>
<div class="section level2" id="chi-square-tests">
<h2>Chi-square Tests</h2>
<p>Like t-tests, chi-square tests come up in a wide variety of circumstances, the most common of which is assessing the independence of two variables in a contingency table (a crosstab). So this chi-square test is specified as an option on a crosstab command.</p>
<div class="section level3" id="menu-and-dialog-box-10">
<h3>Menu and Dialog Box:</h3>
<p><strong>Analyze - Descriptive Statistics - Crosstabs</strong></p>
<p>In the main dialog box, click on the <strong>Statistics</strong> button, then select <strong>Chi-square</strong> and <strong>Continue</strong> back to the main dialog box. Specify your variables and run.</p>
<p><img alt="Crosstab statistics dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS34Chi.jpg"/></p>
</div>
<div class="section level3" id="syntax-10">
<h3>Syntax:</h3>
<pre><code>crosstabs
  /tables=jobcat by minority
  /statistics=chisq
  /cells=count row.</code></pre>
</div>
<div class="section level3" id="output-10">
<h3>Output:</h3>
<p><img alt="Chi-square output" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS35ChiOut.jpg"/></p>
</div>
</div>
<div class="section level2" id="anova-tables-and-tests">
<h2>ANOVA Tables and Tests</h2>
<p>ANOVA tables are a core concept in statistics, and they are produced by several different commands in SPSS, including <code>ONEWAY</code>, <code>GLM</code>, and <code>UNIANOVA</code>. The <code>UNIANOVA</code> command is perhaps the easiest to use overall, because it allows you to use string (character) variables as factors.</p>
<p>(If you are doing a one-way ANOVA and your factor is coded in numeric form, then <code>ONEWAY</code> is even easier to use.)</p>
<div class="section level3" id="menu-and-dialog-box-11">
<h3>Menu and Dialog Box:</h3>
<p><strong>Analyze - General Linear Model - Univariate</strong></p>
<p>For a simple ANOVA, your factors are considered <strong>Fixed Factors</strong>. If you have more than one factor and you do <em>not</em> want to include interactions in your model, you will need to specify that with the <strong>Model</strong> button.</p>
<p><img alt="ANOVA dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS39Anova.jpg"/></p>
</div>
<div class="section level3" id="syntax-11">
<h3>Syntax:</h3>
<pre><code>unianova salary by jobcat.</code></pre>
</div>
<div class="section level3" id="output-11">
<h3>Output:</h3>
<p><img alt="ANOVA output" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS40AnovaOut.jpg"/></p>
</div>
</div>
<div class="section level2" id="regression">
<h2>Regression</h2>
<div class="section level3" id="menu-and-dialog-box-12">
<h3>Menu and Dialog Box:</h3>
<p><strong>Analyze - Regression - Linear</strong></p>
<p><img alt="Regression dialog" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS41Reg.jpg"/></p>
</div>
<div class="section level3" id="syntax-12">
<h3>Syntax:</h3>
<pre><code>regression
  /dependent salary
  /method=enter salbegin.</code></pre>
</div>
<div class="section level3" id="output-12">
<h3>Output:</h3>
<p><img alt="Regression output" src="https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS42RegOut.jpg"/></p>
</div>
</div>
<div class="section level2" id="learning-more">
<h2>Learning More</h2>
<p>To learn more about how to use the SPSS windows, you can look at the on-line tutorial that comes with the software: click <strong>Help - Tutorial</strong>.</p>
<p>To learn more about specific data management or statistical tasks, you should try the on-line Help files. Click <strong>Help - Topics</strong> and you can read about a variety of basic SPSS topics, or search the index.</p>
<p>Your instructor and/or TA are your best resource for class-specific tasks.</p>
<p>If you are at UW-Madison, <a href="mailto:helpdesk@ssc.wisc.edu">Doug Hemken</a>, a statistical consultant for the SSCC, is available to help with SPSS projects. See <a href="https://ssc.wisc.edu/sscc/statconsult.htm">Stat Consulting</a> for details.</p>
<p>Last Revised: 7/5/2016</p>
</div>

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS10Freq.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS11FreqOut.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS12Desc.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS13DescOut.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS14Hist.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS14HistOut.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS15Cross.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS16CrossOut.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS17GroupMeans.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS18GroupMeansOut.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS19Bars.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS20BarChart.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS21BarChartOut.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS22Boxes.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS23BoxPlot.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS24BoxPlotOut.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS25Corr.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS25CorrOut.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS26Scatters.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS27ScatPlot.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS28ScatPlotOut.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS30ScatMatOut.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS31Ttest.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS32Tgroups.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS32TOut.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS34Chi.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS35ChiOut.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS39Anova.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS40AnovaOut.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS41Reg.jpg, https://ssc.wisc.edu/sscc/pubs/spss/classintro/screenshots/spss_students2/SPSS42RegOut.jpg</img_base_url>
</kb_document>
<kb_document>
<kb_title>Articles on Statistical Computing</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<a id="content" name="content"></a>
<div id="RightContentLeftCol"><!-- InstanceBeginEditable name="Menu" -->
<p><a href="#dstr">Data Science Tools for Resesarch</a></p>
<p><a href="#StataBasics">Stata Basics</a></p>
<p><a href="#StataTopics">Stata Topics</a></p>
<p><a href="#RBasics">R Basics</a></p>
<p><a href="#RTopics">R Topics</a></p>
<p><a href="#SASBasics">SAS Basics</a></p>
<p><a href="#SASTopics">SAS Topics</a></p>
<p><a href="#SPSS">SPSS</a></p>
<p><a href="#mplus">Mplus</a></p>
<p><a href="#Python">Python</a></p>
<p><a href="#SPSS"></a><a href="#NVivo">NVivo</a></p>
<p><a href="#SASBasics"></a><a href="#Tools">Research Tools</a></p>
<!-- InstanceEndEditable --></div>
<div id="RightContentRightCol"><div><!-- InstanceBeginEditable name="Content" -->
<h2 id="dstr">Data Science Tools for Research</h2>
<p>This is SSCC's new training curriculum, designed to teach basic data science concepts and relevant software skills.</p>
<table border="1">
<tbody>
<tr>
<td width="227"><h3>R (tidyverse) &amp;<br/>
                              Python (pandas)</h3>
<p style="margin-bottom: 0"><a href="https://ssc.wisc.edu/sscc/pubs/DWE/">Data Wrangling Essentials</a></p>
<ol start="0" style="margin-top: 0">
<li><a href="https://ssc.wisc.edu/sscc/pubs/DWE/book/preface.html">Preface</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/DWE/book/1-programming.html">Programming</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/DWE/book/2-data-frames.html">Data Frames</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/DWE/book/3-visual-exploration-of-data.html">Visual Exploration of data</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/DWE/book/4-cleaning.html">Cleaning</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/DWE/book/5-transforming-variables.html">Transforming variables</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/DWE/book/6-transforming-data-frames.html">Transforming Data Frames</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/DWE/book/7-programming-index.html">Programming index</a></li>
</ol>
<ul style="margin-top: 0">
<li><a href="https://ssc.wisc.edu/sscc/pubs/DWE/datasets.zip">R Example Datasets</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/DWE/dw_py.zip">Python Example Datasets</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/DWE/solutions_R/">Exercise Solutions in R</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/DWE/solutions_Python/preface.html">Exercise Solutions in Python</a></li>
</ul>
</td>
<td width="227"><h3>Stata<br/>
<br/>
</h3>
<p style="margin-bottom: 0"><a href="https://ssc.wisc.edu/sscc/pubs/intro_stata/intro_stata1.htm">Introduction to Stata</a></p>
<ol style="margin-top: 0">
<li><a href="https://ssc.wisc.edu/sscc/pubs/intro_stata/intro_stata1.htm">Using Stata</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/intro_stata/intro_stata2.htm">Structure of a Stata Data Set</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/intro_stata/intro_stata3.htm">Elements of Stata Syntax</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/intro_stata/intro_stata4.htm">Do Files</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/intro_stata/intro_stata5.htm">Statistics</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/intro_stata/intro_stata6.htm">Creating and Changing Variables</a></li>
</ol>
<p style="margin-bottom: 0"><a href="https://ssc.wisc.edu/sscc/pubs/dws/data_wrangling_stata1.htm">Data Wrangling in Stata</a></p>
<ol style="margin-top: 0">
<li><a href="https://ssc.wisc.edu/sscc/pubs/dws/data_wrangling_stata1.htm">Introduction and Review</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/dws/data_wrangling_stata2.htm">Reading in Data</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/dws/data_wrangling_stata3.htm">First Steps With Your Data</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/dws/data_wrangling_stata4.htm">Variable Transformations</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/dws/data_wrangling_stata5.htm">Hierarchical Data</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/dws/data_wrangling_stata6.htm">Restructuring Data Sets</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/dws/data_wrangling_stata7.htm">Combining Data Sets</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/dws/data_wrangling_stata8.htm">Project Management</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/dws/data_wrangling_stata9.htm">Learning More</a></li>
</ol>
</td></tr>
</tbody>
</table>
<h2><a id="StataBasics" name="StataBasics"></a>Stata Basics</h2>
<p style="margin-bottom: 0">Looking for the old Stata for Researchers? It's <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">here</a>, but we think you'll like the Stata track of our new <a href="#dstr">Data Science Tools for Research</a> curriculum even better.</p>
<p style="margin-bottom: 0"><a href="https://ssc.wisc.edu/sscc/pubs/sfs/">Stata for Students</a></p>
<ol style="margin-top: 0">
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/">Introduction</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-where.htm">Where You Can Use Stata</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-files.htm">Managing Stata Files</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-do_files.htm">Doing Your Work Using Do Files</a> </li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ui.htm">Stata's User Interface</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-data.htm">Stata Data Sets</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-syntax.htm">How Stata Commands Work</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-comments.htm">Comments and Other Tools for Making Do Files Readable</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-vars.htm">Creating Variables</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-graphs.htm">Using Graphs</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-import.htm">Reading Data from a Spreadsheet or CSV File</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-qualtrics.htm">Downloading Data from Qualtrics and Importing it into Stata</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm#desc">Descriptive Statistics</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/home.htm#graphs">Graphs</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ci.htm">Means and Confidence Intervals</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-ttest.htm">t-tests</a></li>
<li> <a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-scatter.htm">Scatterplots </a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/sfs/sfs-cor.htm">Correlations</a></li>
</ol>
<p><a href="https://www-stata-journal-com.ezproxy.library.wisc.edu/archives/">Stata Journal at the UW-Madison Library System</a> (2012 vol. 4-present)<br/>
<a href="http://www.library.wisc.edu.ezproxy.library.wisc.edu/databases/launch/uw/resources/Stata-journal/">Stata Journal Archive</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/statahelp.htm">Search Stata's Online Help</a>                       (For full Stata documentation, start Stata and click <span class="MenuOutput">Help</span>, <span class="MenuOutput">PDF Documentation</span>.)</p>
<h2><a id="StataTopics" name="StataTopics"></a>Stata Topics</h2>
<p style="margin-bottom: 0"><a href="https://ssc.wisc.edu/sscc/pubs/stata_prog1.htm">Stata Programming</a></p>
<ol style="margin-top: 0">
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_prog1.htm">Stata Programming Essentials</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_prog2.htm">Stata Programming Tools</a></li>
</ol>
<p style="margin-bottom: 0"><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_intro.htm">Multiple Imputation in Stata</a></p>
<ol style="margin-top: 0">
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_intro.htm">Introduction</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_decide.htm">Deciding to Impute</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_models.htm">Creating Imputation Models</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_impute.htm">Imputing</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_manage.htm">Managing Multiply Imputed Data</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_estimate.htm">Estimating</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm">Examples</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_readings.htm">Recommended Readings</a></li>
</ol>
<p><a href="https://ssc.wisc.edu/sscc/pubs/4-24.htm">An Introduction to Stata Graphics</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/stata_bar_graphs.htm">Bar Graphs in Stata</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/stata_mp.htm">Running Stata/MP at the SSCC</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-26.htm">An Introduction to Mata<br/>
</a><a href="https://ssc.wisc.edu/sscc/pubs/4-16.htm">Finding and Installing User-Written Stata Programs</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/stata_memory.htm">Reducing Stata's Memory Usage</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/readhtml.htm">Stata Tools for Reading Data from Web Pages</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/stata_psmatch.htm">Propensity Score Matching in Stata using teffects</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/RegressionDiagnostics.html">Regression Diagnostics</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/stata_panel.htm">Stata Programming Techniques for Panel Data</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/stata_dates.htm">Working with Dates in Stata</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/stata_margins.htm">Exploring Regression Results using Margins</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/stata_tables.htm">Creating Publication-Quality Tables in Stata</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-23.htm">Using Stata Graphs in Documents</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-25.htm">Including Calculated Results In Stata Graphs</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-28.htm">Using Reshape to Manage Hierarchical Data</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-27.htm">Bootstrapping in Stata</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_condor.htm">Speeding up Multiple Imputation in Stata using Parallel Processing</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-22.htm">Making Predictions with Counter-Factual Data in Stata</a><br/>
</p>
<h2 id="RBasics">R Basics</h2>
<p style="margin-bottom: 0"><a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_Introduction.html">R for Researchers </a></p>
<ol style="margin-top: 0">
<li><a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_Introduction.html">Introduction</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_Projects.html">R Projects</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_RMarkdown.html">R Markdown</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_RScript.html">R Scripts</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_DataPrep.html">Data preparation</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_DataExpl.html">Data exploration</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_DataPres.html">Data presentation</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_Regression.html">Regression (OLS)</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_Diagnostics.html">Diagnostics</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_RegressionGLM.html">Regression (GLM)</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_RegInference.html">Regression inference</a></li>
</ol>
<p style="margin-bottom: 0"><a href="https://ssc.wisc.edu/sscc/pubs/R_intro/book/preface.html">R Introduction to Selected Topics<br/>
</a><a href="https://ssc.wisc.edu/sscc/pubs/r-install.htm">Installing R on Your Personal Computer</a><a href="https://ssc.wisc.edu/sscc/pubs/RBrief/R_BriefIntro.html"> </a> </p>
<h2 id="RTopics">R Topics</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">Mixed Models</a></p>
<ol style="margin-top: 0">
<li><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">Introduction</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_TestEffects.html"> Testing Significance of Effects</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer.html">Diagnostics and Inference</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_MultRand.html">Multiple Random Parameters</a></li>
</ol>
<p><a href="https://ssc.wisc.edu/sscc/pubs/RBrief/R_BriefIntro.html"></a><a href="https://ssc.wisc.edu/sscc/pubs/RegressionDiagnostics.html">Regression Diagnostics</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/r-packages.htm">Using  R Packages on SSCC Computers</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/r-install.htm"></a></p>
<h2><a id="SASBasics" name="SASBasics"></a>SAS Basics</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/4-18.htm">An Introduction to SAS Data	
                        Steps</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/sas_output.htm">Managing Output in SAS 9.3 and Above</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/7-4.htm">Running SAS on Linux</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/bigsas.htm">Running Large SAS Jobs on Linstat<br/>
</a><a href="https://ssc.wisc.edu/sscc/pubs/sas_launch.htm">Launching SAS Files from Windows Explorer</a><br/>
<a href="http://support.sas.com/cdlsearch?ct=80000">SAS Version 
                          9 Online Documentation</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/sas.pdf">SAS Workbook for Writing SAS 
                          Programs to Process Data on UNIX</a><br/>
<a href="https://www.ssc.wisc.edu/sscc/pubs/4-8.htm">Redirecting 
                          and Customizing Tabular Output in SAS</a><br/>
</p>
<h2><a id="SASTopics" name="SASTopics"></a>SAS Topics</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/convert_sas_formats.htm">Converting SAS Formats from 32-Bit to 64-Bit</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/sas_excel.htm">SAS and Excel Files on Winstat</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-21.htm">A Simple Procedure for Producing 
                        Publication-Quality Graphs using SAS</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-19.htm">Storing SAS Formats</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-1.pdf">Using SAS to Perform a Table	
                          Lookup</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-2.pdf">Constructing Indicator Variables 
                          with SAS</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-4.pdf">Converting a Code Book to a 
                          SAS FORMAT Library</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-5.pdf">Using SAS to Reformat Data Records 
                          from One to Several</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-20.htm">Saving SAS Graphs For Printing 
                          or Other Uses</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-11.htm">Using Compressed Data in SAS </a></p>
<h2><a id="OlderSASTopics" name="OlderSASTopics"></a>Older SAS Topics</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/4-3.pdf">SAS Programming Efficiencies</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-12.htm">Creating SAS Transport Files</a></p>
<h2><a id="SPSS" name="SPSS"></a>SPSS</h2>
<p style="margin-bottom: 0"><a href="https://ssc.wisc.edu/sscc/pubs/spss/classintro/spss_students1.html">SPSS Statistics for the Classroom</a></p>
<ol style="margin-top: 0">
<li><a href="https://ssc.wisc.edu/sscc/pubs/spss/classintro/spss_students1.html">The Basics</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/spss/classintro/spss_students2.html">Statistics and Graphs</a></li>
</ol>
<p><a href="https://ssc.wisc.edu/sscc/pubs/spss/Windows/SPSS_Syntax.html">SPSS Syntax</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/spss/Windows/Extension_bundles.html" title="Using Extension Bundles in SSCC">Using Extension Bundles in SSCC</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/spss/Linux/7-18.html">Running SPSS Jobs on Linux</a><br/>
<a href="http://ssc.wisc.edu/sscc_jsp/spssdocs.jsp">SPSS 19
                        Online Documentation</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/4-6.pdf">Using SPSS to Reformat Data 
                        Records from One to Several</a> </p>
<h2>Mplus</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/mplus_linstat.htm">Running Mplus Jobs on Linstat</a></p>
<h2 id="Python">Python</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/python_packages_winstat.htm">Installing Python Packages on Winstat</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/python_linstat.htm">Running Python on Linstat</a><br/>
</p>
<h2><a id="NVivo" name="NVivo"></a>NVivo</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/nvivo.htm">Using NVivo on Winstat</a> </p>
<h2><a id="Tools" name="Tools"></a>Research Tools</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/computing_resources.htm">Computing Resources at the
                        SSCC</a><a href="https://ssc.wisc.edu/sscc/pubs/4-17.htm"><br/>
                          Using Stat/Transfer</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/GitBrief/GitBriefIntro.html">Git - Brief Introduction</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a> <br/>
<a href="https://ssc.wisc.edu/sscc/pubs/linstat_jobs.htm">Managing Jobs on Linstat</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/data_entry_excel.htm">Using Excel for Data Entry</a><br/>
</p>
<p> </p>
<!-- InstanceEndEditable --></div></div>

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Bar Graphs in Stata</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Bar graphs are simple but powerful (or rather, powerful because they are simple) tools for conveying information. They can be understood at a glance by both technical and non-technical audiences, and often tell you much more than summary statistics will. This article will show you how to make a variety of useful bar graphs using Stata.</p>
<h2>The Example Data Set</h2>
<p>SSCC's statistical consultants have been asked to analyze several workplace surveys in recent years, so the example data we'll use has that theme (much of this article came out of our efforts to find ways to present our results to very busy leaders). You can obtain the data by typing, or more likely copying and pasting, the following in a do file:</p>
<p class="InputCode">use http://ssc.wisc.edu/sscc/pubs/bargraphs/bar_example.dta</p>
<p>It contains fictional data with 1,000 observations and four variables:</p>
<ul>
<li><span class="InputCode">sat</span>: responses to the question "In general, how satisfied are you with your job?" on a five-point scale ranging from "Very Dissatisfied" to "Very Satisfied."</li>
<li><span class="InputCode">eng</span>: a numeric measure of employee engagement from 1 to 100.</li>
<li><span class="InputCode">leave</span>: responses to the question "How likely are you to leave your job in the next year?" on a five-point scale ranging from "Very Likely" to "Very Unlikely." </li>
<li><span class="InputCode">stay</span>: a binary variable based on <span class="InputCode">leave</span>. It is 0 if the respondent said they were likely to leave and 1 otherwise.</li>
<li><span class="InputCode">female</span>: a binary variable which is 1 if the respondent is female and 0 if the respondent is male.                </li>
</ul>
<h2>Distribution of a Single Variable</h2>
<p>The most basic task of a bar graph is to help you understand the distribution of a single categorical variable. Begin with the <span class="InputCode">sat</span> variable (job satisfaction) and the most basic bar graph:</p>
<p class="InputCode">graph bar, over(sat)</p>
<p>                The <span class="InputCode">graph bar</span> command tell Stata you want to make a bar graph, and the <span class="InputCode">over()</span> option tells it which variable defines the categories to be described. By default it will tell you the percentage of observations that fall in each category. Unfortunately, the result is not very satisfactory:</p>
<img alt="Basic bar graph" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b1.png" width="550"/>
<p>The categories are labeled using the value labels of the <span class="InputCode">sat</span> variable, but they're unreadable because they overlap. You can fix this problem easily and naturally by making the whole graph horizontal rather than vertical. Just change <span class="InputCode">graph bar</span> to <span class="InputCode">graph hbar</span>.</p>
<p>The y axis title "percent" is vague. Make it more clear with a <span class="InputCode">ytitle()</span> option. Note that this axis will be horizontal since you're now making a horizontal graph, but it's still referred to as the y axis.</p>
<p>This graph is also in dire need of an overall title, which can be added using the <span class="InputCode">title()</span> option. For graphs describing surveys, the question text is often a useful title. The title text doesn't always need to go in quotes, but this one does because it contains a comma. Without quotes, Stata will think you're trying to set title options.</p>
<p>Stata graph commands often get long;  you can make them more readable by splitting them across multiple lines if you use <span class="InputCode">///</span> to tell Stata the command continues on the next line. For this article, we'll put just one option per line, though some options will soon take more than one line. We'll also bold the new or changed parts of each command.</p>
<p class="InputCode">graph <span class="BoldCode">hbar</span>, ///<br/>
                  over(sat) ///<br/>
<span class="BoldCode">ytitle("Percent of Respondents")</span> ///<br/>
<span class="BoldCode">title("In general, how satisfied are you with your job?")</span><br/>
</p>
<img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b2.png" width="550"/>
<p>Now the problem is that the text doesn't fit in the graph. You can do several things to fix that:</p>
<ul>
<li>Reduce the size of the category labels using the <span class="InputCode">label(labsize(small))</span> option</li>
<li>Reduce the size of the y axis title using the <span class="InputCode">size(small)</span> option</li>
<li>Allow the title to use the space above the axis labels (and be centered across the entire space)  using the <span class="InputCode">span</span> option</li>
<li>Reduce the size of the title using the <span class="InputCode">size(medium)</span> option</li>
</ul>
<p>You could also split the title into multiple lines by putting each line in its own set of quotes, but that won't be necessary here.</p>
<p>Each of the new options goes inside the option for the thing it controls. They are options for options!</p>
<p class="InputCode">graph hbar, ///<br/>
                  over(sat<span class="BoldCode">, label(labsize(small))</span>) ///<br/>
                  ytitle("Percent of Respondents"<span class="BoldCode">, size(small)</span>) ///<br/>
                  title("In general, how satisfied are you with your job?" ///<br/>
<span class="BoldCode">, span size(medium)) </span><br/>
</p>
<img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b3.png" width="550"/>
<p>We're getting much closer, but the label "Neither Satisfied nor Dissatisfied" is still being truncated. One good solution would be to  use a shorter label. On the other hand, an elegant command called <span class="InputCode">splitvallabels</span> by Nick Winter and Ben Jann will take value labels, split them into multiple lines, and make them available as an <span class="InputCode">`r(relabel)'</span> macro in a form the <span class="InputCode">relabel()</span> option can understand. (The <span class="InputCode">relabel()</span> option allows you to set category labels to whatever you want without setting value labels for the variable, but using value labels is a good practice for many reasons.) You can get <span class="InputCode">splitvallabels</span>   by running:</p>
<p class="InputCode">ssc install splitvallabels</p>
<p>You only need to run this once—don't put it in a research do file that you'll run over and over.</p>
<p class="InputCode"> <span class="BoldCode">splitvallabels sat</span><br/>
                  graph hbar, ///<br/>
                  over(sat, label(labsize(small)) <span class="BoldCode">relabel(`r(relabel)')</span>) ///<br/>
                  ytitle("Percent of Respondents", size(small)) ///<br/>
                  title("In general, how satisfied are you with your job?" ///<br/>
                  , span size(medium))<br/>
</p>
<p>If you are new to macros, note that the character at the left of <span class="InputCode">`r(relabel)'</span> is the left single quote, found on the left side of your keyboard under the tilde, and the character at the right of it is the right single quote, found on the right side of your keyboard under the double quote.</p>
<p></p>
<img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b4.png" width="550"/>
<p>This  fixes the truncated label and reduces the amount of space taken up by the labels in general, leaving more space for the graph.</p>
<p>Because the <span class="InputCode">splitvallabels</span> command puts its results in the r() vector, they'll be replaced by any other command that stores results in the r() vector, including <span class="InputCode">graph</span>. If you'll be using a set of labels repeatedly, you could store them in a separate macro:</p>
<p class="InputCode">local relabel `r(relabel)'</p>
<p></p>
<p>and then use <span class="InputCode">`relabel'</span> in subsequent commands rather than <span class="InputCode">`r(relabel)'</span>. For this article we'll instead run the <span class="InputCode">splitvallabels</span> command before each graph, so each graph can be run separately.</p>
<p>This is now a usable graph, but some might complain that it does not have the precision of a table giving the percentages as numbers. No problem: you can have the numbers too by adding a <span class="InputCode">blabel(bar)</span> option, meaning Stata should label each bar with the height of the bar. You'll almost certainly want to control the number of decimal places displayed with a <span class="InputCode">format()</span> option like <span class="InputCode">format(%4.1f)</span>. This means the number on each bar should take up four total spaces, including the decimal point, with one number after the decimal point.</p>
<p class="InputCode">splitvallabels sat<br/>
                  graph hbar, ///<br/>
                  over(sat, label(labsize(small)) relabel(`r(relabel)')) ///<br/>
                  ytitle("Percent of Respondents", size(small)) ///<br/>
                  title("In general, how satisfied are you with your job?" ///<br/>
                  , span size(medium)) ///<br/>
<span class="BoldCode">blabel(bar, format(%4.1f))</span></p>
<p><img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b5.png" width="550"/></p>
<p>One final tweak: if someone prints this graph, the bars will use a lot of toner and, depending on the printer, the ink may streak. You can avoid that by reducing the "intensity" of the colors with the <span class="InputCode">intensity()</span> option:</p>
<p class="InputCode">splitvallabels sat<br/>
                  graph hbar, ///<br/>
                  over(sat, label(labsize(small)) relabel(`r(relabel)')) ///<br/>
                  ytitle("Percent of Respondents", size(small)) ///<br/>
                  title("In general, how satisfied are you with your job?" ///<br/>
                  , span size(medium)) ///<br/>
                  blabel(bar, format(%4.1f)) ///<br/>
<span class="BoldCode">intensity(25)</span></p>
<p><img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b6.png" width="550"/></p>
<p>If you want frequencies rather than percentages, tell <span class="InputCode">graph hbar</span> that the thing you want to plot is the <span class="InputCode">(count)</span>. You'll also want to change the <span class="InputCode">ytitle()</span> and the format of the bar labels—with integers the default will do so you can just remove the <span class="InputCode">format()</span> option entirely.</p>
<p class="InputCode">splitvallabels sat<br/>
                  graph hbar <span class="BoldCode">(count)</span>, ///<br/>
                  over(sat, label(labsize(small)) relabel(`r(relabel)')) ///<br/>
                  ytitle(<span class="BoldCode">"Number of Respondents</span>", size(small)) ///<br/>
                  title("In general, how satisfied are you with your job?" ///<br/>
                  , span size(medium)) ///<br/>
<span class="BoldCode">blabel(bar)</span> ///<br/>
                intensity(25)</p>
<p><img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b7.png" width="550"/></p>
<div style="border: medium ridge; margin: 10px 50px 15px 100px">
<p style="margin-left: 35px">Tip for advanced users: When working with survey data, you may find it useful to put the text for each question in a global macro with the same name as the variable:</p>
<p class="InputCode" style="margin-left: 35px">global sat "In general, how satisfied are you with your job?"</p>
<p style="margin-left: 35px"> Then your graph commands can start with:</p>
<p class="InputCode" style="margin-left: 35px">graph hbar, over(sat) title($sat)</p>
<p style="margin-left: 35px">This is highly convenient in loops:</p>
<p class="InputCode" style="margin-left: 35px">foreach question of varlist q1-q10 {<br/>
<span class="indent3">graph hbar, over(`question') title($`question')</span><br/>
                  } </p>
<p style="margin-left: 35px">The macro processor will first replace the local macro <span class="InputCode">`question'</span> with a specific question, and then replace the resulting global macro with that question's text.</p>
<p style="margin-left: 35px">If you create a do file that defines global macros for all your questions, you can just put:</p>
<p class="InputCode" style="margin-left: 35px">include question_file.do</p>
<p style="margin-left: 35px">early in any do file that will use them and they'll be ready to go.</p>
</div>
<h2>Bar Graphs vs. Means</h2>
<p>We often see people use means to summarize Lickert scales and other ordered categorical variables like <span class="InputCode">sat</span>. Means  convey useful information at a glance, but they also hide a lot. They can also hide strong  implicit assumptions. For example, having one person change from "Neither Satisfied nor Dissatisfied" to "Somewhat Satisfied" will have exactly the same effect on the mean as someone moving from "Very Dissatisfied" to "Somewhat Dissatisfied," which may or may not be equivalent in any meaningful sense.<img alt="" class="CenterImage" height="250" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/mean.png" width="550"/></p>
<p>A bar graph can be taken in at a glance just like a mean, but conveys far more information. Once you're comfortable making and using bar graphs, they're almost as easy to add to a document as a mean.</p>
<h2>Relationships between a Categorical Variable and a Quantitative Variable</h2>
<p>Bar graphs are also good tools for examining the relationship (joint distribution) of a categorical variable and some other variable. </p>
<p>To create a bar graph where the length of the bar tells you the mean value of a quantitative variable for each category, just tell <span class="InputCode">graph hbar</span> to plot that variable. If you want a different summary statistic, like the median, put that summary statistic in parentheses before the variable name just like you did with <span class="InputCode">(count)</span>.</p>
<p>You'll also need to change the title and y axis title, and set the formatting of the bar labels.</p>
<p class="InputCode">splitvallabels sat<br/>
                  graph hbar <span class="BoldCode">eng</span>, ///<br/>
                  over(sat, label(labsize(small)) relabel(`r(relabel)')) ///<br/>
                  ytitle("<span class="BoldCode">Mean Engagement</span>", size(small)) ///<br/>
                  title("<span class="BoldCode">Mean Engagement by Job Satisfaction</span>" ///<br/>
                  , span size(medium)) ///<br/>
                  blabel(bar<span class="BoldCode">, format(%4.1f)</span>) ///<br/>
                intensity(25)</p>
<p><img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b8.png" width="550"/></p>
<p>This  suggests a strong but nonlinear relationship.</p>
<p>In this plot, the length of the bar measures how far away from zero the mean is. Sometimes that isn't a meaningful measure: for example, a Lickert scale can never be zero. In those cases you might consider using a dot plot instead—just replace <span class="InputCode">hbar</span> with <span class="InputCode">dot</span>:</p>
<p class="InputCode">splitvallabels sat<br/>
                  graph <span class="BoldCode">dot</span> eng, ///<br/>
                  over(sat, label(labsize(small)) relabel(`r(relabel)')) ///<br/>
                  ytitle("Mean Engagement", size(small)) ///<br/>
                  title("Mean Engagement by Job Satisfaction" ///<br/>
                  , span size(medium)) ///<br/>
                  blabel(bar, format(%4.1f)) ///<br/>
                intensity(25)</p>
<p><img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b8b.png" width="550"/></p>
<p>The trouble with this graph is that the dots interfere with the bar labels. You can fix that by putting a white box around each label which will cover up the dots. This is done with the <span class="InputCode">box</span> option and both <span class="InputCode">fcolor(white)</span> and <span class="InputCode">lcolor(white)</span> to set the "fill" (inside) of the box and the line around it to white. The last label (85.8) will look a little funny if its white box covers up the light blue margin around the graph, so increase the range of the y axis to 90 with <span class="InputCode">yscale(range(0 90))</span> so it no longer crosses over into the margin.</p>
<p class="InputCode">splitvallabels sat<br/>
                  graph dot eng, ///<br/>
                  over(sat, label(labsize(small)) relabel(`r(relabel)')) ///<br/>
                  ytitle("Mean Engagement", size(small)) ///<br/>
                  title("Mean Engagement by Job Satisfaction" ///<br/>
                  , span size(medium)) ///<br/>
                  blabel(bar, format(%4.1f) <span class="BoldCode">box fcolor(white) lcolor(white)</span>) ///<br/>
                  intensity(25) ///<br/>
<span class="BoldCode">yscale(range(0 90))</span></p>
<p><img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b8c.png" width="550"/></p>
<div style="border: medium ridge; margin: 10px 50px 15px 100px">
<p style="margin-left: 35px">Tip for advanced users: If you'd like to have the frequencies for each category in the graph too, put them in the value labels! The following code loops over the values of <span class="InputCode">sat</span>, stores the label associated with each value, counts how many observations have that value, constructs a new label containing both the old label and the number of observations, then applies it:</p>
<p class="InputCode" style="margin-left: 35px">levelsof sat, local(vals)<br/>
                  foreach val of local vals {<br/>
<span class="indent3">local oldlabel: label (sat) `val'</span><br/>
<span class="indent3">count if sat==`val'</span><br/>
<span class="indent3">label define newsat `val' "`oldlabel' (N=`r(N)')", add</span><br/>
}<br/>
label values sat newsat                </p>
<p style="margin-left: 35px">This relies on the macro extended function <span class="InputCode">label</span>, which allows you to access value labels in various ways and store them in macros.</p>
<img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b9.png" width="550"/>
<p style="margin-left: 35px">Just remember to change the labels back to the original when you're done:</p>
<p class="InputCode" style="margin-left: 35px">label values sat sat</p>
</div>
<h2>Relationships between a Categorical Variable and a Binary Variable</h2>
<p>If you're thinking of the binary variable as an outcome, then the proportion of "successes" (whatever that means in your data set) in each group may be of interest. But, assuming the binary variable is coded such that 1 means "success" and 0 means "failure,"  the proportion of successes is just the mean of the binary variable and can be plotted just like the mean of <span class="InputCode">eng</span>:</p>
<p class="InputCode">splitvallabels sat<br/>
                  graph <span class="BoldCode">hbar</span> <span class="BoldCode">stay</span>, ///<br/>
                  over(sat, label(labsize(small)) relabel(`r(relabel)')) ///<br/>
                  ytitle("<span class="BoldCode">Proportion Staying</span>", size(small)) ///<br/>
                  title("<span class="BoldCode">Proportion  Unlikely to Leave by Job Satisfaction</span>" ///<br/>
                  , span size(medium)) ///<br/>
                  blabel(bar, format(%4.2f)) ///<br/>
                intensity(25)</p>
<p><img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b10.png" width="550"/></p>
<p>If the binary variable denotes two groups you're comparing, like <span class="InputCode">female</span>, then you should consider frequencies <span class="InputCode">(count)</span> or percentages (the default) for each combination of the two variables. Start with frequencies.</p>
<p>The binary variable to examine will be specified in another <span class="InputCode">over()</span> option, but it makes a big difference which variable you put first. If you put first <span class="InputCode">sat</span> and then <span class="InputCode">female</span>, you'll get:</p>
<p class="InputCode">splitvallabels sat<br/>
                  graph hbar <span class="BoldCode">(count)</span>, ///<br/>
                  over(sat, label(labsize(small)) relabel(`r(relabel)')) ///<br/>
<span class="BoldCode">over(female,label(labsize(small)))</span> ///<br/>
                  ytitle("<span class="BoldCode">Number of Respondents</span>", size(small)) ///<br/>
                  title("<span class="BoldCode">Job Satisfaction by Gender</span>" ///<br/>
                  , span size(medium)) ///<br/>
<span class="BoldCode">blabel(bar)</span> ///<br/>
                intensity(25)</p>
<img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b11.png" width="550"/>
<p>If you put <span class="InputCode">female</span> first and then <span class="InputCode">sat</span>, you'll get:</p>
<blockquote>
<p class="InputCode">splitvallabels sat<br/>
                    graph hbar (count), ///<br/>
<span class="BoldCode">over(female,label(labsize(small)))</span> ///<br/>
                    over(sat, label(labsize(small)) relabel(`r(relabel)')) ///<br/>
                    ytitle("Number of Respondents", size(small)) ///<br/>
                    title("Job Satisfaction by Gender" ///<br/>
                    , span size(medium)) ///<br/>
                    blabel(bar) ///<br/>
                  intensity(25)</p>
</blockquote>
<img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b12.png" width="550"/>
<p>The latter form generally makes for easier comparisons. But in this case the only thing you can easily learn by comparing them is that more females answered the survey than males. It would be much more useful to look at what percentage of males and females are in each satisfaction category. Unfortunately, just telling <span class="InputCode">graph hbar</span> to plot percentages doesn't do that:</p>
<p class="InputCode">splitvallabels sat<br/>
                  graph hbar, /// <span class="BoldCode">percent is the default</span><br/>
                  over(female,label(labsize(small))) ///<br/>
                  over(sat, label(labsize(small)) relabel(`r(relabel)')) ///<br/>
                  ytitle("<span class="BoldCode">Percent of Respondents</span>", size(small)) ///<br/>
                  title("Job Satisfaction by Gender" ///<br/>
                  , span size(medium)) ///<br/>
                  blabel(bar, <span class="BoldCode">format(%4.1f)</span>) ///<br/>
                intensity(25)</p>
<p><img alt="" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b13.png" width="550"/></p>
<p>This gives you the percentages calculated across all respondents, not calculated separately for males and females. The <span class="InputCode">graph hbar</span> command does not allow you to control how the percentages are calculated.</p>
<p>Enter the very useful <span class="InputCode">catplot</span>, by Nick Cox. Get it with:</p>
<p class="InputCode">ssc install catplot</p>
<p>The <span class="InputCode">catplot</span> command is a "wrapper" for <span class="InputCode">graph hbar</span> so most of what we've done carries over directly. What it adds (among other things) is a <span class="InputCode">percent()</span> option that allows you to specify what groups percentages will be calculated over, in this case <span class="InputCode">percent(female)</span>. </p>
<p>The <span class="InputCode">catplot</span> does some things differently than <span class="InputCode">graph hbar</span>:</p>
<ul>
<li>The variables inside the <span class="InputCode">over()</span> options are moved to a variable list directly after the command itself</li>
<li>The options inside the <span class="InputCode">over()</span> options are moved into options called <span class="InputCode">var1opts()</span>, <span class="InputCode">var2opts()</span>, etc. corresponding to the variable order in the variable list</li>
</ul>
<p>Thus the catplot version of the last command becomes:</p>
<p class="InputCode">splitvallabels sat<br/>
<span class="BoldCode">catplot female sat</span>, ///<br/>
<span class="BoldCode">percent(female)</span> ///<br/>
<span class="BoldCode">var1opts</span>(label(labsize(small))) ///<br/>
<span class="BoldCode">var2opts</span>(label(labsize(small)) relabel(`r(relabel)')) ///<br/>
                  ytitle("<span class="BoldCode">Percent of Respondents by Gender</span>", size(small)) ///<br/>
                  title("Job Satisfaction by Gender" ///<br/>
                  , span size(medium)) ///<br/>
                  blabel(bar, format(%4.1f)) ///<br/>
                intensity(25)</p>
<img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b14.png" width="550"/>
<p>This allows us to see that the the relationship between <span class="InputCode">sat</span> and <span class="InputCode">female</span> is complex in this (fictional) data set, with females more likely to be both very satisfied and very dissatisfied.</p>
<p>An alternative form of this graph uses color to distinguish between the groups, adding a legend to define their meanings. You can get this form by adding the <span class="InputCode">asyvars</span> option.</p>
<p class="InputCode">splitvallabels sat<br/>
                  catplot female sat, ///<br/>
                  percent(female) ///<br/>
                  var1opts(label(labsize(small))) ///<br/>
                  var2opts(label(labsize(small)) relabel(`r(relabel)')) ///<br/>
                  ytitle("Percent of Respondents by Gender", size(small)) ///<br/>
                  title("Job Satisfaction by Gender" ///<br/>
                  , span size(medium)) ///<br/>
                  blabel(bar, format(%4.1f)) ///<br/>
                  intensity(25) ///<br/>
<span class="BoldCode">asyvars</span></p>
<img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b15.png" width="550"/>
<p>This greatly reduces the clutter on the left of the graph, at the cost of adding some to the bottom and forcing the reader to look in two places to understand what the bars mean. You should consider what the graph will look like to someone who is colorblind, and may need to think about whether the bars will be distinguishable if printed on a black and white printer (the graphs in this article fail that test). For this particular graph you may want to change the default colors  to avoid unfortunate associations—you'll soon learn how.</p>
<h2>Relationships between Two Categorical Variables</h2>
<p>The code for creating graphs that compare two categorical variables is identical to comparing one categorical variable and one binary, but the result has a lot more bars. The bar labels will overlap unless you shrink them with a <span class="InputCode">size(vsmall)</span> option.</p>
<p class="InputCode">splitvallabels sat<br/>
                  catplot <span class="BoldCode">leave</span> sat, ///<br/>
                  percent(<span class="BoldCode">sat</span>) ///<br/>
                  var1opts(label(labsize(small))) ///<br/>
                  var2opts(label(labsize(small)) relabel(`r(relabel)')) ///<br/>
                  ytitle("<span class="BoldCode">Percent of Respondents by Satisfaction</span>", size(small)) ///<br/>
                  title("<span class="BoldCode">Probability of Leaving by Job Satisfaction</span>" ///<br/>
                  , span size(medium)) ///<br/>
                  blabel(bar, format(%4.1f) <span class="BoldCode">size(vsmall)</span>) ///<br/>
                  intensity(25) ///<br/>
                asyvars</p>
<img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b16.png" width="550"/>
<p>If you stare at this for a bit you'll see that higher levels of satisfaction are associated with lower probabilities of leaving, but it's not obvious at a glance. It would help if the graph reflected the fact that the categories of <span class="InputCode">leave</span> are ordered. Right now both the colors used and the arrangement of the categories in the legend feel arbitrary.</p>
<p>To fix the colors, take control of the individual bars with  <span class="InputCode">bar()</span> options. Each bar will get its own option, identified by a number inside the parentheses. Then you can use options to control the properties of that bar. For example <span class="InputCode">bar(1, color(maroon) fintensity(inten80))</span>, means the first bar will be maroon (dark red) with a fill intensity of 80% (<span class="InputCode">inten80</span> being shorthand for that). We'll make "likely to leave" red (officially <span class="InputCode">maroon</span>), "neither likely nor unlikely" <span class="InputCode">gray</span>, and and "unlikely to leave" blue (officially <span class="InputCode">navy</span>) with the degree of likelihood represented by fill intensity.</p>
<p>Next the legend, which is controlled by putting options within the <span class="InputCode">legend()</span> option. The category ordering will be much clearer if all the entries are in a single row, which you can do with <span class="InputCode">rows(1)</span>. To make that fit, put the labels underneath the color symbols rather than next to them with <span class="InputCode">stack</span>. Shrink the text with <span class="InputCode">size(small)</span>. However, we still need to break the labels into multiple lines. Unfortunately, the syntax for setting legend labels is just different enough that <span class="InputCode">splitvallabels</span> can't help you, so you'll have to do it yourself. The easy way to set a bunch of labels at once is to use the <span class="InputCode">order()</span> option: </p>
<p class="InputCode">order(1 "Very" "likely" 2 "Somewhat" "likely" ///<br/>
3 "Neither likely" "nor unlikely"  ///<br/>
4 "Somewhat" "unlikely" 5 "Very" "unlikely")</p>
<p>This is getting picky, but everything will line up better if you use <span class="InputCode">symplacement(center)</span> to put the color symbols in the center of their space. You can  add a title to the legend itself by putting a <span class="InputCode">title()</span> option inside <span class="InputCode">legend()</span>,  but you'll want to make it <span class="InputCode">size(small)</span>.</p>
<p>The resulting code is long, but each component part is straightforward:</p>
<p class="InputCode">splitvallabels sat<br/>
                  catplot leave sat, ///<br/>
                  percent(sat) ///<br/>
                  var1opts(label(labsize(small))) ///<br/>
                  var2opts(label(labsize(small)) relabel(`r(relabel)')) ///<br/>
                  ytitle("Percent of Respondents by Satisfaction", size(small)) ///<br/>
                  title("Probability of Leaving by Job Satisfaction" ///<br/>
                  , span size(medium)) ///<br/>
                  blabel(bar, format(%4.1f) size(vsmall)) ///<br/>
                  intensity(25) ///<br/>
                  asyvars ///<br/>
<span class="BoldCode">bar(1, color(maroon) fintensity(inten80)) ///<br/>
                  bar(2, color(maroon) fintensity(inten60)) ///<br/>
                  bar(3, color(gray) fintensity(inten40)) ///<br/>
                  bar(4, color(navy) fintensity(inten60)) ///<br/>
                  bar(5, color(navy) fintensity(inten80))	///<br/>
                  legend(rows(1) stack size(small) ///<br/>
                  order(1 "Very" "likely" 2 "Somewhat" "likely" ///<br/>
                  3 "Neither likely" "nor unlikely"  ///<br/>
                  4 "Somewhat" "unlikely" 5 "Very" "unlikely") ///<br/>
                  symplacement(center) ///<br/>
                  title(Likelihood of Leaving, size(small)))</span><br/>
</p>
<img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b17.png" width="550"/>
<p>The result is still fairly cluttered, however, and the bars to be compared aren't very close together. An alternative is to stack the bars for each category  using the <span class="InputCode">stack</span> option. Unfortunately, getting bar labels to work with stacked bars is not straightforward (there won't always be space for them), so take out the <span class="InputCode">blabel()</span> option. </p>
<p class="InputCode">splitvallabels sat<br/>
                  catplot leave sat, ///<br/>
                  percent(sat) ///<br/>
                  var1opts(label(labsize(small))) ///<br/>
                  var2opts(label(labsize(small)) relabel(`r(relabel)')) ///<br/>
                  ytitle("Percent of Respondents by Satisfaction", size(small)) ///<br/>
                  title("Probability of Leaving by Job Satisfaction" ///<br/>
                  , span size(medium)) ///<br/>
                  intensity(25) ///<br/>
                  asyvars <span class="BoldCode">stack</span> ///<br/>
                  bar(1, color(maroon) fintensity(inten80)) ///<br/>
                  bar(2, color(maroon) fintensity(inten60)) ///<br/>
                  bar(3, color(gray) fintensity(inten40)) ///<br/>
                  bar(4, color(navy) fintensity(inten60)) ///<br/>
                  bar(5, color(navy) fintensity(inten80))	///<br/>
                  legend(rows(1) stack size(small) ///<br/>
                  order(1 "Very" "likely" 2 "Somewhat" "likely" ///<br/>
                  3 "Neither likely" "nor unlikely"  ///<br/>
                  4 "Somewhat" "unlikely" 5 "Very" "unlikely") ///<br/>
                  symplacement(center) ///<br/>
                title(Likelihood of Leaving, size(small)))</p>
<img alt="" class="CenterImage" height="400" src="https://ssc.wisc.edu/sscc/pubs/bargraphs/b18.png" width="550"/>
<p>This graph often requires some explanation. But once people grasp that what they should be looking for is how the colors move left or right as you go up or down categories, they can see the relationship between the variables very clearly. Compare with:</p>
<p class="InputCode">tab sat leave, row</p>
<pre class="InputCode">                      |                         leave
                  sat | Very like  Somewhat   Neither l  Somewhat   Very unli |     Total
----------------------+-------------------------------------------------------+----------
    Very Dissatisfied |         5         22         13          6          0 |        46 
                      |     10.87      47.83      28.26      13.04       0.00 |    100.00 
----------------------+-------------------------------------------------------+----------
Somewhat Dissatisifie |         3         24         28         22          3 |        80 
                      |      3.75      30.00      35.00      27.50       3.75 |    100.00 
----------------------+-------------------------------------------------------+----------
Neither Satisfied nor |         5         43         81         82         20 |       231 
                      |      2.16      18.61      35.06      35.50       8.66 |    100.00 
----------------------+-------------------------------------------------------+----------
   Somewhat Satisfied |         3         31         94        118         52 |       298 
                      |      1.01      10.40      31.54      39.60      17.45 |    100.00 
----------------------+-------------------------------------------------------+----------
       Very Satisfied |         5         37        100        129         74 |       345 
                      |      1.45      10.72      28.99      37.39      21.45 |    100.00 
----------------------+-------------------------------------------------------+----------
                Total |        21        157        316        357        149 |     1,000 
                      |      2.10      15.70      31.60      35.70      14.90 |    100.00 </pre>
<p>Once you've created your bar graphs, you'll need to save them in a format that you can use. <a href="https://ssc.wisc.edu/sscc/pubs/4-23.htm">Using Stata Graphs in Documents</a> will help you with that. You may also be interested in <a href="https://ssc.wisc.edu/sscc/pubs/4-24.htm">An Introduction to Stata Graphics</a>, which will introduce you to many other kinds of graphs, and also more options you can use with bar graphs. A do file that contains all the code for this article is available <a href="https://ssc.wisc.edu/sscc/pubs/bargraphs/bargraph.do">here</a>.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/bargraphs/b1.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b2.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b3.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b4.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b5.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b6.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b7.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/mean.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b8.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b8b.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b8c.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b9.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b10.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b11.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b12.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b13.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b14.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b15.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b16.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b17.png, https://ssc.wisc.edu/sscc/pubs/bargraphs/b18.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Working with Dates in Stata</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Stata has many tools for working with dates. This article will introduce you to some of the most useful and easy to use features.</p>
<p>A Stata date is simply a number, but with the <span class="InputCode">%td</span> format applied Stata will interpret that number as "number of days since January 1, 1960." You can then use that number in a variety of ways. Stata has similar tools that measure time in terms of milliseconds, months, quarters, years and more. This article will focus on days, but if you know how to work with days you can quickly learn the others.</p>
<p>Often the first task is  to convert the data you've been given into official Stata dates.	</p>
<h2>Converting Strings to Dates</h2>
<p>If you've been given a date in string form, such as "November 3, 2010", "11/3/2010" or "2010-11-03 08:35:12" it can be converted using the <span class="InputCode">date</span> function. The date function takes two arguments, the string to be converted, and a series of letters called a "mask" that tells Stata how the string is structured. In a date mask, <span class="InputCode">Y</span> means year, <span class="InputCode">M</span> means month, <span class="InputCode">D</span> means day and <span class="InputCode">#</span> means an element should be skipped.</p>
<p> Thus the mask <span class="InputCode">MDY</span> means "month, day, year" and can be used to convert both "November 3, 2010" and "11/3/2010". A date like "2010-11-03 08:35:12" requires the mask <span class="InputCode">YMD###</span> so that the last three numbers are skipped. If you are interested in tracking the time of day you need to switch to the <span class="InputCode">clock</span> function and the <span class="InputCode">%tc</span> format so time is measured in milliseconds rather than days, but they are very similar.</p>
<p>To see this in action, type (or copy and paste) the following into Stata:</p>
<p class="InputCode">use http://www.ssc.wisc.edu/sscc/pubs/files/dates.dta</p>
<p>This is an example data set containing the above dates as <span class="InputCode">dateString1</span>, <span class="InputCode">dateString2</span> and <span class="InputCode">dateString3</span>. To convert them to Stata dates do the following:</p>
<p class="InputCode">gen date1=date(dateString1,"MDY")<br/>
                  gen date2=date(dateString2,"MDY")<br/>
                gen date3=date(dateString3,"YMD###")</p>
<p>Note that the mask goes in quotes.</p>
<h2>Converting Numbers to Dates</h2>
<p>Another common  scenario gives you dates as three separate numeric variables, one for the year, one for the month and one for the day. The <span class="InputCode">year</span>, <span class="InputCode">month</span> and <span class="InputCode">day</span> variables in the example data set contain the same date as the others but in this format. To convert such dates to Stata dates, use the <span class="InputCode">mdy</span> function. It takes three numeric arguments: the month, day and year to be converted.</p>
<p class="InputCode">gen date4=mdy(month,day,year)</p>
<h2>Formatting Date Variables</h2>
<p>While the four date variables you've created are perfectly functional dates as far as Stata is concerned, they're difficult for humans to interpret. However, the <span class="InputCode">%td</span> format tells Stata to print them out as human readable dates: </p>
<p class="InputCode">format date1 %td<br/>
                format date2 %td<br/>
                format date3 %td<br/>
                format date4 %td</p>
<p>This turns the <span class="InputCode">18569</span> now stored in all four variables into <span class="InputCode">03nov2010</span> (18,569 days since January 1, 1960) in all output. Try a <span class="InputCode">list</span> to see the result. If you remember your <a href="https://ssc.wisc.edu/sscc/pubs/sfr-syntax.htm#Varlists">varlist syntax</a>, you can do them all at once with:</p>
<p class="InputCode">format date? %td</p>
<p>You can have Stata output dates in different formats as well. For instructions type <span class="InputCode">help dates</span> and then click on the link <span class="MenuOutput">Formatting date and time values</span>.</p>
<h2>Using Dates</h2>
<p>Often your goal in creating a Stata date will be to create a time variable that can be included in a statistical command. If so, you can probably use it with no further modification. However, there are some common data preparation tasks involving dates.</p>
<h3>Date Constants</h3>
<p>If you need to refer to a particular date in your code, then in principle you could refer to it by number. However, it's usually more convenient to use the same functions used to import date variables. For example, the following are all equivalent ways of referring to November 3, 2010:</p>
<p class="InputCode">18569<br/>
  date("November 3, 2010","MDY")<br/>
  mdy(11,3,2010)</p>
<p>  The <span class="InputCode">td</span> pseudofunction was designed for tasks like this and is somewhat more convenient to use. It takes a single argument (which cannot be a variable name) and converts it to a date on the assumption that the argument is a string containing a date in the format day, month, year. This matches the output of the <span class="InputCode">%td</span> format, e.g. <span class="InputCode">3nov2010</span>. Thus the following is also equivalent:</p>
<p class="InputCode">td(3nov2010)</p>
<p>However, the following is not:</p>
<p class="InputCode">td(11/3/2010)</p>
<p>This will be interpreted as March 11, 2010, not November 3, 2010.</p>
<h3>Extracting Date Components</h3>
<p>Sometimes you need to pull out the components of a date. You can do so with the <span class="InputCode">year</span>, <span class="InputCode">month</span> and <span class="InputCode">day</span> functions:</p>
<p class="InputCode">gen year1=year(date1)<br/>
  gen month1=month(date1)<br/>
  gen day1=day(date1)</p>
<h3></h3>
<h3>Before and After</h3>
<p>Since dates are just numbers, before and after are equivalent to less than and greater than. Thus:</p>
<p class="InputCode">gen before2010=(date1&lt;td(1,1,2010))<br/>
gen after2010=(date1&gt;date("January 1 2010","MDY"))</p>
<p></p>
<p></p>
<p></p>
<h3>Durations and Intervals</h3>
<p>Durations in days can be found using simple subtraction. The example data set contains the dates <span class="InputCode">beginning</span> and <span class="InputCode">ending</span>, and you can find out the duration of the interval between them with:</p>
<p class="InputCode">gen duration=ending-beginning</p>
<p>Durations in months are more difficult because months vary in length. One common approach is to ignore days entirely and calculate the duration solely from the year and month components of the dates involved:</p>
<p class="InputCode">gen durationInMonths=(year(ending)-year(beginning))*12+month(ending)-month(beginning)</p>
<p>Just keep in mind that this approach says January 31 and February 1 are one month apart, while January 1 and January 31 are zero months apart.</p>
<h3>Date Arithmetic</h3>
<p>If you need to add (or subtract) a period measured in days to a date, it is straightforward to do so. Just remember to format all new date variables as dates with <span class="InputCode">%td</span>:</p>
<p class="InputCode">gen tenDaysLater=date1+10<br/>
  gen yesterday=date1-1<br/>
  format %td tenDaysLater  yesterday</p>
<p>If the period is measured in weeks, just multiply by 7.</p>
<h3>Months and Years</h3>
<p>Months and years are problematic because they don't always represent the same amount of time. A month can be anything from 28 to 31 days, and a calendar year is usually 365 days but is 366 days in leap year.</p>
<p>Suppose today's date were April 20th, 2017. If I asked you what the date will be in one month, you'd probably respond May 20th, 2017. If I asked you what the date will be in one year, you'd probably respond April 20th, 2018.</p>
<p>Now consider two particularly problematic dates: January 31, 2016 and February 29, 2016. One month after January 31st cannot be February 31st, because no such day exists. Similarly, one year after February 29th, 2016 cannot be February 29, 2017, because <a href="https://en.wikipedia.org/wiki/The_Pirates_of_Penzance">February 29th only exists in leap years</a>. So what should be done?</p>
<p>If the dates in your data are mostly just months, consider storing them as dates in monthly format, where the underlying number is the number of months since January, 1960 rather than the number of days. Then all these issues go away. You can convert dates to monthly dates with the <span class="InputCode">mofd()</span> function and then give them the <span class="InputCode">%tm</span> format to make them readable:</p>
<p class="InputCode">clear<br/>
  use http://www.ssc.wisc.edu/sscc/pubs/files/moredates.dta<br/>
<br/>
  gen monthlyDate=mofd(date)<br/>
  gen oneMonthLater1=monthlyDate+1<br/>
  gen oneYearLater1=monthlyDate+12<br/>
  format monthlyDate oneMonthLater1 oneYearLater1 %tm</p>
<p>Alternatively, you can define a "standard month" of 30 or 31 days or a "standard year" of 365 days (no, 365.25 days won't work unless you're storing time as well as date). This has the advantage of making all time intervals uniform. It's also easy to program:</p>
<p class="InputCode">gen oneMonthLater2=date+30<br/>
  gen oneYearLater2=date+365<br/>
  format oneMonthLater2 oneYearLater2 %td</p>
<p>However, note that 30 days after January 31, 2016 is March 1, 2016, and 365 days after January 31, 2016 is January 30, 2017. That might not be ideal in some contexts.</p>
<p>Another practical definition of "one month later" would be "the same day in the next month if that exists, otherwise the last day of the next month." Then one month after January 31st would be February 28th or 29th depending on the year. You can implement this, without programming in how many days each month has, using the following algorithm:</p>
<ol>
<li>Convert the date to a monthly date and add one month to it</li>
<li>Create a new date based on the month and year from the  date created in step 1, and the day of the month from the original date</li>
<li>If the resulting date is invalid (e.g. February 31st) subtract days until you get a valid date</li>
</ol>
<p>The following code implements this algorithm:</p>
<p class="InputCode">gen oneMonthLaterTemp=dofm(mofd(date)+1)<br/>
  gen oneMonthLater3=mdy(month(oneMonthLaterTemp),day(date),year(oneMonthLaterTemp))<br/>
  egen numInvalid=total(oneMonthLater3==.) // calculate number of dates that are invalid<br/>
  local i 1 // number of days to subtract from invalid dates<br/>
  while (numInvalid&gt;0) {<br/>
<span class="indent3">replace oneMonthLater3=mdy(month(oneMonthLaterTemp),day(date)-`i',year(oneMonthLaterTemp)) if oneMonthLater3==.</span><br/>
<span class="indent3">local i=`i'+1 // increase number of days to subtract</span><br/>
<span class="indent3">drop numInvalid</span><br/>
<span class="indent3">egen numInvalid=total(oneMonthLater3==.) // see if we still have invalid dates</span><br/>
  }<br/>
  drop oneMonthLaterTemp numInvalid<br/>
  format oneMonthLater3 %td</p>
<p>The<span class="InputCode"> mofd()</span> function converts a regular date to a monthly date, and the <span class="InputCode">dofm()</span> function converts a monthly date to a regular date.</p>
<p>Very similar code could be used for adding years without needing to program in which years are leap years.</p>
<h2>Learning More</h2>
<p>To read the full documentation on Stata dates, type <span class="InputCode">help dates</span> and then click on the <span class="MenuOutput">dates and times</span> link at the top (the PDF documentation is much easier to read in this case). There you'll learn to:</p>
<ul>
<li>Work with times</li>
<li>Use intervals other than days, such as months, quarters or years</li>
<li>Create your own date format for output (e.g. <span class="InputCode">November 3rd, 2010</span> rather than <span class="InputCode">3nov2010</span>)</li>
<li>Track leap seconds, in case you need to be extremely precise--you'll also find an explanation of why such things exist</li>
</ul>
<h2>Complete Do File</h2>
<p>The following is a do file containing all the code from this article (except for a few code fragments that were discussed but can't be run by themselves):</p>
<p class="InputCode">clear all<br/>
set more off<br/>
use http://www.ssc.wisc.edu/sscc/pubs/files/dates.dta<br/>
<br/>
gen date1=date(dateString1,"MDY")<br/>
gen date2=date(dateString2,"MDY")<br/>
gen date3=date(dateString3,"YMD###")<br/>
gen date4=mdy(month,day,year)<br/>
 format date? %td<br/>
<br/>
gen year1=year(date1)<br/>
gen month1=month(date1)<br/>
gen day1=day(date1)<br/>
<br/>
gen before2010=(date1&lt; td(1,1,2010))<br/>
gen after2010=(date1&gt;date("January 1 2010","MDY"))<br/>
<br/>
gen duration=ending-beginning<br/>
gen durationInMonths=(year(ending)-year(beginning))*12+month(ending)-month(beginning)<br/>
<br/>
gen tenDaysLater=date1+10<br/>
gen yesterday=date1-1<br/>
format tenDaysLater yesterday

%td<br/>
<br/>
clear<br/>
use http://www.ssc.wisc.edu/sscc/pubs/files/moredates.dta<br/>
<br/>
gen monthlyDate=mofd(date)<br/>
gen oneMonthLater1=monthlyDate+1<br/>
gen oneYearLater1=monthlyDate+12<br/>
format monthlyDate oneMonthLater1 oneYearLater1 %tm<br/>
<br/>
gen oneMonthLater2=date+30<br/>
gen oneYearLater2=date+365<br/>
format oneMonthLater2 oneYearLater2 %td<br/>
<br/>
gen oneMonthLaterTemp=dofm(mofd(date)+1)<br/>
gen oneMonthLater3=mdy(month(oneMonthLaterTemp),day(date),year(oneMonthLaterTemp))<br/>
egen numInvalid=total(oneMonthLater3==.) // calculate number of dates that are invalid<br/>
local i 1 // number of days to subtract from invalid dates<br/>
while (numInvalid&gt;0) {
<br/>
<span class="indent3">replace oneMonthLater3=mdy(month(oneMonthLaterTemp),day(date)-`i',year(oneMonthLaterTemp)) if oneMonthLater3==.</span><br/>
<span class="indent3">local i=`i'+1 // increase number of days to subtract</span><br/>
<span class="indent3">drop numInvalid</span><br/>
<span class="indent3">egen numInvalid=total(oneMonthLater3==.) // see if we still have invalid dates</span><br/>
}<br/>
drop oneMonthLaterTemp numInvalid<br/>
format oneMonthLater3 %td </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Exploring Regression Results using Margins</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Once you've run a regression, the next challenge is to figure out what the results mean. The <span class="InputCode">margins</span> command is a powerful tool for understanding a model, and this article will show you how to use it. It contains the following sections:</p>
<ol>
<li><a href="#OLS">OLS Regression (With Non-Linear Terms)</a></li>
<li><a href="#marginslogit">Logistical Regression</a></li>
<li><a href="#MultinomialLogit">Multinomial Logit</a></li>
</ol>
<p>Sections 1 and 2 are taken directly from the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-stats.htm">Statistics section of Stata for Researchers</a> (they are reproduced here for the benefit of those looking specifically for information  about using <span class="InputCode">margins</span>). If you're familiar with that material you can to skip to section 3.</p>
<h2 id="OLS">OLS Regression (With Non-linear Terms)</h2>
<p>The <span class="InputCode">margins</span> command can only be used after you've run a regression, and acts on the results of the most recent regression command. For our first example, load the auto data set that comes with Stata and run the following regression:</p>
<p class="InputCode">sysuse auto<br/>
                reg price c.weight##c.weight i.foreign i.rep78 mpg displacement                </p>
<h3>Levels of the Outcome Variable</h3>
<p>If you just type:</p>
<p class="InputCode">margins</p>
<p>all by itself, Stata will calculate the predicted value of the dependent variable for each observation, then report the mean value of those predictions (along with the standard error, t-statistic, etc.).</p>
<p>If margins is followed by a categorical variable, Stata first identifies all the levels of the categorical variable. Then, for each value it calculates what the mean predicted value of the dependent variable <em>would be</em> if all observations had that value for the categorical variable. All other variables are left unchanged. Thus:</p>
<p class="InputCode">margins foreign</p>
<p>first asks, "What would the mean price be if all the cars were domestic?" (but still had their existing weights, displacements, etc.) and then asks "What would the mean price be if all the cars were foreign?"</p>
<p class="InputCode">margins rep78</p>
<p>does the same for all five values of <span class="InputCode">rep78</span>, but since there are so many of them it's a good candidate for a graphical presentation. The <span class="InputCode">marginsplot</span> command takes the results of the previous <span class="InputCode">margins</span> command and turns them into a graph:</p>
<p class="InputCode">marginsplot</p>
<p>For continuous variables <span class="InputCode">margins</span> obviously can't look at all possible values, but you can specify which values you want to examine with the <span class="InputCode">at</span> option:</p>
<p class="InputCode">margins, at(weight=(2000 4000))</p>
<p>This calculates the mean predicted value of <span class="InputCode">price</span> with <span class="InputCode">weight</span> set to 2000 pounds, and then again with <span class="InputCode">weight</span> set to  4000 pounds. Think of each value as a "scenario"—the above scenarios are very simple, but you can make much more complicated scenarios by listing multiple variables and values in the <span class="InputCode">at</span> option. The <span class="InputCode">margins</span> output first assigns a number to each scenario, then gives their results by number.</p>
<p> The values are specified using a <em>numlist</em>. A <em>numlist</em> is a list of numbers just like a <em>varlist</em> is a list of variables and, like a <em>varlist,</em> there are many different ways to define a <em>numlist</em>. Type <span class="InputCode">help numlist</span> to see them all. The simplest method is just to list the numbers you want, as above. You can also define a <em>numlist</em> with the by specifying <span class="Parameter">start</span><span class="InputCode"> (</span><span class="Parameter">interval</span><span class="InputCode">)</span><span class="Parameter"> end</span>:</p>
<p class="InputCode">margins, at(weight=(1500 (500) 5000))</p>
<p>This calculates the mean predicted value of <span class="InputCode">price</span> with <span class="InputCode">weight</span> set to 1500,  2000, 2500, etc. up to 5000. (The actual weights range from 1760 to 4840.) Again, this is a good candidate for a graphic:</p>
<p class="InputCode">marginsplot</p>
<h3>Effect of a Covariate</h3>
<p>If you want to look at the marginal effect of a covariate, or the derivative of the mean predicted value with respect to that covariate, use the <span class="InputCode">dydx</span> option:</p>
<p class="InputCode">margins, dydx(mpg)</p>
<p>In this simple case, the derivative is just the coefficient on<span class="InputCode"> mpg</span>, which will always be the case for a linear model. But consider changing <span class="InputCode">weight</span>: since the model includes both <span class="InputCode">weight</span> and weight squared you have to take into account the fact that both change. This case is particularly confusing (but not unusual) because the coefficient on <span class="InputCode">weight</span> is negative but the coefficient on weight squared is positive. Thus the  net effect of changing <span class="InputCode">weight</span> for any given car will very much depend on its starting weight.</p>
<p>The <span class="InputCode">margins</span> command can very easily tell you the mean effect:</p>
<p class="InputCode">margins, dydx(weight)</p>
<p>What <span class="InputCode">margins</span> does here is take the numerical derivative of the  expected <span class="InputCode">price</span> with respect to <span class="InputCode">weight</span> for each car, and then calculates the mean. In doing so, <span class="InputCode">margins</span> looks at the actual data. Thus it considers the effect of changing the Honda Civic's weight from 1,760 pounds as well as changing the Lincoln Continental's from 4,840 (the weight squared term is more important with the latter than the former). It then averages  them along with all the other cars to get its result of 2.362865, or that each additional pound of <span class="InputCode">weight</span> increases the mean expected <span class="InputCode">price</span> by $2.36.</p>
<p>To see how the effect of <span class="InputCode">weight</span> changes as <span class="InputCode">weight</span> changes, use the <span class="InputCode">at</span> option again and then plot the results:</p>
<p class="InputCode">margins, dydx(weight) at(weight=(1500 (500) 5000))<br/>
                  marginsplot</p>
<p>This tells us that for low values of weight (less than about 2000), increasing weight actually reduces the price of the car. However, for most cars increasing weight increases price.</p>
<p>The <span class="InputCode">dydx</span> option also works for binary variables:</p>
<p class="InputCode">margins, dydx(foreign)</p>
<p>However, because <span class="InputCode">foreign</span> was entered into the model as <span class="InputCode">i.foreign</span>, <span class="InputCode">margins</span> knows that it cannot take the derivative with respect to <span class="InputCode">foreign</span> (i.e. calculate what would happen if all the cars became slightly more foreign). Thus it reports the difference between the scenario where all the cars are foreign and the scenario where all the cars are domestic. You can verify this by running:</p>
<p class="InputCode">margins foreign</p>
<p>and doing the subtraction yourself.</p>
<h2 id="marginslogit">Binary Outcome Models and Predicted Probabilities</h2>
<p>The <span class="InputCode">margins</span> command becomes even more useful with binary outcome models because they are always nonlinear. Clear the <span class="InputCode">auto</span> data set from memory and then load the <span class="InputCode">grad</span> from the SSCC's web site:</p>
<p class="InputCode">clear<br/>
                  use http://ssc.wisc.edu/sscc/pubs/files/grad.dta</p>
<p>This is a fictional data set consisting of 10,000 students. Exactly one half of them are "high socioeconomic status" (<span class="InputCode">highSES</span>) and one half are not. Exactly one half of each group was given an intervention, or "treatment" (<span class="InputCode">treat</span>) designed to increase the probability of graduation. The <span class="InputCode">grad</span> variable tells us whether they did in fact graduate. Your goals are to determine 1) whether the treatment made any difference, and 2) whether the effect of the treatment differed by socioeconomic status (SES).</p>
<p>You can answer the first question with a simple logit model:</p>
<p class="InputCode">logit grad treat highSES</p>
<p>The coefficient on <span class="InputCode">treat</span> is positive and significant, suggesting the intervention did increase the probability of graduation. Note that <span class="InputCode">highSES</span> had an even bigger impact.</p>
<p>Next examine whether the effect depends on SES by adding an interaction between the two:</p>
<p class="InputCode">logit grad treat##highSES</p>
<p>The coefficient on <span class="InputCode">treat#highSES</span> is not significantly different from zero. But does that really mean the treatment had exactly the same effect regardless of SES?</p>
<p>Binary outcomes are often interpreted in terms of odds ratios, so repeat the previous regression with the <span class="InputCode">or</span> <em>option</em> to see them:</p>
<p class="InputCode">logit grad treat##highSES, or</p>
<p>This tells us that the odds of graduating if you are treated are approximately 2.83 times the odds of graduating if you are not treated, regardless of your SES. Researchers sometimes confuse odds ratios with probability ratios; i.e. they say you are 2.83 times more "likely" to graduate if you are treated. This is incorrect.</p>
<p>If you ask <span class="InputCode">margins</span> to examine the interaction between two categorical variables, it will create scenarios for all possible combinations of those variables. You can use this to easily obtain the predicted probability of graduation for all four possible scenarios (high SES/low SES, treated/not treated):</p>
<p class="InputCode">margins highSES#treat</p>
<p>For low SES students, treatment increases the predicted probability of graduation from about .49 to about .73. For high SES students, treatment increases the predicted probability of graduation from about .96 to about .98. Now, if you plug those probabilities  into the formula for calculating the odds ratio, you will find that the odds ratio is 2.83 in both cases (use the full numbers from the <span class="InputCode">margins</span> output, not the two digit approximations given here). Treatment adds the same amount to the linear function that is passed through the logistic function in both cases. But recall the <em>shape</em> of the logistic function:</p>
<p><img alt="Graph of logistic function, with four possible scenarios marked" height="446" src="https://ssc.wisc.edu/sscc/pubs/screenshots/sfr/logit.png" width="631"/></p>
<p>The treatment has a much smaller effect on the probability of graduation for high SES students because their probability is already very high—it can't get much higher. Low SES students are in the part of the logistic curve that slopes steeply, so  changes in the linear function have much larger effects on the predicted probability.</p>
<p>The <span class="InputCode">margins</span> command can most directly answer the question "Does the effect of the treatment vary with SE?" with a combination of <span class="InputCode">dydx()</span> and <span class="InputCode">at()</span>:</p>
<p class="InputCode">margins, dydx(treat) at(highSES=(0 1))</p>
<p></p>
<p>(You can also do this with <span class="InputCode">margins highSES, dydx(treat)</span>.) Once again, these are the same numbers you'd get by subtracting the levels obtained above. We suggest always looking at levels as well as changes—knowing where the changes start from gives you a much better sense of what's going on.</p>
<p>It's a general rule that it's easiest to change the predicted probability for  subjects who are "on the margin;" i.e. those whose predicted probability starts near 0.5. However, this is a property of the logistic function, not the data. It is an assumption you make when you choose to run a logit model.</p>
<h2><a id="MultinomialLogit" name="MultinomialLogit"></a>Multinomial Logit</h2>
<p>Multinomial logit models can be even harder to interpret because the coefficients only compare two states. Clear Stata's memory and load the following data set, which was carefully constructed to illustrate the pitfalls of interpreting multinomial logit results:<br/>
</p>
<p class="InputCode">clear<br/>
                use http://www.ssc.wisc.edu/sscc/pubs/files/margins_mlogit.dta</p>
<p>It contains two variables, an integer <span class="InputCode">y</span> that takes on the values 1, 2 and 3; and a continuous variable <span class="InputCode">x</span>. They are negatively correlated (<span class="InputCode">cor y x</span>). </p>
<p>Now run the following model:</p>
<p class="InputCode">mlogit y x</p>
<p>The coefficient of <span class="InputCode">x</span> for outcome 2 is negative, so it's tempting to say that as <span class="InputCode">x</span> increases the probability of <span class="InputCode">y</span> being 2 decreases. But in fact that's not the case, as the <span class="InputCode">margins</span> command will show you:</p>
<p class="InputCode">margins, dydx(x) predict(outcome(2))</p>
<p>The <span class="InputCode">predict()</span> options allows you to choose the response <span class="InputCode">margins</span> is examining. <span class="InputCode">predict(outcome(2))</span> specifies that you're interested in the expected probability of outcome 2. And in fact the probability of outcome 2 increases with <span class="InputCode">x</span>, the derivative being 0.016.</p>
<p>How can that be? Recall that the coefficients given by <span class="InputCode">mlogit</span> only compare the probability of a given outcome with the base outcome. Thus the <span class="InputCode">x</span> coefficient of -5.34 for outcome 2 tells you that as <span class="InputCode">x</span> increases, observations are likely to move from outcome 2 to outcome 1. Meanwhile the <span class="InputCode">x</span> coefficient of -21.292 for outcome 3 tells you that as <span class="InputCode">x</span> increases observations are likely to move from outcome 3 to outcome 1. What it doesn't tell you is that as <span class="InputCode">x</span> increases observations also move from outcome 3 to outcome 2, and in fact that effect dominates the movement from 2 to 1.</p>
<p>You can  see it if you change the base category of the regression:</p>
<p class="InputCode">mlogit y x, base(2)</p>
<p>Now the coefficients tell you about the probability of each outcome compared to outcome 2, and the fact that the negative <span class="InputCode">x</span> coefficient for outcome 3 is much larger (in absolute terms) than the positive <span class="InputCode">x</span> coefficient for outcome 1 indicates that increasing <span class="InputCode">x</span> increases the probability of outcome 2.</p>
<p>We strongly recommend using <span class="InputCode">margins</span> to explore what your regression results mean.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/sfr/logit.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Reducing Stata's Memory Usage</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p><em>How to work with big datasets in Stata without running out of memory.</em></p>
<p>When you work with a data set in Stata, Stata must load the entire data set into the computer's memory (RAM). Fortunately,  laptops today have more memory than most servers did 20 years ago, and most people never have to worry about how much memory Stata is using. But if you work with big datasets, you need to be careful: trying to use more memory than you have will end badly, and if you're working on one of SSCC's servers it will affect everyone else who is using that server. <br/>
</p>
<h2>Do I need to worry about memory?</h2>
<p>You only need to worry about memory if the size of your data set is close to the amount of memory in the computer you're using, and if it's bigger you definitely have a problem. The number of observations or variables in your data set won't tell you that, since the amount of memory they take up varies. But a data set takes up the same amount of space in memory as it does on disk. There are many ways to see how big a file on disk is, but here are a few:</p>
<h3>Windows</h3>
<p>Open Windows Explorer, find the data set, right-click on it, and choose <span class="MenuOutput">Properties</span>. Alternatively, go to <span class="MenuOutput">View</span> and select <span class="MenuOutput">Details</span>, and you'll see how big all your files are.</p>
<h3>macOS</h3>
<p>Open the Finder, find the data set, right-click (or Ctrl-click) on it, and choose <span class="MenuOutput">Get Info</span>.</p>
<h3>Linux</h3>
<p>Use <span class="InputCode">cd</span> to get to the proper directory, then type:</p>
<p class="InputCode">ls -lh <span class="Parameter">dataset</span>.dta</p>
<p>where <span class="Parameter">dataset</span> should be replaced by the actual name of your data set.</p>
<h3>Stata</h3>
<p>Assuming you can load the data into Stata, it will tell you how much memory it is using. Look in the <span class="MenuOutput">Properties</span> window for <span class="MenuOutput">Size</span>. <span class="MenuOutput">Memory</span> tells you the total amount of memory Stata is currently using.</p>
<h3>How much is too much?</h3>
<p>That depends on the computer you're using:</p>
<table border="1">
<tbody>
<tr>
<th>Computer</th>
<th>Memory</th>
</tr>
<tr>
<td>Typical laptop or desktop</td>
<td>8-16GB</td>
</tr>
<tr>
<td>Winstat</td>
<td>32GB*</td>
</tr>
<tr>
<td>Linstat</td>
<td>386GB</td>
</tr>
<tr>
<td>SiloLDS</td>
<td>32GB*</td>
</tr>
<tr>
<td>SSCC Condor Server</td>
<td>24-320GB**</td>
</tr>
</tbody>
</table>
<p>*This is a policy limit: we ask you not to use more than 32GB of memory on Winstat or SiloLDS. The servers have more than 32GB, but it must be shared with others and these servers are very sensitive to running out.</p>
<p>**Depending on which Condor server your job is assigned to.</p>
<p>How much memory you need also depends on what you plan to do. Obviously if you plan to add variables or observations to your data set you'll need more memory. You should start paying attention any time you're using more than about half of the memory available to you.</p>
<h2>Reducing the Size of Your Data Set</h2>
<p>There are several things you can do that will probably shrink your data set.</p>
<h3>Drop Unneeded Data</h3>
<p>If there are variables or observations in your data set that you will not use, use the <span class="InputCode">drop</span> command to get rid of them (or <span class="InputCode">keep</span> if that's easier). You can always get them back later by changing the data wrangling do file that dropped them and running it again.</p>
<p>If the full data set is too large to load at all, you can load just the part you want by giving the <span class="InputCode">use</span> command a variable list to act on and/or an if condition. If you do this, then the name of the data set goes after the word  <span class="InputCode">using</span>. For example, the following will only load variables <span class="InputCode">x</span> and <span class="InputCode">y</span> and observations where <span class="InputCode">x</span> is not missing from a data set called <span class="InputCode">bigdata</span>.</p>
<p class="InputCode">use x y if x&lt;. using bigdata</p>
<h3></h3>
<p>Similar syntax can be used with <span class="InputCode">import</span> and <span class="InputCode">infix</span> to read in part of a text file.</p>
<p>This probably shouldn't be your permanent solution, because when you load a subset of a data set Stata must still read the entire data set to find the parts to be loaded. You'll be able to load the subset more quickly in the future if you save it as its own file.</p>
<h3>Use Smaller Variable Types</h3>
<p>For most people, the amount of memory or disk space saved by thinking about variable types isn't worth the effort. But for those working with big data sets, Stata actually has five different types of numeric variables and using the right one can save a significant amount of memory. Three of these are integer types, distinguished by the range of numbers they can store:</p>
<table border="1">
<tbody>
<tr>
<th align="center">Type</th>
<th align="center">Range<br/>
(Approximate)</th>
<th align="center">Bytes of Memory used <br/>
                      per Observation</th>
</tr>
<tr>
<td align="center" class="InputCode">byte</td>
<td align="center">-100 to 100</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center" class="InputCode">int</td>
<td align="center">-32,000 to 32,000</td>
<td align="center">2</td>
</tr>
<tr>
<td align="center" class="InputCode">long</td>
<td align="center">-2,000,000 to 2,000,000</td>
<td align="center">4</td>
</tr>
</tbody>
</table>
<p>Type <span class="InputCode">help datatypes</span> for more details, including the exact ranges, but these are easy to remember.</p>
<p>Two variable types, float and double, store numbers with fractions. They can both store very large numbers, but differ in how many digits of accuracy they have:</p>
<table border="1">
<tbody>
<tr>
<th align="center">Type</th>
<th align="center">Digits of Accuracy<br/>
                      (Approximate)</th>
<th align="center">Bytes of Memory used <br/>
                        per Observation</th>
</tr>
<tr>
<td align="center" class="InputCode">float</td>
<td align="center">7</td>
<td align="center">4</td>
</tr>
<tr>
<td align="center" class="InputCode">double</td>
<td align="center">16</td>
<td align="center">8</td>
</tr>
</tbody>
</table>
<p>The default type is <span class="InputCode">float</span>. To create a variable with a type other than <span class="InputCode">float</span>, specify the type right after the <span class="InputCode">gen</span> command and before the variable name. So instead of:</p>
<p class="InputCode">gen adult = (age&gt;=18)</p>
<p>use:</p>
<p class="InputCode">gen byte adult = (age&gt;=18)</p>
<p>Note that if you tell Stata to make a variable an integer type, it will discard any fractional part. If you run:</p>
<p class="InputCode">gen int x = 1.9</p>
<p>then <span class="InputCode">x</span> will be created and set to 1.</p>
<p>The <span class="InputCode">compress</span> command will examine the data in memory, determine if any variables can be stored in a smaller data type without losing any precision, and convert those that can be. (It has nothing to do with compressing files on disk.) Use it early in your project to compress the data you start with. But you can also run it periodically as an alternative to  thinking carefully about the proper type for each new variable you create.</p>
<h3>Shorten Strings or Encode Them</h3>
<p>Strings require one byte of memory per character for western (ASCII) characters. However, string variables are the same length for all observations. Thus if you have a string variable that contains "Yes", "No", or "I don't know" then the variable will be set to length 12 and use 12 bytes per observation so it can store "I don't know".</p>
<p>If you changed "I don't know" to "DK", then the string only needs to use 3 bytes per observation (for "Yes"). If you changed the three values to "Y", "N", and "D", then it only needs to use 1 byte, though the meaning of "D" is not at all obvious. However, Stata does not actually shrink string variable types when you shorten their values. Run the <span class="InputCode">compress</span> command to actually shrink the variable types.</p>
<p>Encoding a string variable containing "Yes", "No," and "I don't know" as a numeric variable containing 1, 2, and 3 will also reduce its memory usage to 1 byte per observation, but you can set value labels containing the full content of the string. If the string represents a categorical variable, encoding it will allow you to use it in analysis. The <span class="InputCode">encode</span> command will create the numeric variable and set the value labels for you, and we recommend doing so.</p>
<h3>Drop Intermediate Results </h3>
<p>If you create variables to store intermediate results, drop them as soon as you're done with them. For example, the following code creates a variable called <span class="InputCode">incomePovertyRatio</span> just so it can create an indicator variable <span class="InputCode">lowIncome</span> that identifies subjects whose income is less than 150% of the poverty level:</p>
<p class="InputCode">gen incomePovertyRatio = income/povertyLevel<br/>
                  gen lowIncome = (incomePovertyRatio &lt; 1.5)
                    <br/>
                drop incomePovertyRatio</p>
<p>Since <span class="InputCode">incomePovertyRatio</span> is only needed to create <span class="InputCode">lowIncome</span>, you can drop it as soon as <span class="InputCode">lowIncome</span> has been created.</p>
<h3>Break the Data into Smaller Pieces</h3>
<p>If a data set is too big to load into memory, for some tasks you can break it into a set of smaller data sets and work on them one at a time. There might be a categorical variable in the data set such that a separate data set for each category would work well, or you can break it up by observation number. You'll then want to use loops to act on all the individual data sets: <a href="https://ssc.wisc.edu/sscc/pubs/stata_prog1.htm">Stata Programming Essentials</a> will teach you the basics of loops and <a href="https://ssc.wisc.edu/sscc/pubs/stata_prog2.htm">Stata Programming Tools</a> briefly discusses looping over a list of files.</p>
<p>However, many tasks, including almost all analysis, needs the entire data set to be loaded into memory. Breaking the data set into smaller pieces probably only makes sense if you can shrink the size of each piece so that in the end you can combine them all into a single data set that can be loaded into memory.<br/>
</p>
<div></div>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Speeding up Multiple Imputation in Stata using Parallel Processing</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Multiple imputation is computationally intensive and can be time consuming if your data set is large. On the other hand, the process of creating each imputation is independent of the others, which means you can have multiple CPUs working on different imputations at the same time and then combine them when they're all complete. This article will show you how to do so automatically using the SSCC's Condor flock, but the technique can be used on any computer with multiple CPUs (see <a href="#WhatifIdonthaveaccesstoaCondorflock">What if I don't have access to a Condor flock?</a>).</p>
<p>This article uses macros and loops. If you're not familiar with them, you should probably read <a href="https://ssc.wisc.edu/sscc/pubs/stata_prog1.htm">Stata Programming Essentials</a> before proceeding. You'll also need to  run  Stata programs on  the SSCC's Linux servers. If you've never used Linux before this is easier than you probably think--see <a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a> for instructions. You may  want to read <a href="https://ssc.wisc.edu/sscc/pubs/7-1.htm">An Introduction to Condor</a>, though this article will teach you all the Condor commands you'll need.</p>
<p>Stata users who want to do multiple imputation can choose between Stata's official <span class="InputCode">mi</span> commands and the user-written <span class="InputCode">ice</span>. At this point, <span class="InputCode">mi</span> (in particular <span class="InputCode">mi impute chained</span>) can do everything <span class="InputCode">ice</span> can do and we recommend everyone use <span class="InputCode">mi</span>. However, many people are still used to using <span class="InputCode">ice</span>.   Fortunately you can use�<span class="InputCode">ice</span>�for the actual imputation and then convert the data set to�<span class="InputCode">mi</span>'s format so you can do things like combine imputations that were done separately. This article will discuss using both: look for�<span class="InputCode">mi</span>�and�<span class="InputCode">ice</span>�sections describing the commands that are needed only if you're using one or the other.                </p>
<p>We'll introduce three do files. <span class="InputCode">setup.do</span> prepares the data and submits all the imputation jobs to Condor. <span class="InputCode">impute.do</span> is run by Condor--multiple times in parallel--and does the actual imputation. <span class="InputCode">combine.do</span> then combines the results into a single file. Full code for all three do files, with <span class="InputCode">mi</span> and <span class="InputCode">ice</span> versions, can be found at <a href="#CodefortheDoFiles">the end of this article</a>. As written, the do files use an example data set we've made available at <a href="https://www.ssc.wisc.edu/sscc/pubs/files/missing_data.dta">https://www.ssc.wisc.edu/sscc/pubs/files/missing_data.dta</a>. It contains <span class="InputCode">id</span>, <span class="InputCode">y</span> and variables <span class="InputCode">x1</span> through <span class="InputCode">x10</span>. <span class="InputCode">y</span> and all the <span class="InputCode">x</span>'s have missing values. If you want to run the do files as written, make a directory for your work, make it your current directory and then place a copy of this data set in it. The easiest way is probably to run the following in Stata:</p>
<p class="InputCode">use http://www.ssc.wisc.edu/sscc/pubs/files/missing_data.dta<br/>
save missing_data</p>
<p>Alternatively you can adapt the do files to use your data immediately. For this technique to work your data set must have a unique identifier variable, so if your data set does not have one you'll have to create it (<span class="InputCode">gen id=_n </span>will probably do).</p>
<h2><a id="SettingUp" name="SettingUp"></a>Setting Up (setup.do)</h2>
<p>Begin with  the usual housekeeping (clearing the memory, starting a log, etc.).</p>
<h3>mi</h3>
<p><span class="InputCode">mi</span> requires some configuration before you can do any imputing. Begin by loading the data. Then choose the data structure <span class="InputCode">mi</span> should use with the <span class="InputCode">mi set</span> command. If you need to manipulate your data after imputing you should learn what the different formats are and when each should be used--type <span class="InputCode">help my_styles</span>. If not, it makes little difference which you use so use <span class="InputCode">mlong</span>. Next, register the variables you wish to impute and save the result in a new file.</p>
<p class="InputCode">use missing_data<br/>
                  mi set mlong<br/>
                mi register imputed x* y<br/>
                save missing_data_mi, replace
                </p>
<h3>Both</h3>
<p>Now it's time to submit the imputation jobs to Condor. For this example we'll create ten imputations by submitting ten jobs that create one imputation each. <a href="https://www.ssc.wisc.edu/sscc/policies/server_usage.htm">In fairness to other users</a> do not submit more than fifteen jobs, but if you want  more than fifteen imputations  have each job create more than one imputation. The following code submits the jobs:</p>
<p class="InputCode">forvalues jobID=1/10 {<br/>
<span class="indent3">shell condor_stata impute `jobID' &amp;</span><br/>
}</p>
<p>The <span class="InputCode">shell</span> command tell Stata to have Linux execute what follows. <span class="InputCode">condor_stata impute</span> tells Condor to run the Stata job <span class="InputCode">impute.do</span> (the <span class="InputCode">.do</span> is implied). <span class="InputCode">`jobID'</span> passes the current value of the <span class="InputCode">jobID</span> macro to <span class="InputCode">impute.do</span> as an argument--you'll see how <span class="InputCode">impute.do</span> uses it shortly. The <span class="InputCode">&amp;</span> at the end tells Linux to run the <span class="InputCode">condor_stata</span> command in the background, so Stata doesn't have to wait for it to finish before proceeding with the loop.</p>
<h2><a id="Imputing" name="Imputing"></a>Imputing (impute.do)</h2>
<p>When <span class="InputCode">setup.do</span> is complete, ten instances of <span class="InputCode">impute.do</span> have been submitted to Condor and Condor will find CPUs for all of them. They differ in that each one has a different number for its <span class="InputCode">jobID</span> argument.</p>
<p>Since <span class="InputCode">impute.do</span> will always run in batch mode, it doesn't need to clear memory and such. Its first task is to retrieve its <span class="InputCode">jobID</span>. Do so with the <span class="InputCode">args</span> command:</p>
<p class="InputCode">args jobID</p>
<p>This stores the do file's argument in a macro called <span class="InputCode">jobID</span>. You can then use it to start a log file which will be unique to this instance of <span class="InputCode">impute.do</span>:</p>
<p class="InputCode">log using impute`jobID'.log, replace</p>
<p>The ten instances of <span class="InputCode">impute.do</span> will thus create ten log files, named <span class="InputCode">impute1.log</span>, <span class="InputCode">impute2.log</span>, etc. and you can check them individually as needed.</p>
<p>For reproducibility you want to set the seed for the random number generator, but each instance needs a different seed. One easy solution is to set the seed to an arbitrary number plus the instance's <span class="InputCode">jobID</span>:</p>
<p class="InputCode">set seed `=123454321+`jobID''</p>
<h3>mi</h3>
<p>Load the data set you prepared for <span class="InputCode">mi</span> in <span class="InputCode">setup.do</span>:</p>
<p class="InputCode">use missing_data_mi</p>
<p>When <span class="InputCode">mi</span> is actually imputing it creates  temporary files in the current directory, and if the ten instances of impute.do are trying to put their temporary files in the same directory they'll interfere with each other. Thus you need to create a directory for each instance (we'll remove them later) and make that the current directory:</p>
<p class="InputCode">mkdir impute`jobID'<br/>
                  cd impute`jobID'<br/>
</p>
<p>Now you're ready to actually impute:</p>
<p class="InputCode">mi impute chained (regress) x* y, add(1)</p>
<p>When the imputation is complete, go back to the original directory and remove the one you created.</p>
<p class="InputCode">cd ..<br/>
                rmdir impute`jobID'</p>
<p>Note that if your version of <span class="InputCode">impute.do</span> crashes for whatever reason before deleting the directories it creates, you'll need to delete them yourself before running it again.</p>
<p>Finally save the file, including the <span class="InputCode">jobID</span> in the name to make it unique:</p>
<p class="InputCode">save impute`jobID',replace</p>
<h3>ice</h3>
<p>First load the data, then use <span class="InputCode">ice</span> to do the imputation. Use the <span class="InputCode">clear</span> option so the imputed data replaces the old data in memory rather than being saved as a file (since we're not done with it).</p>
<p class="InputCode">use missing_data<br/>
                ice x* y, m(1) clear                </p>
<p>In order to use <span class="InputCode">mi</span>'s tools to combine imputations you need to convert the data to <span class="InputCode">mi</span>'s format. This is done with <span class="InputCode">mi import</span>:</p>
<p class="InputCode">mi import ice, imputed(x* y) clear</p>
<p>The <span class="InputCode">imputed</span> option tells mi that the <span class="InputCode">x</span> variables and <span class="InputCode">y</span> were imputed, but in order to combine imputations <span class="InputCode">mi</span> also needs to be explicitly told that <span class="InputCode">id</span> was not imputed. Do that by registering it as a regular variable:</p>
<p class="InputCode">mi register regular id<br/>
</p>
<p><span class="InputCode">mi import ice</span> puts the data in <span class="InputCode">flong</span> format, since that's basically what <span class="InputCode">ice</span> uses. <span class="InputCode">flong</span> duplicates complete cases unnecessarily, so change the format to <span class="InputCode">mlong</span> (again, type <span class="InputCode">help mi_styles</span> if you want to learn more about the formats <span class="InputCode">mi</span> can use):</p>
<p class="InputCode">mi convert mlong, clear</p>
<p>Now you're ready to save the results. Include <span class="InputCode">jobID</span> in the file name to make it unique.</p>
<p class="InputCode">save impute`jobID',replace</p>
<h2><a id="Combine" name="Combine"></a>Combining (combine.do)</h2>
<p>When all ten instances of <span class="InputCode">impute.do</span> have completed, you'll have ten data sets in your current directory named <span class="InputCode">impute1.dta</span> through <span class="InputCode">impute10.dta</span>. Be sure they're all there before proceeding. You can use the Linux <span class="InputCode">condor_q</span> command on Kite to see if any instances of <span class="InputCode">impute.do</span> are still running. Condor will also email you when each job is completed. (Condor has a tool called DAGMan that can do things like automatically run <span class="InputCode">combine.do</span> when all the instances of <span class="InputCode">impute.do</span> are done, but it's somewhat cumbersome. If you're interested in using it contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">help desk</a> for assistance.)</p>
<p>Your next task is to combine the ten files with one imputation each into one file with ten imputations. Begin (after the usual housekeeping) by loading the first file:</p>
<p class="InputCode">use impute1</p>
<p>Next loop over the remaining files (i.e. 2 through 10), adding them to what's already in memory using <span class="InputCode">mi add</span>:</p>
<p class="InputCode">                  forvalues jobID=2/10 {<br/>
<span class="indent3">mi add id using impute`jobID', assert(match)</span><br/>
}</p>
<p><span class="InputCode">mi add</span> is a bit like a merge, so you need to specify a key variable (in this case <span class="InputCode">id</span>) so it knows which observations to combine. The <span class="InputCode">assert(match)</span> option tells it that every observation should match and the do file should halt if any fail to match. Given how we created these files, a failure to match would mean something went very wrong.</p>
<p>All that's left is to save the output file containing all ten imputations:</p>
<p class="InputCode">save imputed_data, replace</p>
<h2><a id="CodefortheDoFiles" name="CodefortheDoFiles"></a>Code for the Do Files</h2>
<p>Following is complete code for  the do files described in this article. They assume that all the do files and the data are in your current directory, and that you're using an SSCC Linux server and thus can submit jobs to our Condor flock.</p>
<h3>setup.do (mi version)</h3>
<p class="InputCode">clear all<br/>
                  set more off<br/>
                  capture log close<br/>
                  log using setup.log, replace<br/>
<br/>
                  use missing_data<br/>
mi set mlong<br/>
mi register imputed x* y<br/>
save missing_data_mi, replace<br/>
<br/>
forvalues jobID=1/10 {<br/>
<span class="indent3">shell condor_stata  impute `jobID' &amp;</span><br/>
}<br/>
<br/>
log close</p>
<h3>setup.do (ice version)</h3>
<p class="InputCode">clear all<br/>
set more off<br/>
capture log close<br/>
log using setup.log,replace
<br/>
<br/>
forvalues jobID=1/10 {<br/>
<span class="indent3">shell condor_stata -b do impute `jobID' &amp;</span><br/>
}<br/>
<br/>
log close
                </p>
<h3>impute.do (mi version)</h3>
<p class="InputCode">args jobID<br/>
                  log using impute`jobID'.log, replace                  <br/>
                  set seed `=123454321+`jobID''                  <br/>
                  use missing_data_mi                  <br/>
                  mkdir impute`jobID'<br/>
cd impute`jobID'                  <br/>
mi impute chained (regress) x* y, add(1)<br/>
cd ..<br/>
rmdir impute`jobID'<br/>
save impute`jobID',replace<br/>
log close
<br/>
</p>
<h3>impute.do (ice version)</h3>
<p class="InputCode">args jobID<br/>
log using impute`jobID'.log, replace <br/>
set seed `=123454321+`jobID''<br/>
use missing_data<br/>
ice x* y, m(1) clear                <br/>
mi import ice, imputed(x* y) clear                <br/>
mi register regular id                <br/>
mi convert mlong, clear                <br/>
save impute`jobID',replace                <br/>
log close
                </p>
<h3>combine.do (both)</h3>
<p class="InputCode">clear all<br/>
                set more off<br/>
                capture log close<br/>
                log using combine.log, replace<br/>
<br/>
                use impute1                <br/>
                forvalues jobID=2/10 {<br/>
<span class="indent3">mi add id using impute`jobID', assert(match)</span><br/>
}<br/>
save imputed_data, replace</p>
<h2><a id="WhatifIdonthaveaccesstoaCondorflock" name="WhatifIdonthaveaccesstoaCondorflock"></a>What if I don't have access to a Condor flock? </h2>
<p>This article was primarily written to help SSCC members take advantage of the power of the SSCC's Condor flock, but the techniques described can also be used to take advantage of all the CPUs in today's multi-CPU computers. Just replace the command that submits the <span class="InputCode">impute.do</span> jobs to Condor with a command that runs them on your computer. (The <a class="InputCode" href="https://ideas.repec.org/c/boc/bocode/s457527.html">parallel</a> command by George Vega Yon and Brian Quistorff is another option, and easier to use.)</p>
<p> For example, to run these jobs on a Windows PC you might replace:</p>
<p class="InputCode">shell condor_stata -b do impute `jobID' &amp;</p>
<p>with:</p>
<p class="InputCode">winexec "C:\Program Files (x86)\Stata12\StataMP-64.exe" -b do impute `jobID'</p>
<p>The <span class="InputCode">winexec</span> command is very similar to <span class="InputCode">shell</span>, but tells Stata not to wait for the job to finish (since Windows doesn't use <span class="InputCode">&amp;</span> for that). You may need to experiment to find the exact command that will work on your computer.</p>
<p>Some other considerations:</p>
<ul>
<li>Do not submit more jobs than you have CPUs, or they'll just compete for computing time. If you have a two CPU ("Dual Core") computer but want ten imputations, submit two jobs that create five imputations each.</li>
<li>Make sure you have enough memory for all the jobs you submit. If Stata needs to use disk space as virtual memory it will slow down tremendously.</li>
<li>If your <span class="InputCode">profile.do</span> tells Stata to start in a particular directory, remove that command temporarily so the <span class="InputCode">impute.do</span> jobs start in the same directory as <span class="InputCode">setup.do</span>.</li>
<li>If you're not the only one using the computer be sure to leave enough CPUs for others. (SSCC members should <strong>never</strong> use this technique on Winstat--that's what Condor is for.)</li>
</ul>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Multiple Imputation in Stata:</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This is part two of the Multiple Imputation in Stata series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_intro.htm">Introduction</a>.</em></p>
<p>The decision to use multiple imputation rather than simply analyzing complete cases should not be made lightly. First, multiple imputation takes a substantial amount of time to learn, and a substantial amount of time to implement. Expect to spend at least as much time on your imputation model as on your analysis model—the model whose results you are interested in for your research. Second, the practical technique for doing it in the social sciences, multiple imputation by chained equations or MICE, lacks theoretical justification and using it may draw objections from some reviewers (of course not using it may draw objections from other reviewers). Third, it's quite possible to do it wrong and thus get invalid results without realizing it. This leads to a dilemma: if multiple imputation gives different results than complete case analysis, which will you believe? (And if it doesn't, what was the point?) Clearly you'll need to make sure you understand multiple imputation well enough to be confident you're using it properly.</p>
<p>On the other hand, complete cases analysis has substantial weaknesses as well. There is no single right answer to the question of how to handle missing data.</p>
<h2>Why MICE?</h2>
<p>This series will focus almost exclusively on Multiple Imputation by Chained Equations, or MICE, as implemented by the <span class="InputCode">mi impute chained</span> command. We recognize that it does not have the theoretical justification Multivariate Normal (MVN) imputation has. However, most SSCC members work with data sets that include binary and categorical variables, which cannot be modeled with MVN. (There are ways to adapt it for such variables, but they have no more theoretical justification than MICE.) We will not discuss monotone or univariate   imputation methods because we have yet to see an SSCC member with monotone data or just one variable to impute.</p>
<h2>Why <span class="InputCode">mi impute chained</span> rather than <span class="InputCode">ice</span>?</h2>
<p>For many years Patrick Royston's <span class="InputCode">ice</span> command was the standard implementation of MICE in Stata. We express our appreciation for his contribution to the Stata community. However, the new <span class="InputCode">mi impute chained</span> command has all the resources of Stata Corporation behind it, works directly with the  <span class="InputCode">mi</span> framework for handling imputed data, and we feel it is somewhat easier to learn and use. We'll thus use <span class="InputCode">mi impute chained</span> throughout this series and we suggest <span class="InputCode">ice</span> users switch to it.</p>
<h2>Issues to Consider</h2>
<p>Issues you should consider when deciding whether to use multiple imputation or not include the following:</p>
<h3>Power</h3>
<p>The reason you probably considered multiple imputation in the first place was to avoid losing observations because they contain missing values. Multiple imputation allows you to use what information is available in those observations that contain missing values, which can lead to smaller confidence intervals and more ability to reject null hypotheses.</p>
<p><a id="Power" name="Power"></a><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm#Power">Example: Power</a></p>
<h3>MCAR Data vs. MAR Data</h3>
<p>In the multiple imputation literature, data are "missing completely at random" (MCAR) if the probability of a particular value being missing is completely independent of both the observed data and the unobserved data. In other words, the complete cases are a random sample. If the data are MCAR, then both complete cases analysis and multiple imputation give unbiased estimates.</p>
<p>If the probability of a particular value being missing depends only on the observed data, then the data is "missing at random" (MAR) and the complete cases are not a random sample. With MAR data, complete cases analysis gives biased results but multiple imputation does not. If you believe your data are MAR rather than MCAR, then you should definitely consider using multiple imputation.</p>
<p>If the probability of a particular value being missing depends on the unobserved data, then the data are "missing not at random" (MNAR). In theory multiple imputation can give unbiased estimates with MNAR data, but only if the imputation method includes a model of the missingness mechanism. You'd need to code such a method yourself; it cannot be done using <span class="InputCode">mi impute</span>, <span class="InputCode">ice</span>, etc. In practice, if your data are MNAR it's going to be very hard to carry out legitimate analysis.</p>
<p>Note that MCAR and MAR do not require that the probability of one value being missing be independent of the probability of another value being missing. Missing values are often linked. For example, if a person was not contacted in a survey wave, that person will be missing all the variables from that wave but that data could still be MCAR, MAR or MNAR.</p>
<p></p>
<p><a id="missmech" name="missmech"></a><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm#MCARvsMARvsMNAR">Example: MCAR vs. MAR vs. MNAR</a></p>
<h4><a id="AreMyDataMCARMARorMNAR" name="AreMyDataMCARMARorMNAR"></a>Are My Data MCAR, MAR, or MNAR?</h4>
<p>Testing whether a given data set is MCAR or MAR is straightforward. First create a new indicator variable for each existing variable which is 1 if a given observation is missing that variable and 0 if it is not. The <span class="InputCode">misstable</span> command can do this part automatically with the <span class="InputCode">gen()</span> option. Then run  logit models to test if any of the other variables predict whether a given variable is missing. If they do, then the data is MAR rather than MCAR.</p>
<p>If you had variables <span class="InputCode">y,</span> <span class="InputCode">x1</span> and <span class="InputCode">x2</span>, the code would look like:</p>
<p class="InputCode">misstable sum, gen(miss_)<br/>
                  logit miss_y x1 x2<br/>
                  logit miss_x1 y x2<br/>
                  logit miss_x2 y x1</p>
<p>It would also be a good idea to run t-tests to see if the values of the other variables vary between missingness groups:</p>
<p class="InputCode">ttest x1, by(miss_y)<br/>
                  ttest x2, by(miss_y)<br/>
                  ttest y, by(miss_x1)<br/>
                  ttest x2, by(miss_x1)<br/>
                  ttest y, by(miss_x2)<br/>
                  ttest x1, by(miss_x2) </p>
<p>The following code automates this entire process:</p>
<p class="InputCode">                  local numvars <span class="Parameter">list of all numeric variables in data set</span><br/>
                  local missvars <span class="Parameter">list of all variables with missing values in data set</span><br/>
  misstable sum, gen(miss_)<br/>
                  foreach var of local missvars {<br/>
<span class="indent3">local covars: list numvars - var</span><br/>
<span class="indent3">display _newline(3) "logit missingness of `var' on `covars'"</span><br/>
<span class="indent3">logit miss_`var' `covars'</span><br/>
<span class="indent3">foreach nvar of local covars {</span><br/>
<span class="indent6">display _newline(3) "ttest of `nvar' by missingness of `var'"</span><br/>
<span class="indent6">ttest `nvar', by(miss_`var')</span><br/>
<span class="indent3">}</span><br/>
                  }</p>
<p>If you have a lot of variables and can put them into a convenient <em>varlist</em> (like <span class="InputCode">x1-x10</span> or even <span class="InputCode">_all</span>) replace the two initial <span class="InputCode">local</span> commands with <span class="InputCode">unab</span>:</p>
<p class="InputCode">unab numvars: <span class="Parameter">numeric variables as varlist</span><br/>
                  unab missvars: <span class="Parameter">variables with missing values as varlist</span></p>
<p>There is no formal test for determining whether a given set of logit results means the data is MCAR or MAR, but they will give you a sense of how close the data are to MCAR and how big a problem the deviations from MCAR are likely to be. The bigger the deviation the stronger the case for using multiple imputation rather than complete cases analysis.</p>
<p></p>
<p>By definition you cannot determine whether data are MNAR  by looking at the observed values. Think carefully about how the data was collected and consider whether some values of the variables might make the data more or less likely to be observed. For example, people with very high or very low incomes might be less willing to disclose them, or people with high BMIs. People with a strong interest in the topic of a survey might be more likely to respond than those who care less. Schools might try very hard to make sure  students they expect to do well take standardized tests but put much less effort into having students they expect to do poorly take them. In the last example, adding variables like grades or socioeconomic status that predict test performance and thus probability of taking the test might make the data plausibly MAR.</p>
<h3>Amount of Missing Data</h3>
<p>If you have low amounts of missing data (say, 1%) then multiple imputation and complete cases analysis are very likely to give essentially the same results, and complete cases analysis is much easier.</p>
<p>On the other hand, if you have very large amounts of missing data then your final results will be driven in large part by your imputation model rather than the observed data. There's no consensus on how much missing data is too much for multiple imputation, but certainly imputing 50% of your data is asking for trouble.</p>
<p>Multiple imputation is useful somewhere in between.</p>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_models.htm">Creating Imputation Models</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_intro.htm">Introduction</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Multiple Imputation in Stata: Estimating</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p><em>This article is part of the Multiple Imputation in Stata series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_intro.htm">Introduction</a>.</em></p>
<p>In most cases, the hard work of using multiple imputation comes in the imputation process. Once the imputations are created and checked, Stata makes estimation using the imputed data relatively easy.</p>
<h2>mi estimate</h2>
<p>The main command for running estimations on imputed data is <span class="InputCode">mi estimate</span>. It is a prefix command, like <span class="InputCode">svy</span> or <span class="InputCode">by</span>, meaning that it goes in front of whatever estimation command you're running.</p>
<p>The <span class="InputCode">mi estimate</span> command first runs the estimation command on each imputation separately. It then combines the results using Rubin's rules and displays the output. Because the output is created by <span class="InputCode">mi estimate</span>, options that affect output, such as <span class="InputCode">or</span> to display odds ratios, must be applied to <span class="InputCode">mi estimate</span> rather than the estimation command. Thus:</p>
<p class="InputCode">mi estimate, or: logit y x</p>
<p><strong>not:</strong></p>
<p class="InputCode">mi estimate: logit y x, or</p>
<p><span class="InputCode">mi estimate</span> has a list of estimation commands for which it knows Rubin's rules are appropriate. If a command is not on that list, you can tell <span class="InputCode">mi estimate</span> to apply them anyway with the <span class="InputCode">cmdok</span> ("command ok") option. However, it is your responsibility to ensure that the results will be valid.                </p>
<h2 id="SubsamplesBasedonImputedVariables">Subsamples Based on Imputed Variables</h2>
<p>Consider a regression like:                </p>
<p class="InputCode">mi estimate: reg wage edu exp if race==1</p>
<p>If <span class="InputCode">race</span> is an imputed variable, then some observations  will likely have a one for <span class="InputCode">race</span> in some imputations and not others. Thus the subsample to be used will vary between imputations, and <span class="InputCode">mi estimate</span> will give you an error message.</p>
<p>You have two options at this point. One is to simply tell <span class="InputCode">mi estimate</span> to ignore the problem with the <span class="InputCode">esampvaryok</span> option. The Stata documentation says this may result in "may result in biased or inefficient estimates" but we don't have any guidance at this time as to the seriousness of the problem.</p>
<p class="InputCode">mi estimate, esampvaryok: reg wage edu exp if race==1</p>
<p>The other is to not use observations that have imputed values of the variables used to select the subsample. Hopefully you created indicator variables telling you which observations are missing which variables in the process of <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_decide.htm#AreMyDataMCARMARorMNAR">determining whether your data are MCAR, MCAR or MNAR</a> with:</p>
<p class="InputCode">misstable sum, gen(miss_)</p>
<p>If so, you can use those variables as part of your subsample selection:</p>
<p class="InputCode">mi estimate: reg wage edu exp if race==1 &amp; !miss_race</p>
<p>Of course this raises the same issues as complete cases analysis, though the effects will likely be smaller.</p>
<h2>Dropping Variables</h2>
<p>More rarely, you could run into problems with different imputations using different sets of variables. In our experience that's been the result of perfect prediction in some imputations and not others, which suggests problems with the model being run (such as too many categorical covariates for the number of observations available). But it can also arise from the estimation command choosing different base categories. In that case specifying the base category should fix the problem.</p>
<h2 id="Postestimation">Postestimation</h2>
<p>Postestimation with imputed data must be done with caution. Rubin's rules require certain assumptions to be valid, notably asymptotic normality, and if a quantity does not meet those assumptions then Rubin's rules cannot provide a valid estimate of it. Fortunately, regression coefficients do meet those assumptions. Some quantities can be estimated if they are transformed to make them approximately normal, such as R-squared values. Others simply cannot, such as likelihood ratio test statistics. See <a href="http://onlinelibrary.wiley.com.ezproxy.library.wisc.edu/doi/10.1002/sim.4067/pdf">White, Royston, and Wood</a> for a list of quantities that can and cannot be combined using Rubin's Rules. </p>
<p>Unlike standard estimation commands, <span class="InputCode">mi estimate</span> cannot save all the information needed for  postestimation tasks in the <span class="InputCode">e()</span> vector. Some tasks require the <span class="InputCode">e()</span> vector from the regression run on each completed data set. If you're planning to do postestimation, tell <span class="InputCode">mi estimate</span> to store the needed information in a small file with the <span class="InputCode">saving()</span> option:</p>
<p class="InputCode">mi estimate, saving(myestimates, replace): ... </p>
<p>This will create the file <span class="InputCode">myestimates.ster</span> in the current directory.</p>
<h3 id="TestsofCoefficients">Tests of Coefficients</h3>
<p>Hypothesis tests on coefficients can be performed using the <span class="InputCode">mi test</span> command. For testing whether coefficients are equal to zero, the syntax is the same as the regular <span class="InputCode">test</span> command. However, testing transformations or combinations of coefficients is more complicated—type <span class="InputCode">help mi test</span> for more information.</p>
<p>Likelihood ratio tests cannot be performed with multiply imputed data. However, if your goal is to test whether adding covariates  improves your basic model, you can test the hypothesis that the coefficients on all those additional covariates are jointly zero.</p>
<h3 id="Prediction">Prediction</h3>
<p>Predicted values can be treated as parameters to be estimated. Linear predictions meet the assumptions of Rubin's rules and thus they can be computed for each imputation and then combined as usual. This is done using the <span class="InputCode">mi predict</span> command, but <span class="InputCode">mi predict</span> needs the additional information contained in the estimates file saved by <span class="InputCode">mi estimate</span>. Thus the full command is:</p>
<p class="InputCode">mi predict <span class="Parameter">myprediction</span> using <span class="Parameter">myestimates</span></p>
<p>Predicted probabilities do not meet the assumptions of Rubin's rules. However, you can estimate predicted probabilities by first estimating the linear prediction using <span class="InputCode">mi predict</span> and then putting the result through an inverse-logit transformation:</p>
<p class="InputCode">mi predict linear_prediction using myestimates, xb<br/>
                  mi xeq: gen predicted_probability=invlogit(linear_prediction)</p>
<p>The <span class="InputCode">xb</span>  option tells <span class="InputCode">mi predict</span> to calculate the linear prediction even if the most recent regression involved probabilities.</p>
<h2 id="MonteCarloError">Monte Carlo Error and the Number of Imputations</h2>
<p>Since multiple imputation includes a random component, repeating the same analysis will give slightly different results each time (unless you set the seed of the random number generator). This is obviously an undesirable property, but acceptable as long as the amount of variation is small enough to be unimportant. The variation due to the random component is called the Monte Carlo error.</p>
<p><span class="InputCode">mi estimate</span> with the <span class="InputCode">mcerror</span> option will report an  estimate of the  Monte Carlo error in estimation results. The process for calculating it involves leaving out one imputation at a time. <a href="http://onlinelibrary.wiley.com.ezproxy.library.wisc.edu/doi/10.1002/sim.4067/pdf">White, Royston, and Wood</a> suggest the following guidelines for what constitutes an acceptable amount of Monte Carlo error:</p>
<ol>
<li>The Monte Carlo error of a coefficient should be less than or equal to 10% of its standard error</li>
<li>The Monte Carlo error of a coefficient's T-statistic should be less than or equal to 0.1</li>
<li>The Monte Carlo error of a coefficient's P-value should be less than or equal to 0.01 if the true P-value is 0.05, or 0.02 if the true P-value is 0.1</li>
</ol>
<p>If those conditions are not met, you should increase the number of imputations.</p>
<h2>Example</h2>
<p>Consider the example data set we imputed in an <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_impute.htm">earlier section</a>. It contains (fictional) <span class="InputCode">wage</span> data, which we will model using the covariates <span class="InputCode">exp</span>, <span class="InputCode">edu</span>, <span class="InputCode">female</span>, <span class="InputCode">urban</span> and <span class="InputCode">race</span>. Given what we found in the prior section, we will also interact <span class="InputCode">female</span> with <span class="InputCode">exp</span> and <span class="InputCode">edu</span>.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/mi/mi1.dta">Data set to be analyzed (includes imputations)</a></p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/mi/miexan.do">Do file that carries out the analysis</a></p>
<p>Complete cases analysis (obtained with <span class="InputCode">mi xeq 0:</span> since the data set contains imputations) gives the following results:</p>
<p class="InputCode"> mi xeq 0: reg wage  female##(c.exp i.edu) urban i.race</p>
<pre class="InputCode">
m=0 data:
-&gt; reg wage  female##(c.exp i.edu) urban i.race

      Source |       SS       df       MS              Number of obs =    1779
-------------+------------------------------           F( 12,  1766) =   98.93
       Model |  1.0350e+12    12  8.6247e+10           Prob &gt; F      =  0.0000
    Residual |  1.5396e+12  1766   871809267           R-squared     =  0.4020
-------------+------------------------------           Adj R-squared =  0.3979
       Total |  2.5746e+12  1778  1.4480e+09           Root MSE      =   29526

------------------------------------------------------------------------------
        wage |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    1.female |  -7033.218   4180.626    -1.68   0.093    -15232.71    1166.277
         exp |   2004.479    102.498    19.56   0.000     1803.449    2205.509
             |
         edu |
          2  |   10679.82   2634.031     4.05   0.000     5513.673    15845.96
          3  |   28279.73   2844.885     9.94   0.000     22700.03    33859.42
          4  |   51097.61   4591.212    11.13   0.000     42092.83    60102.39
             |
female#c.exp |
          1  |   -511.406   150.6243    -3.40   0.001    -806.8267   -215.9853
             |
  female#edu |
        1 2  |    -5736.4   4041.507    -1.42   0.156    -13663.04     2190.24
        1 3  |  -3876.886   4208.948    -0.92   0.357    -12131.93    4378.159
        1 4  |  -12072.54   5845.627    -2.07   0.039    -23537.62   -607.4622
             |
       urban |   4076.262   1577.229     2.58   0.010     982.8305    7169.694
             |
        race |
          1  |  -4409.319    1739.41    -2.53   0.011    -7820.838   -997.8001
          2  |  -4952.449   1790.243    -2.77   0.006    -8463.667   -1441.232
             |
       _cons |   31591.61   3200.808     9.87   0.000     25313.84    37869.38
------------------------------------------------------------------------------</pre>
<p>Compare with results using the imputations:</p>
<p class="InputCode">mi estimate, saving(miexan,replace): reg wage  female##(c.exp i.edu) urban i.race</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =          5
Linear regression                                 Number of obs   =       3000
                                                  Average RVI     =     0.3261
                                                  Largest FMI     =     0.3672
                                                  Complete DF     =       2987
DF adjustment:   Small sample                     DF:     min     =      35.46
                                                          avg     =     206.66
                                                          max     =     710.00
Model F test:       Equal FMI                     F(  12,  516.3) =     122.88
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
        wage |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    1.female |  -7637.933   3554.531    -2.15   0.034    -14676.67   -599.1996
         exp |   2003.071   82.22401    24.36   0.000     1841.639    2164.502
             |
         edu |
          2  |   12388.95   2190.569     5.66   0.000     8063.544    16714.36
          3  |   28619.32   2443.457    11.71   0.000     23764.93    33473.71
          4  |   51773.01   4248.138    12.19   0.000     43152.79    60393.23
             |
female#c.exp |
          1  |  -459.7754    130.917    -3.51   0.001    -719.6377   -199.9131
             |
  female#edu |
        1 2  |   -5981.89   3390.213    -1.76   0.080     -12676.1    712.3196
        1 3  |   -4640.03   3554.687    -1.31   0.194    -11672.93    2392.866
        1 4  |  -12926.75   5274.621    -2.45   0.018    -23517.89   -2335.615
             |
       urban |   4467.026   1465.326     3.05   0.004     1508.758    7425.294
             |
        race |
          1  |  -3221.866   1394.161    -2.31   0.021    -5960.173    -483.559
          2  |  -5977.193   1579.916    -3.78   0.000    -9123.292   -2831.093
             |
       _cons |   30617.76   2545.795    12.03   0.000     25614.32     35621.2
------------------------------------------------------------------------------</pre>
<p>The 95% confidence intervals are smaller, which is just enough to put the P-value of <span class="InputCode">female</span> under the .05 cutoff for "significance."</p>
<p>These results were calculated with just five imputations, which we suggested as a starting point. How much Monte Carlo error does this leave?</p>
<p class="InputCode">mi estimate, mcerr: reg wage  female##(c.exp i.edu) urban i.race</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =          5
Linear regression                                 Number of obs   =       3000
                                                  Average RVI     =     0.3261
                                                  Largest FMI     =     0.3672
                                                  Complete DF     =       2987
DF adjustment:   Small sample                     DF:     min     =      35.46
                                                          avg     =     206.66
                                                          max     =     710.00
Model F test:       Equal FMI                     F(  12,  516.3) =     122.88
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
        wage |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    1.female |  -7637.933   3554.531    -2.15   0.034    -14676.67   -599.1996
             |   614.5666   219.6112     0.22   0.018     810.9298    823.4979
             |
         exp |   2003.071   82.22401    24.36   0.000     1841.639    2164.502
             |    8.54593   1.876621     0.61   0.000     10.89688    7.715809
             |
             |
         edu |
          2  |   12388.95   2190.569     5.66   0.000     8063.544    16714.36
             |   347.7053   136.7152     0.24   0.000     182.1151    637.3576
             |
          3  |   28619.32   2443.457    11.71   0.000     23764.93    33473.71
             |   453.6681   191.0128     0.92   0.000     628.9118    692.7885
             |
          4  |   51773.01   4248.138    12.19   0.000     43152.79    60393.23
             |   1000.615   225.8875     0.44   0.000     494.3933    1592.194
             |
             |
female#c.exp |
          1  |  -459.7754    130.917    -3.51   0.001    -719.6377   -199.9131
             |   23.88987   6.507623     0.26   0.001     27.60468    30.27696
             |
             |
  female#edu |
        1 2  |   -5981.89   3390.213    -1.76   0.080     -12676.1    712.3196
             |   538.2219   166.8896     0.15   0.024     785.7183    522.4397
             |
        1 3  |   -4640.03   3554.687    -1.31   0.194    -11672.93    2392.866
             |   600.5342   309.3857     0.30   0.090     278.1348    1288.453
             |
        1 4  |  -12926.75   5274.621    -2.45   0.018    -23517.89   -2335.615
             |   1134.893   383.1226     0.21   0.012     1831.385    1154.305
             |
             |
       urban |   4467.026   1465.326     3.05   0.004     1508.758    7425.294
             |   331.6953   169.3962     0.58   0.006     715.5021    340.4445
             |
             |
        race |
          1  |  -3221.866   1394.161    -2.31   0.021    -5960.173    -483.559
             |   155.3758   26.42719     0.10   0.006     183.4623    145.6764
             |
          2  |  -5977.193   1579.916    -3.78   0.000    -9123.292   -2831.093
             |   305.4687   167.2478     0.61   0.001     251.5403    676.1527
             |
             |
       _cons |   30617.76   2545.795    12.03   0.000     25614.32     35621.2
             |   307.1376   84.98822     0.48   0.000     423.9462     281.053
------------------------------------------------------------------------------
Note: values displayed beneath estimates are Monte Carlo error estimates.</pre>
<p>A brief glance at the estimates for <span class="InputCode">female</span> shows this does not meet the suggested criteria: the Monte Carlo error on the coefficient is about 17% of the standard error rather than 10%, and the Monte Carlo error on the P-value is .018 when we'd want it to be less than .01 if we believe the true P-value is .05 or less. This suggests you should use more imputations.</p>
<p>Even if it turned out that the Monte Carlo error was acceptable, we'd still recommend using more imputations in this case. About 40% of the observations are missing values, so White, Royston, and Wood would suggest 40 imputations. While that may seem like a lot, the entire process from imputation to analysis (including many diagnostics) still ran in less than 15 minutes in our testing. Thus there's no reason not to use at least that many imputations when you're ready to produce final results.</p>
<p> Here are the results with 40 imputations, and you'll see that the Monte Carlo error now meets the guidelines:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         40
Linear regression                                 Number of obs   =       3000
                                                  Average RVI     =     0.2340
                                                  Largest FMI     =     0.2505
                                                  Complete DF     =       2987
DF adjustment:   Small sample                     DF:     min     =     494.37
                                                          avg     =     723.63
                                                          max     =    1046.30
Model F test:       Equal FMI                     F(  12, 2407.3) =     134.54
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
        wage |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
    1.female |  -8444.446   3568.764    -2.37   0.018    -15450.36   -1438.528
             |   242.2941   70.94422     0.08   0.004      294.817    266.1893
             |
         exp |   1981.635   90.55428    21.88   0.000      1803.76    2159.509
             |   6.812604   2.379668     0.61   0.000     9.595854    6.819707
             |
             |
         edu |
          2  |   11896.82   2277.964     5.22   0.000     7423.364    16370.28
             |   164.9826    51.1388     0.14   0.000     200.7386    187.6542
             |
          3  |   28702.41   2405.316    11.93   0.000      23980.9    33423.92
             |   160.1252   56.74204     0.31   0.000     218.7132    170.9788
             |
          4  |   52000.64   3991.622    13.03   0.000        44158    59843.27
             |   310.4559   94.26391     0.35   0.000     426.0258    288.6724
             |
             |
female#c.exp |
          1  |  -435.3699   126.7969    -3.43   0.001     -684.175   -186.5648
             |   7.621008   1.908626     0.08   0.000     8.635785    8.400978
             |
             |
  female#edu |
        1 2  |  -5278.077   3463.037    -1.52   0.128    -12076.34    1520.188
             |   234.4022   91.09243     0.07   0.017     330.3471    259.2769
             |
        1 3  |  -4498.973   3525.953    -1.28   0.202    -11418.57    2420.619
             |   220.3948   79.45707     0.07   0.025     265.3468    277.5948
             |
        1 4  |   -11832.2   4963.477    -2.38   0.017    -21576.09   -2088.301
             |   336.8887   98.06887     0.08   0.004     383.8081    395.9982
             |
             |
       urban |   4301.578     1351.3     3.18   0.002     1648.864    6954.293
             |   91.36621   21.07064     0.09   0.000     104.6887    96.41936
             |
             |
        race |
          1  |  -3478.967   1540.658    -2.26   0.024    -6505.774   -452.1594
             |   118.6348   35.97534     0.11   0.006     120.0791    155.5802
             |
          2  |  -5657.502   1575.349    -3.59   0.000    -8751.359   -2563.646
             |   115.2371   35.82667     0.12   0.000     120.9807    149.2301
             |
             |
       _cons |   31156.05   2678.619    11.63   0.000     25898.25    36413.85
             |   176.8282   54.19707     0.23   0.000     177.3412    233.6436
------------------------------------------------------------------------------
Note: values displayed beneath estimates are Monte Carlo error estimates.</pre>
<p>One reasonable question is whether the interactions are actually required, and with unimputed data one might use a likelihood ratio test to answer it. With imputed data you'll instead test whether the coefficients on the interaction terms are jointly equal to zero:</p>
<p class="InputCode">mi test 1.female#c.exp 1.female#2.edu 1.female#3.edu 1.female#4.edu</p>
<pre class="InputCode">note: assuming equal fractions of missing information

 ( 1)  1.female#c.exp = 0
 ( 2)  1.female#2.edu = 0
 ( 3)  1.female#3.edu = 0
 ( 4)  1.female#4.edu = 0

       F(  4, 156.0) =    4.63
            Prob &gt; F =    0.0015</pre>
<p>Given that some of the terms are significantly different from zero on their own, it's no surprise that the joint test rejects the hypothesis that they are all zero.</p>
<p>Finally, if we wanted to calculate predicted wages, we would use the following:</p>
<p class="InputCode">mi predict wagehat using miexan</p>
<p>Note the use of the <span class="InputCode">miexan.ster</span> file (without needing to specify the extension) created by the initial <span class="InputCode">mi estimate</span> command. It contains the coefficients from the regressions on each completed data set, which are needed to form the individual predictions combined by <span class="InputCode">mi predict</span>.</p>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm">Examples</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_manage.htm">Managing Multiply Imputed Data</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Multiple Imputation Examples</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p><em>This article is part of the Multiple Imputation in Stata series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_intro.htm">Introduction</a>.</em></p>
<p>This article contains examples that illustrate some of the issues involved in using multiple imputation. Articles in the <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm">Multiple Imputation in Stata</a> series refer to these examples, and more discussion of the principles involved can be found in those articles. However, it is possible to read this article independently, or to just read about the particular example that interests you (see the list of examples below).</p>
<p> These examples are not intended to test the validity of the techniques used or rigorously compare their effectiveness. However, they should give you some intuition about how they work and their strengths and weaknesses. Some of the simulation parameters (and occasionally the seed for the random number generator) were chosen in order to highlight the issue at hand, but none of them are atypical of real-world situations. The data are generated randomly from standard distributions in such a way that the "right" answers are known and you can see how closely different techniques approach those answers.</p>
<p>A Stata do file is provided for each example, along with commentary and selected output (in this web page). The do file also generates the data set used, with a set seed for reproducibility. Our suggestion is that you open the do file in Stata's do file editor or your favorite text editor and read it in parallel with the discussion in the article. Please note that the example do files are not intended to demonstrate the entire process of multiple imputation—they don't always check the fit or convergence of the imputation models, for example, which are very important things to do in real world use of multiple imputation.</p>
<p>Each example concludes with a "Lessons Learned" section, but we'd like to highlight one overall lesson: <em>Multiple imputation can be a useful tool, but there are many ways to get it wrong and invalidate your results. Be very careful, and don't expect it to be quick and easy.</em></p>
<p>The examples are:</p>
<ol>
<li><a href="#Power">Power</a></li>
<li><a href="#MCARvsMARvsMNAR">MCAR vs. MAR vs. MNAR</a></li>
<li><a href="#ImputingtheDependentVariable">Imputing the Dependent Variable</a></li>
<li><a href="#Non-NormalData">Non-Normal Data</a></li>
<li><a href="#Transformations">Transformations</a></li>
<li><a href="#Non-Linearity">Non-Linearity</a></li>
<li><a href="#Interactions">Interactions</a></li>
</ol>
<p> </p>
<h2><a id="Power" name="Power"></a>Power</h2>
<p>The most common motivation for using multiple imputation is to try to increase the power of statistical tests by increasing the number of observations used (i.e. by not losing observations due to missing values). In our experience it rarely makes a large difference in practice. This example uses ideal circumstances to illustrate what extremely successful multiple imputation would look like.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/mi/power.do">Code for this example</a></p>
<h3>Data</h3>
<p><strong>Observations</strong>: 1,000</p>
<p><strong>Variables</strong>:</p>
<ul>
<li><span class="InputCode">x1</span>-<span class="InputCode">x10</span> drawn from standard normal distribution (independently)</li>
<li><span class="InputCode">y</span> is the sum of all <span class="InputCode">x</span>'s, plus a normal error term</li>
</ul>
<p><strong>Missingness</strong>: Each value of the <span class="InputCode">x</span> variables has a 10% chance of being missing (MCAR).</p>
<p><strong>Right Answers</strong>: Regressing <span class="InputCode">y</span> on all the <span class="InputCode">x</span>'s, each <span class="InputCode">x</span> should have a coefficient of 1.</p>
<h3>Procedure</h3>
<p>Begin with complete cases analysis:</p>
<pre class="InputCode">      Source |       SS       df       MS              Number of obs =     369
-------------+------------------------------           F( 10,   358) =    6.71
       Model |  3882.86207    10  388.286207           Prob &gt; F      =  0.0000
    Residual |  20722.7734   358   57.884842           R-squared     =  0.1578
-------------+------------------------------           Adj R-squared =  0.1343
       Total |  24605.6355   368    66.86314           Root MSE      =  7.6082

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
          x1 |    .733993   .4216582     1.74   0.083    -.0952453    1.563231
          x2 |   1.664231   .3867292     4.30   0.000      .903684    2.424777
          x3 |    1.51406   .3907875     3.87   0.000     .7455327    2.282588
          x4 |   .2801067    .395164     0.71   0.479    -.4970278    1.057241
          x5 |   .8524305   .4076557     2.09   0.037     .0507297    1.654131
          x6 |   .7704437    .413519     1.86   0.063     -.042788    1.583675
          x7 |   .6512155   .3938107     1.65   0.099    -.1232575    1.425689
          x8 |   .9173208   .3969585     2.31   0.021     .1366572    1.697984
          x9 |   .8736406   .4115488     2.12   0.034     .0642835    1.682998
         x10 |   .9222064   .4123417     2.24   0.026       .11129    1.733123
       _cons |  -.1999121   .3975523    -0.50   0.615    -.9817434    .5819192
------------------------------------------------------------------------------</pre>
<p>Note that although each <span class="InputCode">x</span> value has just a 10% chance of being missing, because we have ten <span class="InputCode">x</span> variables per observation almost 2/3 of the observations are missing at least one value and must be dropped. As a result, the standard errors are quite large, and the coefficients on four of the ten <span class="InputCode">x</span>'s are not significantly different from zero.</p>
<p>After multiple imputation, the same regression gives the following:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =       1000
                                                  Average RVI     =     0.1483
                                                  Largest FMI     =     0.2356
                                                  Complete DF     =        989
DF adjustment:   Small sample                     DF:     min     =     142.63
                                                          avg     =     425.17
                                                          max     =     928.47
Model F test:       Equal FMI                     F(  10,  802.0) =      18.13
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
          x1 |    .793598   .2679515     2.96   0.003     .2657743    1.321422
          x2 |   1.133405   .2482047     4.57   0.000     .6460259    1.620785
          x3 |    1.33182   .2521916     5.28   0.000     .8364684    1.827172
          x4 |   1.159887   .2714759     4.27   0.000      .624309    1.695465
          x5 |   1.181207   .2901044     4.07   0.000      .607747    1.754667
          x6 |   1.305636   .2835268     4.60   0.000     .7466279    1.864645
          x7 |   .6258813   .2568191     2.44   0.015      .121268    1.130494
          x8 |   1.143631    .253376     4.51   0.000     .6461328     1.64113
          x9 |   1.112347   .2838261     3.92   0.000     .5520503    1.672644
         x10 |   1.053309   .2612807     4.03   0.000     .5397648    1.566854
       _cons |   .0305628   .2499378     0.12   0.903    -.4599457    .5210712
------------------------------------------------------------------------------</pre>
<p>The standard errors are much smaller than with complete cases analysis, and all of the coefficients are  significantly different from zero. This illustrates the primary motivation for using multiple imputation.</p>
<h3>Lessons Learned</h3>
<p>This data set is ideal for multiple imputation because it has large numbers of observations with partial data. Complete cases analysis must discard all these observations. Multiple imputation can use the information they contain to improve the results.</p>
<p>Note that the imputation model could not do a very good job of predicting the missing values of the <span class="InputCode">x</span>'s based on the observed data. The <span class="InputCode">x</span>'s are completely independent of each other and thus have no predictive power. <span class="InputCode">y</span> has some but not much: if you regress each <span class="InputCode">x</span> on <span class="InputCode">y</span> and all the other <span class="InputCode">x</span>'s (which is what the  imputation model used does), the R-squared values are all less than 0.1 and most are less than 0.03.  The success of multiple imputation does not depend on imputing the "right" values of the missing variables for individual observations, but rather on correctly modeling their distribution conditional on the observed data.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_decide.htm#Power">Return to the source article</a></p>
<h3></h3>
<h2><a id="MCARvsMARvsMNAR" name="MCARvsMARvsMNAR"></a>MCAR vs. MAR vs. MNAR</h2>
<p>Whether your data are Missing Completely at Random (probability of being missing does not depend on either observed or unobserved data), Missing at Random (probability of being missing depends only on observed data), or Missing Not at Random (probability of being missing depends on unobserved data) is very important in deciding how to analyze it. This example shows how complete cases analysis and multiple imputation respond to different mechanisms for missingness.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/mi/missmech.do">Code for this example</a></p>
<h3>Data</h3>
<p><strong>Observations</strong>: 1,000</p>
<p><strong>Variables</strong>:</p>
<ul>
<li><span class="InputCode">x</span> is drawn from standard normal distribution</li>
<li><span class="InputCode">y</span> is x plus a normal error term</li>
</ul>
<p><strong>Missingness</strong>:</p>
<ul>
<li><span class="InputCode">y</span> is always observed</li>
<li>First run: probability of <span class="InputCode">x</span> being missing is 10% for all observations (MCAR)</li>
<li>Second run: probability of <span class="InputCode">x</span> being missing is proportional to <span class="InputCode">y</span> (MAR)</li>
<li>Third run: probability of <span class="InputCode">x</span> being missing is proportional to x (MNAR)</li>
</ul>
<p><strong>Right Answers</strong>: Regressing <span class="InputCode">y</span> on <span class="InputCode">x</span>, <span class="InputCode">x</span> should have a coefficient of 1.</p>
<h3>Procedure</h3>
<p>We'll analyze this data set three times, once when it is MCAR, once when it is MAR, and once when it is MNAR.</p>
<h4>MCAR</h4>
<p>In the first run, the data set is MCAR and both complete cases analysis and multiple imputation give unbiased results.</p>
<p>Complete cases analysis:</p>
<pre class="InputCode">      Source |       SS       df       MS              Number of obs =     882
-------------+------------------------------           F(  1,   880) =  932.47
       Model |   918.60551     1   918.60551           Prob &gt; F      =  0.0000
    Residual |  866.913167   880  .985128598           R-squared     =  0.5145
-------------+------------------------------           Adj R-squared =  0.5139
       Total |  1785.51868   881  2.02669543           Root MSE      =  .99254

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   .9842461   .0322319    30.54   0.000     .9209858    1.047506
       _cons |  -.0481664   .0334249    -1.44   0.150    -.1137683    .0174354
------------------------------------------------------------------------------
</pre>
<p>Multiple imputation:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =       1000
                                                  Average RVI     =     0.1112
                                                  Largest FMI     =     0.1583
                                                  Complete DF     =        998
DF adjustment:   Small sample                     DF:     min     =     262.51
                                                          avg     =     541.98
                                                          max     =     821.46
Model F test:       Equal FMI                     F(   1,  821.5) =    1014.02
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   .9837383   .0308928    31.84   0.000     .9231003    1.044376
       _cons |  -.0377668   .0342445    -1.10   0.271    -.1051958    .0296621
------------------------------------------------------------------------------</pre>
<h4>MAR</h4>
<p>Now, consider the case where the probability of <span class="InputCode">x</span> being missing is proportional to <span class="InputCode">y</span> (which is always observed), making the data MAR. With MAR data, complete cases analysis is biased:</p>
<pre class="InputCode">      Source |       SS       df       MS              Number of obs =     652
-------------+------------------------------           F(  1,   650) =  375.85
       Model |  252.090968     1  252.090968           Prob &gt; F      =  0.0000
    Residual |  435.966034   650  .670716976           R-squared     =  0.3664
-------------+------------------------------           Adj R-squared =  0.3654
       Total |  688.057002   651   1.0569232           Root MSE      =  .81897

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   .6857927    .035374    19.39   0.000     .6163317    .7552538
       _cons |   -.558313   .0352209   -15.85   0.000    -.6274736   -.4891525
------------------------------------------------------------------------------</pre>
<p>However, multiple imputation gives unbiased estimates:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =       1000
                                                  Average RVI     =     0.4234
                                                  Largest FMI     =     0.3335
                                                  Complete DF     =        998
DF adjustment:   Small sample                     DF:     min     =      78.63
                                                          avg     =      90.20
                                                          max     =     101.78
Model F test:       Equal FMI                     F(   1,   78.6) =     750.78
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   .9909115   .0361642    27.40   0.000     .9189232      1.0629
       _cons |  -.0544014   .0366092    -1.49   0.140    -.1270175    .0182146
------------------------------------------------------------------------------</pre>
<h4>MNAR</h4>
<p>Finally  consider the case where the probability of <span class="InputCode">x</span> being missing proportional to <span class="InputCode">x</span>. This makes the data missing not at random (MNAR), and with MNAR data both complete cases analysis and multiple imputation are biased.</p>
<p>Complete cases analysis:</p>
<pre class="InputCode">      Source |       SS       df       MS              Number of obs =     679
-------------+------------------------------           F(  1,   677) =  463.29
       Model |   464.94386     1   464.94386           Prob &gt; F      =  0.0000
    Residual |  679.422756   677  1.00357866           R-squared     =  0.4063
-------------+------------------------------           Adj R-squared =  0.4054
       Total |  1144.36662   678  1.68785636           Root MSE      =  1.0018

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   1.093581   .0508074    21.52   0.000     .9938225     1.19334
       _cons |   .0420364   .0469578     0.90   0.371     -.050164    .1342368
------------------------------------------------------------------------------</pre>
<p>Multiple imputation:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =       1000
                                                  Average RVI     =     0.3930
                                                  Largest FMI     =     0.3425
                                                  Complete DF     =        998
DF adjustment:   Small sample                     DF:     min     =      74.96
                                                          avg     =     144.00
                                                          max     =     213.04
Model F test:       Equal FMI                     F(   1,   75.0) =     561.03
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   1.223772   .0516665    23.69   0.000     1.120846    1.326698
       _cons |   .3816984   .0402614     9.48   0.000     .3023366    .4610602
------------------------------------------------------------------------------</pre>
<p>Complete cases analysis actually does better with this particular data set, but that's not true in general.</p>
<h3>Lessons Learned</h3>
<p>Always investigate whether your data set is plausibly MCAR or MAR. (For example, run logits on indicators of missingness and see if anything predicts it—if it does the data set is MAR rather than MCAR.) If your data set is MAR,  consider using multiple imputation rather than complete cases analysis.</p>
<p> MNAR, by definition, cannot be detected by looking at the observed data. You'll have to think carefully about how the data was collected and consider whether some values of the variables might make the data more or less likely to be observed. Unfortunately, the options for working with MNAR data are limited.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_decide.htm#missmech">Return to the source article</a></p>
<h2><a id="ImputingtheDependentVariable" name="ImputingtheDependentVariable"></a>Imputing the Dependent Variable</h2>
<p>Many researchers believe it is inappropriate to use imputed values of the dependent variable in the analysis model, especially if the variables used in the imputation model are the same as the variables used in the analysis model. The thinking is that the imputed values add no information since they were generated using the model that is being analyzed.</p>
<p>Unfortunately, this sometimes is misunderstood as meaning that the dependent variable should not be included in the imputation model. That would be a major mistake.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/mi/imputey.do">Complete code for this example</a></p>
<h3>Data</h3>
<p><strong>Observations</strong>: 1,000</p>
<p><strong>Variables</strong>:</p>
<ul>
<li><span class="InputCode">x1</span>-<span class="InputCode">x3</span> drawn from standard normal distribution (independently)</li>
<li><span class="InputCode">y</span> is the sum of all <span class="InputCode">x</span>'s, plus a normal error term</li>
</ul>
<p><strong>Missingness</strong>: <span class="InputCode">y</span> and <span class="InputCode">x1-x3</span> have a 20% probability of being missing (MCAR).</p>
<p><strong>Right Answers</strong>: Regressing <span class="InputCode">y</span> on <span class="InputCode">x1-x3</span>, the coefficient on each should be 1.</p>
<h3>Procedure</h3>
<p>The following are the results of complete cases analysis:</p>
<pre class="InputCode">      Source |       SS       df       MS              Number of obs =    4079
-------------+------------------------------           F(  3,  4075) = 3944.41
       Model |  12264.8582     3  4088.28608           Prob &gt; F      =  0.0000
    Residual |  4223.63457  4075  1.03647474           R-squared     =  0.7438
-------------+------------------------------           Adj R-squared =  0.7437
       Total |  16488.4928  4078  4.04327926           Root MSE      =  1.0181

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
          x1 |   .9834974   .0160921    61.12   0.000     .9519481    1.015047
          x2 |   1.000172   .0160265    62.41   0.000     .9687511    1.031593
          x3 |   1.003089   .0159724    62.80   0.000     .9717744    1.034404
       _cons |  -.0003362   .0159445    -0.02   0.983    -.0315962    .0309238
------------------------------------------------------------------------------</pre>
<p>If you leave <span class="InputCode">y</span> out of the imputation model, imputing only <span class="InputCode">x1-x3</span>, the coefficients on the <span class="InputCode">x</span>'s in the final model are biased towards zero:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =       7993
                                                  Average RVI     =     0.4014
                                                  Largest FMI     =     0.3666
                                                  Complete DF     =       7989
DF adjustment:   Small sample                     DF:     min     =      72.62
                                                          avg     =     119.53
                                                          max     =     161.84
Model F test:       Equal FMI                     F(   3,  223.0) =    1761.75
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
          x1 |   .7946113   .0185175    42.91   0.000     .7580219    .8312007
          x2 |   .7983325   .0199962    39.92   0.000     .7584766    .8381885
          x3 |   .8001109   .0193738    41.30   0.000     .7616436    .8385782
       _cons |   .0041643   .0183891     0.23   0.821    -.0321492    .0404778
------------------------------------------------------------------------------</pre>
<p>Why is that? An easy way to see the problem is to look at correlations. First, the correlation between <span class="InputCode">y</span> and <span class="InputCode">x1</span> in the unimputed data:</p>
<pre class="InputCode">            |        y       x1
-------------+------------------
           y |   1.0000
          x1 |   0.5032   1.0000</pre>
<p>Now, the correlation between <span class="InputCode">y</span> and <span class="InputCode">x1</span> for those observations where <span class="InputCode">x1</span> is imputed (this is calculated for the first imputation, but the others are similar):</p>
<pre class="InputCode">             |        y       x1
-------------+------------------
           y |   1.0000
          x1 |  -0.0073   1.0000</pre>
<p>Because <span class="InputCode">y</span> is not included in the imputation model, the imputation model creates values of <span class="InputCode">x1</span> (and <span class="InputCode">x2</span> and <span class="InputCode">x3</span>) which are not correlated with <span class="InputCode">y</span>. This does not match the observed data. It also biases the results of the final model by adding observations in which <span class="InputCode">y</span> really is unrelated to <span class="InputCode">x1</span>, <span class="InputCode">x2,</span> and <span class="InputCode">x3</span>.</p>
<p>This problem goes away if <span class="InputCode">y</span> is included in the imputation model. Given the nature of chained equations, this means that values of <span class="InputCode">y </span>must be imputed. However, you're under no obligation to use those values in your analysis model. Simply create an indicator variable for "<span class="InputCode">y</span> is missing in the observed data," which can be done automatically with <span class="InputCode">misstable sum, gen(miss_)</span>, and then add <span class="InputCode">if !miss_y</span> to the regression command. This restricts the regression to those observations where <span class="InputCode">y</span> is actually observed, so any imputed values of <span class="InputCode">y</span> are not used. Here are the results:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =       7993
                                                  Average RVI     =     0.6402
                                                  Largest FMI     =     0.5076
                                                  Complete DF     =       7989
DF adjustment:   Small sample                     DF:     min     =      38.27
                                                          avg     =      82.39
                                                          max     =     182.83
Model F test:       Equal FMI                     F(   3,  137.9) =    4691.72
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
          x1 |   .9852388   .0150348    65.53   0.000     .9550372     1.01544
          x2 |   .9923264   .0158077    62.77   0.000     .9603327     1.02432
          x3 |   .9936324   .0129186    76.91   0.000     .9681437    1.019121
       _cons |  -.0015309   .0145755    -0.11   0.917    -.0306997    .0276378
------------------------------------------------------------------------------</pre>
<p>On the other hand, using the imputed values of <span class="InputCode">y</span> turns out to make almost no difference in this case (see the complete code).</p>
<h3>Lessons Learned</h3>
<p>Always include the dependent variable in your imputation model. Whether you should use imputed values of the dependent variable in your analysis model is unclear, but always impute them.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_models.htm#depvar">Return to the source article</a></p>
<h2><a id="Non-NormalData" name="Non-NormalData"></a>Non-Normal Data</h2>
<p>The obvious way to impute a continuous variable is regression (i.e. the <span class="InputCode">regress</span> command in <span class="InputCode">mi impute chained</span>). However, it applies a normal error term. What happens if a variable is not at all normally distributed?</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/mi/nonnormal.do">Complete code for this example</a></p>
<h3>Data</h3>
<p><strong>Observations</strong>: 10,000</p>
<p><strong>Variables</strong>:</p>
<ul>
<li><span class="InputCode">g</span> is a binary (1/0) variable with a 50% probability of being 1</li>
<li><span class="InputCode">x</span> is drawn from the standard normal distribution, then 5 is added if <span class="InputCode">g</span> is 1. Thus <span class="InputCode">x</span> is bimodal.</li>
<li><span class="InputCode">y</span> is <span class="InputCode">x</span> plus a normal error term</li>
</ul>
<p><strong>Missingness</strong>: Both <span class="InputCode">y</span> and <span class="InputCode">x</span> have a 10% probability of being missing (MCAR).</p>
<p><strong>Right Answers</strong>: Regressing <span class="InputCode">y</span> on  <span class="InputCode">x</span>, <span class="InputCode">x</span> should have a coefficient of 1.</p>
<h3>Procedure</h3>
<p>Given the way <span class="InputCode">x</span> was constructed, it has a bimodal distribution and is definitely not normal:</p>
<p><img alt="Original distribution of x" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/nonnormal1.png" width="585"/></p>
<p>The obvious imputation model (regress <span class="InputCode">x</span> on <span class="InputCode">y</span>) captures some of this bimodality because of the influence of <span class="InputCode">y</span>. However, the error term is normal and does not take into account the non-normal distribution of the data. Thus this model is too likely to create imputed values that are near 2.5 (the "valley" between the two "peaks") and the distribution of the imputed data is "too normal":</p>
<p><img alt="x imputed with regression--too normal" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/nonnormal2.png" width="585"/></p>
<p>However, the regression results are quite good:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =      10000
                                                  Average RVI     =     0.2471
                                                  Largest FMI     =     0.1977
                                                  Complete DF     =       9998
DF adjustment:   Small sample                     DF:     min     =     238.92
                                                          avg     =     414.68
                                                          max     =     590.43
Model F test:       Equal FMI                     F(   1,  590.4) =   63916.86
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   1.001225   .0039603   252.82   0.000     .9934473    1.009003
       _cons |  -.0068119   .0152489    -0.45   0.655    -.0368514    .0232276
------------------------------------------------------------------------------</pre>
<p>Replacing regression with Predictive Mean Matching gives a much better fit. PMM begins with regression, but it then finds the observed value of <span class="InputCode">x</span> that is the nearest match. Because there are fewer observed values in the "valley" PMM is less likely to find a match there, resulting in a distribution that is closer to the original:</p>
<p><img alt="x imputed with pmm--much better fit" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/nonnormal3.png" width="585"/></p>
<p>Regression results after imputing with PMM are also good:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =      10000
                                                  Average RVI     =     0.2885
                                                  Largest FMI     =     0.2698
                                                  Complete DF     =       9998
DF adjustment:   Small sample                     DF:     min     =     131.79
                                                          avg     =     148.15
                                                          max     =     164.50
Model F test:       Equal FMI                     F(   1,  131.8) =   53733.02
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   .9976108   .0043037   231.80   0.000     .9890976    1.006124
       _cons |   .0105094   .0156034     0.67   0.502    -.0202993    .0413181
------------------------------------------------------------------------------</pre>
<p>On the other hand, <span class="InputCode">x</span> is distributed normally within each <span class="InputCode">g</span> group. If you impute the two groups separately then  ordinary regression fits the data quite well:</p>
<p><img alt="x imputed with regression, but separately for the two groups" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/nonnormal4.png" width="585"/></p>
<p>The regression results are also good:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =      10000
                                                  Average RVI     =     0.6503
                                                  Largest FMI     =     0.4656
                                                  Complete DF     =       9998
DF adjustment:   Small sample                     DF:     min     =      45.53
                                                          avg     =      63.49
                                                          max     =      81.45
Model F test:       Equal FMI                     F(   1,   81.4) =   48664.75
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   .9996345   .0045314   220.60   0.000     .9906191     1.00865
       _cons |   .0032657   .0183149     0.18   0.859    -.0336105    .0401419
------------------------------------------------------------------------------</pre>
<h3>Lessons Learned</h3>
<p>PMM can be a very effective tool for imputing non-normal data. On the other hand, if you can identify groups whose data may vary in systematically different ways, consider imputing them separately.</p>
<p>However, the regression results were uniformly good, even when the data were imputed using the original regression model where the distribution of the imputed values didn't match the distribution of the observed values very well. In part this is because we had a large number of observations and a simple model, but in general the relationship between face validity and getting valid estimates using the imputed data is   unclear.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_models.htm#nonnorm">Return to the source article</a></p>
<h2><a id="Transformations" name="Transformations"></a>Transformations</h2>
<p>Given non-normal data, it's appealing to try to transform it in a way that makes it more normal. But what if the other variables in the model are related to the original values of the variable rather than the transformed values?</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/mi/transform.do">Complete code for this example</a></p>
<h3>Data</h3>
<p><strong>Observations</strong>: 10,000</p>
<p><strong>Variables</strong>:</p>
<ul>
<li><span class="InputCode">x1</span> is drawn from the standard normal distribution, then exponentiated. Thus it is log-normal</li>
<li><span class="InputCode">x2</span> is drawn from the standard normal distribution</li>
<li><span class="InputCode">y</span> is the sum of <span class="InputCode">x1</span>, <span class="InputCode">x2</span> and  a normal error term</li>
</ul>
<p><strong>Missingness</strong>: <span class="InputCode">x1</span>, <span class="InputCode">x2</span> and <span class="InputCode">y</span> have a 10% probability of being missing (MCAR)</p>
<p><strong>Right Answers</strong>: Regressing <span class="InputCode">y</span> on  <span class="InputCode">x1</span> and <span class="InputCode">x2</span>, both should have a coefficient of 1.</p>
<h3>Procedure</h3>
<p>First, complete cases analysis for comparison. It does quite well, as we'd expect with MCAR data (and a simple model with lots of observations):</p>
<pre class="InputCode">      Source |       SS       df       MS              Number of obs =    7299
-------------+------------------------------           F(  2,  7296) =19024.33
       Model |  38421.4045     2  19210.7023           Prob &gt; F      =  0.0000
    Residual |  7367.47472  7296  1.00979643           R-squared     =  0.8391
-------------+------------------------------           Adj R-squared =  0.8391
       Total |  45788.8793  7298  6.27416816           Root MSE      =  1.0049

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
          x1 |   1.001594   .0057231   175.01   0.000     .9903751    1.012813
          x2 |   .9973623   .0117407    84.95   0.000     .9743471    1.020377
       _cons |   .0035444   .0149663     0.24   0.813     -.025794    .0328827
------------------------------------------------------------------------------</pre>
<p>This data set presents a dilemma for imputation: <span class="InputCode">x1</span> can be made normal simply by taking its log, but <span class="InputCode">y</span> is related to <span class="InputCode">x1</span>, not the log of <span class="InputCode">x1</span>. Regressing <span class="InputCode">ln(x1)</span> on <span class="InputCode">x2</span> and <span class="InputCode">y</span> (as the obvious imputation model will do) results in the following plot of residuals vs. fitted values (<span class="InputCode">rvfplot</span>):</p>
<p><img alt="rvfplot--the pattern indicates that the model is mispecified" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/transform1.png" width="585"/></p>
<p>If the model were specified correctly, we'd expect the points to be randomly distributed around the <span class="InputCode">y</span> axis regardless of their <span class="InputCode">x</span> location. Clearly that's not the case.</p>
<p>The obvious way to impute this data would be to:</p>
<ol>
<li>Log transform <span class="InputCode">x1</span> by creating <span class="InputCode">lnx1 = ln(x1)</span></li>
<li>Impute <span class="InputCode">lnx1</span> using regression</li>
<li>Create the passive variable <span class="InputCode">ix1 = exp(lnx1)</span> to reverse the transformation</li>
</ol>
<p>Here are the regression results after doing so:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =      10000
                                                  Average RVI     =   196.4421
                                                  Largest FMI     =     0.9987
                                                  Complete DF     =       9997
DF adjustment:   Small sample                     DF:     min     =       5.89
                                                          avg     =     242.41
                                                          max     =     701.09
Model F test:       Equal FMI                     F(   2,   12.8) =       3.84
Within VCE type:          OLS                     Prob &gt; F        =     0.0493

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         ix1 |    .014417   .0213705     0.67   0.525    -.0381112    .0669452
          x2 |   .9951566   .0235333    42.29   0.000     .9489525    1.041361
       _cons |   1.583044   .0384844    41.13   0.000     1.502835    1.663253
------------------------------------------------------------------------------</pre>
<p>As you see, the coefficient on <span class="InputCode">ix1</span> (imputed untransformed <span class="InputCode">x1</span>) is very strongly biased towards zero. Now try imputing <span class="InputCode">lnx1</span> using Predictive Mean Matching rather than regression:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =      10000
                                                  Average RVI     =     0.7058
                                                  Largest FMI     =     0.6292
                                                  Complete DF     =       9997
DF adjustment:   Small sample                     DF:     min     =      24.80
                                                          avg     =      53.56
                                                          max     =      74.84
Model F test:       Equal FMI                     F(   2,   52.8) =    8286.63
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         ix1 |   .9554301    .009311   102.61   0.000     .9362457    .9746144
          x2 |   .9537128   .0146582    65.06   0.000     .9245112    .9829144
       _cons |   .0843407   .0192948     4.37   0.000     .0457588    .1229226
------------------------------------------------------------------------------</pre>
<p>Now both coefficients are biased towards zero, though not nearly as strongly.</p>
<p>What if we simply ignore the fact that <span class="InputCode">x1</span> is not normally distributed and impute it directly? The results are actually  better:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =      10000
                                                  Average RVI     =     0.3873
                                                  Largest FMI     =     0.3401
                                                  Complete DF     =       9997
DF adjustment:   Small sample                     DF:     min     =      84.25
                                                          avg     =     179.94
                                                          max     =     337.16
Model F test:       Equal FMI                     F(   2,  133.4) =   17538.58
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
          x1 |   .9980159   .0060605   164.68   0.000     .9859646    1.010067
          x2 |   .9912113   .0117879    84.09   0.000      .967869    1.014554
       _cons |   .0108679   .0140238     0.77   0.439    -.0167172     .038453
------------------------------------------------------------------------------</pre>
<p>This clearly works well, but raises the question of face validity. Here is a kernel density plot of the observed values of <span class="InputCode">x1</span>:</p>
<p><img alt="kdensity of observed, log-normal data" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/transform2.png" width="585"/></p>
<p>Here is a kernel density plot of the imputed values of <span class="InputCode">x1</span>:</p>
<p><img alt="kdensity of imputed data--many values &lt;0, too spread out" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/transform3.png" width="585"/></p>
<p>The obvious problem is that the imputed values of <span class="InputCode">x1</span> are frequently less than zero while the observed values of <span class="InputCode">x1</span> are always positive. This would be especially problematic if you thought you might want to use a log transform later in the process.</p>
<p>Given the constraint that <span class="InputCode">x1</span> cannot be less than zero, <span class="InputCode">truncreg</span> seems like a plausible alternative. Unfortunately, <span class="InputCode">truncreg</span> fails to converge for this data set (for reasons not yet clear to us). But PMM will also honor that constraint:</p>
<p><img alt="kdensity plot of imputed x1 using PMM" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/transform5.png" width="585"/></p>
<p>Here are the regression results with PMM:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =      10000
                                                  Average RVI     =     0.3702
                                                  Largest FMI     =     0.3664
                                                  Complete DF     =       9997
DF adjustment:   Small sample                     DF:     min     =      72.89
                                                          avg     =     147.11
                                                          max     =     193.33
Model F test:       Equal FMI                     F(   2,  145.1) =   17890.15
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
          x1 |   1.000568   .0056325   177.64   0.000     .9894588    1.011677
          x2 |   .9977033    .012447    80.16   0.000     .9728958    1.022511
       _cons |    .009171    .014612     0.63   0.531    -.0196674    .0380094
------------------------------------------------------------------------------</pre>
<h3>Lessons Learned</h3>
<p>The lesson of this example is not that you should never transform covariates. Keep in mind that what makes transforming <span class="InputCode">x1</span> problematic in this example is that the relationship between <span class="InputCode">y</span> and <span class="InputCode">x1</span> is known to be linear.</p>
<p> The real lesson is that misspecification in your imputation model can cause problems in your analysis model. Be sure to run the regressions implied by your imputation models separately and check them for misspecification. A secondary lesson is that PMM can work well for non-normal data.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_models.htm#transform">Return to the source article</a></p>
<h2><a id="Non-Linearity" name="Non-Linearity"></a>Non-Linearity</h2>
<p>Non-linear terms in your analysis model present a major challenge in creating an imputation model, because the non-linear relationship between variables can't be easily inverted.</p>
<p>Note: in this example we'll frequently use Stata's syntax for interactions to create squared terms. A varlist of <span class="InputCode">c.x##c.x</span> is equivalent to the  varlist  <span class="InputCode">x  x2</span> where <span class="InputCode">x2</span> is defined by <span class="InputCode">gen x2=x^2</span>. The squared term shows up in the output as <span class="InputCode">c.x#c.x</span>. Using <span class="InputCode">c.x##c.x</span> is convenient because you don't have to create a separate variable, and because in that form post-estimation commands can take into account the fact that <span class="InputCode">x</span> and <span class="InputCode">x^2</span> are not independent variables.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/mi/nonlinear.do">Complete code for this example</a></p>
<h3>Data</h3>
<p><strong>Observations</strong>: 1,000</p>
<p><strong>Variables</strong>:</p>
<ul>
<li><span class="InputCode">x</span> is drawn from the standard normal distribution</li>
<li><span class="InputCode">y</span> is <span class="InputCode">x</span> plus <span class="InputCode">x^2</span> plus a normal error term</li>
</ul>
<p><strong>Missingness</strong>: <span class="InputCode">y</span> and <span class="InputCode">x</span> have a 10% probability of being missing (MCAR).</p>
<p><strong>Right Answers</strong>: Regressing <span class="InputCode">y</span> on  <span class="InputCode">x</span> and <span class="InputCode">x^2</span>, both should have a coefficient of 1.</p>
<h3>Procedure</h3>
<p>First, complete cases analysis for comparison:</p>
<pre class="InputCode">      Source |       SS       df       MS              Number of obs =     815
-------------+------------------------------           F(  2,   812) = 1184.66
       Model |   2350.4449     2  1175.22245           Prob &gt; F      =  0.0000
    Residual |  805.533089   812  .992035824           R-squared     =  0.7448
-------------+------------------------------           Adj R-squared =  0.7441
       Total |  3155.97799   814  3.87712284           Root MSE      =  .99601

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   .9798841   .0344861    28.41   0.000     .9121917    1.047577
             |
     c.x#c.x |   .9948393   .0244134    40.75   0.000     .9469185     1.04276
             |
       _cons |  -.0047983   .0429475    -0.11   0.911    -.0890994    .0795029
------------------------------------------------------------------------------</pre>
<p>The obvious thing to do is to impute <span class="InputCode">x</span>, then allow <span class="InputCode">x^2</span> to be a passive function of <span class="InputCode">x</span> (it makes no difference whether you create a variable for <span class="InputCode">x^2</span> using <span class="InputCode">mi passive</span> or allow Stata to do it for you by putting <span class="InputCode">c.x##c.x</span> in your regression). However, this means that the imputation model for <span class="InputCode">x</span> simply regresses <span class="InputCode">x</span> on <span class="InputCode">y</span>. This is misspecified, as you can see from an <span class="InputCode">rvfplot</span>:</p>
<p><img alt="rvfplot shows that the model is misspecified" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/nonlinear.png" width="585"/></p>
<p>Here are the regression results. Because the imputation model is misspecified , the coefficient on <span class="InputCode">x^2</span> (<span class="InputCode">c.x#c.x</span>) is biased:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =       1000
                                                  Average RVI     =     0.9729
                                                  Largest FMI     =     0.5328
                                                  Complete DF     =        997
DF adjustment:   Small sample                     DF:     min     =      32.79
                                                          avg     =      37.89
                                                          max     =      46.68
Model F test:       Equal FMI                     F(   2,   50.2) =     351.77
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   .9586506   .0570451    16.81   0.000     .8427484    1.074553
             |
     c.x#c.x |    .844537   .0409527    20.62   0.000     .7611974    .9278765
             |
       _cons |   .1986436   .0662195     3.00   0.004     .0654027    .3318845
------------------------------------------------------------------------------</pre>
<p>Next  impute <span class="InputCode">x</span> using PMM. It's an improvement but still biased:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =       1000
                                                  Average RVI     =     0.3974
                                                  Largest FMI     =     0.3984
                                                  Complete DF     =        997
DF adjustment:   Small sample                     DF:     min     =      56.92
                                                          avg     =     101.37
                                                          max     =     134.94
Model F test:       Equal FMI                     F(   2,  167.9) =     763.23
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   .9511347    .041403    22.97   0.000     .8691019    1.033167
             |
     c.x#c.x |   .9170003    .027871    32.90   0.000     .8618798    .9721207
             |
       _cons |   .1160666   .0565846     2.05   0.045     .0027546    .2293787
------------------------------------------------------------------------------</pre>
<p>The <span class="InputCode">include()</span> option of <span class="InputCode">mi impute chained</span> is usually used to add variables to the imputation model of an individual variable, but it can also accept expressions. Does adding <span class="InputCode">x^2</span> to the imputation for <span class="InputCode">y</span> with <span class="InputCode">(regress, include((x^2))) y</span> fix the problem? Unfortunately not, though it helps:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =       1000
                                                  Average RVI     =     1.1210
                                                  Largest FMI     =     0.7256
                                                  Complete DF     =        997
DF adjustment:   Small sample                     DF:     min     =      17.48
                                                          avg     =      70.29
                                                          max     =     118.18
Model F test:       Equal FMI                     F(   2,   39.1) =     377.13
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   .9629371   .0452655    21.27   0.000     .8727678    1.053106
             |
     c.x#c.x |   .8874316   .0475562    18.66   0.000     .7873051    .9875581
             |
       _cons |    .125851    .053619     2.35   0.021     .0196724    .2320296
------------------------------------------------------------------------------</pre>
<p>The imputation model for <span class="InputCode">y</span> has been fixed, but the imputation model for <span class="InputCode">x</span> is still misspecified and this still biases the results of the analysis model. Unfortunately, the true dependence of <span class="InputCode">x</span> on <span class="InputCode">y</span> does not match any standard regression model.</p>
<p>Next we'll use what White, Royston and Wood (<a href="http://onlinelibrary.wiley.com.ezproxy.library.wisc.edu/doi/10.1002/sim.4067/pdf">Multiple imputation using chained equations: Issues and guidance for practice</a>, Statistics in Medicine, November 2010) call the "Just Another Variable" approach. This creates a variable to contain <span class="InputCode">x^2</span> (<span class="InputCode">x2</span>) and then imputes both <span class="InputCode">x</span> and <span class="InputCode">x2</span> as if <span class="InputCode">x2</span> were "just another variable" rather than being determined by <span class="InputCode">x</span>. The obvious disadvantage is that in the imputed data <span class="InputCode">x2</span> is not equal to <span class="InputCode">x^2</span>, so it lacks face validity. But the regression results are a huge improvement:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =       1000
                                                  Average RVI     =     0.2375
                                                  Largest FMI     =     0.3033
                                                  Complete DF     =        997
DF adjustment:   Small sample                     DF:     min     =      92.98
                                                          avg     =     331.43
                                                          max     =     610.11
Model F test:       Equal FMI                     F(   2,  496.2) =    1330.20
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   .9905117   .0324469    30.53   0.000     .9267905    1.054233
          x2 |   1.005361   .0240329    41.83   0.000     .9580613    1.052662
       _cons |  -.0018354    .046395    -0.04   0.969    -.0939669    .0902961
------------------------------------------------------------------------------</pre>
<p>So would imputing <span class="InputCode">x</span> and <span class="InputCode">x2</span> using PMM be even better on the theory that PMM is better in sticky situations of all sorts? Not this time:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =       1000
                                                  Average RVI     =     0.3068
                                                  Largest FMI     =     0.3151
                                                  Complete DF     =        997
DF adjustment:   Small sample                     DF:     min     =      86.95
                                                          avg     =     201.95
                                                          max     =     312.22
Model F test:       Equal FMI                     F(   2,  163.9) =    1138.59
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   .9761798   .0346402    28.18   0.000     .9078863    1.044473
          x2 |   .9987715   .0258422    38.65   0.000      .947407    1.050136
       _cons |  -.0032279   .0416431    -0.08   0.938    -.0851645    .0787087
------------------------------------------------------------------------------</pre>
<h3>Lessons Learned</h3>
<p>Again, the principal lesson is that misspecification in your imputation model can lead to bias in your analysis model. Be very careful, and always check the fit of your imputation models.</p>
<p> This is a continuing research area, but there appears to be some agreement that imputing non-linear terms as passive variables should be avoided. "Just Another Variable" seems to be a good alternative.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_models.htm#nonlin">Return to the source article</a></p>
<h2><a id="Interactions" name="Interactions"></a>Interactions</h2>
<p>Interaction terms in your analysis model also lead to challenges in creating an imputation model because it should take into account the interaction in the model for the covariates being interacted.</p>
<p>Note: we'll again use Stata's syntax for interactions. Putting <span class="InputCode">g##c.x</span> in the covariate list of a regression regresses the dependent variable on <span class="InputCode">g</span>, continuous variable <span class="InputCode">x</span>, and the interaction between <span class="InputCode">g</span> and <span class="InputCode">x</span>. The interaction term shows up in the output as <span class="InputCode">g#c.x</span>.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/mi/interact.do">Complete code for this example</a></p>
<h3>Data</h3>
<p><strong>Observations</strong>: 10,000</p>
<p><strong>Variables</strong>:</p>
<ul>
<li><span class="InputCode">g</span> is a binary (1/0) variable with a 50% probability of being 1</li>
<li><span class="InputCode">x</span> is drawn from the standard normal distribution</li>
<li><span class="InputCode">y</span> is <span class="InputCode">x</span> plus <span class="InputCode">x*g</span> plus a normal error term. Put differently, <span class="InputCode">y</span> is <span class="InputCode">x</span> plus a normal  error term for group 0 and <span class="InputCode">2*x</span> plus a normal error term for group 1.</li>
</ul>
<p><strong>Missingness</strong>: <span class="InputCode">y</span> and <span class="InputCode">x</span> have a 20% probability of being missing (MCAR).</p>
<p><strong>Right Answers</strong>: Regressing <span class="InputCode">y</span> on  <span class="InputCode">x</span>, <span class="InputCode">g</span>, and the interaction between <span class="InputCode">x</span> and <span class="InputCode">g</span>, the coefficients for <span class="InputCode">x</span> and the interaction term should be 1, and the coefficient on <span class="InputCode">g</span> should be 0.</p>
<h3>Procedure</h3>
<p> The following are the results of complete cases analysis:</p>
<pre class="InputCode">      Source |       SS       df       MS              Number of obs =    6337
-------------+------------------------------           F(  3,  6333) = 5435.30
       Model |  16167.6705     3   5389.2235           Prob &gt; F      =  0.0000
    Residual |  6279.30945  6333  .991522099           R-squared     =  0.7203
-------------+------------------------------           Adj R-squared =  0.7201
       Total |    22446.98  6336   3.5427683           Root MSE      =  .99575

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         1.g |   -.012915   .0250189    -0.52   0.606    -.0619605    .0361305
           x |   .9842869    .017752    55.45   0.000     .9494869    1.019087
             |
       g#c.x |
          1  |   1.026204   .0249124    41.19   0.000     .9773671    1.075041
             |
       _cons |  -.0195648   .0177789    -1.10   0.271    -.0544175    .0152879
------------------------------------------------------------------------------</pre>
<p>The obvious way to impute this data is to impute <span class="InputCode">x</span> and create the interaction term passively. However that means <span class="InputCode">x</span> is regressed on <span class="InputCode">y</span> and <span class="InputCode">g</span> without any interactions. The result is biased estimates (in opposite directions) of the coefficients for both <span class="InputCode">x</span> and the interaction term:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =      10000
                                                  Average RVI     =     0.5760
                                                  Largest FMI     =     0.3048
                                                  Complete DF     =       9996
DF adjustment:   Small sample                     DF:     min     =     104.17
                                                          avg     =     130.43
                                                          max     =     182.89
Model F test:       Equal FMI                     F(   3,  205.4) =    4870.03
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         1.g |  -.0077291   .0251103    -0.31   0.759    -.0575089    .0420506
           x |   1.119861   .0182704    61.29   0.000     1.083631    1.156091
             |
       g#c.x |
          1  |   .7300249   .0239816    30.44   0.000     .6827087     .777341
             |
       _cons |  -.0148091   .0174857    -0.85   0.399    -.0494078    .0197896
------------------------------------------------------------------------------
</pre>
<p>An alternative approach is to create a variable for the interaction term, <span class="InputCode">gx</span>, and impute it separately from <span class="InputCode">x</span> (White, Royston and Wood's "Just Another Variable" approach). As in the previous example with a squared term, the obvious disadvantage is that the imputed value of <span class="InputCode">gx</span> will not in fact be <span class="InputCode">g*x</span> for any given observation. However, the results of the analysis model are much better:</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =      10000
                                                  Average RVI     =     0.4359
                                                  Largest FMI     =     0.3753
                                                  Complete DF     =       9996
DF adjustment:   Small sample                     DF:     min     =      69.58
                                                          avg     =     111.30
                                                          max     =     210.61
Model F test:       Equal FMI                     F(   3,  223.1) =    5908.62
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
           x |   .9832953   .0159157    61.78   0.000     .9519209     1.01467
          xg |   1.018901   .0239421    42.56   0.000     .9713602    1.066443
           g |  -.0141319   .0247797    -0.57   0.570    -.0635346    .0352709
       _cons |  -.0087754   .0176281    -0.50   0.620    -.0439374    .0263866
------------------------------------------------------------------------------</pre>
<p>Another alternative is to impute the two groups separately. This allows <span class="InputCode">x</span> to have the proper relationship with <span class="InputCode">y</span> in both groups. However, it also allows the relationships between other variables to vary between groups. If you know that some relationships do not vary between groups you'll lose some precision by not taking advantage of this knowledge, but in the real world it's rare know such things.</p>
<pre class="InputCode">Multiple-imputation estimates                     Imputations     =         10
Linear regression                                 Number of obs   =      10000
                                                  Average RVI     =     0.3627
                                                  Largest FMI     =     0.3482
                                                  Complete DF     =       9996
DF adjustment:   Small sample                     DF:     min     =      80.48
                                                          avg     =     218.72
                                                          max     =     369.37
Model F test:       Equal FMI                     F(   3,  456.6) =    6783.26
Within VCE type:          OLS                     Prob &gt; F        =     0.0000

------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         1.g |  -.0218404   .0243087    -0.90   0.372    -.0702117    .0265309
           x |   .9869436   .0156451    63.08   0.000     .9561207    1.017766
             |
       g#c.x |
          1  |   1.018534   .0214947    47.39   0.000      .976267    1.060802
             |
       _cons |  -.0076746   .0158825    -0.48   0.629    -.0390027    .0236534
------------------------------------------------------------------------------</pre>
<h3>Lessons Learned</h3>
<p>Once again, the principal lesson is that misspecification in your imputation model can lead to bias in your analysis model. Be very careful, and always check the fit of your imputation models.</p>
<p> </p>
<p>This is also an area of ongoing research, but there appears to be some agreement that imputing interaction effects passively is problematic. If your interactions are all a matter of variables having different effects for different groups, imputing each group separately is probably the obvious solution, though "Just Another Variable" also works well. If you have interactions between continuous variables then use "Just Another Variable."</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_models.htm#interact">Return to the source article</a></p>
<h2><a id="CaveatsandAcknowlegements" name="CaveatsandAcknowlegements"></a>Acknowledgements</h2>
<p>Some of these examples follow the discussion in White, Royston, and Wood. ("<a href="http://onlinelibrary.wiley.com.ezproxy.library.wisc.edu/doi/10.1002/sim.4067/pdf">Multiple imputation using chained equations: Issues and guidance for practice.</a>" Statistics in Medicine. 2011.) We highly recommend this article to anyone who is learning to use multiple imputation.</p>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_readings.htm">Recommended Readings</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_estimate.htm">Estimating</a> </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/mi/nonnormal1.png, https://ssc.wisc.edu/sscc/pubs/mi/nonnormal2.png, https://ssc.wisc.edu/sscc/pubs/mi/nonnormal3.png, https://ssc.wisc.edu/sscc/pubs/mi/nonnormal4.png, https://ssc.wisc.edu/sscc/pubs/mi/transform1.png, https://ssc.wisc.edu/sscc/pubs/mi/transform2.png, https://ssc.wisc.edu/sscc/pubs/mi/transform3.png, https://ssc.wisc.edu/sscc/pubs/mi/transform5.png, https://ssc.wisc.edu/sscc/pubs/mi/nonlinear.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Multiple Imputation in Stata: Imputing</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This is part four of the Multiple Imputation in Stata series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_intro.htm">Introduction</a>.</em></p>
<p>This section will talk you through the details of the imputation process. Be sure you've read at least the previous section, <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_models.htm">Creating Imputation Models</a>, so you have a sense of what issues can affect the validity of your results.</p>
<h2>Example Data</h2>
<p>To illustrate the process, we'll use a fabricated data set. Unlike those in the examples section, this data set is designed to have some resemblance to real world data. </p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/mi/midata.do">Do file that creates this data set</a></p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/mi/midata.dta">The data set as a Stata data file</a></p>
<p><strong>Observations</strong>: 3,000</p>
<p><strong>Variables</strong>:</p>
<ul>
<li><span class="InputCode">female</span> (binary)</li>
<li><span class="InputCode">race</span> (categorical, three values)</li>
<li><span class="InputCode">urban</span> (binary)</li>
<li><span class="InputCode">edu</span> (ordered categorical, four values)</li>
<li><span class="InputCode">exp</span> (continuous)</li>
<li><span class="InputCode">wage</span> (continuous)</li>
</ul>
<p><strong>Missingness</strong>: Each value of all the variables except <span class="InputCode">female</span> has a 10% chance of being missing completely at random, but of course in the real world we won't know that it is MCAR ahead of time. Thus we will check whether it is MCAR or MAR (MNAR cannot be checked by looking at the observed data) using the procedure outlined in <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_decide.htm#AreMyDataMCARMARorMNAR">Deciding to Impute</a>:</p>
<p class="InputCode">unab numvars: *<br/>
                  unab missvars: urban-wage<br/>
                  misstable sum, gen(miss_)<br/>
<br/>

                foreach var of local missvars {<br/>
<span class="indent3">local covars: list numvars - var</span><br/>
<span class="indent3">display _newline(3) "logit missingness of `var' on `covars'"</span><br/>
<span class="indent3">logit miss_`var' `covars'</span><br/>
<span class="indent3">foreach nvar of local covars {</span><br/>
<span class="indent6">display _newline(3) "ttest of `nvar' by missingness of `var'"</span><br/>
<span class="indent6">ttest `nvar', by(miss_`var')</span><br/>
<span class="indent3">}</span><br/>
                  }<br/>
</p>
<p>See the <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_impute_log.htm#missingness">log file</a> for results.</p>
<p>Our goal is to regress wages  on sex, race, education level, and experience. To see the "right" answers, open the do file that creates the data set and examine the <span class="InputCode">gen</span> command that defines wage.</p>
<p>Complete code for the imputation process  can be found in the following do file:</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/mi/miex.do">Imputation do file</a></p>
<p>The imputation process creates a lot of output. We'll put highlights in this page, however, a complete log file including the associated graphs can be found here:</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_impute_log.htm">Imputation log file with graphs</a></p>
<p>Each section of this article will have links to the relevant section of the log. Click "back" in your browser to return to this page.</p>
<h2>Setting up</h2>
<p>The first step in using <span class="InputCode">mi</span> commands is to <span class="InputCode">mi set</span> your data. This is somewhat similar to <span class="InputCode">svyset</span>, <span class="InputCode">tsset</span>, or <span class="InputCode">xtset</span>. The <span class="InputCode">mi set</span> command tells Stata how it should store the additional imputations you'll create. We suggest using the <span class="InputCode">wide</span> format, as it is slightly faster.  On the other hand, <span class="InputCode">mlong</span> uses slightly less memory.</p>
<p>To have Stata use the <span class="InputCode">wide</span> data structure, type:</p>
<p class="InputCode">mi set wide</p>
<p>To have Stata use the <span class="InputCode">mlong</span> (marginal long) data structure, type:</p>
<p class="InputCode">mi set mlong</p>
<p>The wide vs. long terminology is borrowed from <span class="InputCode">reshape</span> and the structures are  similar. However, they are not equivalent and you would never use <span class="InputCode">reshape</span> to change the data structure used by <span class="InputCode">mi</span>. Instead,  type <span class="InputCode">mi convert wide</span> or <span class="InputCode">mi convert mlong</span> (add <span class="InputCode">,clear</span> if the data have not been saved since the last change).</p>
<p>Most of the time you don't need to worry about how the imputations are stored: the <span class="InputCode">mi</span> commands figure out automatically how to  apply whatever you do to each imputation. But if you need to manipulate the data in a way <span class="InputCode">mi</span> can't do for you, then you'll need to learn about the details of the structure you're using. You'll also need to be very, very careful. If you're interested in such things (including the rarely used <span class="InputCode">flong</span> and <span class="InputCode">flongsep</span> formats) run <a href="https://ssc.wisc.edu/sscc/pubs/mi/styles.do">this do file</a> and read the comments it contains while examining the data browser to see what the data look like in each form.</p>
<h3>Registering Variables</h3>
<p>The <span class="InputCode">mi</span> commands recognize three kinds of variables:</p>
<p><em>Imputed</em> variables are variables that <span class="InputCode">mi</span> is to impute or has imputed.</p>
<p><em>Regular</em> variables are variables that <span class="InputCode">mi</span> is not to impute, either by choice or because they are not missing any values.</p>
<p><em>Passive</em> variables are variables that are completely determined by other variables. For example, log wage is determined by wage, or an indicator for obesity might be determined by a function of weight and height. Interaction terms are also <em>passive</em> variables, though if you use Stata's interaction syntax you won't have to declare them as such. <em>Passive</em> variables are often problematic—the examples on <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm#Transformations">transformations</a>, <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm#Non-Linearity">non-linearity</a>, and <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm#Interactions">interactions</a> show how using them inappropriately can lead to biased estimates.</p>
<p>If a <em>passive</em> variable is determined by <em>regular</em> variables, then it can be treated as a <em>regular</em> variable since no imputation is needed. <em>Passive</em> variables only have to be treated as such if they depend on <em>imputed</em> variables.</p>
<p>Registering a variable tells Stata what kind of variable it is. <em>Imputed</em> variables must always be registered:</p>
<p class="InputCode">mi register imputed <span class="Parameter">varlist</span></p>
<p>where <span class="InputCode"><span class="Parameter">varlist</span></span> should be replaced by the actual list of variables to be imputed.</p>
<p><em>Regular</em> variables often don't have to be registered, but it's a good idea:</p>
<p class="InputCode">mi register regular <span class="Parameter">varlist</span></p>
<p>Passive variables must be registered:</p>
<p class="InputCode">mi register passive <span class="Parameter">varlist</span></p>
<p>However,  <em>passive</em> variables are more often created after imputing. Do so with <span class="InputCode">mi passive</span> and they'll be registered as <em>passive</em> automatically.</p>
<p>In our example data, all the variables except <span class="InputCode">female</span> need to be imputed. The appropriate <span class="InputCode">mi register</span> command is:</p>
<p class="InputCode">mi register imputed race-wage</p>
<p>(Note that you cannot use <span class="InputCode">*</span> as your <em>varlist</em> even if you have to impute all your variables, because that would include the system variables added by <span class="InputCode">mi set</span> to keep track of the imputation structure.)</p>
<p>Registering <span class="InputCode">female</span> as regular is optional, but a good idea:</p>
<p class="InputCode">mi register regular female</p>
<h2>Checking the  Imputation Model</h2>
<p>Based on the types of the variables, the obvious imputation methods are:</p>
<ul>
<li><span class="InputCode">race</span> (categorical, three values): <span class="InputCode">mlogit</span></li>
<li><span class="InputCode">urban</span> (binary): <span class="InputCode">logit</span></li>
<li><span class="InputCode">edu</span> (ordered categorical, four values): <span class="InputCode">ologit</span></li>
<li><span class="InputCode">exp</span> (continuous): <span class="InputCode">regress</span></li>
<li><span class="InputCode">wage</span> (continuous): <span class="InputCode">regress</span></li>
</ul>
<p><span class="InputCode">female</span> does not need to be imputed, but should be included in the imputation models both because it is in the analysis model and because it's likely to be relevant.</p>
<p>Before proceeding to impute we will check each of the imputation models. <strong>Always run each of your imputation models individually, outside the <span class="InputCode">mi impute chained</span> context, to see if they converge and (insofar as it is possible) verify that they are specified correctly.</strong></p>
<p>Code to run each of these models is:</p>
<p class="InputCode">  mlogit race i.urban exp wage i.edu i.female<br/>
  logit urban i.race exp wage i.edu i.female<br/>
			ologit edu i.urban i.race exp wage i.female<br/>
			regress exp i.urban i.race wage i.edu i.female<br/>
                  regress wage i.urban i.race exp i.edu i.female                </p>
<p>Note that when categorical variables (ordered or not) appear as covariates <span class="InputCode">i.</span> expands them into sets of indicator variables.                </p>
<p> As we'll see later, the output of the <span class="InputCode">mi impute chained</span> command includes the commands for the individual models it runs. Thus a useful shortcut, especially if you have a lot of variables to impute, is to set up your <span class="InputCode">mi impute chained</span> command  with the <span class="InputCode">dryrun</span> option to prevent it from doing any actual imputing, run it, and then copy the commands from the output into your do file for testing.</p>
<h3>Convergence Problems</h3>
<p>The first thing to note is that all of these models run successfully. Complex models like <span class="InputCode">mlogit</span> may fail to converge if you have large numbers of categorical variables, because that often leads to small cell sizes. To pin down the cause of the problem,  remove most of the variables, make sure the model works with what's left, and then add variables back one at a time or in small groups until it stops working. With some experimentation you should be able to identify the problem variable or combination of variables. At that point you'll have to decide if you can combine categories or drop variables or make other changes in order to create a workable model.</p>
<h3>Prefect Prediction</h3>
<p>Perfect prediction is another problem to note. The imputation process cannot simply drop the perfectly predicted observations the way <span class="InputCode">logit</span> can. You could drop them before imputing, but that seems to defeat the purpose of multiple imputation. The alternative is to add the <span class="InputCode">augment</span> (or just <span class="InputCode">aug</span>) option to the affected methods. This tells <span class="InputCode">mi impute chained</span> to use the "augmented regression" approach, which adds fake observations with very low weights in such a way that they have a negligible effect on the results but prevent perfect prediction. For details see the section  "The issue of perfect prediction during imputation of categorical data" in the Stata MI documentation.</p>
<h3>Checking for Misspecification</h3>
<p>You should also try to evaluate whether the models are specified correctly. A full discussion of how to determine whether a regression model is specified correctly or not is well beyond the scope of this article, but use whatever tools you find appropriate. Here are some examples:</p>
<h4>Residual vs. Fitted Value Plots</h4>
<p>For continuous variables, residual vs. fitted value plots (easily done with <span class="InputCode">rvfplot</span>) can be useful—several of the <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm">examples</a> use them to detect problems. Consider the plot for experience:</p>
<p class="InputCode">regress exp i.urban i.race wage i.edu i.female<br/>
                  rvfplot</p>
<p><img alt="rvfplot of exp" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/exp1.png" width="585"/></p>
<p>Note how a number of points are clustered along a line in the lower left, and no points are below it:</p>
<p><img alt="rvfplot plus constraint line" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/exp2.png" width="585"/></p>
<p>This reflects the constraint that experience cannot be less than zero, which means that the fitted values must always be greater than or equal to the residuals, or alternatively that the residuals must be greater than or equal to the negative of the fitted values. (If the graph had the same scale on both axes, the constraint line would be a 45 degree line.) If all the points were below a similar line rather than above it, this would tell you that there was an upper bound on the variable rather than a lower bound. The y-intercept of the constraint line tells you the limit in either case. You can also have both a lower bound and an upper bound, putting all the points in a band between them. </p>
<p>The "obvious" model, <span class="InputCode">regress</span>, is inappropriate for experience because it won't apply this constraint. It's also inappropriate for wages for the same reason. Alternatives include <span class="InputCode">truncreg, ll(0) </span>and <span class="InputCode">pmm</span> (we'll use <span class="InputCode">pmm</span>).                </p>
<p></p>
<h4>Adding Interactions</h4>
<p> In this example, it seems plausible that the relationships between variables may vary between race, gender, and urban/rural groups. Thus one way to check for misspecification is to add interaction terms to the models and see whether they turn out to be important. For example, we'll compare the obvious model:</p>
<p class="InputCode">regress exp i.race wage i.edu i.urban i.female<br/>
</p>
<p>with one that includes interactions:</p>
<p class="InputCode">regress exp (i.race i.urban i.female)##(c.wage i.edu)</p>
<p>We'll run  similar comparisons for the models of the other variables. This creates a great deal of output, so see the <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_impute_log.htm#models">log file</a> for results. Interactions between <span class="InputCode">female</span> and other variables are significant in the models for <span class="InputCode">exp</span>, <span class="InputCode">wage</span>, <span class="InputCode">edu</span>, and <span class="InputCode">urban</span>. There are a few significant interactions between <span class="InputCode">race</span> or <span class="InputCode">urban</span> and other variables, but not nearly as many (and keep in mind that with this many coefficients we'd expect some false positives using a significance level of .05). We'll thus impute the men and women separately. This is an especially good option for this data set because <span class="InputCode">female</span> is never missing. If it were, we'd have to drop those observations which are missing <span class="InputCode">female</span> because they could not be placed in one group or the other.</p>
<p> In the imputation command this means adding the <span class="InputCode">by(female)</span> option. When testing models, it means starting the commands with the <span class="InputCode">by female:</span> prefix (and removing <span class="InputCode">female</span> from the lists of covariates). The improved imputation models are thus:</p>
<p class="InputCode">bysort female: reg exp i.urban i.race wage i.edu<br/>
                  by female: logit urban exp i.race wage i.edu<br/>
                  by female: mlogit race exp i.urban wage i.edu<br/>
                  by female: reg wage exp i.urban i.race i.edu<br/>
                by female: ologit edu exp i.urban i.race wage</p>
<p><span class="InputCode">pmm</span> itself cannot be run outside the imputation context, but since it's based on regression you can use regular regression to test it.</p>
<p>These models should be tested again, but we'll omit that process.</p>
<h2>Imputing</h2>
<p>The basic syntax for mi impute chained is:</p>
<p class="InputCode">mi impute chained (<span class="Parameter">method1</span>)<span class="Parameter"> varlist1 </span>(<span class="Parameter">method2</span>)<span class="Parameter"> varlist2...</span> = <span class="Parameter">regvars</span></p>
<p>Each <span class="Parameter">method</span> specifies the method to be used for imputing the following <span class="Parameter">varlist</span>  The possibilities for <span class="Parameter">method</span> are <span class="InputCode">regress</span>, <span class="InputCode">pmm</span>, <span class="InputCode">truncreg</span>, <span class="InputCode">intreg</span>, <span class="InputCode">logit</span>, <span class="InputCode">ologit</span>, <span class="InputCode">mlogit</span>, <span class="InputCode">poisson</span>, and <span class="InputCode">nbreg</span>.  <span class="Parameter">regvars</span> is a list of regular variables to be used as covariates in the imputation models but not imputed (there may not be any).</p>
<p>The basic options are:</p>
<p class="InputCode">, add(<span class="Parameter">N</span>) rseed(<span class="Parameter">R</span>) savetrace(<span class="Parameter">tracefile</span>, replace)</p>
<p><span class="Parameter">N</span> is the number of imputations to be added to the data set. <span class="Parameter">R</span> is the seed to be used for the random number generator—if you do not set this you'll get slightly different imputations each time the command is run. The <span class="Parameter">tracefile</span> is a dataset in which <span class="InputCode">mi impute chained</span> will store information about the imputation process. We'll use this dataset to check for convergence.</p>
<p> Options that are relevant to a particular method go with the method, inside the parentheses but following a comma (e.g. <span class="InputCode">(mlogit, aug)</span> ). Options that are relevant to the imputation process as a whole (like <span class="InputCode">by(female)</span> ) go at the end, after the comma.</p>
<p>For our example, the command would be:</p>
<p class="InputCode">mi impute chained (logit) urban (mlogit) race (ologit) edu (pmm) exp wage, add(5) rseed(4409) by(female)</p>
<p>Note that this does not include a <span class="InputCode">savetrace()</span> option. As of this writing, <span class="InputCode">by()</span> and <span class="InputCode">savetrace()</span> cannot be used at the same time, presumably because it would require one trace file for each <em>by</em> group. Stata is aware of this problem and we hope this will be changed soon. For purposes of this article, we'll remove the <span class="InputCode">by()</span> option when it comes time to illustrate  use of the trace file. If this problem comes up in your research, talk to us about work-arounds.</p>
<h3>Choosing the Number of Imputations</h3>
<p>There is some disagreement among authorities about how many imputations are sufficient. Some say 3-10 in almost all circumstances, the Stata documentation suggests at least 20, while White, Royston, and Wood argue that the number of imputations should be roughly equal to the percentage of cases with missing values. However, we are not aware of any argument that increasing the number of imputations ever causes problems (just that the marginal benefit of another imputation asymptotically approaches zero).</p>
<p>Increasing the number of imputations in your analysis takes essentially no work on your part. Just change the number in the <span class="InputCode">add()</span> option to something bigger. On the other hand, it can be a lot of work for the computer—multiple imputation has introduced many researchers into the world of jobs that take hours or days to run. You can generally assume that the amount of time required will be proportional to the number of imputations used (e.g. if a do file takes two hours to run with five imputations, it will probably take about four hours to run with ten imputations).  So here's our suggestion:</p>
<ol>
<li>Start with five imputations (the low end of what's broadly considered legitimate).</li>
<li>Work on  your research project until you're reasonably confident you have the analysis in its final form. Be sure to do everything with do files so you can run it again at will.</li>
<li>Note how long the process takes, from imputation to final analysis.</li>
<li>Consider how much time you have available and decide how many imputations you can afford to run, using the rule of thumb that time required is  proportional to the number of imputations. If possible, make the number of imputations  roughly equal to the percentage of cases with missing data (a high end  estimate of what's required). Allow  time to recover if things to go wrong, as they generally do.</li>
<li>Increase the number of imputations in your do file and start it.</li>
<li>Do something else while the do file runs, like write your paper. Adding imputations shouldn't change your results significantly—and in the unlikely event that they do, consider yourself lucky to have found that out before publishing.</li>
</ol>
<h3>Speeding up the Imputation Process</h3>
<p>Multiple imputation has introduced many researchers into the world of jobs that take hours, days, or even weeks to run. Usually it's not worth spending your time to make Stata code run faster, but multiple imputation can be an exception.</p>
<p>Use the fastest computer available to you. For SSCC members that means learning to run jobs on Linstat, the SSCC's Linux computing cluster. Linux is not as difficult as you may think—<a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a> has instructions.</p>
<p>Multiple imputation involves more reading and writing to disk than most Stata commands. Sometimes this includes writing temporary files in the current working directory. Use the fastest disk space available to you, both for your data set and for the working directory. In general local disk space will be faster than network disk space, and on Linstat <span class="InputCode">/ramdisk</span> (a "directory" that is actually stored in RAM) will be faster than local disk space. On the other hand, you would not want to permanently store data sets anywhere but network disk space. So consider having your do file do something like the following:</p>
<h4>Windows (Winstat or your own PC)</h4>
<p class="InputCode">copy x:\mydata\dataset c:\windows\temp\dataset<br/>
                cd c:\windows\temp<br/>
                use dataset<br/>
                {<span class="Parameter">do stuff, including saving results to the network as needed</span>}<br/>
                erase c:\windows\temp\dataset</p>
<h4>Linstat</h4>
<p class="InputCode">copy /project/mydata/dataset /ramdisk/dataset<br/>
                cd /ramdisk<br/>
                use dataset<br/>
                {<span class="Parameter">do stuff, including saving results to the network as needed</span>}<br/>
                erase /ramdisk/dataset</p>
<p>This applies when you're using imputed data as well. If your data set is large enough that working with it after imputation is slow, the above procedure may help.</p>
<h2 id="CheckingforConvergence">Checking for Convergence</h2>
<p>MICE is an iterative process. In each iteration, <span class="InputCode">mi impute chained</span> first estimates the imputation model, using both the observed data and the imputed data from the previous iteration. It then draws new imputed values from the resulting distributions. Note that as a result, each iteration has some autocorrelation with the previous imputation.</p>
<p>The first iteration must be a special case: in it, <span class="InputCode">mi impute chained</span> first estimates the imputation model for the variable with the fewest missing values based only on the observed data and draws imputed values for that variable. It then estimates the model for the variable with the next fewest missing values, using both the observed values and the imputed values of the first variable, and proceeds similarly for the rest of the variables. Thus the first iteration is often atypical, and because iterations are correlated it can make subsequent iterations atypical as well.</p>
<p>To avoid this, <span class="InputCode">mi impute chained</span> by default goes through ten iterations for each imputed data set you request, saving only the results of the tenth iteration. The first nine iterations are called the burn-in period. Normally this is plenty of time for the effects of the first iteration to become insignificant and for the process to converge to a stationary state. However, you should check for convergence and increase the number of iterations if necessary to ensure it using the <span class="InputCode">burnin()</span> option.                </p>
<p>To do so, examine the trace file saved by <span class="InputCode">mi impute chained</span>. It contains the mean and standard deviation of each imputed variable in each iteration. These will vary randomly, but they should not show any trend. An easy way to check is with <span class="InputCode">tsline</span>, but it requires reshaping the data first.</p>
<p>Our preferred imputation model uses <span class="InputCode">by()</span>, so it cannot save a trace file. Thus we'll remove <span class="InputCode">by()</span> for the moment. We'll also increase the <span class="InputCode">burnin()</span> option to 100 so it's easier to see what a stable trace looks like. We'll then use <span class="InputCode">reshape</span> and <span class="InputCode">tsline</span> to check for convergence:</p>
<p class="InputCode">preserve<br/>
                  mi impute chained (logit) urban (mlogit) race (ologit) edu (pmm) exp wage = female, add(5) rseed(88) savetrace(extrace, replace) burnin(100)<br/>
use extrace, replace<br/>
                  reshape wide *mean *sd, i(iter) j(m)<br/>
                  tsset iter<br/>
                  tsline exp_mean*, title("Mean of Imputed Values of Experience") note("Each line is for one imputation") legend(off)<br/>
                  graph export conv1.png, replace<br/>
                  tsline exp_sd*, title("Standard Deviation of Imputed Values of Experience") note("Each line is for one imputation") legend(off)<br/>
                  graph export conv2.png, replace<br/>
                  restore</p>
<p>The resulting graphs do not show any obvious problems:</p>
<p><img alt="Mean of imputed values of experience" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/conv1.png" width="585"/></p>
<p><img alt="SD of imputed values of experience" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/conv2.png" width="585"/></p>
<p>If you do see signs that the process may not have converged after the default ten iterations, increase the number of iterations performed before saving imputed values with the <span class="InputCode">burnin()</span> option. If convergence is never achieved this indicates a problem with the imputation model.</p>
<h2>Checking the Imputed Values</h2>
<p>After imputing, you should check to see if the imputed data resemble the observed data. Unfortunately there's no formal test to determine what's "close enough." Of course if the data are MAR but not MCAR, the imputed data should be systematically different from the observed data. Ironically, the fewer missing values you have to impute, the more variation you'll see between the imputed data and the observed data (and between imputations).</p>
<p>For binary and categorical variables, compare frequency tables. For continuous variables, comparing means and standard deviations is a good starting point, but you should look at the overall shape of the distribution as well. For that we suggest kernel density graphs or perhaps histograms. Look at each imputation separately rather than pooling all the imputed values so you can see if any one of them went wrong.</p>
<h3><a id="mixeq" name="mixeq"></a>mi xeq:</h3>
<p>The <span class="InputCode">mi xeq:</span> prefix tell Stata to apply the subsequent command to each imputation individually. It also applies to the original data, the "zeroth imputation." Thus:</p>
<p class="InputCode">mi xeq: tab race</p>
<p>will give you six frequency tables: one for the original data, and one for each of the five imputations.</p>
<p>However, we want to compare the observed data to just the imputed data, not the entire data set. This requires adding an <em>if</em> condition to the <span class="InputCode">tab</span> commands for the imputations, but not the observed data. Add a number or <em>numlist</em> to have <span class="InputCode">mi xeq</span> act on particular imputations:</p>
<p class="InputCode">mi xeq 0: tab race<br/>
  mi xeq 1/5: tab race if miss_race
</p>
<p>This creates frequency tables for the observed values of <span class="InputCode">race</span> and then the imputed values in all five imputations.</p>
<p>If you have a significant number of variables to examine you can easily loop over them:</p>
<p class="InputCode">foreach var of varlist urban race edu {<br/>
<span class="indent3">mi xeq 0: tab `var'</span><br/>
<span class="indent3">mi xeq 1/5: tab `var' if miss_`var'</span><br/>
}</p>
<p>For results see the <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_impute_log.htm#checkcat">log file</a>.</p>
<p>Running summary statistics on continuous variables follows the same process, but creating kernel density graphs adds a complication: you need to either save the graphs or give yourself a chance to look at them. <span class="InputCode">mi xeq:</span> can carry out multiple commands for each imputation: just place them all in one line with a semicolon (<span class="InputCode">;</span>) at the end of each. (This will not work if you've changed the general end-of-command delimiter to a semicolon.) The <span class="InputCode">sleep</span> command tells Stata to pause for a specified period, measured in milliseconds.</p>
<p class="InputCode"> mi xeq 0: kdensity wage; sleep 1000<br/>
mi xeq 1/5: kdensity wage if miss_`var'; sleep 1000</p>
<p>Again, this can all be automated:</p>
<p class="InputCode">foreach var of varlist wage exp {<br/>
<span class="indent3">mi xeq 0: sum `var'</span><br/>
<span class="indent3">mi xeq 1/5: sum `var' if miss_`var'</span><br/>
<span class="indent3">mi xeq 0: kdensity `var'; sleep 1000</span><br/>
<span class="indent3">mi xeq 1/5: kdensity `var' if miss_`var'; sleep 1000</span><br/>
}</p>
<p>Saving the graphs turns out to be a bit trickier, because you need to give the graph from each imputation a different file name. Unfortunately you cannot access the imputation number within <span class="InputCode">mi xeq</span>. However, you can do a <span class="InputCode">forvalues</span> loop over imputation numbers, then have <span class="InputCode">mi xeq</span> act on each of them:</p>
<p class="InputCode">forval i=1/5 {<br/>
<span class="indent3">mi xeq `i': kdensity exp if miss_exp; graph export exp`i'.png, replace</span><br/>
}</p>
<p>Integrating this with the previous version gives:</p>
<p class="InputCode">foreach var of varlist wage exp {<br/>
<span class="indent3">mi xeq 0: sum `var'</span><br/>
<span class="indent3">mi xeq 1/5: sum `var' if miss_`var'</span><br/>
<span class="indent3">mi xeq 0: kdensity `var'; graph export chk`var'0.png, replace</span><br/>
<span class="indent3">forval i=1/5 {</span><br/>
<span class="indent6">mi xeq `i': kdensity `var' if miss_`var'; graph export chk`var'`i'.png, replace</span><br/>
<span class="indent3">}</span><br/>
}</p>
<p>For results, see the <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_impute_log.htm#checkcont">log file</a>.</p>
<p>It's troublesome that in all imputations the mean of the imputed values of <span class="InputCode">wage</span> is higher than the mean of the observed values of <span class="InputCode">wage</span>, and the mean of the imputed values of <span class="InputCode">exp</span> is lower than the mean of the observed values of <span class="InputCode">exp</span>. We did not find evidence that the data is MAR but not MCAR, so we'd expect the means of the imputed data to be clustered around the means of the observed data. There is no formal test to tell us definitively whether this is a problem or not. However, it should raise suspicions, and if the final results with these imputed data are different from the results of complete cases analysis, it raises the question of whether the difference is due to problems with the imputation model.</p>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_manage.htm">Managing Multiply Imputed Data</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_models.htm">Creating Imputation Models</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/mi/exp1.png, https://ssc.wisc.edu/sscc/pubs/mi/exp2.png, https://ssc.wisc.edu/sscc/pubs/mi/conv1.png, https://ssc.wisc.edu/sscc/pubs/mi/conv2.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Multiple Imputation in Stata: Imputation Log File</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>This web page contains the log file from the example imputation discussed in the <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_impute.htm">Imputing</a> section, plus the graphics it creates.</p>
<p> </p>
<pre class="InputCode">----------------------------------------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  \sscc\pubs\mi\miex.log
  log type:  text
 opened on:  17 Aug 2012, 10:51:48

. 
. use midata

. 
. // test missingness of data
. unab numvars: *

. unab missvars: urban-wage

. misstable sum, gen(miss_)
                                                               Obs&lt;.
                                                +------------------------------
               |                                | Unique
      Variable |     Obs=.     Obs&gt;.     Obs&lt;.  | values        Min         Max
  -------------+--------------------------------+------------------------------
          race |       293               2,707  |      3          0           2
         urban |       273               2,727  |      2          0           1
           edu |       319               2,681  |      4          1           4
           exp |       293               2,707  |   &gt;500          0     47.8623
          wage |       299               2,701  |   &gt;500          0    227465.2
  -----------------------------------------------------------------------------
<a id="missingness" name="missingness"></a>
. 
. foreach var of local missvars {
  2.         local covars: list numvars - var
  3.         display _newline(3) "logit missingness of `var' on `covars'"
  4.         logit miss_`var' `covars'
  5.         foreach nvar of local covars {
  6.                 display _newline(3) "ttest of `nvar' by missingness of `var'"
  7.                 ttest `nvar', by(miss_`var')
  8.         }
  9. }



logit missingness of urban on female race edu exp wage

Iteration 0:   log likelihood = -613.04047  
Iteration 1:   log likelihood = -611.32144  
Iteration 2:   log likelihood = -611.31554  
Iteration 3:   log likelihood = -611.31554  

Logistic regression                               Number of obs   =       1964
                                                  LR chi2(5)      =       3.45
                                                  Prob &gt; chi2     =     0.6310
Log likelihood = -611.31554                       Pseudo R2       =     0.0028

------------------------------------------------------------------------------
  miss_urban |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      female |   .1505333   .1696945     0.89   0.375    -.1820618    .4831284
        race |   -.068621   .0980029    -0.70   0.484     -.260703    .1234611
         edu |   .0098348   .0973647     0.10   0.920    -.1809964     .200666
         exp |  -.0033092   .0094184    -0.35   0.725    -.0217689    .0151504
        wage |   3.68e-06   2.57e-06     1.43   0.153    -1.36e-06    8.71e-06
       _cons |  -2.513739   .2871859    -8.75   0.000    -3.076613   -1.950865
------------------------------------------------------------------------------



ttest of female by missingness of urban

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2727    .4979831    .0095764    .5000876    .4792053    .5167609
       1 |     273    .4761905    .0302826      .50035    .4165725    .5358085
---------+--------------------------------------------------------------------
combined |    3000        .496    .0091299    .5000674    .4780984    .5139016
---------+--------------------------------------------------------------------
    diff |            .0217927    .0317471               -.0404556    .0840409
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =   0.6864
Ho: diff = 0                                     degrees of freedom =     2998

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.7538         Pr(|T| &gt; |t|) = 0.4925          Pr(T &gt; t) = 0.2462



ttest of race by missingness of urban

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2456    1.014658    .0163483    .8101878    .9826002    1.046716
       1 |     251    1.055777    .0513125    .8129431     .954717    1.156837
---------+--------------------------------------------------------------------
combined |    2707    1.018471    .0155756    .8103808    .9879293    1.049012
---------+--------------------------------------------------------------------
    diff |           -.0411189    .0537051               -.1464261    .0641883
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =  -0.7656
Ho: diff = 0                                     degrees of freedom =     2705

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.2220         Pr(|T| &gt; |t|) = 0.4440          Pr(T &gt; t) = 0.7780



ttest of edu by missingness of urban

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2442    2.356675    .0184465    .9115617    2.320503    2.392847
       1 |     239    2.368201    .0595328    .9203542    2.250922    2.485479
---------+--------------------------------------------------------------------
combined |    2681    2.357702     .017617     .912182    2.323158    2.392247
---------+--------------------------------------------------------------------
    diff |            -.011526    .0618353               -.1327757    .1097237
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =  -0.1864
Ho: diff = 0                                     degrees of freedom =     2679

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.4261         Pr(|T| &gt; |t|) = 0.8521          Pr(T &gt; t) = 0.5739



ttest of exp by missingness of urban

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2450    15.56019    .1954164     9.67262    15.17699    15.94339
       1 |     257    15.69341    .5938361    9.519917    14.52399    16.86284
---------+--------------------------------------------------------------------
combined |    2707    15.57284    .1856003    9.656566    15.20891    15.93677
---------+--------------------------------------------------------------------
    diff |           -.1332234    .6332773                -1.37498    1.108533
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =  -0.2104
Ho: diff = 0                                     degrees of freedom =     2705

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.4167         Pr(|T| &gt; |t|) = 0.8334          Pr(T &gt; t) = 0.5833



ttest of wage by missingness of urban

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2458    71240.46    763.6437    37860.09    69743.01    72737.91
       1 |     243    74058.12     2597.11    40484.95    68942.29    79173.95
---------+--------------------------------------------------------------------
combined |    2701    71493.95    733.1819     38104.3     70056.3    72931.61
---------+--------------------------------------------------------------------
    diff |           -2817.665    2562.273               -7841.881    2206.551
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =  -1.0997
Ho: diff = 0                                     degrees of freedom =     2699

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.1358         Pr(|T| &gt; |t|) = 0.2716          Pr(T &gt; t) = 0.8642



logit missingness of edu on female race urban exp wage

Iteration 0:   log likelihood = -670.64062  
Iteration 1:   log likelihood = -669.91049  
Iteration 2:   log likelihood = -669.90956  
Iteration 3:   log likelihood = -669.90956  

Logistic regression                               Number of obs   =       1989
                                                  LR chi2(5)      =       1.46
                                                  Prob &gt; chi2     =     0.9174
Log likelihood = -669.90956                       Pseudo R2       =     0.0011

------------------------------------------------------------------------------
    miss_edu |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      female |  -.0194159   .1557151    -0.12   0.901    -.3246119    .2857801
        race |   .0569055   .0903871     0.63   0.529    -.1202499    .2340609
       urban |   .0476788    .157765     0.30   0.762    -.2615349    .3568925
         exp |  -.0028472   .0086668    -0.33   0.743    -.0198338    .0141393
        wage |   1.93e-06   2.25e-06     0.86   0.390    -2.47e-06    6.33e-06
       _cons |  -2.314849   .2528625    -9.15   0.000     -2.81045   -1.819248
------------------------------------------------------------------------------



ttest of female by missingness of edu

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2681    .4983215    .0096583    .5000905    .4793831      .51726
       1 |     319     .476489    .0280076    .5002316    .4213854    .5315926
---------+--------------------------------------------------------------------
combined |    3000        .496    .0091299    .5000674    .4780984    .5139016
---------+--------------------------------------------------------------------
    diff |            .0218325    .0296195               -.0362442    .0799092
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =   0.7371
Ho: diff = 0                                     degrees of freedom =     2998

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.7694         Pr(|T| &gt; |t|) = 0.4611          Pr(T &gt; t) = 0.2306



ttest of race by missingness of edu

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2416    1.016142    .0164994    .8109934    .9837879    1.048497
       1 |     291    1.037801    .0472723    .8064058    .9447603    1.130841
---------+--------------------------------------------------------------------
combined |    2707    1.018471    .0155756    .8103808    .9879293    1.049012
---------+--------------------------------------------------------------------
    diff |           -.0216583    .0502926                -.120274    .0769574
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =  -0.4306
Ho: diff = 0                                     degrees of freedom =     2705

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.3334         Pr(|T| &gt; |t|) = 0.6668          Pr(T &gt; t) = 0.6666



ttest of urban by missingness of edu

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2442    .6588862    .0095956    .4741806    .6400698    .6777025
       1 |     285    .6912281    .0274139    .4627995    .6372679    .7451882
---------+--------------------------------------------------------------------
combined |    2727    .6622662    .0090582     .473024    .6445046    .6800278
---------+--------------------------------------------------------------------
    diff |           -.0323419    .0296084               -.0903991    .0257153
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =  -1.0923
Ho: diff = 0                                     degrees of freedom =     2725

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.1374         Pr(|T| &gt; |t|) = 0.2748          Pr(T &gt; t) = 0.8626



ttest of exp by missingness of edu

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2419    15.61121    .1972722    9.702505    15.22437    15.99805
       1 |     288    15.25056    .5463414     9.27172    14.17522    16.32591
---------+--------------------------------------------------------------------
combined |    2707    15.57284    .1856003    9.656566    15.20891    15.93677
---------+--------------------------------------------------------------------
    diff |            .3606459    .6020106               -.8198013    1.541093
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =   0.5991
Ho: diff = 0                                     degrees of freedom =     2705

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.7254         Pr(|T| &gt; |t|) = 0.5492          Pr(T &gt; t) = 0.2746



ttest of wage by missingness of edu

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2412    71484.16    778.2065    38219.37    69958.14    73010.19
       1 |     289    71575.65    2187.928    37194.77     67269.3    75882.01
---------+--------------------------------------------------------------------
combined |    2701    71493.95    733.1819     38104.3     70056.3    72931.61
---------+--------------------------------------------------------------------
    diff |           -91.48891    2372.352               -4743.299    4560.321
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =  -0.0386
Ho: diff = 0                                     degrees of freedom =     2699

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.4846         Pr(|T| &gt; |t|) = 0.9692          Pr(T &gt; t) = 0.5154



logit missingness of exp on female race urban edu wage

Iteration 0:   log likelihood = -654.79701  
Iteration 1:   log likelihood = -653.43555  
Iteration 2:   log likelihood = -653.43222  
Iteration 3:   log likelihood = -653.43222  

Logistic regression                               Number of obs   =       1982
                                                  LR chi2(5)      =       2.73
                                                  Prob &gt; chi2     =     0.7416
Log likelihood = -653.43222                       Pseudo R2       =     0.0021

------------------------------------------------------------------------------
    miss_exp |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      female |   .0225336   .1628237     0.14   0.890     -.296595    .3416622
        race |  -.0595427   .0946498    -0.63   0.529    -.2450529    .1259675
       urban |   .0187602   .1634337     0.11   0.909     -.301564    .3390845
         edu |   .1058189   .0930734     1.14   0.256    -.0766016    .2882394
        wage |  -2.42e-06   2.20e-06    -1.10   0.271    -6.73e-06    1.89e-06
       _cons |  -2.216882   .2563097    -8.65   0.000     -2.71924   -1.714524
------------------------------------------------------------------------------



ttest of female by missingness of exp

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2707    .4931659    .0096109    .5000457    .4743204    .5120114
       1 |     293    .5221843    .0292315    .5003622    .4646532    .5797154
---------+--------------------------------------------------------------------
combined |    3000        .496    .0091299    .5000674    .4780984    .5139016
---------+--------------------------------------------------------------------
    diff |           -.0290184    .0307552               -.0893219    .0312851
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =  -0.9435
Ho: diff = 0                                     degrees of freedom =     2998

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.1727         Pr(|T| &gt; |t|) = 0.3455          Pr(T &gt; t) = 0.8273



ttest of race by missingness of exp

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2448    1.020425    .0163788    .8103788    .9883071    1.052543
       1 |     259           1    .0504388    .8117356    .9006758    1.099324
---------+--------------------------------------------------------------------
combined |    2707    1.018471    .0155756    .8103808    .9879293    1.049012
---------+--------------------------------------------------------------------
    diff |            .0204248    .0529598               -.0834209    .1242705
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =   0.3857
Ho: diff = 0                                     degrees of freedom =     2705

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.6501         Pr(|T| &gt; |t|) = 0.6998          Pr(T &gt; t) = 0.3499



ttest of urban by missingness of exp

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2450    .6628571    .0095526    .4728306    .6441251    .6815892
       1 |     277    .6570397    .0285735    .4755575    .6007901    .7132894
---------+--------------------------------------------------------------------
combined |    2727    .6622662    .0090582     .473024    .6445046    .6800278
---------+--------------------------------------------------------------------
    diff |            .0058174    .0299902               -.0529884    .0646233
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =   0.1940
Ho: diff = 0                                     degrees of freedom =     2725

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.5769         Pr(|T| &gt; |t|) = 0.8462          Pr(T &gt; t) = 0.4231



ttest of edu by missingness of exp

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2419    2.355105    .0185189    .9108219    2.318791     2.39142
       1 |     262    2.381679    .0572124    .9260638    2.269023    2.494336
---------+--------------------------------------------------------------------
combined |    2681    2.357702     .017617     .912182    2.323158    2.392247
---------+--------------------------------------------------------------------
    diff |            -.026574    .0593371               -.1429251    .0897771
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =  -0.4478
Ho: diff = 0                                     degrees of freedom =     2679

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.3271         Pr(|T| &gt; |t|) = 0.6543          Pr(T &gt; t) = 0.6729



ttest of wage by missingness of exp

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2432    71682.77    773.3145    38136.25    70166.35     73199.2
       1 |     269    69786.84    2307.266    37841.97    65244.17    74329.51
---------+--------------------------------------------------------------------
combined |    2701    71493.95    733.1819     38104.3     70056.3    72931.61
---------+--------------------------------------------------------------------
    diff |            1895.932    2448.559               -2905.309    6697.173
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =   0.7743
Ho: diff = 0                                     degrees of freedom =     2699

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.7806         Pr(|T| &gt; |t|) = 0.4388          Pr(T &gt; t) = 0.2194



logit missingness of wage on female race urban edu exp

Iteration 0:   log likelihood = -647.94103  
Iteration 1:   log likelihood = -645.05158  
Iteration 2:   log likelihood =  -645.0361  
Iteration 3:   log likelihood =  -645.0361  

Logistic regression                               Number of obs   =       1979
                                                  LR chi2(5)      =       5.81
                                                  Prob &gt; chi2     =     0.3252
Log likelihood =  -645.0361                       Pseudo R2       =     0.0045

------------------------------------------------------------------------------
   miss_wage |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
      female |   -.191566   .1570953    -1.22   0.223    -.4994672    .1163353
        race |  -.1705262   .0959515    -1.78   0.076    -.3585876    .0175352
       urban |  -.1708259   .1599631    -1.07   0.286    -.4843478     .142696
         edu |   .0710834   .0886472     0.80   0.423     -.102662    .2448288
         exp |   .0040734   .0079491     0.51   0.608    -.0115065    .0196534
       _cons |  -2.049828   .2771956    -7.39   0.000    -2.593121   -1.506535
------------------------------------------------------------------------------



ttest of female by missingness of wage

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2701    .5012958    .0096225    .5000909    .4824277     .520164
       1 |     299    .4481605    .0288081    .4981391    .3914674    .5048537
---------+--------------------------------------------------------------------
combined |    3000        .496    .0091299    .5000674    .4780984    .5139016
---------+--------------------------------------------------------------------
    diff |            .0531353     .030468                -.006605    .1128755
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =   1.7440
Ho: diff = 0                                     degrees of freedom =     2998

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.9594         Pr(|T| &gt; |t|) = 0.0813          Pr(T &gt; t) = 0.0406



ttest of race by missingness of wage

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2442    1.020885    .0164342    .8121201    .9886582    1.053111
       1 |     265    .9962264    .0488572    .7953373    .9000271    1.092426
---------+--------------------------------------------------------------------
combined |    2707    1.018471    .0155756    .8103808    .9879293    1.049012
---------+--------------------------------------------------------------------
    diff |            .0246581    .0524204               -.0781299    .1274461
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =   0.4704
Ho: diff = 0                                     degrees of freedom =     2705

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.6809         Pr(|T| &gt; |t|) = 0.6381          Pr(T &gt; t) = 0.3191



ttest of urban by missingness of wage

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2458    .6647681    .0095237    .4721675    .6460928    .6834434
       1 |     269    .6394052    .0293312    .4810681    .5816562    .6971542
---------+--------------------------------------------------------------------
combined |    2727    .6622662    .0090582     .473024    .6445046    .6800278
---------+--------------------------------------------------------------------
    diff |            .0253629    .0303797               -.0342066    .0849324
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =   0.8349
Ho: diff = 0                                     degrees of freedom =     2725

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.7981         Pr(|T| &gt; |t|) = 0.4039          Pr(T &gt; t) = 0.2019



ttest of edu by missingness of wage

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2412    2.357794    .0185831    .9126566    2.321354    2.394235
       1 |     269    2.356877    .0554598    .9096083    2.247685     2.46607
---------+--------------------------------------------------------------------
combined |    2681    2.357702     .017617     .912182    2.323158    2.392247
---------+--------------------------------------------------------------------
    diff |             .000917     .058647                -.114081    .1159151
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =   0.0156
Ho: diff = 0                                     degrees of freedom =     2679

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.5062         Pr(|T| &gt; |t|) = 0.9875          Pr(T &gt; t) = 0.4938



ttest of exp by missingness of wage

Two-sample t test with equal variances
------------------------------------------------------------------------------
   Group |     Obs        Mean    Std. Err.   Std. Dev.   [95% Conf. Interval]
---------+--------------------------------------------------------------------
       0 |    2432    15.51836    .1952193    9.627299    15.13555    15.90117
       1 |     275    16.05461    .5979892    9.916529    14.87737    17.23184
---------+--------------------------------------------------------------------
combined |    2707    15.57284    .1856003    9.656566    15.20891    15.93677
---------+--------------------------------------------------------------------
    diff |           -.5362457    .6143811                -1.74095    .6684581
------------------------------------------------------------------------------
    diff = mean(0) - mean(1)                                      t =  -0.8728
Ho: diff = 0                                     degrees of freedom =     2705

    Ha: diff &lt; 0                 Ha: diff != 0                 Ha: diff &gt; 0
 Pr(T &lt; t) = 0.1914         Pr(|T| &gt; |t|) = 0.3828          Pr(T &gt; t) = 0.8086

. 
. 
. // set up trial imputation command just to get the individual regression commands
. mi set wide

. mi register imputed race-wage

. mi register regular female

. mi impute chained (logit) urban (mlogit) race (ologit) edu (regress) exp wage = i.female, dryrun

Conditional models:
             urban: logit urban i.race exp wage i.edu i.female
              race: mlogit race i.urban exp wage i.edu i.female
               exp: regress exp i.urban i.race wage i.edu i.female
              wage: regress wage i.urban i.race exp i.edu i.female
               edu: ologit edu i.urban i.race exp wage i.female


<a id="models" name="models"></a>. 
. // test imputation model for race
. mlogit race exp wage i.edu i.urban i.female

Iteration 0:   log likelihood =   -1953.43  
Iteration 1:   log likelihood = -1879.0566  
Iteration 2:   log likelihood = -1877.6678  
Iteration 3:   log likelihood = -1877.6668  
Iteration 4:   log likelihood = -1877.6668  

Multinomial logistic regression                   Number of obs   =       1779
                                                  LR chi2(14)     =     151.53
                                                  Prob &gt; chi2     =     0.0000
Log likelihood = -1877.6668                       Pseudo R2       =     0.0388

------------------------------------------------------------------------------
        race |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
0            |
         exp |  -.0160644   .0075448    -2.13   0.033     -.030852   -.0012767
        wage |   5.80e-06   2.07e-06     2.80   0.005     1.75e-06    9.85e-06
             |
         edu |
          2  |  -.8129621   .1829418    -4.44   0.000    -1.171521   -.4544027
          3  |  -1.593897   .1971316    -8.09   0.000    -1.980268   -1.207526
          4  |   -2.72232   .2886243    -9.43   0.000    -3.288013   -2.156626
             |
     1.urban |   .7865707   .1339259     5.87   0.000     .5240808    1.049061
    1.female |   .2893221   .1342653     2.15   0.031      .026167    .5524772
       _cons |    .226939    .225613     1.01   0.314    -.2152544    .6691324
-------------+----------------------------------------------------------------
1            |
         exp |   .0052958   .0071395     0.74   0.458    -.0086974    .0192891
        wage |   6.69e-07   1.97e-06     0.34   0.734    -3.19e-06    4.53e-06
             |
         edu |
          2  |  -.5144888   .1832349    -2.81   0.005    -.8736226    -.155355
          3  |  -1.125629   .1949919    -5.77   0.000    -1.507806    -.743452
          4  |  -1.307677   .2464598    -5.31   0.000    -1.790729   -.8246246
             |
     1.urban |   .4772458   .1266699     3.77   0.000     .2289775    .7255142
    1.female |   .1276518   .1290494     0.99   0.323    -.1252803     .380584
       _cons |    .253432    .220844     1.15   0.251    -.1794143    .6862783
-------------+----------------------------------------------------------------
2            |  (base outcome)
------------------------------------------------------------------------------

. // test for misspecification by adding interactions
. mlogit race (c.exp c.wage i.edu)##(i.female i.urban)

Iteration 0:   log likelihood =   -1953.43  
Iteration 1:   log likelihood = -1873.2138  
Iteration 2:   log likelihood = -1871.3005  
Iteration 3:   log likelihood = -1871.2474  
Iteration 4:   log likelihood = -1871.2473  

Multinomial logistic regression                   Number of obs   =       1779
                                                  LR chi2(34)     =     164.37
                                                  Prob &gt; chi2     =     0.0000
Log likelihood = -1871.2473                       Pseudo R2       =     0.0421

-------------------------------------------------------------------------------
         race |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
--------------+----------------------------------------------------------------
0             |
          exp |  -.0032793   .0152468    -0.22   0.830    -.0331624    .0266038
         wage |   7.15e-06   4.01e-06     1.78   0.075    -7.13e-07     .000015
              |
          edu |
           2  |  -.7354223   .3525541    -2.09   0.037    -1.426416    -.044429
           3  |  -1.842053   .4005341    -4.60   0.000    -2.627085    -1.05702
           4  |  -3.830948   1.095232    -3.50   0.000    -5.977563   -1.684332
              |
     1.female |   .1884419   .4158562     0.45   0.650    -.6266212    1.003505
      1.urban |   1.056967   .4258448     2.48   0.013     .2223265    1.891608
              |
 female#c.exp |
           1  |  -.0064319   .0151943    -0.42   0.672    -.0362122    .0233484
              |
  urban#c.exp |
           1  |  -.0133441   .0161867    -0.82   0.410    -.0450693    .0183812
              |
female#c.wage |
           1  |   1.91e-06   4.18e-06     0.46   0.648    -6.29e-06    .0000101
              |
 urban#c.wage |
           1  |  -3.07e-06   4.27e-06    -0.72   0.472    -.0000114    5.30e-06
              |
   edu#female |
         2 1  |  -.0181898   .3925029    -0.05   0.963    -.7874813    .7511017
         3 1  |  -.0172244   .4175976    -0.04   0.967    -.8357006    .8012518
         4 1  |   .4977631   .6962046     0.71   0.475    -.8667728    1.862299
              |
    edu#urban |
         2 1  |  -.0763182   .3951518    -0.19   0.847    -.8508015    .6981651
         3 1  |   .3914775    .440372     0.89   0.374    -.4716358    1.254591
         4 1  |   .8667237   1.155459     0.75   0.453    -1.397934    3.131381
              |
        _cons |   .0469868   .3959872     0.12   0.906    -.7291337    .8231074
--------------+----------------------------------------------------------------
1             |
          exp |   .0117503   .0139703     0.84   0.400     -.015631    .0391316
         wage |   6.92e-07   3.72e-06     0.19   0.852    -6.59e-06    7.98e-06
              |
          edu |
           2  |  -.4485059   .3458792    -1.30   0.195    -1.126417    .2294049
           3  |   -1.31316   .3798982    -3.46   0.001    -2.057747   -.5685735
           4  |  -1.904266   .5852199    -3.25   0.001    -3.051275   -.7572556
              |
     1.female |   .1574212   .4125146     0.38   0.703    -.6510925    .9659349
      1.urban |   .3765925    .421229     0.89   0.371    -.4490011    1.202186
              |
 female#c.exp |
           1  |  -.0173227   .0144194    -1.20   0.230    -.0455843    .0109389
              |
  urban#c.exp |
           1  |   .0034701    .015149     0.23   0.819    -.0262214    .0331615
              |
female#c.wage |
           1  |   3.64e-06   4.00e-06     0.91   0.363    -4.20e-06    .0000115
              |
 urban#c.wage |
           1  |  -2.70e-06   4.03e-06    -0.67   0.503    -.0000106    5.20e-06
              |
   edu#female |
         2 1  |   -.227974   .3945182    -0.58   0.563    -1.001215    .5452674
         3 1  |  -.0181844    .414751    -0.04   0.965    -.8310815    .7947127
         4 1  |   .4709082   .5673412     0.83   0.407    -.6410601    1.582876
              |
    edu#urban |
         2 1  |   .0936678   .3968078     0.24   0.813    -.6840612    .8713968
         3 1  |   .3483946   .4271216     0.82   0.415    -.4887483    1.185538
         4 1  |   .3778603   .6590117     0.57   0.566     -.913779      1.6695
              |
        _cons |   .2636095   .3807272     0.69   0.489    -.4826021    1.009821
--------------+----------------------------------------------------------------
2             |  (base outcome)
-------------------------------------------------------------------------------

. 
. // test imputation model for exp
. regress exp i.race wage i.edu i.urban i.female

      Source |       SS       df       MS              Number of obs =    1779
-------------+------------------------------           F(  8,  1770) =   93.75
       Model |  49906.8412     8  6238.35514           Prob &gt; F      =  0.0000
    Residual |   117780.77  1770  66.5428078           R-squared     =  0.2976
-------------+------------------------------           Adj R-squared =  0.2944
       Total |  167687.611  1778  94.3124921           Root MSE      =  8.1574

------------------------------------------------------------------------------
         exp |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
        race |
          1  |   1.391616   .4799807     2.90   0.004      .450227    2.333004
          2  |   1.031061   .4947771     2.08   0.037     .0606522     2.00147
             |
        wage |   .0001343   5.71e-06    23.50   0.000     .0001231    .0001455
             |
         edu |
          2  |   -1.96545   .5537782    -3.55   0.000    -3.051578   -.8793225
          3  |  -5.058849   .5979374    -8.46   0.000    -6.231586   -3.886111
          4  |  -7.905853   .8106653    -9.75   0.000    -9.495815   -6.315891
             |
     1.urban |  -.5730682   .4234363    -1.35   0.176    -1.403556    .2574196
    1.female |  -1.111798   .4256352    -2.61   0.009    -1.946598   -.2769972
       _cons |   9.243531    .716064    12.91   0.000     7.839111    10.64795
------------------------------------------------------------------------------

. // test for misspecification with rvfplot
. // constraint line indicates exp&gt;=0
. rvfplot, ylabel(-40 -20 0 20 40)

. graph export exp1.png, replace
(file exp1.png written in PNG format)
<img alt="rvfplot" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/exp1.png" width="585"/>
. predict exphat
(option xb assumed; fitted values)
(1018 missing values generated)

. predict expres, res
(1221 missing values generated)

. gen y=-exphat
(1018 missing values generated)

. scatter expres exphat || line y exphat, legend(order(2 "Exp&gt;=0 Constraint"))

. graph export exp2.png, replace
(file exp2.png written in PNG format)
<img alt="rvfplot with constraint line added" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/exp2.png" width="585"/>
. drop expres exphat y

. //test for misspecification by adding interactions
. regress exp (i.race i.urban i.female)##(c.wage i.edu)

      Source |       SS       df       MS              Number of obs =    1779
-------------+------------------------------           F( 24,  1754) =   32.28
       Model |  51376.4689    24   2140.6862           Prob &gt; F      =  0.0000
    Residual |  116311.142  1754  66.3119396           R-squared     =  0.3064
-------------+------------------------------           Adj R-squared =  0.2969
       Total |  167687.611  1778  94.3124921           Root MSE      =  8.1432

-------------------------------------------------------------------------------
          exp |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
--------------+----------------------------------------------------------------
         race |
           1  |   .8903704   1.271895     0.70   0.484     -1.60422    3.384961
           2  |   1.418534    1.46223     0.97   0.332    -1.449363    4.286431
              |
      1.urban |  -1.905077    1.19761    -1.59   0.112     -4.25397    .4438155
     1.female |  -.0698405   1.188445    -0.06   0.953    -2.400758    2.261077
         wage |   .0001473   .0000136    10.87   0.000     .0001207    .0001739
              |
          edu |
           2  |  -3.806439   1.314344    -2.90   0.004    -6.384285   -1.228592
           3  |  -6.196198   1.456027    -4.26   0.000     -9.05193   -3.340466
           4  |  -8.003504   2.559556    -3.13   0.002    -13.02361   -2.983403
              |
  race#c.wage |
           1  |  -8.72e-06   .0000133    -0.65   0.513    -.0000349    .0000174
           2  |  -.0000135    .000013    -1.04   0.296     -.000039    .0000119
              |
     race#edu |
         1 2  |   2.488045   1.259945     1.97   0.048      .016893    4.959198
         1 3  |  -.1736131   1.376548    -0.13   0.900     -2.87346    2.526234
         1 4  |    2.29836    2.10793     1.09   0.276    -1.835959    6.432679
         2 2  |   1.029303    1.46414     0.70   0.482    -1.842342    3.900947
         2 3  |  -.0586898   1.510437    -0.04   0.969    -3.021136    2.903756
         2 4  |   2.118492   2.158164     0.98   0.326    -2.114354    6.351337
              |
 urban#c.wage |
           1  |   8.06e-06   .0000115     0.70   0.482    -.0000144    .0000306
              |
    urban#edu |
         1 2  |   .8233918   1.191193     0.69   0.490    -1.512916      3.1597
         1 3  |   1.802902    1.29168     1.40   0.163    -.7304935    4.336297
         1 4  |  -3.443128    2.15643    -1.60   0.111    -7.672571    .7863152
              |
female#c.wage |
           1  |  -.0000233   .0000115    -2.02   0.044     -.000046   -6.71e-07
              |
   female#edu |
         1 2  |   .5626791   1.188512     0.47   0.636    -1.768369    2.893728
         1 3  |   .4449296   1.252109     0.36   0.722    -2.010853    2.900712
         1 4  |   2.712876     1.8349     1.48   0.139    -.8859457    6.311698
              |
        _cons |   9.321907   1.382308     6.74   0.000     6.610763    12.03305
-------------------------------------------------------------------------------

. 
. 
. // test imputation model for wage
. regress wage i.race exp i.edu i.urban i.female

      Source |       SS       df       MS              Number of obs =    1779
-------------+------------------------------           F(  8,  1770) =  145.49
       Model |  1.0214e+12     8  1.2767e+11           Prob &gt; F      =  0.0000
    Residual |  1.5532e+12  1770   877509504           R-squared     =  0.3967
-------------+------------------------------           Adj R-squared =  0.3940
       Total |  2.5746e+12  1778  1.4480e+09           Root MSE      =   29623

------------------------------------------------------------------------------
        wage |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
        race |
          1  |  -4353.207   1744.074    -2.50   0.013    -7773.869   -932.5451
          2  |  -4939.278   1795.106    -2.75   0.006    -8460.029   -1418.526
             |
         exp |   1771.135   75.35312    23.50   0.000     1623.344    1918.925
             |
         edu |
          2  |   8345.912   2008.366     4.16   0.000     4406.894    12284.93
          3  |   26875.02   2120.707    12.67   0.000     22715.66    31034.37
          4  |   44200.82   2833.404    15.60   0.000     38643.65    49757.99
             |
     1.urban |    3737.22     1535.9     2.43   0.015     724.8518    6749.588
    1.female |  -19496.65   1477.669   -13.19   0.000    -22394.81   -16598.49
       _cons |   37847.82   2566.897    14.74   0.000     32813.35    42882.29
------------------------------------------------------------------------------

. // test for misspecification with rvfplot
. // constraint line indicates wage&gt;=0
. rvfplot

. graph export wage.png, replace
<img alt="rvfplot for wage" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/wage.png" width="585"/>
(note: file wage.png not found)
(file wage.png written in PNG format)

. // test interactions
. regress wage (i.race i.urban i.female)##(c.exp i.edu) 

      Source |       SS       df       MS              Number of obs =    1779
-------------+------------------------------           F( 24,  1754) =   51.27
       Model |  1.0615e+12    24  4.4230e+10           Prob &gt; F      =  0.0000
    Residual |  1.5130e+12  1754   862625195           R-squared     =  0.4123
-------------+------------------------------           Adj R-squared =  0.4043
       Total |  2.5746e+12  1778  1.4480e+09           Root MSE      =   29370

------------------------------------------------------------------------------
        wage |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
        race |
          1  |   409.0987   4761.366     0.09   0.932    -8929.451    9747.648
          2  |    40.7097     5452.8     0.01   0.994    -10653.96    10735.38
             |
     1.urban |   2955.393   4512.636     0.65   0.513     -5895.32     11806.1
    1.female |  -5986.333    4393.73    -1.36   0.173    -14603.83    2631.167
         exp |   2086.047   188.9033    11.04   0.000     1715.547    2456.546
             |
         edu |
          2  |   12596.53   4787.695     2.63   0.009     3206.339    21986.72
          3  |    33416.6   5179.464     6.45   0.000     23258.02    43575.17
          4  |   29270.41   9233.095     3.17   0.002     11161.38    47379.44
             |
  race#c.exp |
          1  |  -367.0251   180.2227    -2.04   0.042     -720.499   -13.55117
          2  |  -53.25982   182.8739    -0.29   0.771    -411.9335    305.4139
             |
    race#edu |
        1 2  |  -482.0457   4541.364    -0.11   0.915    -9389.103    8425.011
        1 3  |   1861.724   4875.674     0.38   0.703    -7701.021    11424.47
        1 4  |   7840.737   7555.631     1.04   0.300    -6978.253    22659.73
        2 2  |  -7391.542   5296.316    -1.40   0.163     -17779.3    2996.213
        2 3  |  -4044.694   5390.587    -0.75   0.453    -14617.35    6527.957
        2 4  |   3039.309   7774.405     0.39   0.696    -12208.77    18287.38
             |
 urban#c.exp |
          1  |   119.1172   157.4763     0.76   0.450    -189.7437    427.9781
             |
   urban#edu |
        1 2  |   644.4913   4304.863     0.15   0.881    -7798.712    9087.694
        1 3  |  -7540.896   4566.843    -1.65   0.099    -16497.92    1416.132
        1 4  |   25090.89   7625.385     3.29   0.001     10135.09    40046.69
             |
female#c.exp |
          1  |   -547.008   151.0542    -3.62   0.000    -843.2732   -250.7427
             |
  female#edu |
        1 2  |  -6295.529   4285.177    -1.47   0.142    -14700.12    2109.064
        1 3  |  -3410.924   4406.216    -0.77   0.439    -12052.91    5231.064
        1 4  |  -19915.24   6326.051    -3.15   0.002    -32322.64   -7507.849
             |
       _cons |   29172.73   5272.194     5.53   0.000     18832.28    39513.17
------------------------------------------------------------------------------

. 
. 
. // test imputation model for edu
. ologit edu i.race exp wage i.urban i.female

Iteration 0:   log likelihood = -2295.6305  
Iteration 1:   log likelihood =   -2021.07  
Iteration 2:   log likelihood = -2013.1176  
Iteration 3:   log likelihood = -2013.1071  
Iteration 4:   log likelihood = -2013.1071  

Ordered logistic regression                       Number of obs   =       1779
                                                  LR chi2(6)      =     565.05
                                                  Prob &gt; chi2     =     0.0000
Log likelihood = -2013.1071                       Pseudo R2       =     0.1231

------------------------------------------------------------------------------
         edu |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
        race |
          1  |   .5023646   .1109327     4.53   0.000     .2849405    .7197886
          2  |   1.220383   .1136064    10.74   0.000     .9977182    1.443047
             |
         exp |  -.0604264   .0055268   -10.93   0.000    -.0712587    -.049594
        wage |   .0000253   1.50e-06    16.89   0.000     .0000224    .0000282
     1.urban |   .8322351   .0973248     8.55   0.000      .641482    1.022988
    1.female |   .9733093   .0976488     9.97   0.000     .7819211    1.164697
-------------+----------------------------------------------------------------
       /cut1 |   .6530809   .1597114                      .3400522    .9661095
       /cut2 |   2.796932   .1712768                      2.461236    3.132628
       /cut3 |    5.04024   .2008955                      4.646492    5.433988
------------------------------------------------------------------------------

. // test for misspecification by adding interactions
. ologit edu (i.race i.urban i.female)##(c.exp c.wage)

Iteration 0:   log likelihood = -2295.6305  
Iteration 1:   log likelihood =  -2013.335  
Iteration 2:   log likelihood = -2004.1162  
Iteration 3:   log likelihood = -2004.0949  
Iteration 4:   log likelihood = -2004.0949  

Ordered logistic regression                       Number of obs   =       1779
                                                  LR chi2(14)     =     583.07
                                                  Prob &gt; chi2     =     0.0000
Log likelihood = -2004.0949                       Pseudo R2       =     0.1270

-------------------------------------------------------------------------------
          edu |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
--------------+----------------------------------------------------------------
         race |
           1  |   .1327298   .2534179     0.52   0.600    -.3639601    .6294198
           2  |   1.003797   .2497778     4.02   0.000     .5142413    1.493352
              |
      1.urban |   1.366727   .2189527     6.24   0.000     .9375876    1.795866
     1.female |    .618023   .2149086     2.88   0.004     .1968099    1.039236
          exp |  -.0465445   .0139356    -3.34   0.001    -.0738578   -.0192312
         wage |   .0000226   3.55e-06     6.38   0.000     .0000157    .0000296
              |
   race#c.exp |
           1  |   .0009364   .0132133     0.07   0.944    -.0249611    .0268339
           2  |  -.0018853   .0134862    -0.14   0.889    -.0283179    .0245472
              |
  race#c.wage |
           1  |   5.02e-06   3.42e-06     1.47   0.142    -1.68e-06    .0000117
           2  |   3.62e-06   3.35e-06     1.08   0.280    -2.95e-06    .0000102
              |
  urban#c.exp |
           1  |  -.0137359   .0115411    -1.19   0.234    -.0363561    .0088844
              |
 urban#c.wage |
           1  |  -4.85e-06   2.88e-06    -1.68   0.092    -.0000105    7.92e-07
              |
 female#c.exp |
           1  |  -.0057173   .0108306    -0.53   0.598    -.0269449    .0155103
              |
female#c.wage |
           1  |   6.55e-06   2.81e-06     2.33   0.020     1.05e-06    .0000121
--------------+----------------------------------------------------------------
        /cut1 |   .6270383   .2723209                      .0932992    1.160777
        /cut2 |   2.779004   .2811126                      2.228033    3.329974
        /cut3 |   5.047488   .2980929                      4.463237     5.63174
-------------------------------------------------------------------------------

. 
. // test imputation model for urban
. logit urban i.race exp wage i.edu i.female

Iteration 0:   log likelihood = -1142.4725  
Iteration 1:   log likelihood = -1075.0707  
Iteration 2:   log likelihood = -1073.6056  
Iteration 3:   log likelihood = -1073.6034  
Iteration 4:   log likelihood = -1073.6034  

Logistic regression                               Number of obs   =       1779
                                                  LR chi2(8)      =     137.74
                                                  Prob &gt; chi2     =     0.0000
Log likelihood = -1073.6034                       Pseudo R2       =     0.0603

------------------------------------------------------------------------------
       urban |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
        race |
          1  |  -.2954482   .1311706    -2.25   0.024    -.5525378   -.0383585
          2  |  -.7792647   .1334625    -5.84   0.000    -1.040846    -.517683
             |
         exp |  -.0088777   .0063875    -1.39   0.165     -.021397    .0036416
        wage |   4.29e-06   1.77e-06     2.42   0.015     8.23e-07    7.76e-06
             |
         edu |
          2  |    .606303   .1394181     4.35   0.000     .3330484    .8795575
          3  |    1.03064   .1574484     6.55   0.000     .7220471    1.339233
          4  |   1.994752   .2554113     7.81   0.000     1.494155    2.495349
             |
    1.female |  -.0520909   .1138005    -0.46   0.647    -.2751358     .170954
       _cons |   .1577303   .1863126     0.85   0.397    -.2074357    .5228963
------------------------------------------------------------------------------

. // test for misspecification by adding interactions
. logit urban (i.race i.female)##(c.exp c.wage i.edu)

Iteration 0:   log likelihood = -1142.4725  
Iteration 1:   log likelihood = -1020.9319  
Iteration 2:   log likelihood = -1015.6326  
Iteration 3:   log likelihood = -1015.3365  
Iteration 4:   log likelihood = -1015.3347  
Iteration 5:   log likelihood = -1015.3347  

Logistic regression                               Number of obs   =       1779
                                                  LR chi2(23)     =     254.28
                                                  Prob &gt; chi2     =     0.0000
Log likelihood = -1015.3347                       Pseudo R2       =     0.1113

-------------------------------------------------------------------------------
        urban |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
--------------+----------------------------------------------------------------
         race |
           1  |  -.7713392   .3795508    -2.03   0.042    -1.515245   -.0274332
           2  |  -1.156397   .4315566    -2.68   0.007    -2.002233   -.3105619
              |
     1.female |   -1.51098   .3321957    -4.55   0.000    -2.162072   -.8598889
          exp |  -.0231263   .0138578    -1.67   0.095    -.0502871    .0040344
         wage |   5.59e-06   3.70e-06     1.51   0.131    -1.66e-06    .0000129
              |
          edu |
           2  |  -.2098759   .2750943    -0.76   0.446    -.7490508     .329299
           3  |  -.0925368   .3264801    -0.28   0.777    -.7324261    .5473525
           4  |   .4987983   1.103814     0.45   0.651    -1.664638    2.662234
              |
   race#c.exp |
           1  |   .0257714   .0168647     1.53   0.126    -.0072828    .0588256
           2  |   .0187349   .0166967     1.12   0.262      -.01399    .0514598
              |
  race#c.wage |
           1  |  -5.02e-07   4.54e-06    -0.11   0.912    -9.40e-06    8.39e-06
           2  |   3.07e-06   4.36e-06     0.70   0.481    -5.47e-06    .0000116
              |
     race#edu |
         1 2  |   .1629017   .3408843     0.48   0.633    -.5052193    .8310227
         1 3  |   .0019093   .4077384     0.00   0.996    -.7972432    .8010619
         1 4  |  -.5458701   1.203649    -0.45   0.650    -2.904979    1.813238
         2 2  |   .0964406   .3983642     0.24   0.809     -.684339    .8772201
         2 3  |  -.3518724   .4347531    -0.81   0.418    -1.203973     .500228
         2 4  |  -.9799584   1.159742    -0.84   0.398     -3.25301    1.293093
              |
 female#c.exp |
           1  |     -.0047   .0134151    -0.35   0.726    -.0309931    .0215931
              |
female#c.wage |
           1  |  -4.51e-06   3.73e-06    -1.21   0.227    -.0000118    2.81e-06
              |
   female#edu |
         1 2  |   1.671398     .30319     5.51   0.000     1.077157     2.26564
         1 3  |   2.788041   .3342213     8.34   0.000      2.13298    3.443103
         1 4  |   4.461757   .5745605     7.77   0.000     3.335639    5.587875
              |
        _cons |   1.049029   .3234171     3.24   0.001     .4151428    1.682915
-------------------------------------------------------------------------------

. 
. 
. // refine models after reviewing results
. mi impute chained (logit) urban (mlogit) race (ologit) edu (pmm) exp wage, dryrun by(female)

Performing setup for each by() group:

-&gt; female = 0
Conditional models:
               exp: pmm exp i.urban i.race wage i.edu
             urban: logit urban exp i.race wage i.edu
              race: mlogit race exp i.urban wage i.edu
              wage: pmm wage exp i.urban i.race i.edu
               edu: ologit edu exp i.urban i.race wage

-&gt; female = 1
Conditional models:
             urban: logit urban wage i.race i.edu exp
              wage: pmm wage i.urban i.race i.edu exp
              race: mlogit race i.urban wage i.edu exp
               edu: ologit edu i.urban wage i.race exp
               exp: pmm exp i.urban wage i.race i.edu
. 
. // test new models for convergence
. bysort female: reg exp i.urban i.race wage i.edu

----------------------------------------------------------------------------------------------------------------------------------
-&gt; female = 0

      Source |       SS       df       MS              Number of obs =     892
-------------+------------------------------           F(  7,   884) =   52.98
       Model |   24670.002     7    3524.286           Prob &gt; F      =  0.0000
    Residual |  58807.4441   884   66.524258           R-squared     =  0.2955
-------------+------------------------------           Adj R-squared =  0.2900
       Total |  83477.4461   891   93.689614           Root MSE      =  8.1562

------------------------------------------------------------------------------
         exp |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
     1.urban |  -.5563624   .5784369    -0.96   0.336    -1.691632    .5789075
             |
        race |
          1  |   1.799778   .6750693     2.67   0.008     .4748526    3.124704
          2  |   .8400697   .7025656     1.20   0.232    -.5388214    2.218961
             |
        wage |   .0001445   7.61e-06    18.99   0.000     .0001295    .0001594
             |
         edu |
          2  |  -2.074689   .7327518    -2.83   0.005    -3.512825   -.6365529
          3  |  -5.124519    .816809    -6.27   0.000     -6.72763   -3.521407
          4  |  -8.313709   1.337503    -6.22   0.000    -10.93876   -5.688656
             |
       _cons |   8.402518   .9403253     8.94   0.000     6.556987    10.24805
------------------------------------------------------------------------------

----------------------------------------------------------------------------------------------------------------------------------
-&gt; female = 1

      Source |       SS       df       MS              Number of obs =     887
-------------+------------------------------           F(  7,   879) =   29.74
       Model |  13874.8765     7  1982.12521           Prob &gt; F      =  0.0000
    Residual |  58577.2689   879  66.6408065           R-squared     =  0.1915
-------------+------------------------------           Adj R-squared =  0.1851
       Total |  72452.1454   886  81.7744305           Root MSE      =  8.1634

------------------------------------------------------------------------------
         exp |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
     1.urban |  -.6693439   .6690433    -1.00   0.317    -1.982453    .6437649
             |
        race |
          1  |   .9598328   .6860308     1.40   0.162    -.3866169    2.306282
          2  |   1.164061   .7025743     1.66   0.098     -.214858     2.54298
             |
        wage |    .000121   8.71e-06    13.89   0.000     .0001039    .0001381
             |
         edu |
          2  |  -1.867343   .8689937    -2.15   0.032    -3.572888   -.1617985
          3  |   -4.84498   .9371085    -5.17   0.000    -6.684211   -3.005748
          4  |  -7.366648   1.147116    -6.42   0.000    -9.618054   -5.115242
             |
       _cons |   8.896763   .8998265     9.89   0.000     7.130704    10.66282
------------------------------------------------------------------------------

. by female: logit urban exp i.race wage i.edu

----------------------------------------------------------------------------------------------------------------------------------
-&gt; female = 0

Iteration 0:   log likelihood = -576.14858  
Iteration 1:   log likelihood = -568.10266  
Iteration 2:   log likelihood = -568.08745  
Iteration 3:   log likelihood = -568.08745  

Logistic regression                               Number of obs   =        892
                                                  LR chi2(7)      =      16.12
                                                  Prob &gt; chi2     =     0.0240
Log likelihood = -568.08745                       Pseudo R2       =     0.0140

------------------------------------------------------------------------------
       urban |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         exp |  -.0083494    .008748    -0.95   0.340    -.0254951    .0087964
             |
        race |
          1  |  -.0250462   .1793684    -0.14   0.889    -.3766018    .3265095
          2  |  -.3721612   .1813618    -2.05   0.040    -.7276238   -.0166986
             |
        wage |   6.78e-06   2.36e-06     2.88   0.004     2.16e-06    .0000114
             |
         edu |
          2  |  -.1155276   .1933929    -0.60   0.550    -.4945708    .2635156
          3  |  -.2803377   .2178799    -1.29   0.198    -.7073745    .1466991
          4  |  -.3283938   .3534695    -0.93   0.353    -1.021181    .3643936
             |
       _cons |   .5155881   .2385894     2.16   0.031     .0479615    .9832148
------------------------------------------------------------------------------

----------------------------------------------------------------------------------------------------------------------------------
-&gt; female = 1

Iteration 0:   log likelihood = -566.19162  
Iteration 1:   log likelihood = -450.72498  
Iteration 2:   log likelihood = -445.73919  
Iteration 3:   log likelihood = -445.57881  
Iteration 4:   log likelihood = -445.57813  
Iteration 5:   log likelihood = -445.57813  

Logistic regression                               Number of obs   =        887
                                                  LR chi2(7)      =     241.23
                                                  Prob &gt; chi2     =     0.0000
Log likelihood = -445.57813                       Pseudo R2       =     0.2130

------------------------------------------------------------------------------
       urban |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         exp |  -.0107927    .010163    -1.06   0.288    -.0307119    .0091265
             |
        race |
          1  |  -.6841661   .2108969    -3.24   0.001    -1.097516   -.2708159
          2  |  -1.259647   .2157675    -5.84   0.000    -1.682544   -.8367507
             |
        wage |   1.35e-06   2.93e-06     0.46   0.645    -4.39e-06    7.09e-06
             |
         edu |
          2  |   1.619022   .2371928     6.83   0.000     1.154132    2.083911
          3  |   2.681609   .2672965    10.03   0.000     2.157717      3.2055
          4  |    4.43645   .4644515     9.55   0.000     3.526142    5.346758
             |
       _cons |   -.531204   .2617202    -2.03   0.042    -1.044166   -.0182419
------------------------------------------------------------------------------

. by female: mlogit race exp i.urban wage i.edu

----------------------------------------------------------------------------------------------------------------------------------
-&gt; female = 0

Iteration 0:   log likelihood = -979.43224  
Iteration 1:   log likelihood = -935.80472  
Iteration 2:   log likelihood = -934.98446  
Iteration 3:   log likelihood = -934.97944  
Iteration 4:   log likelihood = -934.97944  

Multinomial logistic regression                   Number of obs   =        892
                                                  LR chi2(12)     =      88.91
                                                  Prob &gt; chi2     =     0.0000
Log likelihood = -934.97944                       Pseudo R2       =     0.0454

------------------------------------------------------------------------------
        race |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
0            |
         exp |  -.0274735   .0102909    -2.67   0.008    -.0476434   -.0073037
     1.urban |   .0262569   .1794679     0.15   0.884    -.3254937    .3780074
        wage |   6.28e-06   2.77e-06     2.27   0.023     8.60e-07    .0000117
             |
         edu |
          2  |  -.4080685    .206086    -1.98   0.048    -.8119896   -.0041474
          3  |  -.5017744   .2464439    -2.04   0.042    -.9847955   -.0187533
          4  |  -1.492324   .5722452    -2.61   0.009    -2.613904   -.3707442
             |
       _cons |   .2462701   .2715063     0.91   0.364    -.2858725    .7784127
-------------+----------------------------------------------------------------
1            |  (base outcome)
-------------+----------------------------------------------------------------
2            |
         exp |  -.0143098   .0102621    -1.39   0.163    -.0344231    .0058036
     1.urban |  -.3510997   .1744316    -2.01   0.044    -.6929795     -.00922
        wage |   9.35e-07   2.75e-06     0.34   0.734    -4.46e-06    6.33e-06
             |
         edu |
          2  |   .3857799   .2450301     1.57   0.115    -.0944702      .86603
          3  |   1.092693   .2658459     4.11   0.000     .5716446    1.613741
          4  |   1.673159   .4094672     4.09   0.000     .8706185      2.4757
             |
       _cons |   -.254461   .2948447    -0.86   0.388     -.832346    .3234241
------------------------------------------------------------------------------

----------------------------------------------------------------------------------------------------------------------------------
-&gt; female = 1

Iteration 0:   log likelihood = -973.97087  
Iteration 1:   log likelihood = -934.18474  
Iteration 2:   log likelihood = -933.62658  
Iteration 3:   log likelihood = -933.62647  
Iteration 4:   log likelihood = -933.62647  

Multinomial logistic regression                   Number of obs   =        887
                                                  LR chi2(12)     =      80.69
                                                  Prob &gt; chi2     =     0.0000
Log likelihood = -933.62647                       Pseudo R2       =     0.0414

------------------------------------------------------------------------------
        race |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
0            |
         exp |  -.0180992   .0106928    -1.69   0.091    -.0390567    .0028584
     1.urban |     1.2596   .2155262     5.84   0.000     .8371769    1.682024
        wage |   6.92e-06   3.05e-06     2.27   0.023     9.36e-07    .0000129
             |
         edu |
          2  |  -1.015529   .2869699    -3.54   0.000     -1.57798   -.4530781
          3  |  -1.873085   .3132415    -5.98   0.000    -2.487027   -1.259143
          4  |  -2.917669   .3964615    -7.36   0.000    -3.694719   -2.140619
             |
       _cons |   .3468113    .282675     1.23   0.220    -.2072216    .9008442
-------------+----------------------------------------------------------------
1            |
         exp |  -.0030983   .0100496    -0.31   0.758    -.0227951    .0165985
     1.urban |   .5720785   .1999865     2.86   0.004     .1801122    .9640448
        wage |   2.49e-06   2.89e-06     0.86   0.388    -3.17e-06    8.16e-06
             |
         edu |
          2  |  -.7094723   .2814518    -2.52   0.012    -1.261108    -.157837
          3  |  -1.229685   .3028501    -4.06   0.000    -1.823261     -.63611
          4  |  -1.319989   .3548621    -3.72   0.000    -2.015506   -.6244719
             |
       _cons |   .4289424    .276908     1.55   0.121    -.1137873     .971672
-------------+----------------------------------------------------------------
2            |  (base outcome)
------------------------------------------------------------------------------

. by female: reg wage exp i.urban i.race i.edu

----------------------------------------------------------------------------------------------------------------------------------
-&gt; female = 0

      Source |       SS       df       MS              Number of obs =     892
-------------+------------------------------           F(  7,   884) =   74.03
       Model |  4.7872e+11     7  6.8388e+10           Prob &gt; F      =  0.0000
    Residual |  8.1660e+11   884   923758881           R-squared     =  0.3696
-------------+------------------------------           Adj R-squared =  0.3646
       Total |  1.2953e+12   891  1.4538e+09           Root MSE      =   30393

------------------------------------------------------------------------------
        wage |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         exp |   2005.904   105.6246    18.99   0.000       1798.6    2213.208
     1.urban |   6217.463   2146.452     2.90   0.004     2004.727     10430.2
             |
        race |
          1  |  -5654.544     2518.5    -2.25   0.025    -10597.48   -711.6073
          2  |  -4775.141   2615.229    -1.83   0.068    -9907.923    357.6405
             |
         edu |
          2  |   10720.55   2719.075     3.94   0.000     5383.955    16057.15
          3  |   28231.17   2962.326     9.53   0.000     22417.16    34045.18
          4  |    50933.9   4794.995    10.62   0.000        41523     60344.8
             |
       _cons |   30542.89   3511.689     8.70   0.000     23650.67    37435.11
------------------------------------------------------------------------------

----------------------------------------------------------------------------------------------------------------------------------
-&gt; female = 1

      Source |       SS       df       MS              Number of obs =     887
-------------+------------------------------           F(  7,   879) =   54.13
       Model |  3.1047e+11     7  4.4353e+10           Prob &gt; F      =  0.0000
    Residual |  7.2028e+11   879   819436657           R-squared     =  0.3012
-------------+------------------------------           Adj R-squared =  0.2956
       Total |  1.0308e+12   886  1.1634e+09           Root MSE      =   28626

------------------------------------------------------------------------------
        wage |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         exp |   1488.074   107.0972    13.89   0.000     1277.878     1698.27
     1.urban |   1266.729   2347.021     0.54   0.590     -3339.69    5873.148
             |
        race |
          1  |  -3442.619   2405.519    -1.43   0.153    -8163.851    1278.613
          2  |  -5492.975   2460.533    -2.23   0.026    -10322.18   -663.7687
             |
         edu |
          2  |   5988.045   3048.533     1.96   0.050     4.792275     11971.3
          3  |   26068.51   3217.693     8.10   0.000     19753.25    32383.77
          4  |   41106.03   3875.211    10.61   0.000     33500.29    48711.78
             |
       _cons |   25087.89   3216.737     7.80   0.000     18774.51    31401.27
------------------------------------------------------------------------------

. by female: ologit edu exp i.urban i.race wage

----------------------------------------------------------------------------------------------------------------------------------
-&gt; female = 0

Iteration 0:   log likelihood = -1092.3176  
Iteration 1:   log likelihood = -986.99706  
Iteration 2:   log likelihood =  -984.5232  
Iteration 3:   log likelihood = -984.51851  
Iteration 4:   log likelihood = -984.51851  

Ordered logistic regression                       Number of obs   =        892
                                                  LR chi2(5)      =     215.60
                                                  Prob &gt; chi2     =     0.0000
Log likelihood = -984.51851                       Pseudo R2       =     0.0987

------------------------------------------------------------------------------
         edu |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         exp |   -.059575   .0078897    -7.55   0.000    -.0750385   -.0441115
     1.urban |  -.1649053   .1336636    -1.23   0.217    -.4268811    .0970705
             |
        race |
          1  |    .420148   .1571087     2.67   0.007     .1122206    .7280753
          2  |   1.275139   .1623148     7.86   0.000     .9570078     1.59327
             |
        wage |   .0000242   2.09e-06    11.58   0.000     .0000201    .0000283
-------------+----------------------------------------------------------------
       /cut1 |  -.1678223    .205886                     -.5713513    .2357068
       /cut2 |   2.064867    .217243                      1.639079    2.490656
       /cut3 |   4.553283   .2681615                      4.027696     5.07887
------------------------------------------------------------------------------

----------------------------------------------------------------------------------------------------------------------------------
-&gt; female = 1

Iteration 0:   log likelihood = -1172.2304  
Iteration 1:   log likelihood = -973.18412  
Iteration 2:   log likelihood = -964.74324  
Iteration 3:   log likelihood = -964.72408  
Iteration 4:   log likelihood = -964.72408  

Ordered logistic regression                       Number of obs   =        887
                                                  LR chi2(5)      =     415.01
                                                  Prob &gt; chi2     =     0.0000
Log likelihood = -964.72408                       Pseudo R2       =     0.1770

------------------------------------------------------------------------------
         edu |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         exp |  -.0555539   .0078704    -7.06   0.000    -.0709795   -.0401282
     1.urban |   1.938634   .1527146    12.69   0.000     1.639319    2.237949
             |
        race |
          1  |   .6760943   .1598405     4.23   0.000     .3628128    .9893759
          2  |   1.299797   .1621729     8.01   0.000      .981944     1.61765
             |
        wage |   .0000265   2.22e-06    11.93   0.000     .0000221    .0000309
-------------+----------------------------------------------------------------
       /cut1 |   .5531119   .1965451                      .1678906    .9383332
       /cut2 |   2.799431   .2172816                      2.373567    3.225295
       /cut3 |   5.078792   .2594613                      4.570257    5.587326
------------------------------------------------------------------------------

. // for real work you would explore misspecification of refined models as well
. 
. 
. // test convergence of imputation process
. // since by() and savetrace() don't get along right now, we'll remove by() then throw away these imputations and do them with by
&gt; () but no savetrace().
. preserve

. mi impute chained (logit) urban (mlogit) race (ologit) edu (pmm) exp wage = female, add(5) rseed(88) savetrace(extrace, replace)
&gt;  burnin(100)

Conditional models:
             urban: logit urban i.race exp wage i.edu female
              race: mlogit race i.urban exp wage i.edu female
               exp: pmm exp i.urban i.race wage i.edu female
              wage: pmm wage i.urban i.race exp i.edu female
               edu: ologit edu i.urban i.race exp wage female

Performing chained iterations ...

Multivariate imputation                     Imputations =        5
Chained equations                                 added =        5
Imputed: m=1 through m=5                        updated =        0

Initialization: monotone                     Iterations =      500
                                                burn-in =      100

             urban: logistic regression
              race: multinomial logistic regression
               edu: ordered logistic regression
               exp: predictive mean matching
              wage: predictive mean matching

------------------------------------------------------------------
                   |               Observations per m             
                   |----------------------------------------------
          Variable |   Complete   Incomplete   Imputed |     Total
-------------------+-----------------------------------+----------
             urban |       2727          273       273 |      3000
              race |       2707          293       293 |      3000
               edu |       2681          319       319 |      3000
               exp |       2707          293       293 |      3000
              wage |       2701          299       299 |      3000
------------------------------------------------------------------
(complete + incomplete = total; imputed is the minimum across m
 of the number of filled-in observations.)

. 
. use extrace, replace
(Summaries of imputed values from -mi impute chained-)

. reshape wide *mean *sd, i(iter) j(m)
(note: j = 1 2 3 4 5)

Data                               long   -&gt;   wide
-----------------------------------------------------------------------------
Number of obs.                      505   -&gt;     101
Number of variables                  12   -&gt;      51
j variable (5 values)                 m   -&gt;   (dropped)
xij variables:
                             urban_mean   -&gt;   urban_mean1 urban_mean2 ... urban_mean5
                              race_mean   -&gt;   race_mean1 race_mean2 ... race_mean5
                               exp_mean   -&gt;   exp_mean1 exp_mean2 ... exp_mean5
                              wage_mean   -&gt;   wage_mean1 wage_mean2 ... wage_mean5
                               edu_mean   -&gt;   edu_mean1 edu_mean2 ... edu_mean5
                               urban_sd   -&gt;   urban_sd1 urban_sd2 ... urban_sd5
                                race_sd   -&gt;   race_sd1 race_sd2 ... race_sd5
                                 exp_sd   -&gt;   exp_sd1 exp_sd2 ... exp_sd5
                                wage_sd   -&gt;   wage_sd1 wage_sd2 ... wage_sd5
                                 edu_sd   -&gt;   edu_sd1 edu_sd2 ... edu_sd5
-----------------------------------------------------------------------------

. tsset iter
        time variable:  iter, 0 to 100
                delta:  1 unit

. tsline exp_mean*, title("Mean of Imputed Values of Experience") note("Each line is for one imputation") legend(off)

. graph export conv1.png, replace
(file conv1.png written in PNG format)
<img alt="Convergence check, mean of exp" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/conv1.png" width="585"/>
. tsline exp_sd*, title("Standard Deviation of Imputed Values of Experience") note("Each line is for one imputation") legend(off)

. graph export conv2.png, replace
(file conv2.png written in PNG format)
<img alt="Convergence check, sd of exp" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/conv2.png" width="585"/>
. restore

. 
. 
. // "real" imputation
. mi impute chained (logit) urban (mlogit) race (ologit) edu (pmm) exp wage = i.female, add(5) rseed(88) by(female)

Performing setup for each by() group:

-&gt; female = 0
Conditional models:
               exp: pmm exp i.urban i.race wage i.edu i.female
             urban: logit urban exp i.race wage i.edu i.female
              race: mlogit race exp i.urban wage i.edu i.female
              wage: pmm wage exp i.urban i.race i.edu i.female
               edu: ologit edu exp i.urban i.race wage i.female

-&gt; female = 1
Conditional models:
             urban: logit urban wage i.race i.edu exp i.female
              wage: pmm wage i.urban i.race i.edu exp i.female
              race: mlogit race i.urban wage i.edu exp i.female
               edu: ologit edu i.urban wage i.race exp i.female
               exp: pmm exp i.urban wage i.race i.edu i.female

Performing imputation for each by() group:

-&gt; female = 0
Performing chained iterations ...

-&gt; female = 1
Performing chained iterations ...

Multivariate imputation                     Imputations =        5
Chained equations                                 added =        5
Imputed: m=1 through m=5                        updated =        0

Initialization: monotone                     Iterations =       50
                                                burn-in =       10

             urban: logistic regression
              race: multinomial logistic regression
               edu: ordered logistic regression
               exp: predictive mean matching
              wage: predictive mean matching

------------------------------------------------------------------
                   |               Observations per m             
by()               |----------------------------------------------
          Variable |   Complete   Incomplete   Imputed |     Total
-------------------+-----------------------------------+----------
female = 0         |                                   |
             urban |       1369          143       143 |      1512
              race |       1364          148       148 |      1512
               edu |       1345          167       167 |      1512
               exp |       1372          140       140 |      1512
              wage |       1347          165       165 |      1512
                   |                                   |
female = 1         |                                   |
             urban |       1358          130       130 |      1488
              race |       1343          145       145 |      1488
               edu |       1336          152       152 |      1488
               exp |       1335          153       153 |      1488
              wage |       1354          134       134 |      1488
                   |                                   |
-------------------+-----------------------------------+----------
Overall            |                                   |
             urban |       2727          273       273 |      3000
              race |       2707          293       293 |      3000
               edu |       2681          319       319 |      3000
               exp |       2707          293       293 |      3000
              wage |       2701          299       299 |      3000
------------------------------------------------------------------
(complete + incomplete = total; imputed is the minimum across m
 of the number of filled-in observations.)
<a id="checkcat" name="checkcat"></a>
. 
. // check if imputed values match observed values
. foreach var of varlist urban race edu {
  2.         mi xeq 0: tab `var'
  3.         mi xeq 1/5: tab `var' if miss_`var'
  4. }

m=0 data:
-&gt; tab urban

      urban |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |        921       33.77       33.77
          1 |      1,806       66.23      100.00
------------+-----------------------------------
      Total |      2,727      100.00

m=1 data:
-&gt; tab urban if miss_urban

      urban |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |        102       37.36       37.36
          1 |        171       62.64      100.00
------------+-----------------------------------
      Total |        273      100.00

m=2 data:
-&gt; tab urban if miss_urban

      urban |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |         97       35.53       35.53
          1 |        176       64.47      100.00
------------+-----------------------------------
      Total |        273      100.00

m=3 data:
-&gt; tab urban if miss_urban

      urban |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |        107       39.19       39.19
          1 |        166       60.81      100.00
------------+-----------------------------------
      Total |        273      100.00

m=4 data:
-&gt; tab urban if miss_urban

      urban |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |        102       37.36       37.36
          1 |        171       62.64      100.00
------------+-----------------------------------
      Total |        273      100.00

m=5 data:
-&gt; tab urban if miss_urban

      urban |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |         97       35.53       35.53
          1 |        176       64.47      100.00
------------+-----------------------------------
      Total |        273      100.00

m=0 data:
-&gt; tab race

       race |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |        864       31.92       31.92
          1 |        929       34.32       66.24
          2 |        914       33.76      100.00
------------+-----------------------------------
      Total |      2,707      100.00

m=1 data:
-&gt; tab race if miss_race

       race |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |         97       33.11       33.11
          1 |        113       38.57       71.67
          2 |         83       28.33      100.00
------------+-----------------------------------
      Total |        293      100.00

m=2 data:
-&gt; tab race if miss_race

       race |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |        107       36.52       36.52
          1 |         88       30.03       66.55
          2 |         98       33.45      100.00
------------+-----------------------------------
      Total |        293      100.00

m=3 data:
-&gt; tab race if miss_race

       race |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |        101       34.47       34.47
          1 |         98       33.45       67.92
          2 |         94       32.08      100.00
------------+-----------------------------------
      Total |        293      100.00

m=4 data:
-&gt; tab race if miss_race

       race |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |        119       40.61       40.61
          1 |         77       26.28       66.89
          2 |         97       33.11      100.00
------------+-----------------------------------
      Total |        293      100.00

m=5 data:
-&gt; tab race if miss_race

       race |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |         76       25.94       25.94
          1 |        116       39.59       65.53
          2 |        101       34.47      100.00
------------+-----------------------------------
      Total |        293      100.00

m=0 data:
-&gt; tab edu

            edu |      Freq.     Percent        Cum.
----------------+-----------------------------------
  &lt; High School |        511       19.06       19.06
    High School |        996       37.15       56.21
      Bachelors |        878       32.75       88.96
Advanced Degree |        296       11.04      100.00
----------------+-----------------------------------
          Total |      2,681      100.00

m=1 data:
-&gt; tab edu if miss_edu

            edu |      Freq.     Percent        Cum.
----------------+-----------------------------------
  &lt; High School |         50       15.67       15.67
    High School |        135       42.32       57.99
      Bachelors |         98       30.72       88.71
Advanced Degree |         36       11.29      100.00
----------------+-----------------------------------
          Total |        319      100.00

m=2 data:
-&gt; tab edu if miss_edu

            edu |      Freq.     Percent        Cum.
----------------+-----------------------------------
  &lt; High School |         53       16.61       16.61
    High School |        129       40.44       57.05
      Bachelors |        109       34.17       91.22
Advanced Degree |         28        8.78      100.00
----------------+-----------------------------------
          Total |        319      100.00

m=3 data:
-&gt; tab edu if miss_edu

            edu |      Freq.     Percent        Cum.
----------------+-----------------------------------
  &lt; High School |         60       18.81       18.81
    High School |        124       38.87       57.68
      Bachelors |        105       32.92       90.60
Advanced Degree |         30        9.40      100.00
----------------+-----------------------------------
          Total |        319      100.00

m=4 data:
-&gt; tab edu if miss_edu

            edu |      Freq.     Percent        Cum.
----------------+-----------------------------------
  &lt; High School |         62       19.44       19.44
    High School |        124       38.87       58.31
      Bachelors |         93       29.15       87.46
Advanced Degree |         40       12.54      100.00
----------------+-----------------------------------
          Total |        319      100.00

m=5 data:
-&gt; tab edu if miss_edu

            edu |      Freq.     Percent        Cum.
----------------+-----------------------------------
  &lt; High School |         55       17.24       17.24
    High School |        138       43.26       60.50
      Bachelors |         93       29.15       89.66
Advanced Degree |         33       10.34      100.00
----------------+-----------------------------------
          Total |        319      100.00

.<a id="checkcont" name="checkcont"></a>
. foreach var of varlist wage exp {
  2.         mi xeq 0: sum `var'
  3.         mi xeq 1/5: sum `var' if miss_`var'
  4.         mi xeq 0: kdensity `var'; graph export chk`var'0.png, replace
  5.         forval i=1/5 {
  6.                 mi xeq `i': kdensity `var' if miss_`var'; graph export chk`var'`i'.png, replace
  7.         }
  8. }

m=0 data:
-&gt; sum wage

    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
        wage |      2701    71493.95     38104.3          0   227465.2

m=1 data:
-&gt; sum wage if miss_wage

    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
        wage |       299    73701.88    38620.86          0   192810.8

m=2 data:
-&gt; sum wage if miss_wage

    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
        wage |       299    75122.22    38976.49          0   193577.9

m=3 data:
-&gt; sum wage if miss_wage

    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
        wage |       299    73354.54    40547.16          0   193577.9

m=4 data:
-&gt; sum wage if miss_wage

    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
        wage |       299    75166.36    40163.56          0   193577.9

m=5 data:
-&gt; sum wage if miss_wage

    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
        wage |       299    75681.66    41793.81          0   198598.6

m=0 data:
-&gt; kdensity wage
-&gt; graph export chkwage0.png, replace
(file chkwage0.png written in PNG format)
<img alt="kdensity of observed wages" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/chkwage0.png" width="585"/>
m=1 data:
-&gt; kdensity wage if miss_wage
-&gt; graph export chkwage1.png, replace
(file chkwage1.png written in PNG format)
<img alt="kdensity of imputed wages" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/chkwage1.png" width="585"/>
m=2 data:
-&gt; kdensity wage if miss_wage
-&gt; graph export chkwage2.png, replace
(file chkwage2.png written in PNG format)
<img alt="kdensity of imputed wages" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/chkwage2.png" width="585"/>
m=3 data:
-&gt; kdensity wage if miss_wage
-&gt; graph export chkwage3.png, replace
(file chkwage3.png written in PNG format)
<img alt="kdensity of imputed wages" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/chkwage3.png" width="585"/>
m=4 data:
-&gt; kdensity wage if miss_wage
-&gt; graph export chkwage4.png, replace
(file chkwage4.png written in PNG format)
<img alt="kdensity of imputed wages" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/chkwage4.png" width="585"/>
m=5 data:
-&gt; kdensity wage if miss_wage
-&gt; graph export chkwage5.png, replace
(file chkwage5.png written in PNG format)
<img alt="kdensity of imputed wages" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/chkwage5.png" width="585"/>
m=0 data:
-&gt; sum exp

    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
         exp |      2707    15.57284    9.656566          0    47.8623

m=1 data:
-&gt; sum exp if miss_exp

    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
         exp |       293    14.98541     10.0319          0   46.35374

m=2 data:
-&gt; sum exp if miss_exp

    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
         exp |       293    15.42685    10.09567          0   46.35374

m=3 data:
-&gt; sum exp if miss_exp

    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
         exp |       293    15.19209    9.870792          0   41.14571

m=4 data:
-&gt; sum exp if miss_exp

    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
         exp |       293    14.67198    10.40626          0    47.8623

m=5 data:
-&gt; sum exp if miss_exp

    Variable |       Obs        Mean    Std. Dev.       Min        Max
-------------+--------------------------------------------------------
         exp |       293    14.94231    9.530698          0   46.35374

m=0 data:
-&gt; kdensity exp
-&gt; graph export chkexp0.png, replace
(file chkexp0.png written in PNG format)
<img alt="kdensity of observed experience" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/chkexp0.png" width="585"/>
m=1 data:
-&gt; kdensity exp if miss_exp
-&gt; graph export chkexp1.png, replace
(file chkexp1.png written in PNG format)
<img alt="kdensity of imputed experience" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/chkexp1.png" width="585"/>
m=2 data:
-&gt; kdensity exp if miss_exp
-&gt; graph export chkexp2.png, replace
(file chkexp2.png written in PNG format)
<img alt="kdensity of imputed experience" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/chkexp2.png" width="585"/>
m=3 data:
-&gt; kdensity exp if miss_exp
-&gt; graph export chkexp3.png, replace
(file chkexp3.png written in PNG format)
<img alt="kdensity of imputed experience" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/chkexp3.png" width="585"/>
m=4 data:
-&gt; kdensity exp if miss_exp
-&gt; graph export chkexp4.png, replace
(file chkexp4.png written in PNG format)
<img alt="kdensity of imputed experience" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/chkexp4.png" width="585"/>
m=5 data:
-&gt; kdensity exp if miss_exp
-&gt; graph export chkexp5.png, replace
(file chkexp5.png written in PNG format)
<img alt="kdensity of imputed experience" height="426" src="https://ssc.wisc.edu/sscc/pubs/mi/chkexp5.png" width="585"/>
. 
. save mi1,replace
file mi1.dta saved

. log close
      name:  <unnamed>
       log:  \sscc\pubs\mi\miex.log
  log type:  text
 closed on:  17 Aug 2012, 13:11:21
----------------------------------------------------------------------------------------------------------------------------------

</unnamed></unnamed></pre>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/mi/exp1.png, https://ssc.wisc.edu/sscc/pubs/mi/exp2.png, https://ssc.wisc.edu/sscc/pubs/mi/wage.png, https://ssc.wisc.edu/sscc/pubs/mi/conv1.png, https://ssc.wisc.edu/sscc/pubs/mi/conv2.png, https://ssc.wisc.edu/sscc/pubs/mi/chkwage0.png, https://ssc.wisc.edu/sscc/pubs/mi/chkwage1.png, https://ssc.wisc.edu/sscc/pubs/mi/chkwage2.png, https://ssc.wisc.edu/sscc/pubs/mi/chkwage3.png, https://ssc.wisc.edu/sscc/pubs/mi/chkwage4.png, https://ssc.wisc.edu/sscc/pubs/mi/chkwage5.png, https://ssc.wisc.edu/sscc/pubs/mi/chkexp0.png, https://ssc.wisc.edu/sscc/pubs/mi/chkexp1.png, https://ssc.wisc.edu/sscc/pubs/mi/chkexp2.png, https://ssc.wisc.edu/sscc/pubs/mi/chkexp3.png, https://ssc.wisc.edu/sscc/pubs/mi/chkexp4.png, https://ssc.wisc.edu/sscc/pubs/mi/chkexp5.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Multiple Imputation in Stata</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Many SSCC members are eager to use multiple imputation in their research, or have been told they should be by reviewers or advisors. This series is intended to be a practical guide to the technique and its implementation in Stata, based on the questions SSCC members are asking the SSCC's statistical computing consultants.</p>
<p>The series assumes you are already familiar with the basic concepts of multiple imputation and is not intended as a substitute for a study of the literature on it. White, Royston and Wood's article <a href="http://onlinelibrary.wiley.com.ezproxy.library.wisc.edu/doi/10.1002/sim.4067/pdf">Multiple Imputation using chained equations: Issues and guidance for practice</a> (Statistics in Medicine, November 2010) is a good starting point for that study.</p>
<p>The article  also assumes you are familiar with Stata usage and syntax. If you are not, we suggest working through our <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Stata for Researchers</a> series and (optionally but usefully) <a href="https://ssc.wisc.edu/sscc/pubs/stata_prog1.htm">Stata Programming Essentials</a>. We also note that the Stata documentation on the <span class="InputCode">mi</span> commands used for multiple imputation is very good and much broader than this series, which will focus on the most common scenarios among SSCC members.</p>
<p>One of the best ways to get an intuitive sense for how multiple imputation works is to run examples using constructed data sets where the right answers are known. We've created a <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm">set of examples</a> to go along with this series. For the sake of narrative continuity they have been placed in a separate article, but you'll find links at the appropriate places. We strongly suggest you read them, but ideally you'll run the provided code yourself and experiment with changing it.</p>
<p>This series currently includes the following sections:</p>
<ol>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_intro.htm">Introduction</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_decide.htm">Deciding to Impute</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_models.htm">Creating Imputation Models</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_impute.htm">Imputing</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_manage.htm">Managing Multiply Imputed Data</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_estimate.htm">Estimating</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm">Examples</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_readings.htm">Recommended Readings</a></li>
</ol>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_decide.htm">Deciding to Impute</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Multiple Imputation in Stata: Managing Multiply Imputed Data</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This is part five of the Multiple Imputation in Stata series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_intro.htm">Introduction</a>.</em></p>
<p>In many cases you can avoid managing multiply imputed data completely. <strong>Wherever possible, do any needed data cleaning, recoding, restructuring, variable creation, or other data management tasks before imputing. </strong>Because this is not always possible, the <span class="InputCode">mi</span> framework includes tools for managing multiply imputed data. However, in practice we rarely see them used. (This section may be expanded in the future as issues arise.)</p>
<ul>
<li><a href="#miver">mi Versions of Data Management Commands</a>
<ul>
<li><a href="#set">Setting mi data</a></li>
</ul>
</li>
<li><a href="#miupdate">mi update</a></li>
<li><a href="#mixeq">mi xeq</a></li>
<li><a href="#vars">Creating or Changing Variables
                  </a>
<ul>
<li><a href="#regular">Regular Variables</a></li>
<li><a href="#passive">Passive Variables</a></li>
<li><a href="#supervarying">Super-varying Variables</a></li>
</ul>
</li>
<li><a href="#extract">mi extract</a></li>
<li><a href="#ice">mi import ice</a></li>
</ul>
<h2><a id="miver" name="miver"></a>mi Versions of Data Management Commands</h2>
<p>Once you <span class="InputCode">mi set</span> your data and add imputations to it, the imputed values are added to the data set as either additional observations or additional variables, depending on which structure you chose. Commands which do not take that into account may or may not give correct results. The <span class="InputCode">mi</span> versions of basic data management commands do take the <span class="InputCode">mi</span> structure into account, ensuring that the changes you make are applied to all the imputations properly. These include <span class="InputCode">mi merge</span>, <span class="InputCode">mi append</span>, <span class="InputCode">mi expand</span>, <span class="InputCode">mi rename</span>, and many others (see the <span class="InputCode">mi</span> documentation). For all these commands the syntax for the <span class="InputCode">mi</span> version is identical to that of the regular version other than having some additional options available which are related to multiply imputed data.</p>
<p>The command that's most commonly needed is <span class="InputCode">mi reshape</span>. Panel data (subjects observed over time) should be imputed in wide form where there is one observation per subject rather than one observation per subject per time period. That way the imputation model for a given variable in a given period can include values of the same variable in other periods, which are likely to be good predictors. However, analysis often requires the long form, where there is one observation per subject per period. Before imputing, switch to the wide form with:</p>
<p class="InputCode"> reshape wide...</p>
<p>After imputing, switch back with:</p>
<p class="InputCode"> mi reshape long...</p>
<p>The two commands will be identical except for adding <span class="InputCode">mi</span> and changing <span class="InputCode">wide</span> to <span class="InputCode">long</span>.</p>
<p>See the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-hier.htm">Hierarchical Data</a> section of <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Stata for Researchers</a> for more discussion of <span class="InputCode">reshape</span> and long vs. wide forms.</p>
<h3><a id="set" name="set"></a>Setting mi Data</h3>
<p>Commands like <span class="InputCode">svyset</span>, <span class="InputCode">tsset</span>, and <span class="InputCode">xtset</span> also have <span class="InputCode">mi</span> versions: <span class="InputCode">mi svyset</span>, <span class="InputCode">mi tsset</span>, <span class="InputCode">mi xtset</span>, etc. If you set your data before imputing (using the regular version of the command) it will still be set  after imputing. If you need to set it after imputing, use the <span class="InputCode">mi</span> version.</p>
<p>Keep in mind that <span class="InputCode">mi impute chained</span> cannot correct for survey structure. See the section on Survey Data in <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_models.htm#SurveyData">Creating Imputation Models</a> for more discussion.</p>
<h2><a id="miupdate" name="miupdate"></a>mi update</h2>
<p>Certain things should always be true in multiply imputed data sets. For example, <em>regular</em> (unimputed) variables should have the same values in all imputations. The <span class="InputCode">mi update</span> command will check that this is so and fix any problems it finds (in this case, by setting the value in all imputations to the value in the observed data).</p>
<p>You may never need to run an <span class="InputCode">mi update</span> yourself, because each <span class="InputCode">mi</span> command that changes your data also runs  <span class="InputCode">mi update</span> afterwards. While this is automatic, you should be aware of it for two reasons. First, if you're running a string of data management commands there's no need to do an <span class="InputCode">mi update</span> after each one. If your data set is big enough that the process is taking significant time, consider adding the <span class="InputCode">noupdate</span> option to all but the last command. Second, if you introduce <em>super-varying</em> variables or make other changes that <span class="InputCode">mi update</span> could find problematic, you need to be sure that <span class="InputCode">mi update</span> won't change your data inappropriately. For <em>super-varying</em> variables, that just means you shouldn't register them (see the section on <a href="#supervarying"><em>super-varying</em> variables</a>). But if you're making complicated data changes you should read the <span class="InputCode">mi update</span> documentation carefully so that you know what it will do.</p>
<p> On the other hand, some data management commands do not have an <span class="InputCode">mi</span> version (<span class="InputCode">drop</span> is an example). You should  run <span class="InputCode">mi update</span> yourself after using one of them.</p>
<h2><a id="mixeq" name="mixeq"></a>mi xeq</h2>
<p>The <span class="InputCode">mi xeq</span> command allows you to act on your imputations one at a time. Since we needed this capability to check on our imputation results it was introduced in <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_impute.htm#mixeq">Imputing</a>. Be sure you're familiar with it before continuing.</p>
<h2><a id="vars" name="vars"></a>Creating or Changing Variables</h2>
<p>The process for creating or changing a variable depends on whether the variable is a <em>regular</em> variable, a <em>passive</em> variable, or a <em>super-varying</em> variable.</p>
<h3><a id="regular" name="regular"></a>Regular Variables</h3>
<p>New or changed variables that are functions of existing <em>regular</em> variables are also <em>regular</em> variables. They will have the same value in every imputation. You can create new <em>regular</em> variables or change the values of existing <em>regular</em> variables using <span class="InputCode">mi xeq</span> plus the standard <span class="InputCode">gen</span>, <span class="InputCode">egen</span>, and <span class="InputCode">replace</span> commands. You should register new <em>regular</em> variables as such, though it's not required.</p>
<p class="InputCode">mi xeq: gen lnIncome=ln(income)<br/>
                  mi register regular lnIncome
                </p>
<p>(Assuming <span class="InputCode">income</span> is <em>regular</em>, not <em>imputed</em>.)</p>
<h3><a id="passive" name="passive"></a>Passive Variables</h3>
<p><em>Passive</em> variables are functions of <em>imputed</em> variables. Thus they will have different values in different imputations. They can be created or changed using <span class="InputCode">mi passive</span> followed by the standard <span class="InputCode">gen</span> or <span class="InputCode">replace</span> commands.  However, <span class="InputCode">mi passive</span> should only be used with <span class="InputCode">egen</span> for functions that  depend solely on the current observation, like <span class="InputCode">rowtotal()</span>. Functions like <span class="InputCode">total()</span> or <span class="InputCode">mean()</span> create <em>super-varying</em> variables. Using <span class="InputCode">mi passive</span> automatically registers new variables as <em>passive</em>.</p>
<p class="InputCode">mi passive: gen lnIncome=ln(income)</p>
<p>(Now assuming <span class="InputCode">income</span> is <em>imputed</em>.)                </p>
<p><em>Passive</em> variables are not automatically changed if the variables they are based on change. If you need to update <em>passive</em> variables, the easiest way is probably to drop the existing versions and then rerun the commands that created them in the first place.</p>
<p><em>Passive</em> variables are often problematic—the examples on <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm#Transformations">transformations</a>, <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm#Non-Linearity">non-linearity</a>, and <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm#Interactions">interactions</a> show how using them inappropriately can lead to biased estimates.                </p>
<h3><a id="supervarying" name="supervarying"></a>Super-varying Variables</h3>
<p>Normally, if a case is complete (has no missing values) it will be identical in all imputations. But consider a household income variable which is the total of all the individual incomes in the household: if one person's income is missing and must be imputed, then  household income for everyone in that person's household will be different in each imputation, <em>even  people who are complete cases</em>. Variables with the property that they vary between imputations even for complete cases are known as <em>super-varying</em> variables. Variables that are functions of the values of imputed variables for other observations are likely to be <em>super-varying</em>. Functions that depend on values in other observations include most <span class="InputCode">egen</span> functions, but also <span class="InputCode">gen</span> or <span class="InputCode">replace</span> expressions <span class="InputCode"></span>that use square brackets (<span class="InputCode">x[1]</span> or <span class="InputCode">x[_n+1]</span>, for example).</p>
<p>If you need to create <em>super-varying</em> variables, switch to the <span class="InputCode">flong</span> format (or <span class="InputCode">flongsep</span> if you don't have enough memory for <span class="InputCode">flong</span>). In <span class="InputCode">flong</span>, there is one copy of each observation for each imputation, even for complete cases. Thus <em>super-varying</em> variables can have different values in each copy. The <span class="InputCode">mlong</span> and <span class="InputCode">wide</span> formats save memory by storing just one copy of complete cases, but this makes them unable to store <em>super-varying</em> variables.</p>
<p><em>Super-varying</em> variables should be created or changed  using <span class="InputCode">mi xeq</span> and the standard <span class="InputCode">gen</span>, <span class="InputCode">egen</span>, or <span class="InputCode">replace</span> commands (most likely <span class="InputCode">egen</span>).</p>
<p class="InputCode">mi convert flong, clear<br/>
                mi xeq: egen householdIncome=total(income)</p>
<p><strong>Super-varying variables must not be registered</strong>. While they are theoretically passive variables, registering them as either <em>passive</em> or <em>regular</em> will prompt <span class="InputCode">mi update</span> to apply the (normally true) constraint that complete cases do not vary between imputations and "correct" their values. Leaving <em>super-varying</em> variables unregistered makes <span class="InputCode">mi update</span> leave them alone, but they'll still work in estimation commands.</p>
<p>All the statistical concerns raised by <em>passive</em> variables also apply to <em>super-varying</em> variables.</p>
<h2><a id="extract" name="extract"></a>mi extract</h2>
<p>Sometimes you need to work with an individual imputation as a regular data set, ignoring the fact that it was imputed. Also, some special purpose software like HLM can work with multiply imputed data but expects that you will put each imputation in a separate file.</p>
<p>The tool for doing selecting a single imputation and turning it into a regular data set is <span class="InputCode">mi extract</span>, and the syntax is very simple:</p>
<p class="InputCode">mi extract <span class="Parameter">n</span></p>
<p> where <span class="Parameter">n</span> is the number of the imputation you want to work with. After extraction, the data will not be <span class="InputCode">mi set</span> and there will be no indication it was ever imputed. <span class="Parameter">n</span> can be 0, in which case <span class="InputCode">mi extract</span>  gives you the observed data, missing values and all.</p>
<p>HLM reads SPSS files, not Stata files, but you can call on Stat/Transfer to convert your data sets to SPSS format. If you have 10 imputations, the following code will extract each imputation, save it as a separate data set, then have Stat/Transfer convert it to SPSS format:</p>
<p class="InputCode">forval i=1/10 {<br/>
<span class="indent3">preserve</span><br/>
<span class="indent3">mi extract `i'</span><br/>
<span class="indent3">save hlm`i',replace</span><br/>
<span class="indent3">! "c:\program files (x86)\stattransfer11\st.exe" "hlm`i'.dta" "hlm`i'.sav"</span><br/>
<span class="indent3">restore</span><br/>
}<br/>
</p>
<p>The command to call Stat/Transfer is written to work on Winstat. If Stat/Transfer is located in a different directory on your computer, you will need to modify that line accordingly. On Linstat it can be simply:</p>
<p class="InputCode"><span class="indent3">! st hlm`i'.dta hlm`i'.sav</span></p>
<h2><a id="ice" name="ice"></a>mi import ice</h2>
<p>If you have imputed data using <span class="InputCode">ice</span>, <span class="InputCode">mi import ice</span> will convert it from <span class="InputCode">ice</span> format to <span class="InputCode">mi</span> format, allowing you to use <span class="InputCode">mi</span> commands. The <span class="InputCode">automatic</span> option tells <span class="InputCode">mi import ice</span> to  register all the variables and is highly recommended. It can tell which variables are  <em>regular</em>  by noting which ones never change between imputations, but it cannot distinguish between <em>imputed</em> and <em>passive</em> variables. If you have <em>passive</em> variables, use the <span class="InputCode">passive()</span> option and list them in the parentheses. If <span class="InputCode">mi import ice</span> finds that a variable is not <em>regular</em> and it is not listed in a <span class="InputCode">passive()</span> option, then it will mark the variable as <em>imputed</em>.</p>
<p>Example:</p>
<p class="InputCode">mi import ice, automatic passive(passiveVar1 passiveVar2)</p>
<p>Data imported from <span class="InputCode">ice</span> will be placed in the <span class="InputCode">flong</span> form, since that's essentially what <span class="InputCode">ice</span> uses. We suggest converting to <span class="InputCode">wide</span> or perhaps <span class="InputCode">mlong</span> (unless you have <em>super-varying</em> variables, which require <span class="InputCode">flong</span>):</p>
<p class="InputCode">mi convert wide, clear</p>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_estimate.htm">Estimating</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_impute.htm">Imputing</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Multiple Imputation in Stata</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p class="intro"><em>This is part three of the Multiple Imputation in Stata series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_intro.htm">Introduction</a>.</em></p>
<p>In theory, an imputation model estimates the joint distribution of all the variables it contains. MICE breaks this problem  into a series of estimations that regress one variable  on all the other variables in the model. (The downside is that a series of models of the distributions of individual variables does not necessarily add up to a consistent model of the joint distribution.)</p>
<p> The <span class="InputCode">mi impute chained</span> command does not require you to specify the model for each variable separately: you just list the variables to be imputed along with information about how they should be imputed, and <span class="InputCode">mi impute chained</span> will form the individual models automatically. However, the success of the overall imputation model depends on the success of all the individual models. If a single model fails to converge, the imputation process as a whole will fail. If a single model is misspecified, it may bias the results of your analysis model. <strong>We  strongly recommend that you run each of the individual models on its own, outside the context of <span class="InputCode">mi impute chained</span>, to test for convergence and misspecification.</strong> We'll discuss the details of doing so in the next section. This section will focus on  issues you must consider in creating your imputation models.</p>
<ul>
<li><a href="#ChoosingVariables">Choosing Variables</a>
<ul>
<li><a href="#CustomizingImputationModels">Customizing Imputation Models</a></li>
<li><a href="#PanelLongitudinalData">Panel/Longitudinal Data</a></li>
<li><a href="#SurveyData">Survey Data </a></li>
</ul>
</li>
<li><a href="#ChoosingMethods">Choosing Methods</a>
<ul>
<li><a href="#ContinuousButNonNormalVariables">Continuous But Non-Normal Variables</a></li>
<li><a href="#Transformations">Transformations</a></li>
<li><a href="#BoundedVariables">Bounded Variables</a></li>
<li><a href="#NonLinearTerms">Non-Linear Terms</a></li>
<li><a href="#InteractionTerms">Interaction Terms</a></li>
<li><a href="#SetsofIndicatorVariables">Sets of Indicator Variables </a></li>
</ul>
</li>
</ul>
<h3><a id="ChoosingVariables" name="ChoosingVariables"></a>Choosing Variables</h3>
<p>The first step in creating an imputation model is deciding which variables to impute. The imputation model should always include all the variables in the analysis model. This includes the dependent variable of your analysis model, though there is some debate about whether the imputed values of the dependent variable should be used. Even if you don't plan to use the imputed values of the dependent variable, the observed values of the dependent variable provide information about the other variables, and the information available from those observations which are missing the dependent variable should be used in the imputation model as well.</p>
<p><a id="depvar" name="depvar"></a><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm#ImputingtheDependentVariable">Example: Imputing the Dependent Variable</a></p>
<p>The imputation model should include any other variables that provide information either about the true values of the missing data or about their probability of being missing. Avoid creating a "kitchen sink" model however. Large numbers of variables, especially categorical variables, can lead to models that fail to converge. Use theory to guide you in choosing appropriate variables.</p>
<p>You can add variables to the imputation model that do not need to be (or shouldn't be) imputed by putting them at the end of the variable list following an equals sign.</p>
<h4><a id="CustomizingImputationModels" name="CustomizingImputationModels"></a>Customizing Imputation Models</h4>
<p>You can add variables to or remove variables from the imputation model for an individual variable or group of variables using the <span class="InputCode">include()</span> or <span class="InputCode">omit()</span> options. The <span class="InputCode">include()</span> option  even allows you add expressions to a model such as <span class="InputCode">(x^2)</span>, but they have to go inside an additional set of parentheses (e.g. <span class="InputCode">include((x^2)) </span>). These options go with the imputation method for a variable or variables (e.g. <span class="InputCode">(regress, include(x))</span> ) rather than at the end of the <span class="InputCode">mi impute chained</span> command.</p>
<p>Be cautious about adding expressions to imputation models: if <span class="InputCode">y</span> depends on some function of <span class="InputCode">x</span>, then <span class="InputCode">x</span> should depend on the inverse function of <span class="InputCode">y</span> and failing to model both  can bias your results. See <a href="#NonLinearTerms">Non-Linear Terms</a> for further discussion.</p>
<h4><a id="PanelLongitudinalData" name="PanelLongitudinalData"></a>Panel/Longitudinal Data</h4>
<p>If you have data where units are observed over time, the best predictors of a missing value in one period are likely the values of that variable in the previous and subsequent periods. However, the imputation model can only take advantage of this information if the data set is in wide form (one observation per unit, not one observation per unit per time period). You can convert back to long form after imputing if needed.</p>
<p>To convert the data to wide form before imputing, use <span class="InputCode">reshape</span>. To convert back to long form after imputing, use <span class="InputCode">mi reshape</span>. This has the same syntax as <span class="InputCode">reshape</span>, but makes sure the imputations are handled properly. If you're not familiar with <span class="InputCode">reshape</span>, see the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-hier.htm">Hierarchical Data</a> section of <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Stata for Researchers</a>.</p>
<h4><a id="SurveyData" name="SurveyData"></a>Survey Data</h4>
<p>The <span class="InputCode">mi estimate:</span> and <span class="InputCode">svy:</span> prefix commands can be used together (in that order) to run models on survey data that have been multiple imputed. However, <span class="InputCode">svy:</span> cannot be used with <span class="InputCode">mi impute chained</span>. You can apply weights (e.g.<span class="InputCode"> [pweight=weight]</span>) but not correct for other elements of survey structure like strata or PSU. The current recommendation is to include survey structure variables like strata and PSU in the imputation models as sets of indicator variables (e.g. <span class="InputCode">i.psu</span>). This is an area of ongoing research.</p>
<p></p>
<p> When you test your individual imputation models, we suggest running them first with the <span class="InputCode">svy:</span> prefix and then without it but with weights applied and  survey structure variables added to the model. If the two give very different results, try adding interactions between the survey structure variables or additional variables related to survey structure. If they continue to give very different results despite your best efforts, be wary about using multiple imputation.</p>
<h3><a id="ChoosingMethods" name="ChoosingMethods"></a>Choosing Methods</h3>
<p>There are nine  methods available for imputing a variable: <span class="InputCode">regress</span>, <span class="InputCode">pmm</span>, <span class="InputCode">truncreg</span>, <span class="InputCode">intreg</span>, <span class="InputCode">logit</span>, <span class="InputCode">ologit</span>, <span class="InputCode">mlogit</span>, <span class="InputCode">poisson</span> and <span class="InputCode">nbreg</span>. In most cases you'll choose the same imputation method you'd choose if you were going to model the variable normally: <span class="InputCode">regress</span> for most continuous variables, <span class="InputCode">logit</span> for binary variables, <span class="InputCode">mlogit</span> for unordered categorical variables, etc.</p>
<h4><a id="ContinuousButNonNormalVariables" name="ContinuousButNonNormalVariables"></a>Continuous But Non-Normal Variables</h4>
<p>Keep in mind that the standard <span class="InputCode">regress</span> implies a normal error term after controlling for the covariates. If you have a continuous variable that is not normal, <span class="InputCode">regress</span> may not give you a distribution of imputed values that matches the observed values very well.</p>
<p>An alternative is Predictive Mean Matching (PMM). PMM  is an ad hoc technique with little theory behind it, but it seems to work quite well in practice. PMM starts out by regressing the variable to be imputed on the covariates, and then drawing a set of coefficients from the results, taking into accout both the estimated coefficients and the uncertainty about them. Those coefficients are used to calculate a predicted value for all missing values. However, it then uses the predicted value for a given observation to identify those observations whose observed value of the variable are close to the predicted value and chooses one of them randomly to be the imputed value. If the observed values of a variable are not normal, PMM will usually produce a distribution of imputed values that matches the distribution of the observed values more closely than  regression.</p>
<p>The <span class="InputCode">knn()</span> option controls how many observations are considered as matches (based on their observed values of the variable being close to the predicted value for the observation being imputed). Recent work by <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4051964/">Morris, White and Royston</a> indicates that larger numbers of observations should be used than was standard practice in the past. They suggest at least 10, and more if your data set is very large (tens of thousands of observations or more).</p>
<p>Because PMM draws its imputed values from the observed values, it has the property that the imputed values will never be outside the range of the observed values. This makes it very useful for bounded variables  (discussed below). It can also be used for some non-continuous distributions. However, PMM is not appropriate if you have reason to believe the unobserved values are outside the range of the observed values.                </p>
<p><a id="nonnorm" name="nonnorm"></a><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm#Non-NormalData">Example: Non-Normal Data</a></p>
<h4><a id="Transformations" name="Transformations"></a>Transformations</h4>
<p>Skewed variables may be made more normal by transformations such as taking the log. However, you should consider how this affects the relationships between variables. For example, if you have variables for "income" and "spending on entertainment" and you believe the relationship between the two is linear, replacing "income" with "log income" makes the imputation model for both variables misspecified.</p>
<p><a id="transform" name="transform"></a><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm#Transformations">Example: Transformations</a></p>
<h4><a id="BoundedVariables" name="BoundedVariables"></a>Bounded Variables</h4>
<p>Another common situation is bounded variables. For example, "hours worked" cannot go below zero, and percentages must be between zero and 100. Such variables can be imputed using <span class="InputCode">truncreg</span>. The <span class="InputCode">ll()</span> and <span class="InputCode">ul()</span> options contain the lower limit and upper limit for the variable, which can be either numbers or variables. You are not required to specify both (e.g. hours worked probably only needs <span class="InputCode">ll(0)</span>, unless you're worried that the model might try to have someone work more than 168 hours per week). Unfortunately, in our experience it's not unusual for <span class="InputCode">truncreg</span> to have convergence problems  in imputation models with many variables.</p>
<p>PMM is a good alternative to <span class="InputCode">truncreg</span> because it naturally honors any bounds that exist in the observed data.</p>
<h4><a id="NonLinearTerms" name="NonLinearTerms"></a>Non-Linear Terms</h4>
<p>If your analysis model contains non-linear terms, most likely variables squared, then this must be taken into account when creating your imputation model. Suppose your analysis model regresses <span class="InputCode">y</span> on <span class="InputCode">x</span> and <span class="InputCode">x^2</span>. If you just impute <span class="InputCode">y</span> and <span class="InputCode">x</span>, creating <span class="InputCode">x^2</span> later (either with <span class="InputCode">mi passive</span> or <span class="InputCode">c.x#c.x</span>), then the imputed values of <span class="InputCode">y</span> will only depend on <span class="InputCode">x</span> and the imputed values of <span class="InputCode">x</span> will depend linearly on <span class="InputCode">y</span>. When you run your analysis model, the coefficient on the squared term will be biased towards zero because for observations where either <span class="InputCode">y</span> or <span class="InputCode">x</span> is imputed, <span class="InputCode">y</span> really is unrelated to <span class="InputCode">x^2</span>. (Never forget that when you write your <span class="InputCode">mi impute chained</span> command you are building models, not just listing variables to impute.)</p>
<p>The best alternative appears to be what White, Royston and Wood  call the "Just Another Variable" approach. Create new variables to store the non-linear terms (e.g. <span class="InputCode">gen x2=x^2</span>) and then impute them as if they were just another variable, unrelated to the linear terms. The imputed values of the non-linear terms won't have the proper relationship to the linear terms (i.e. the imputed values <span class="InputCode">x2</span> will not in fact be <span class="InputCode">x^2</span>) but as long as they are distributed properly this does not appear to affect the results of the analysis model. This is an area of ongoing research.</p>
<p><a id="nonlin" name="nonlin"></a><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm#Non-Linearity">Example: Non-Linearity</a></p>
<h4><a id="InteractionTerms" name="InteractionTerms"></a>Interaction Terms</h4>
<p>Interaction terms raise issues very similar to those raised by non-linear terms: if the interaction term isn't included in the imputation model, the coefficient on the interaction term will be biased towards zero in the analysis model. The "Just Another Variable" approach also works well for interaction terms: create variables storing the interaction effects (e.g. <span class="InputCode">gen gx=g*x</span>) and then impute them separately.</p>
<p> If, however, the interactions  involve binary or categorical variables that represent groups, consider instead using the <span class="InputCode">by()</span> option to impute each group separately. This allows coefficients to vary between groups without the problem of imputed interaction terms not actually matching the variables being interacted.</p>
<p>For example, suppose you're regressing <span class="InputCode">income</span> on <span class="InputCode">education</span>, <span class="InputCode">experience</span>, and <span class="InputCode">black</span> (an indicator for "subject is black"), but think the returns to education vary by race and thus include <span class="InputCode">black##c.education</span> in the regression. The just another variable approach would create a variable <span class="InputCode">edblack=black*race</span> and impute it, but it's possible for the model to impute a zero for <span class="InputCode">black</span> and a non-zero value for <span class="InputCode">edblack</span>. There's no indication this would cause problems in the analysis model, however.</p>
<p>An alternative would be to add the <span class="InputCode">by(black)</span> option to the imputation command, so that whites and blacks are imputed separately. This would allow you to use <span class="InputCode">black##c.education</span> in your analysis model without bias (and it would always correspond to the actual values of <span class="InputCode">black</span> and <span class="InputCode">education</span>). However, running two separate imputation models allows the returns to experience to vary by race in the imputation model, not just education. If you had strong theoretical reasons to believe that was not the case (which is unlikely) that would be a specification problem. A far more more common problem is small sample size: make sure each of your <span class="InputCode">by()</span> groups is big enough for reasonable regressions.</p>
<p>Trying to use "Just Another Variable" for interactions between categorical variables and imputing them with <span class="InputCode">logit</span> is problematic. Use <span class="InputCode">by()</span> instead.</p>
<p><a id="interact" name="interact"></a><a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm#Interactions">Example: Interactions</a></p>
<h4><a id="SetsofIndicatorVariables" name="SetsofIndicatorVariables"></a>Sets of Indicator Variables</h4>
<p>If you have a set of mutually exclusive indicator variables, use them to create a single categorical variable and then impute it using <span class="InputCode">mlogit</span>. For example, combine <span class="InputCode">white</span>, <span class="InputCode">black</span>, <span class="InputCode">hispanic</span>, <span class="InputCode">other</span> into <span class="InputCode">race</span>, or <span class="InputCode">highSchool</span>, <span class="InputCode">someCollege</span>, <span class="InputCode">bachelors</span>, <span class="InputCode">advanced</span> into <span class="InputCode">education</span>. You can recreate the indicator variables after imputing, either with <span class="InputCode">mi passive</span> or by simply using <span class="InputCode">i.race</span> or <span class="InputCode">i.education</span> in your models.</p>
<p>If you impute the indicator variables themselves using <span class="InputCode">logit</span>, the imputation model will not impose the constraint that only one of them can be one. Thus you'll likely get people with more than one race or more than one education level. By converting the indicators to a categorical variable and imputing the categorical variable using <span class="InputCode">mlogit</span> you force the model to choose just one category.</p>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_impute.htm">Imputing</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_decide.htm">Deciding to Impute</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Multiple Imputation in Stata: Recommended Readings</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p><em>This article is part of the Multiple Imputation in Stata series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_intro.htm">Introduction</a>.</em></p>
<p>Multiple Imputation is an ongoing research area, so be sure to pay attention to when papers on the topic were published. You'll find that advice in some areas changes, and older discussions of software are often completely out-of-date. You'll also need to keep current on the topic. That said, here is what we'd suggest reading to learn more about multiple imputation:</p>
<p> </p>
<ul>
<li>White, Royston, and Wood. "<a href="http://onlinelibrary.wiley.com.ezproxy.library.wisc.edu/doi/10.1002/sim.4067/pdf">Multiple imputation using chained equations: Issues and guidance for practice.</a>" Statistics in Medicine. 2011</li>
<li> Stata MI Documentation.  Type "help mi" in Stata, click on the link at the top.</li>
<li> UCLA Statistical Computing Seminars. "<a href="http://www.ats.ucla.edu/stat/stata/seminars/missing_data/mi_in_stata_pt1.htm">Multiple Imputation in Stata.</a>"</li>
<li> Van Buuren,  "<a href="http://web.ebscohost.com.ezproxy.library.wisc.edu/ehost/pdfviewer/pdfviewer?sid=6ac98e9f-3480-4900-a2ad-4f61ce07ac28%40sessionmgr12&amp;vid=2&amp;hid=17">Multiple imputation of discrete and continuous data by fully conditional specification</a>." Statistical Methods in Medical Research, 2007 </li>
<li>Van Buuren, Brand, Groothuis-Oudshoorn, and Rubin.  "Fully conditional specification in multivariate imputation." Journal of Statistical Computation and Simulation. 2006</li>
<li> Paul Allison. "Missing Data." Sage University Papers Series: Quantitative Applications in the Social Sciences. 2001 Joseph Shafer.</li>
<li> White, Royston, and Wood. "<a href="http://onlinelibrary.wiley.com.ezproxy.library.wisc.edu/doi/10.1002/sim.4067/pdf">Multiple imputation using chained equations: Issues and guidance for practice.</a>" Statistics in Medicine. 2011 Yes, read it again.</li>
<li>Any of the  references in the Stata MI Documentation</li>
<li>Any useful article published since this list was made (<a href="mailto:helpdesk@ssc.wisc.edu">tell us about it</a>!)</li>
</ul>
<p>Note that some of these links will only work if you are connected to the UW-Madison network.</p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/stata_mi_ex.htm">Examples</a> </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Running Stata MP at the SSCC</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>The SSCC has two varieties of Stata. Standard Stata uses just one processor, but Stata/MP can take advantage of up to 32 processors for a huge increase in performance. Use it whenever you have a Stata job that's taking a long time due to computations, such as mixed models or multiple imputation (unfortunately it can't help with loading large data sets). No need to change your do files, just how you run them.</p>
<p>Stata/MP32 licenses are very expensive, so we have a limited number of them. If you are  told all the licenses are in use you'll need to wait until one becomes available.</p>
<h2>Winstat</h2>
<p>On Winstat, right-click on a do file and choose <span class="MenuOutput">Execute StataMP Batch Mode</span>. Stata will not start its usual graphical user interface: it will simply run your do file and then quit. A log file with the same name as your do file will be created in the same directory as your do file automatically, but any <span class="InputCode">log using</span> commands will be honored as well. Please note that in accordance with the SSCC’s <a href="https://ssc.wisc.edu/sscc/policies/server_usage.htm">Server Usage Policy</a>, Stata/MP on Winstat will actually use 8 cores.</p>
<p>Unfortunately this method will not work if the name of your do file or any of the folders it is located in contain spaces. Rename things like <span class="InputCode">U:\My Dissertation\My Do Files\My Do File.do</span> to <span class="InputCode">U:\MyDissertation\MyDoFiles\MyDoFile.do</span>.</p>
<h2>Linstat</h2>
<p>On Linstat, do files run using the <span class="InputCode">stata, xstata,</span> and <span class="InputCode">condor_stata</span> commands will be run using Stata/MP, though some HTCondor servers only have 8 or 16 cores and Stata/MP will adapt accordingly. If you use <span class="InputCode">xstata</span> to get a graphical user interface, be sure to close Stata as soon as your done actively using it so the license becomes available to others.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata Programming Techniques for Panel Data in Stata</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Panel data, where subjects are observed repeatedly over time, is a very common data structure in the social sciences. This article will teach you some  programming techniques used to prepare panel data for analysis. They include:</p>
<ul>
<li><a href="#ever">Did a subject ever experience this event?</a></li>
<li><a href="#how_many">How many times did the subject experience this event?</a></li>
<li><a href="#yet">Has a subject experienced this event yet?</a></li>
<li><a href="#how_many_thus_far">How many times has the subject experienced the event thus far?</a></li>
<li><a href="#sequence">Events in Sequence</a></li>
<li><a href="#time">Changing Time Periods</a></li>
</ul>
<h2>Background</h2>
<p>Panel data is a particular kind of hierarchical data, where the level 2 unit is a subject and the level 1 unit is a subject observed in a particular period. (If you're not familiar with this vocabulary for describing hierarchical data, <a href="https://ssc.wisc.edu/sscc/pubs/sfr-hier.htm">here's an introduction to it</a>.) Panel data normally includes both variables that change over time (level 1 variables) and variables that do not (level 2 or subject-level variables). It's very important that you know the type of each of your variables.</p>
<p>While this article will describe the problems to be solved in terms of subjects observed over time, some of these techniques apply to any hierarchical data structure. In fact the code for some of these examples is essentially identical to code used in the <a href="https://ssc.wisc.edu/sscc/pubs/sfr-groups.htm">Working with Groups</a> section of <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Stata for Researchers</a> to identify characteristics of households composed of individuals.</p>
<p> This article will assume that the data set is in the long form, i.e. there is one observation per person per period. (The kind of work described here is usually much easier in long form.) It will also assume that the data set is sorted by subject and period, so the observations for each subject are in chronological order.</p>
<p>A note on variable names: with this sort of data you could easily have variables for "was incarcerated in this month," "was incarcerated at some point," or "had been incarcerated by this period."  Use clear variable names and/or labels to help you distinguish between them.</p>
<h2>Identifying an Event</h2>
<p>An event  could be anything from "was incarcerated" to "was diagnosed with diabetes" to "attended a four-year college." Before doing anything else, you need to identify an <em>if</em> condition which will be true if the event happened in a given time period and false otherwise. For example, if you have an <span class="InputCode">inc</span> variable which is 1 if the subject was incarcerated in a given month and 0 otherwise, the condition is simply <span class="InputCode">inc==1</span>. (If you have no missing data, just  <span class="InputCode">inc</span> will do because to Stata 1 is true and 0 is false—just keep in mind that any other value, including missing, is also treated as true.) Other examples might be <span class="InputCode">diag==146</span> (assuming 146 is the code for diabetes in your data set) or <span class="InputCode">enrolled &amp; type==4</span>.</p>
<h2 id="ever">Did a subject ever experience this event?</h2>
<p>Often you need to be able to identify those subjects for whom the event occurred at any point. At this level it does not matter when the event occurred or how many times. The result will be a subject-level binary variable which will be 1 in all time periods if subject ever experienced the event and 0 in all time periods otherwise.                </p>
<p>Use <span class="InputCode">max()</span> function in the <span class="InputCode">egen</span> library to identify whether the event condition identified above is ever true:</p>
<p class="InputCode">by subject: egen everInc=max(inc)</p>
<p class="InputCode"> by subject: egen everDiabetes=max(diag==146)</p>
<p class="InputCode"> by subject: egen ever4yr=max(enrolled &amp; type==4) </p>
<p>Recall that true is 1 and false is 0. Thus if the condition is true (1) for any observation  <span class="InputCode">max()</span> will return 1. If it always false (0), <span class="InputCode">max()</span> will return 0.</p>
<h2 id="how_many">How many times did the subject experience this event?</h2>
<p>If you need to know how many times the subject experienced the event during the study period, use the <span class="InputCode">total()</span> function:</p>
<p class="InputCode">by subject: egen timesInc=total(inc)</p>
<p class="InputCode">by subject: egen timesDiag=total(diag==146)</p>
<p class="InputCode"> by subject: egen semesters4yr=total(enrolled &amp; type==4)</p>
<h2 id="how_many_thus_far">How many times has the subject experienced the event thus far?</h2>
<p>If you need to know how many times the subject has experienced the event up to and including the current period, use the <span class="InputCode">sum()</span> function. It calculates a running sum over all the observations it has seen thus far (which is why it is a regular function and not part of the <span class="InputCode">egen</span> library).</p>
<p class="InputCode">by subject: gen timesIncThusFar=sum(inc)</p>
<p class="InputCode">by subject: gen timesDiagThusFar=sum(diag==146)</p>
<p class="InputCode"> by subject: gen semesters4yrThusFar=sum(enrolled &amp; type==4)</p>
<h2 id="yet">Has a subject experienced this event yet?</h2>
<p>Sometimes you need to identify which periods come before  the subject first experienced an event and which come after. The result will be a binary variable which changes over time, but only from 0 to 1 (i.e. it will be some number of zeros followed by some number of ones). The easy way to do this is to first create a variable counting how many times the subject has experienced the event thus far using <span class="InputCode">sum()</span> as described above. If that number is greater than zero, the subject has experienced the event.</p>
<p class="InputCode">gen hasBeenInc=(timesIncThusFar&gt;0)</p>
<p class="InputCode">gen hasDiabetes=(timesDiagThusFar&gt;0)</p>
<p class="InputCode">gen has4yr=(semesters4yrThusFar&gt;0)</p>
<h2 id="sequence">Events in Sequence</h2>
<p>Sometimes the order in which events happen matters. For example, you may be interested in events where a given drug is prescribed before the patient has received a diabetes diagnosis, or in people who attend a two-year college after attending a four-year college. We'll call the first event event A and the second event B.</p>
<p>The first step is to create a variable for "Has a subject experienced event A yet?" as described in the previous section. Then you can take whatever condition identifies event B, add the condition that the subject either has or has not experienced event A yet, and use any of the techniques described above. Two examples:</p>
<p class="InputCode">gen prescribeBefore=(drug==216 &amp; !hasDiabetes)</p>
<p class="InputCode">by subject: egen everPrescribedBefore=max(drug==216 &amp; !hasDiabetes)</p>
<p>After running this code, <span class="InputCode">prescribeBefore</span> is an indicator for "in this period the subject was prescribed drug 216 before having received a diagnosis of diabetes" and <span class="InputCode">everPrescribedBefore </span>is a subject-level indicator for "the subject was prescribed drug 216 before receiving a diagnosis of diabetes at some point."</p>
<p>If you were interested in "after" rather than "before" you'd simply change <span class="InputCode">&amp; !hasDiabetes</span> to <span class="InputCode">&amp; hasDiabetes</span>.</p>
<h2 id="time">Changing Time Periods</h2>
<p>Sometimes the "periods" in panel data represent different amounts of time for different subjects. For example, the time between survey interviews may vary, or semesters start and end at different times at different institutions. In that case it may be convenient to break up the original time periods into smaller standard periods,  such as months, especially if the data for each period can be assumed not to change during the period.</p>
<p>Load the following example data set:</p>
<p class="InputCode">use http://ssc.wisc.edu/sscc/pubs/files/semester_panel.dta</p>
<p>This contains (fictional) data about students in college. There is one row per student per semester, and the <span class="InputCode">level</span> variable tells us whether they attended a two-year or four-year institution in that semester. The variables <span class="InputCode">startYear</span>, <span class="InputCode">startMonth</span>, <span class="InputCode">endYear</span>, and <span class="InputCode">endMonth</span> tell us when each semester began and ended. Our goal is to restructure the data such that we have one observation per student per month.</p>
<p>Begin by creating a semester identifier, numbering them in chronological order:</p>
<p class="InputCode">sort id startYear startMonth<br/>
by id: gen semester=_n</p>
<p>Next convert the date variables into Stata's date format, using months as the base unit:</p>
<p class="InputCode">gen start=ym(startYear,startMonth)<br/>
                  gen end=ym(endYear,endMonth)<br/>
                format start end %tm</p>
<p>(If you're not familiar with Stata dates, you can learn about them <a href="https://ssc.wisc.edu/sscc/pubs/stata_dates.htm">here</a>.)</p>
<p>Since the dates are now stored as "number of months since January 1960" (with a format that makes them readable by humans when printed in output) the duration of a semester can be calculated by subtracting the start date from the end date and adding 1:</p>
<p class="InputCode">gen duration=end-start+1</p>
<p>Next, use the <span class="InputCode">expand</span> command to create one copy of each semester for each month the semester lasted:</p>
<p class="InputCode">expand duration</p>
<p>We now have one observation per student per month, but there's no indication which month a particular observation represents. Since they're all the same (the student is assumed to have attended the same institution for the duration of the semester) we will simply assign them in order: the first observation for a given semester will represent the first month of the semester, the second observation the second month, etc.</p>
<p>Sometimes relative times (first month, second month, etc.) are adequate. In that case you can simply set an observation's month to its observation number within the semester:</p>
<p class="InputCode">bysort id semester: gen month=_n</p>
<p>But in this case it's probably much more useful to have a time variable that tells us in absolute terms which month the observation represents. The month the semester started is stored in the <span class="InputCode">start</span> variable, so all you have to do is add the observation number minus one:</p>
<p class="InputCode">bysort id semester: gen time=start+_n-1<br/>
                  format time %tm<br/>
</p>
<p><span class="InputCode">time</span> is now the only time variable you need, so you can drop all others plus the variables used to get this far:</p>
<p class="InputCode">drop start* end* dur semester</p>
<p>You now have a data set with one observation per student per month <em>for the months the student was enrolled in school</em>. You probably want observations for all of the months in the study period where the student was not enrolled in school as well.</p>
<p>The <span class="InputCode">fillin</span> command ensures there's an observation for each unique combination of the variables it's given, creating new observations as needed. Newly created observations will have missing values for all the other variables and will have a <span class="InputCode">_fillin</span> variable set to 1, but we won't need that variable for this task. Running:</p>
<p class="InputCode">fillin id time<br/>
                drop _fillin                </p>
<p>will ensure there's an observation for each student for  each month in the data set. If at least one student is enrolled  in every month during the study period, this will create a full set of observations.</p>
<p>At this point months in which the student was not enrolled have a missing value for <span class="InputCode">level</span> (the level of the institution attended, two-year or four-year). You could change that to 0 if you prefer:</p>
<p class="InputCode">replace level=0 if level==.</p>
<p></p>
<p>However, if a month is entirely missing from the data set (because no one is enrolled during that month) <span class="InputCode">fillin</span> will not create observations for that month. In that case, if you want observations for every month in the study period you'll need to  add the missing months.</p>
<p>The following code calculates the length of the study period, creates one observation for every month in that period for a fake student, then combines that with the original data, runs <span class="InputCode">fillin</span>, and drops the fake student. The result is a data set with an observation for every month for all students.</p>
<p class="InputCode">// save what you've done thus far<br/>
                save sem_panel2, replace<br/>
<br/>
                // keep only the time variable<br/>
keep time<br/>
<br/>
// calculate the duration of the study period<br/>
// sort by time, then subtract first time from last time<br/>
sort time<br/>
gen dur=time[_N]-time[1]<br/>
<br/>
// cut to one observation<br/>
keep if _n==1<br/>
<br/>
// expand it to one observation per month in the study period
<br/>
expand dur<br/>
<br/>
// set time for each observation<br/>
replace time=time+_n-1<br/>
<br/>
// create id for fake student <br/>
gen id=-9<br/>
<br/>
// add back to full data<br/>
append using sem_panel2<br/>
<br/>
// create observations using fillin<br/>
fillin id time<br/>
drop _fillin<br/>
<br/>
// drop the fake student<br/>
drop if id==-9</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata Programming Essentials</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Ever needed to do the same thing to ten different variables and wished that you didn't have to write it out ten times? If so, then this article is for you. If not, someday you will—so you might as well keep reading anyway.</p>
<p>Stata has all the tools required to write very sophisticated programs, but knowing just a few of them allows you to make everyday do files shorter and more efficient. This article will focus on those programming tools that, in our experience, anyone who uses Stata heavily will eventually want to learn. To benefit from this article you'll need a solid understanding of basic Stata syntax, such as you can get from our <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Stata for Researchers</a> series. The primary intended audience is Stata users with no other programming experience. If you've done a lot of Stata programming already and are looking to expand your "bag of tricks" check out <a href="https://ssc.wisc.edu/sscc/pubs/stata_prog2.htm">Stata Programming Tools</a>.                </p>
<p>This article is best read at the computer with Stata running. Typing the commands in the examples yourself will help you notice and retain all the details, and prepare you to write your own code.</p>
<h2><a id="Macros" name="Macros"></a>Macros</h2>
<p>A Stata macro is a box you  put  text in. You then use what's in the box in subsequent commands. (The real trick is getting a single command to run multiple times with a different bit of text in the box each time--we'll get there).</p>
<p>The macros we'll use are "local" macros. If you're familiar with global and local variables from other languages, Stata's local macros are local in the same way. If not, just trust us that local macros are the right ones to use.</p>
<p>The command to define a local macro is:</p>
<p class="InputCode">local <span class="Parameter">name</span> <span class="Parameter">value</span></p>
<p>For example:</p>
<p class="InputCode">local x 1</p>
<p>This creates a local macro called <span class="InputCode">x</span> and puts the character '<span class="InputCode">1</span>' in it (not the value 1 as in "one unit to the right of zero on the number line"). To use a macro, you put its name in a command, surrounded by a particular set of quotation marks:</p>
<p class="InputCode">display `x'</p>
<p>The quote before the <span class="InputCode">x</span> is the left single quote. It is found in the upper left corner of the keyboard, under the tilde (<span class="InputCode">~</span>). The quote after the <span class="InputCode">x</span> is the right single quote. It is found under the double quotation mark (<span class="InputCode">"</span>) on the right side of the keyboard.</p>
<p>Macros are handled by a  macro processor that examines commands before passing them to Stata proper. When it sees a macro (denoted by that particular set of quotation marks) it replaces the  macro with its table. Thus what Stata proper saw was:</p>
<p class="InputCode">display 1</p>
<p>Now try a slightly more complicated macro:</p>
<p class="InputCode">local x 2+2<br/>
                  display `x'
                </p>
<p>The result is <span class="MenuOutput">4</span>, but that's because the display command acts like a calculator. The command Stata saw was:</p>
<p class="InputCode">display 2+2</p>
<p>so it evaluated <span class="InputCode">2+2</span> and gave you the answer. If you want <span class="InputCode">display</span> to put something on the screen without evaluating it,  put it in quotes. Then <span class="InputCode">display</span> will treat it like a string.</p>
<p class="InputCode">display "`x'"</p>
<p>gives the result <span class="MenuOutput">2+2</span>. But consider what happened before you put it in quotes: your macro contained a working bit of Stata code which Stata happily executed when you used it. In fact Stata proper didn't know or care that <span class="InputCode">2+2</span> came from a macro. This feature allows you to use macros absolutely anywhere, even in macro definitions.</p>
<h3><a id="StoringResultsinMacros" name="StoringResultsinMacros"></a>Storing Results in Macros</h3>
<p>If you want to put the result of a calculation in a macro, put an equals sign after the macro name:</p>
<p class="InputCode">local x=2+2<br/>
                display "`x'"                </p>
<p>If the <span class="InputCode">local</span> command contains an equals sign, Stata will evaluate what follows before putting it in the macro. Now <span class="InputCode">x</span> really does contain <span class="InputCode">4</span> and not <span class="InputCode">2+2</span> no matter how you display it.</p>
<h3><a id="MacroExpressions" name="MacroExpressions"></a>Macro Expressions</h3>
<p>Stata's macro processor can evaluate Stata expressions; i.e. any formula you could put after the equals sign in a <span class="InputCode">generate</span> or <span class="InputCode">replace</span> command (but not <span class="InputCode">egen</span>). The syntax is:</p>
<p class="InputCode">`=<span class="Parameter">expression</span>'</p>
<p>where <span class="Parameter">expression</span> is the expression to be evaluated. Try:</p>
<p class="InputCode">display "`=2+2'"</p>
<p>The result is <span class="MenuOutput">4</span>, but <span class="InputCode">display</span> didn't calculate it (the quotes prevent that). Instead, the equals sign before <span class="InputCode">2+2</span> told the macro processor to evaluate that expression and put the result in the code, so what Stata proper saw was <span class="InputCode">display "4"</span>. Another common use is <span class="InputCode">`=_N'</span>, which will be the number of observations in the current data set (and can be used in places where <span class="InputCode">_N</span> by itself can't).</p>
<p> Macro expressions--and macros in general--can contain other macros. Try:</p>
<p class="InputCode">display "`=`x'-1'"</p>
<p>This tells the macro processor to subtract one from the value of the macro x and then place the result in the code. This can be extremely useful: for example, if you had a macro <span class="InputCode">`year'</span> containing the current year, <span class="InputCode">`=`year'-1'</span> would be the year before the current year.</p>
<h3><a id="UndefinedMacros" name="UndefinedMacros"></a>Undefined Macros</h3>
<p>Unfortunately, using a macro you haven't defined doesn't generate an error message. Stata's macro processor just replaces it with nothing:</p>
<p class="InputCode">display `y'</p>
<p>Gives the same result as:</p>
<p class="InputCode">display </p>
<p>This can cause headaches: if you mistype a macro's name you'll probably get a generic syntax error with no indication that a macro is the cause of the problem. Even worse, in some circumstances the command will still work but give incorrect results. Be very careful to type the names of macros properly.</p>
<h3><a id="SomeUsesforMacrosOutsideofLoops" name="SomeUsesforMacrosOutsideofLoops"></a>Some Uses for Macros Outside of Loops</h3>
<p>The main reason for learning about macros is so you can use them in loops. But there are times when using them all by themselves can make complex code easier to read.</p>
<p>Suppose you need to run a large number of regressions of various types, but they all include a fixed set of control variables. Consider putting the list of control variables in a macro:</p>
<p class="InputCode">local controlVars age sex occupation location maritalStatus hasChildren</p>
<p>This will make the regression commands shorter:</p>
<p class="InputCode">reg income education `controlVars'<br/>
                  logit 
                employed education `controlVars'</p>
<p>Now suppose you frequently work with  subsamples of your data set. You can define macros for them as well:</p>
<p class="InputCode">local blackWoman race==1 &amp; female<br/>
                local hispMan race==2 &amp; !female<br/>
                reg income education `controlVars' if `blackWoman'<br/>
				logit employed education `controlVars' if `hispMan'</p>
<p>The point here is not to save keystrokes, but to make the code more clear. Using macros hides the details of what the control variables are or how a black woman can be identified in this data set and helps you focus on what you're trying to do. Not having to type out those details every time also removes an opportunity for error. You can  make changes more quickly too: if you need to add a control variable you only have to add it to the definition of the <span class="InputCode">controlVars</span> macro rather than adding it to each regression command.</p>
<p> Saving keystrokes is a nice side effect, but resist the temptation to make your code less clear in the name of making it shorter. Taking a few minutes to type out clear code is far more efficient than spending hours debugging code that's short but hard to understand.</p>
<h2><a id="ForLoops" name="ForLoops"></a>For Loops</h2>
<p>A <span class="InputCode">foreach</span> loop takes a list and then executes a command or set of commands for each element of the list. The element currently being worked on is stored in a macro so you can refer to it in the commands. The list to be looped over can be a generic list  containing  text, or there are several kinds of  structured lists (we'll only discuss <em>varlists</em>).</p>
<p>The syntax for a <span class="InputCode">foreach</span> loop with a generic list is:</p>
<p class="InputCode">foreach <span class="Parameter">macro</span> in <span class="Parameter">list</span> {<br/>
<span class="indent3"><span class="Parameter">command(s)</span></span><br/>
                  }</p>
<p>As a very simple example:</p>
<p class="InputCode">foreach color in red blue green {<br/>
<span class="indent3">display "`color'"</span><br/>}</p>
<p>Here, <span class="InputCode">color</span> is the name of the macro that will contain the list elements. <span class="InputCode">red blue green</span> is the list itself. Stata breaks the list into elements wherever it sees spaces, so this list contains three elements: <span class="InputCode">red</span>, <span class="InputCode">blue,</span> and <span class="InputCode">green</span>. The left curly bracket (<span class="InputCode">{</span>) marks the beginning of the loop and must be at the end of the <span class="InputCode">foreach</span> command. The right curly bracket (<span class="InputCode">}</span>) marks the end of the loop and must go on its own line. If you type this in interactive Stata the Results window adds line numbers for the commands inside the loop, but you do not need to type them. Note how nothing is actually executed until you type the right curly bracket, and then Stata runs the whole thing. When it does you'll get the following output:</p>
<p class="MenuOutput">red<br/>
                  blue<br/>
                green</p>
<p></p>
<p>Stata begins by analyzing your list and identifying the elements it contains. It then puts the first element (<span class="InputCode">red</span>) in the loop's macro (<span class="InputCode">color</span>) and executes the command in the loop. Given the tables of <span class="InputCode">color</span>, the command becomes <span class="InputCode">display "red"</span> and <span class="MenuOutput">red</span> is printed on the screen. Stata then puts the second element in the macro and runs the command again, printing <span class="MenuOutput">blue</span> on the screen. It then repeats the process for <span class="MenuOutput">green</span>, and when that's done Stata realizes the list is out of elements and the <span class="InputCode">foreach</span> loop is  complete.</p>
<p>Throughout this article you'll see that commands which are inside a loop are indented. This makes the loop's structure visually obvious and we highly recommend you do the same when writing do files. All you need to do is press <span class="InputCode">Tab</span> before you begin the first line of the loop. Stata's do file editor and any other text editor suitable for programming will indent subsequent lines automatically. (There's no need to worry about indenting when working interactively, but in real work it's very rare to use loops interactively.)</p>
<p>You can use a generic list to loop over many different kinds of things: variables, values, files, subsamples, subscripts, anything you can describe using text. If an element needs to contain spaces, put it in quotes.</p>
<h3><a id="LoopingoverVariables" name="LoopingoverVariables"></a>Looping over Variables</h3>
<p>The most common thing to loop over is variables. For example, suppose you wanted to regress several different dependant variables on the same independent variables. The following code does so, using the automobile example data set that comes with Stata:</p>
<p class="InputCode">sysuse auto<br/>
                foreach yvar in mpg price displacement {<br/>
<span class="indent3">reg `yvar' foreign weight</span><br/>
                }
                </p>
<h3><a id="LoopingoverPartsofVariableNames" name="LoopingoverPartsofVariableNames"></a>Looping over Parts of Variable Names</h3>
<p>Consider the following data set:</p>
<p class="InputCode">use http://www.ssc.wisc.edu/sscc/pubs/files/stata_prog/months.dta</p>
<p>It contains a fictitious (and not terribly plausible) data set of people and their incomes over twelve months. This is panel data in the wide form, so there are twelve income variables: <span class="InputCode">incJan</span>, <span class="InputCode">incFeb</span>, <span class="InputCode">incMar</span>, etc. Suppose you want to create a corresponding set of indicator variables for whether the person had any income in that month. Creating one of them is straightforward:</p>
<p class="InputCode">gen hadIncJan=(incJan&gt;0) if incJan&lt;.</p>
<p>but creating all twelve in the same way would be tedious.</p>
<p> (If you checked, you'd find that this data set does not have any missing values so excluding them with <span class="InputCode">if incJan&lt;.</span> is not strictly necessary. Consider it a reminder to always think about missing values when creating such indicator variables.)</p>
<p>You can create all twelve indicator variables quickly and easily with a <span class="InputCode">foreach</span> loop:</p>
<p class="InputCode">foreach month in Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec {<br/>
<span class="indent3">gen hadInc`month'=(inc`month'&gt;0) if inc`month'&lt;.</span><br/>
}</p>
<p>This sets up a generic list containing the months, and then uses those months as parts of variable names.</p>
<p>Note the process we used to create this loop: first we figured out the command we'd use for a single element of the list and then changed it to use macros. This is a good habit whenever you need to write non-trivial code involving macros.</p>
<h3><a id="LoopingoverVarlists" name="LoopingoverVarlists"></a>Looping over Varlists</h3>
<p>While generic lists can contain variable names, you have to type out all the names individually. If you tell Stata that the list you want to loop over is an official Stata <em>varlist</em> you can use standard <em>varlist</em> shortcuts, like <span class="InputCode">x*</span> for all variables that begin with <span class="InputCode">x</span> and <span class="InputCode">x-z</span> for all the variables from <span class="InputCode">x</span> to <span class="InputCode">z</span>. To review <em>varlist</em> syntax, see the appropriate section in  <a href="https://ssc.wisc.edu/sscc/pubs/sfr-syntax.htm#Varlists">Stata for Researchers</a>.</p>
<p>The syntax for a <span class="InputCode">foreach</span> loop over a <em>varlist</em> is as follows:</p>
<p class="InputCode">foreach <span class="Parameter">macro</span> of varlist <span class="Parameter">vars</span> {</p>
<p>Note that while the <span class="InputCode">foreach</span> syntax for a generic list contains <span class="InputCode">in</span>, the syntax for a structured list has <span class="InputCode">of</span>. Stata uses the <span class="InputCode">in</span> or <span class="InputCode">of</span> to determine whether the next word is the first element of the list or a type of list.</p>
<p>Researchers occasionally receive data sets created in other programs where the variable names are  in upper case letters. Since Stata actually cares about case, upper case variable names can be tiresome to work with. Stata recently gave the <span class="InputCode">rename</span> command the ability to convert names to lower case:</p>
<p class="InputCode">rename *, lower</p>
<p>But this such a great example that let's do it with a <span class="InputCode">foreach</span> loop over a <em>varlist</em> anyway:</p>
<p class="InputCode">foreach oldname of varlist * {<br/>
<span class="indent3">local newname=lower("`oldname'")</span><br/>
<span class="indent3">rename `oldname' `newname'</span><br/>
                }</p>
<p>The asterisk (<span class="InputCode">*</span>) all by itself matches all variables, so  the list <span class="InputCode">foreach</span> is to loop over contains all the variables in the current data set. The <span class="InputCode">lower()</span> function takes a string, in this case the tables of the macro <span class="InputCode">oldname</span>, and converts it to lower case. Note the use of the equals sign in the <span class="InputCode">local</span> command that defines <span class="InputCode">newname</span>, so that <span class="InputCode">lower("`oldname'")</span> is evaluated and the result is stored.</p>
<h3><a id="LoopingoverNumbers" name="LoopingoverNumbers"></a>Looping over Numbers</h3>
<p>A <span class="InputCode">forvalues</span> loop (frequently abbreviated <span class="InputCode">forval</span>) loops over numbers. Rather than defining a list, you define a range of numbers.</p>
<p>By far the most common range consists of a starting number and an ending number, and Stata assumes it should count by ones between them. The syntax is simply:</p>
<p class="InputCode">forvalues <span class="Parameter">macro</span>=<span class="Parameter">start</span>/<span class="Parameter">end</span> {</p>
<p>For example:</p>
<p class="InputCode">forvalues i=1/5 {<br/>
<span class="indent3">display `i'</span><br/>
                  }
                </p>
<p>gives the output:</p>
<p class="MenuOutput">1<br/>
                  2<br/>
                  3<br/>
                  4<br/>
                  5                </p>
<p>If you need to count in a different way, type <span class="InputCode">help forvalues</span> to see more options.</p>
<p>Consider the following data set:</p>
<p class="InputCode">use http://www.ssc.wisc.edu/sscc/pubs/files/stata_prog/years.dta</p>
<p>This data set is very similar to the data set of monthly incomes we examined earlier, but it contains yearly incomes from 1990 to 2010. Your task is again to create an indicator for whether a person had any income in a given year. Using <span class="InputCode">forvalues</span> this is very easy to do:</p>
<p class="InputCode">forvalues year=1990/2010 {<br/>
<span class="indent3">gen hadInc`year'=(inc`year'&gt;0) if inc`year'&lt;.</span><br/>
                }</p>
<p>This would be more difficult if the years did not include the century (i.e. <span class="InputCode">90</span> instead of <span class="InputCode">1990</span>) because Stata thinks <span class="InputCode">100</span> should come after <span class="InputCode">99</span> and not <span class="InputCode">00</span>. If your data include such years, consider adding the century before doing any serious work with it.</p>
<h3><a id="LoopingoverValues" name="LoopingoverValues"></a>Looping over Values and levelsof</h3>
<p>Sometimes you need to loop over the values a particular variable takes on. Consider the following data set:</p>
<p class="InputCode">use http://www.ssc.wisc.edu/sscc/pubs/files/stata_prog/vals.dta</p>
<p>This contains  data on the race, income, age and education category of  a set of fictional people. Suppose you want to regress <span class="InputCode">income</span> on <span class="InputCode">age</span> and <span class="InputCode">education</span>, but believe that the effects of age and education may be different for people of different races. One approach (probably not the best one) would be to run a separate regression for the people of each race. Normally you could do that with:</p>
<p class="InputCode">by race: regress income age i.education</p>
<p>(The construction <span class="InputCode">i.education</span> tells Stata that <span class="InputCode">education</span> is a factor or categorical variable and should be converted into a set of indicators. See the <a href="https://www.ssc.wisc.edu/sscc/pubs/sfr-syntax.htm#FactorVariables">section on factor variables in Stata for Researchers</a> if you'd like to review factor variable syntax.)</p>
<p>However, this is fictional survey data and you need to correct for the survey design in running regressions. If you're not familiar with Stata's survey commands, that means the following:</p>
<ol>
<li>The survey design is described using the <span class="InputCode">svyset</span> (survey set) command. This data set has primary sampling units given by the variable <span class="InputCode">psu</span> and probability weights given by the variable <span class="InputCode">weight</span>. The corresponding command <span class="InputCode">svyset</span> command (which has already been run so you don't need to) is:<br/>
<span class="InputCode">svyset psu [pweight=weight]</span></li>
<li>To have Stata correct for those weights in estimation commands, add the <span class="InputCode">svy:</span> prefix, for example:<br/>
<span class="InputCode">svy: regress income age i.education</span></li>
<li>You can't use the standard <em>if</em> syntax with survey data or the weights may not be applied correctly. Instead, use the <span class="InputCode">subpop()</span> option of <span class="InputCode">svy:</span>, for example:<br/>
<span class="InputCode">svy, subpop(if race==1): regress income age i.education</span></li>
<li><span class="InputCode">by:</span> can't be used with <span class="InputCode">svy:</span></li>
</ol>
<p>Point #4 means you can't run your regression for all races using <span class="InputCode">by:</span>, but you can do it with a loop. All <span class="InputCode">by:</span> does is identify the values of <span class="InputCode">race</span> and then loop over them, and at this point you know how to do that yourself (though <span class="InputCode">by:</span> is faster when you can use it). The <span class="InputCode">race</span> variable takes on the values one, two and three, so an appropriate loop is:</p>
<p class="InputCode">forvalues race=1/3 {<br/>
<span class="indent3">svy, subpop(if race==`race'): reg income age i.education</span><br/>
                  }</p>
<p>What if you had a fourth race, and its number were nine ("Other") rather than four? You could simply recode it and make it four. But if that's not a good idea for your project, you'll have to switch to the less structured <span class="InputCode">foreach</span> loop:</p>
<p class="InputCode">foreach race in 1 2 3 9 {<br/>
<span class="indent3">svy, subpop(if race==`race'): reg income age i.education</span><br/>
                  }</p>
<p>On the other hand, it's not unusual to have to loop over dozens or even hundreds of values, or not to know ahead of time what values a variable takes on. In that case you can let the <span class="InputCode">levelsof</span> command identify them for you and put them in a macro. The syntax is:</p>
<p class="InputCode">levelsof <span class="Parameter">variable</span>, local(<span class="Parameter">macro</span>)</p>
<p>For example,</p>
<p class="InputCode">levelsof race, local(races)</p>
<p>will list all the values of the variable <span class="InputCode">race</span> and  store them in a macro called <span class="InputCode">races</span>. You can then loop over all of them with:</p>
<p class="InputCode">foreach race in `races' {<br/>
<span class="indent3">svy, subpop(if race==`race'): reg income age i.education</span><br/>
                  }</p>
<p>However, this situation is common enough that Stata wrote special code for parsing macros into lists for looping. The syntax is:</p>
<p class="InputCode">foreach race of local races {<br/>
<span class="indent3">svy, subpop(if race==`race'): reg income age i.education</span><br/>
                  }</p>
<p>Note that <span class="InputCode">races</span> is not in the usual macro quotes: the whole point of this construction is to bypass the regular macro processor in favor of code that's faster in the context of loops. It makes a very small difference, but if you do enough looping it will add up.</p>
<p>One feature you'll miss from <span class="InputCode">by:</span> is the text in the output telling you which by group is currently being worked on, but you can add it yourself. The following version of the loop adds a <span class="InputCode">display</span> command that inserts two blank lines and then prints the current value of the <span class="InputCode">race</span> macro before running the regression:</p>
<p class="InputCode">foreach race of local races {<br/>
<span class="indent3">display _newline(2) "Race=`race'"</span><br/>
<span class="indent3">svy, subpop(if race==`race'): reg income age i.education</span><br/>
                  }</p>
<p>Using <span class="InputCode">display</span> to print out the value of a macro at a given point in your program is also a very useful tool for debugging.</p>
<p>Keep in mind that this was just an example. A better way to examine the effect of <span class="InputCode">race</span> would probably be to interact race with  the other variables. The <a href="https://www.ssc.wisc.edu/sscc/pubs/sfr-syntax.htm#FactorVariables">new syntax for factor variables and interactions</a> makes this very easy:</p>
<p class="InputCode">svy: regress income i.race##(c.age i.education)</p>
<p>This model contains all the previous models--if you're new to regressions that include interactions, figuring out why that is might be a good exercise.</p>
<h2><a id="NestedLoops" name="NestedLoops"></a>Nested Loops</h2>
<p>The commands contained in a loop can include other loops:</p>
<p class="InputCode">forval i=1/3 {<br/>
<span class="indent3">forval j=1/3 {</span><br/>
<span class="indent3"><span class="indent3">display "`i',`j'"</span></span><br/>
<span class="indent3">}</span><br/>
                }</p>
<p>This code creates the following output:</p>
<p><span class="MenuOutput">1,1<br/>
                1,2<br/>
                1,3<br/>
                2,1<br/>
                2,2<br/>
                2,3<br/>
                3,1<br/>
                3,2<br/>
                3,3</span><br/>
</p>
<p>The inner loop (the one that uses <span class="InputCode">j</span>) is executed three times, once for each value of <span class="InputCode">i</span>. Thus the <span class="InputCode">display</span> command runs a total of nine times. Note how the <span class="InputCode">display</span> command is indented twice: once because it is part of the <span class="InputCode">i</span> loop and once because it is part of the <span class="InputCode">j</span> loop. When you start working with nested loops it's even more important that you can easily tell what each loop contains.</p>
<p>Consider one final data set:</p>
<p class="InputCode">use http://www.ssc.wisc.edu/sscc/pubs/files/stata_prog/monthyear.dta</p>
<p>This contains monthly income data, but for the period 1990-2010. The variable names are in the form <span class="InputCode">incJan1990</span>, <span class="InputCode">incFeb1990</span>, etc. To generate a set of corresponding indicators you need to loop over both the months and the years:</p>
<p class="InputCode">forval year=1990/2010 {<br/>
<span class="indent3">foreach month in Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec {</span><br/>
<span class="indent3"><span class="indent3">gen hadInc`month'`year'=(inc`month'`year'&gt;0) if inc`month'`year'&lt;.</span></span><br/>
<span class="indent3">}</span><br/>
}</p>
<p>This is certainly workable, but somewhat cumbersome. It would be especially awkward if you were interested in lags, leads, or changes over time: you'd need code to tell Stata that the month before January 1991 is December 1990. For most purposes it's easier if time periods are simply numbered sequentially. In this case January 1990 would be period 1, December 1990 would be period 12 and January 1991 period 13. Fortunately it's fairly easy to switch:</p>
<p class="InputCode">local period 1<br/>
                  forval year=1990/2010 {<br/>
<span class="indent3">foreach month in Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec {</span><br/>
<span class="indent3"><span class="indent3">rename inc`month'`year' inc`period'</span></span><br/>
<span class="indent3"><span class="indent3">rename hadInc`month'`year' hadInc`period'</span></span><br/>
<span class="indent3"><span class="indent3">local period=`period'+1</span></span><br/>
<span class="indent3">}</span><br/>
}</p>
<p>The macro <span class="InputCode">period</span> is used as a counter. It starts out set to <span class="InputCode">1</span>, and thus as the nested loops begin <span class="InputCode">incJan1990</span> is renamed <span class="InputCode">inc1</span> (and similarly <span class="InputCode">hadIncJan1990</span> to <span class="InputCode">hadInc1</span>). The command <span class="InputCode">local period=`period'+1</span> increases <span class="InputCode">period</span> by one: once the macro processor is done with it Stata proper sees <span class="InputCode">local period=1+1</span>. That completes the inner loop, so <span class="InputCode">month</span> is changed to <span class="InputCode">Feb</span>, and <span class="InputCode">incFeb1990</span> is renamed to <span class="InputCode">inc2</span>. The <span class="InputCode">period</span> macro is increased again (Stata proper now sees <span class="InputCode">local period=2+1</span>), <span class="InputCode">month</span> is set to <span class="InputCode">Mar</span>, <span class="InputCode">incMar1990</span> is renamed to <span class="InputCode">inc3</span>, and so forth until all 252 months are converted. (Note that 1990 to 2010 inclusive is 21 years.)</p>
<p>In making this conversion you lose the ability to look at a variable and know immediately what calendar month it describes. But it's much easier to loop over. The nested loops can be replaced with:</p>
<p class="InputCode">forvalues period=1/252 {</p>
<h2><a id="TheImportanceofNamingConventions" name="TheImportanceofNamingConventions"></a>The Importance of Naming Conventions</h2>
<p>The variable name <span class="InputCode">incJan1990</span> contains three components: the thing being observed (income) and  the month and year in which it is observed. The loops we wrote depend on the variable names describing all three in a consistent way: they would fail if the data set contained <span class="InputCode">incJan1990</span> along with <span class="InputCode">incomeJan1991</span>, <span class="InputCode">incjan1992</span>, <span class="InputCode">incJanuary1993</span> or <span class="InputCode">incJan94</span>. In the real world such things are not unusual. Data sets from surveys are a particular challenge because their variable names often come from the form of the questionnaire rather than the information they contain. Taking the time to rename your variables in a way that makes sense to you is a good idea at the beginning of any project, but if you'll be using loops it's vital that you create and apply a consistent naming convention for variables.</p>
<h2>Take Advantage of Stata's Automatic Loops</h2>
<p>Now that you've learned how to use loops, it can be tempting to use them for everything. Keep in mind that most Stata commands are already loops (do something to observation one, then do it to observation two, etc.) and those loops are much faster than any <span class="InputCode">foreach</span> or <span class="InputCode">forvalues</span> loop. For example, the following uses <span class="InputCode">forvalues</span> to loop over all the observations in the data set and set the value of <span class="InputCode">y</span> for each observation to the value of <span class="InputCode">x</span> for that observation:</p>
<p class="InputCode">                gen y=.<br/>
                forvalues i=1/`=_N' {<br/>
<span class="indent3">replace y=x[`i'] if _n==`i'</span><br/>
                }</p>
<p>but you'll get the exact same result far more quickly and easily with:</p>
<p class="InputCode">gen y=x</p>
<p>Occasionally someone finds a task that really does requires explicit looping over observations, but it's rare.</p>
<p>Clever programming can sometimes turn other loops into the standard loop over observations, making <span class="InputCode">foreach</span> or <span class="InputCode">forvalues</span> unnecessary. For example, reshaping wide form panel data into long form will eliminate the need for many loops.</p>
<p>Go back to the original 12 months of income data:</p>
<p class="InputCode">use http://www.ssc.wisc.edu/sscc/pubs/files/stata_prog/months.dta</p>
<p>Recall that we created <span class="InputCode">hadInc</span> indicator variables with the following loop:</p>
<p class="InputCode">foreach month in Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec {<br/>
<span class="indent3">gen hadInc`month'=(inc`month'&gt;0) if inc`month'&lt;.</span><br/>
}</p>
<p>However, you'll get the  same results with the following:</p>
<p class="InputCode">reshape long inc, i(id) j(month) string<br/>
                  gen hadInc=(inc&gt;0) if inc&lt;.<br/>
                reshape wide inc hadInc, i(id) j(month) string</p>
<p>(Take a moment to examine the data after each step.)</p>
<p>Reshaping a large data set is time consuming, so  don't switch between wide form and long form lightly. But if you can identify a block of things you need to do that would be easier to do in long form, it may be worth reshaping at the beginning and end of that block.                </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Stata Programming Tools</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>This article will introduce you to many Stata programming tools that are not  needed by everyone but are very useful in certain circumstances. The intended audience is Stata veterans who are already familiar with and comfortable using  Stata syntax and fundamental programming tools like macros, <span class="InputCode">foreach</span> and <span class="InputCode">forvalues</span>.</p>
<p>If you are new to Stata, our <a href="https://ssc.wisc.edu/sscc/pubs/sfr-intro.htm">Stata for Researchers</a> will teach you basic Stata syntax, and <a href="https://ssc.wisc.edu/sscc/pubs/stata_prog1.htm">Stata Programming Essentials</a> will teach you the fundamental programming tools. Unlike this article, they do not assume any Stata or general programming experience.</p>
<p>Topics discussed in this article include:</p>
<ul>
<li><a href="#CompoundDoubleQuotes">Compound Double Quotes</a></li>
<li><a href="#Capture">Capture</a></li>
<li><a href="#VariablesinScalarContexts">Variables in Scalar Contexts</a></li>
<li><a href="#AdvancedMacros">Advanced Macros</a></li>
<li><a href="#BranchingIf">Branching If</a></li>
<li><a href="#WhileLoops">While Loops</a></li>
<li><a href="#Programs">Programs</a></li>
</ul>
<p>If you need to learn about a specific topic, feel free to skip to it. Some of the examples use material  covered previously (i.e. a program containing a branching <em>if</em>) but the explanations are self-contained.</p>
<h2><a id="CompoundDoubleQuotes" name="CompoundDoubleQuotes"></a>Compound Double Quotes</h2>
<p>The beginning and ending of a string are normally denoted by double quotes ("string"). This causes problems when the string itself contains double quotes. For example, if you wanted to display the string <span class="InputCode">Hamlet said "To be, or not to be."</span> you could not use the code:</p>
<p class="InputCode">display "Hamlet said "To be, or not to be.""</p>
<p> The solution is what Stata calls compound double quotes. When Stata sees <span class="InputCode">`"</span> (left single quote followed by a double quote) it treats what follows as a string until it sees <span class="InputCode">"'</span> (double quote followed by a right single quote). Thus:</p>
<p class="InputCode">display `"Hamlet said "To be, or not to be.""'</p>
<h2><a id="Capture" name="Capture"></a>Capture</h2>
<p> On occasion you may expect a command to generate an error under certain circumstances  but choose to ignore it. For example, putting <span class="InputCode">log close</span> at the beginning of a do file prevents a previously opened log from interfering with your do file, but generates an error if no log  is open--even though not having a log open is exactly the situation you want to create.</p>
<p> The <span class="InputCode">capture</span> prefix prevents Stata from halting your do file if the ensuing command generates an error. The error is "captured" first. Thus:</p>
<p class="InputCode">capture log close</p>
<p>will close any open log but not crash a do file if no log file is open.</p>
<p>The <span class="InputCode">capture</span> prefix should only be used when you fully understand the error the command sometimes generates and why it does so--and you are very confident that that error can be ignored.</p>
<p>When a command is complete it stores a "return code" in <span class="InputCode">_rc</span>. A return code of zero generally means the command executed successfully. You can use <span class="InputCode">capture</span> followed by a <a href="#BranchingIf">branching if</a> based on the return code to have Stata do different things depending on whether an error occurred or not.</p>
<h2><a id="VariablesinScalarContexts" name="VariablesinScalarContexts"></a>Variables in Scalar Contexts</h2>
<p>A Stata variable is a vector: it has many values. If you type <span class="InputCode">list x</span> you get a list of all the values of <span class="InputCode">x</span>. However, some contexts call for a scalar. For example, the <span class="InputCode">display</span> command displays just one thing. If a variable is used in a scalar context,   the  value of the variable for the first observation is used. Thus if you type:</p>
<p class="InputCode">display x</p>
<p>you'll get just the first value of x, as if you'd typed:</p>
<p class="InputCode">display x[1]</p>
<p>We suggest not taking advantage of this behavior, because it makes for confusing code. If a command calls for a scalar and you want that scalar to be the first value of <span class="InputCode">x</span>, type <span class="InputCode">x[1]</span> rather than just <span class="InputCode">x</span>.</p>
<p>This behavior can cause real problems if you don't realize a particular context calls for a scalar, as you'll see in the section on <a href="#BranchingIf">branching if</a>. </p>
<h2><a id="AdvancedMacros" name="AdvancedMacros"></a>Advanced Macros</h2>
<p>This section will discuss many tricks you can use to define macros. Type <span class="InputCode">help local</span> for even more.</p>
<h3><a id="StoringListsofValuesWithlevelsof" name="StoringListsofValuesWithlevelsof"></a>Storing Lists of Values with levelsof</h3>
<p>The <span class="InputCode">levelsof</span> command lists the valid values of a variable and stores them in a local macro. The syntax is:</p>
<p class="InputCode">levelsof <span class="Parameter">variable</span>, local(<span class="Parameter">macro</span>)</p>
<p>It is frequently used with an <em>if</em> condition to store those values of a variable that appear in a given subsample.</p>
<p>The following example (taken from <a href="https://ssc.wisc.edu/sscc/pubs/stata_prog1.htm">Stata Programming Essentials</a>) uses <span class="InputCode">levelsof</span> and a <span class="InputCode">foreach</span> loop to run a survey-weighted regression separately for each race. This recreates the functionality of <span class="InputCode">by:</span> even though <span class="InputCode">by:</span> can't be used with <span class="InputCode">svy</span>:</p>
<p class="InputCode">levelsof race, local(races)<br/>
                  foreach race of local races {<br/>
<span class="indent3">display _newline(2) "Race=`race'"</span><br/>
<span class="indent3">svy, subpop(if race==`race'): reg income age i.education</span><br/>
}</p>
<p>Since <span class="InputCode">levelsof</span> doesn't include missing values in its list, the above code will not run a regression for observations with a missing value for <span class="InputCode">race</span>. This is different from <span class="InputCode">by:</span>, which treats observations with a missing value of the <em>by</em> variable as just another group to act on.</p>
<p>Suppose you asked individuals to list the social groups they belong to. The groups are  encoded as numbers and stored in variables <span class="InputCode">group_</span><span class="Parameter">i</span> where <span class="Parameter">i</span> is an integer. Thus if a person said she belongs to group five and group three (in that order)  her value of <span class="InputCode">group_1</span> would be <span class="InputCode">5</span> and her value of <span class="InputCode">group_2</span> would be <span class="InputCode">3</span>. (If she lists fewer groups than the maximum number allowed, she will have missing values for some <span class="InputCode">group_</span><span class="Parameter">i</span> variables.) You then want to create an indicator variable  for each group which has a value of 1 if the person said she is a member of that group and zero otherwise:</p>
<p class="InputCode">foreach groupvar of varlist group_* {<br/>
<span class="indent3">levelsof `groupvar', local(groups)</span><br/>
<span class="indent3">foreach group of local groups {</span><br/>
<span class="indent6">capture gen mem_`group'=0</span><br/>
<span class="indent6">replace mem_`group'=1 if `groupvar'==`group'</span><br/>
<span class="indent3">}</span><br/>
                  }</p>
<p>This loops over the <span class="InputCode">group_</span><span class="Parameter">i</span> variables, figures out which groups were listed in each one, loops over them, creates an indicator variable for each group, and sets the indicator to 1 if the person listed that group.</p>
<p>Note that you don't need to know ahead of time how many groups a person can list or the numbers of the groups that can appear. The <span class="InputCode">gen</span> command has <span class="InputCode">capture</span> in front of it because the indicator for a given group may have already been created: if someone listed group 5 as his first group and someone else listed group 5 as his second group, <span class="InputCode">mem_5</span> will be created when processing <span class="InputCode">group_1</span> and trying to create <span class="InputCode">mem_5</span> again when processing <span class="InputCode">group_2</span> gives an error--but you know it's an error you can ignore.</p>
<h3><a id="ExpandingVariableListswithunab" name="ExpandingVariableListswithunab"></a>Expanding Variable Lists with unab</h3>
<p>The <span class="InputCode">unab</span> command "unabbreviates"  a <em>varlist</em> ("expand" was taken) and puts the results in a macro. The syntax is:</p>
<p class="InputCode">unab <span class="Parameter">macro</span>: <span class="Parameter">varlist</span></p>
<p>For example, if you had variables <span class="InputCode">x1</span>, <span class="InputCode">x2</span> and <span class="InputCode">x3</span>, then:</p>
<p class="InputCode">unab vars: x*</p>
<p>would create a local macro called <span class="InputCode">vars</span> and place in it <span class="InputCode">x1 x2 x3</span>. This can be  useful for commands that require a list of variables but cannot use <em>varlist</em> syntax, like <span class="InputCode">reshape</span> when going from long to wide.</p>
<h3><a id="ListsofFiles" name="ListsofFiles"></a>Lists of Files</h3>
<p>You can place a list of files in a macro by sending <span class="InputCode">local</span> the output of a <span class="InputCode">dir</span> command. The syntax is:</p>
<p class="InputCode">local <span class="Parameter">macroname</span>: dir <span class="Parameter">directory</span> files "<span class="Parameter">pattern they must match</span>"</p>
<p>Here <span class="Parameter">macroname</span> is the name of the macro you want to create, <span class="Parameter">directory</span> is the directory where the files are located and <span class="Parameter">pattern they must match</span> is something like <span class="InputCode">"*"</span> for all files or <span class="InputCode">"*.dta"</span> for all Stata data sets. For example, the following would put a list of all Stata data sets in the current working directory in a macro called <span class="InputCode">datafiles</span>:</p>
<p class="InputCode">local datafiles: dir . files "*.dta"</p>
<p>One complication is that  the file names are placed in quotes (so it can handle file names with spaces in them). Thus to display them you have to use compound double quotes:</p>
<p class="InputCode">di `"`datafiles'"'</p>
<p>However, this doesn't cause problems if you want to loop over the list of files:</p>
<p class="InputCode">foreach file of local datafiles {<br/>
<span class="indent3">use `file', clear</span><br/>
<span class="indent3">// do something with the file</span><br/>
                  }</p>
<h3><a id="FormattingtheContentsofaMacro" name="FormattingtheContentsofaMacro"></a>Formatting the Contents of a Macro</h3>
<p>You can apply a format to a number before storing it in a macro by sending <span class="InputCode">local</span> the output of a <span class="InputCode">display</span> command that includes a format. For example, the following command stores the R-squared of the most recently run regression, <span class="InputCode">e(r2)</span>, in a macro called <span class="InputCode">r2</span>, but using the format <span class="InputCode">%5.4f</span> so it has four digits rather than sixteen.</p>
<p class="InputCode">local r2: display %5.4f e(r2)</p>
<p>See <a href="https://ssc.wisc.edu/sscc/pubs/4-25.htm">Including Calculated Results In Stata Graphs</a> for an example that uses this tool.</p>
<h2></h2>
<h3><a id="IncrementingandDecrementingMacros" name="IncrementingandDecrementingMacros"></a>Incrementing and Decrementing Macros</h3>
<p>Macros frequently need to be increased by one and less frequently decreased by one. You can do so with the <span class="InputCode">++</span> and <span class="InputCode">--</span> operators. These go inside the macro quotes either before or after the macro name. If they are placed before,  the macro is incremented (or decremented) and then the result placed in the command. If they are placed after, the current value of the macro is placed in the command and then the macro is incremented (or decremented). Try the following:</p>
<p class="InputCode">local x 1<br/>
                  display `++x'<br/>
                  display `x--'<br/>
                display `x'</p>
<p>You can use the increment or decrement operators in a <span class="InputCode">local</span> command to change a macro without doing anything else, but be sure to put the operator before the macro's name. For example the following does <strong>not</strong> increase <span class="InputCode">x</span>:</p>
<p class="InputCode">                local x `x++'<br/>
</p>
<p> The macro processor replaces the macro <span class="InputCode">`x++'</span> with <span class="InputCode">1</span>. It then  increases <span class="InputCode">x</span> to <span class="InputCode">2</span>, but then when Stata proper executes the command it sees <span class="InputCode">local x 1</span> and sets <span class="InputCode">x</span> back to <span class="InputCode">1</span>. The following does increase <span class="InputCode">x</span>:</p>
<p class="InputCode">                  local x `++x'<br/>
</p>
<h2><a id="BranchingIf" name="BranchingIf"></a>Branching If</h2>
<p>You're familiar with  <em>if</em> conditions at the end of commands, meaning "only carry out this command for the observations where this condition is true." This is a subsetting <em>if</em>. When <em>if</em> starts a command, it is a branching <em>if</em> and  has a very different meaning: "don't execute the following command or commands at all unless this condition is true." The syntax is for a single command is:</p>
<p class="InputCode">if <span class="Parameter">condition</span> <span class="Parameter">command</span></p>
<p>For a block of commands, it's:</p>
<p class="InputCode">if <span class="Parameter">condition</span> {<br/>
<span class="indent3"><span class="Parameter">commands<br/></span></span>
}</p>
<p>An <span class="InputCode">if</span> block can be followed by an <span class="InputCode">else</span> block, meaning "commands to be executed if the condition is not true." The <span class="InputCode">else</span> can precede another <span class="InputCode">if</span>, allowing for <span class="InputCode">else if</span> chains of any length:</p>
<p class="InputCode">if <span class="Parameter">condition1</span> {<br/>
<span class="indent3"><span class="Parameter">commands to execute if condition1 is true</span></span><br/>
}<br/>
else if <span class="Parameter">condition2</span> {<br/>
<span class="indent3"><span class="Parameter">commands to execute if condition one is false and 
	condition2 is true</span></span><br/>
}<br/>
else {<br/>
<span class="indent3"><span class="Parameter">commands to execute if both condition1 and condition2 
	are false</span></span><br/>
}</p>
<p>Consider trying to demean a  list of variables, where the list is contained in a macro called <span class="InputCode">varlist</span> which was generated elsewhere and could contain string variables:</p>
<p class="InputCode">foreach var of  local varlist {<br/>
<span class="indent3">capture confirm numeric variable `var'</span><br/>
<span class="indent3">if _rc==0 {</span><br/>
<span class="indent3"><span class="indent3">sum `var', meanonly</span></span><br/>
<span class="indent3"><span class="indent3">replace `var'=`var'-r(mean)</span></span><br/>
<span class="indent3">} </span><br/>
<span class="indent3">else display as error "`var' is not a numeric variable and cannot be demeaned."</span><br/>}</p>
<p>The command <span class="InputCode">confirm numeric variable `var'</span> checks that <span class="InputCode">`var'</span> is a numeric variable, but when preceded by <span class="InputCode">capture</span> it does not crash the program if the variable is a string. Instead, <span class="InputCode">if _rc==0 {</span> checks whether the <span class="InputCode">confirm</span> command succeeded (implying <span class="InputCode">`var'</span> is in fact numeric). If it did, the program proceeds to demean <span class="InputCode">`var'</span>. If not, the program displays an error message (<span class="InputCode">as error</span> makes the message red) and then proceeds to the next variable.</p>
<p>The condition for a branching <em>if</em> is only evaluated once, so a branching <em>if</em> is a scalar context and the rule that only the first value of a variable will be used applies. In particular, a branching <em>if</em> cannot be used for subsetting. Imagine a data set made up of observations from multiple census years where the data from 1960 is coded in a different way and thus has to be handled differently. What you should <strong>not</strong> write is something like:</p>
<p class="InputCode">if year==1960 { //don't do this!<br/>
<span class="indent3"><span class="Parameter">code 
                for handling observations from 1960</span></span><br/>
                }<br/>
                else {<br/>
<span class="indent3"><span class="Parameter">code for handling observations from other year</span></span>s<br/>
                }</p>
<p>Since this is a scalar context, the condition <span class="InputCode">year==1960</span><span class="InputCode"></span> is only evaluated once, and the only value of <span class="InputCode">year</span> Stata will look at is that of the first observation. Thus if the first observation happens to be from 1960, the entire data set will be coded as if it came from 1960. If not, the entire data set will be coded as if it came from other years. This is not a job for branching <em>if</em>, it is a job for a standard subsetting <em>if</em> at the end of each command.</p>
<p>The above code might make sense if it were embedded in a loop that processed multiple data sets, where each data set came from a single year. Then <span class="InputCode">year</span> would be the same for all the observations in a given data set, and the first observation could stand in for all of them. But in that case we'd  suggest writing something like:</p>
<p class="InputCode">if year[1]==1960 { // if  year for the first observation is 1960  this is a 1960 data set</p>
<p>Conditions for branching <em>if</em> frequently involve macros. If the macros contain text rather than numbers,  the values on both sides of the equals sign need to be placed in quotes:</p>
<p class="InputCode">foreach school in West East Memorial {<br/>
<span class="indent3">if "`school'"=="West" {</span><br/>
<span class="indent6"><span class="Parameter">commands that should only be carried out for West High School</span></span><br/>
<span class="indent3">}</span><br/>
<span class="indent3"><span class="Parameter">commands that should be carried out for all schools</span></span><br/>
                  }
                </p>
<h2><a id="WhileLoops" name="WhileLoops"></a>While Loops</h2>
<p><span class="InputCode">foreach</span> and <span class="InputCode">forvalues</span> loops repeat a block of commands a set number of times, but <span class="InputCode">while</span> loops repeat them until a given condition is no longer true. For example:</p>
<p class="InputCode">local i 1<br/>
                while `i'&lt;=5 {<br/>
<span class="indent3">display `i++'</span><br/>
                }</p>
<p>is equivalent to:</p>
<p class="InputCode"> forval i=1/5 {<br/>
<span class="indent3">display `i'</span><br/>
                }</p>
<p>Note that <span class="InputCode">i</span> is increased by 1 each time through the <span class="InputCode">while</span> loop--if you left out that step the loop would never end.</p>
<p>The following code is a more typical use of while:</p>
<p class="InputCode">local xnew 1<br/>
                  local xold 0<br/>
                  local iteration 1<br/>
                  while abs(`xnew'-`xold')&gt;.001 &amp; `iteration'&lt;100 {<br/>
<span class="indent3">local xold `xnew'</span><br/>
<span class="indent3">local xnew=`xold'-(3-`xold'^3)/(-3*`xold'^2)</span><br/>
<span class="indent3">display "Iteration: `iteration++', x: `xnew'"</span><br/>
}</p>
<p>The above uses the Newton-Raphson method to solve the equation 3-x^3=0. The algorithm proceeds until the result from the current iteration differs from that of the last iteration by less than .001, or  it completes 100 iterations. The second condition acts as a failsafe in case the algorithm does not converge. Note that the initial value of <span class="InputCode">xold</span> is not used, but if it were the same as the initial value of <span class="InputCode">xnew</span> then the <span class="InputCode">while</span> condition would be false immediately and the loop would never be executed.</p>
<h2><a id="Programs" name="Programs"></a>Programs</h2>
<p>A Stata program is a block of code which can be executed at any time by invoking the program's name. They are useful when you need to perform a task repeatedly, but not all at once. To begin defining a program, type:</p>
<p class="InputCode">program define <span class="Parameter">name</span></p>
<p>where <span class="Parameter">name</span> is replaced by the name of the program to be defined. Subsequent commands are considered part of the program, until you type</p>
<p class="InputCode">end</p>
<p>Thus a basic "Hello World" program is:</p>
<p class="InputCode">program define hello<br/>
<span class="indent3">display "Hello World"</span><br/>
                end</p>
<p>To run this program, type <span class="InputCode">hello</span>.</p>
<p>A program cannot be modified after it is defined; to change it you must first drop the existing version with <span class="InputCode">program drop</span> and then define it again. Since a do file run in an interactive session can't be  sure what's been  defined previously, it's best to <span class="InputCode">capture program drop</span> a program before you define it:</p>
<p class="InputCode">capture program drop hello<br/>
                program define hello<br/>
<span class="indent3">display "Hello World Again"</span><br/>
                  end</p>
<h3>Arguments</h3>
<p>Programs can be controlled by passing in <em>arguments</em>. An argument can be anything you can put in a macro: numbers, text, names of variables, etc. You pass arguments into a program by typing them after it's program name. Thus:</p>
<p class="InputCode">hello Russell Dimond</p>
<p>runs the <span class="InputCode">hello</span> program with two arguments: <span class="InputCode">Russell</span> and <span class="InputCode">Dimond</span>. But arguments only matter if the program does something with them--the current version of <span class="InputCode">hello</span>  will completely ignore them.</p>
<p>Programs that use arguments  should first use the <span class="InputCode">args</span> command to assign them to local macros. The command:</p>
<p class="InputCode">args fname lname</p>
<p>puts the first argument the program received in the macro <span class="InputCode">fname</span> and the second in the macro <span class="InputCode">lname</span>. You can then use those macros in subsequent commands:</p>
<p class="InputCode">capture program drop hello<br/>
program define hello<br/>
<span class="indent3">args fname lname</span><br/>
<span class="indent3">display "Hello `fname' `lname'</span>"<br/>
end
                </p>
<p>If you then type:</p>
<p class="InputCode">hello Russell Dimond</p>
<p>the output will be:</p>
<p class="InputCode">Hello Russell Dimond</p>
<p>Of course if you type:</p>
<p class="InputCode">hello Dimond Russell</p>
<p>the output will be:</p>
<p class="InputCode">Hello Dimond Russell</p>
<p>It's up to you to make sure the arguments you pass in match what the program is expecting.</p>
<p>The macro <span class="InputCode">0</span> is always defined, and contains a list of all the arguments that were passed into the program. This is useful for handling lists of unknown length. For example, you could take the code you wrote earlier for demeaning lists of variables and turn it into a program:</p>
<p class="InputCode">program define demean<br/>
<span class="indent3">foreach var of  local 0 {</span><br/><span class="indent3">
<span class="indent3">capture confirm numeric variable `var'</span></span><br/><span class="indent3">
<span class="indent3">if _rc==0 {</span></span><br/>
<span class="indent3">
<span class="indent3"><span class="indent3">sum `var', meanonly</span></span></span><br/><span class="indent3">
<span class="indent3"><span class="indent3">replace `var'=`var'-r(mean)</span></span></span><br/><span class="indent3">
<span class="indent3">} </span></span><br/><span class="indent3">
<span class="indent3">else display as error "`var' is not a numeric variable and cannot be demeaned."</span></span><br/><span class="indent3">
                }<br/>
                end</span></p>
<p>To run this program, you'd type <span class="InputCode">demean</span> and then a list of variables to be demeaned:</p>
<p class="InputCode">demean x y z</p>
<p>You might also want to look at the <span class="InputCode">syntax</span> command, which makes it relatively easy to write a program that understands standard Stata syntax, but <span class="InputCode">syntax</span> is beyond the scope of this article.</p>
<h3>Returning Values</h3>
<p>Your program can  return values in the <span class="InputCode">r()</span> or <span class="InputCode">e()</span> vectors, just like official Stata commands. This is critical if your program is intended for use with <span class="InputCode">bootstrap</span> or <span class="InputCode">simulate</span>. To do so, first declare in your <span class="InputCode">program define</span> command that the program is either <span class="InputCode">rclass</span> (puts results in the <span class="InputCode">r()</span> vector) or <span class="InputCode">eclass</span> (puts results in the <span class="InputCode">e()</span> vector):</p>
<p class="InputCode">program define myprogram, rclass</p>
<p>When you have a result to return, use the <span class="InputCode">return</span> command. The general syntax is:</p>
<p class="InputCode">return <span class="Parameter">type</span> <span class="Parameter">name</span>=<span class="Parameter">value</span></p>
<p>where <span class="Parameter">type</span> can be <span class="InputCode">scalar</span>, <span class="InputCode">local</span> or <span class="InputCode">matrix</span>, <span class="Parameter">value</span> is what you want to return, and <span class="Parameter">name</span> is what you want it to be called. As a trivial example:</p>
<p class="InputCode">return scalar x=3</p>
<p>When the program is complete, you can refer to the result as <span class="InputCode">r(</span><span class="Parameter">name</span><span class="InputCode">)</span> or <span class="InputCode">e(</span><span class="Parameter">name</span><span class="InputCode">)</span>. Thus if you've just run  a program containing the above <span class="InputCode">return</span> command, typing:</p>
<p class="InputCode">gen var=r(x)</p>
<p>creates a variable <span class="InputCode">var</span> with the value <span class="InputCode">3</span>.</p>
<p>For a more realistic example, see the last section of <a href="https://ssc.wisc.edu/sscc/pubs/4-27.htm#BootstrappingResultsYouveCalculated">Bootstrapping in Stata</a>.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Propensity Score Matching in Stata using teffects</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>For many years, the standard tool for propensity score matching in Stata has been the <span class="InputCode">psmatch2</span> command, written by Edwin Leuven and Barbara Sianesi. However, Stata 13 introduced a new <span class="InputCode">teffects</span> command for estimating treatments effects in a variety of ways, including propensity score matching. The <span class="InputCode">teffects psmatch</span> command has one very important advantage over <span class="InputCode">psmatch2</span>: it takes into account the fact that propensity scores are estimated rather than known when calculating standard errors. This often turns out to make a significant difference, and sometimes in surprising ways. We thus strongly recommend switching from <span class="InputCode">psmatch2</span> to <span class="InputCode">teffects psmatch</span>, and this article will help you make the transition.</p>
<h2><a id="AnExampleofPropensityScoreMatching" name="AnExampleofPropensityScoreMatching"></a>An Example of Propensity Score Matching</h2>
<p>Run the following command in Stata to load an example data set:                </p>
<p class="InputCode">use http://ssc.wisc.edu/sscc/pubs/files/psm</p>
<p>It consists of four variables: a treatment indicator <span class="InputCode">t</span>, covariates <span class="InputCode">x1</span> and <span class="InputCode">x2</span>, and an outcome <span class="InputCode">y</span>. This is constructed data, and the effect of the treatment is in fact a one unit increase in <span class="InputCode">y</span>. However, the probability of treatment is positively correlated with <span class="InputCode">x1</span> and <span class="InputCode">x2</span>, and both <span class="InputCode">x1</span> and <span class="InputCode">x2</span> are positively correlated with <span class="InputCode">y</span>. Thus simply comparing the mean value of <span class="InputCode">y</span> for the treated and untreated groups badly overestimates the effect of treatment:</p>
<p class="InputCode">ttest y, by(t)</p>
<p>(Regressing <span class="InputCode">y</span> on <span class="InputCode">t</span>, <span class="InputCode">x1</span>, and <span class="InputCode">x2</span> will give you a pretty good picture of the situation.)</p>
<p>The <span class="InputCode">psmatch2</span> command will give you a  much better estimate of the treatment effect:</p>
<p class="InputCode">psmatch2 t x1 x2, out(y)</p>
<pre class="InputCode">----------------------------------------------------------------------------------------
        Variable     Sample |    Treated     Controls   Difference         S.E.   T-stat
----------------------------+-----------------------------------------------------------
               y  Unmatched |  1.8910736  -.423243358   2.31431696   .109094342    21.21
                        ATT |  1.8910736   .871388246   <span class="Blue"><span class="InputCode">1.01968536</span></span>   <span class="Red"><span class="InputCode">.173034999</span></span>     5.89
----------------------------+-----------------------------------------------------------
Note: S.E. does not take into account that the propensity score is estimated.</pre>
<h2><a id="TheteffectsCommand" name="TheteffectsCommand"></a>The teffects Command</h2>
<p>You can carry out the same estimation with <span class="InputCode">teffects</span>. The basic syntax of the <span class="InputCode">teffects</span> command when used for propensity score matching is:</p>
<p class="InputCode">teffects psmatch (<span class="Parameter">outcome</span>) (<span class="Parameter">treatment</span> <span class="Parameter">covariates</span>)</p>
<p>In this case the basic command would be:</p>
<p class="InputCode">teffects psmatch (y) (t x1 x2)</p>
<p>However, the default behavior of <span class="InputCode">teffects</span> is not the same as <span class="InputCode">psmatch2</span> so we'll need to use some options to get the same results. First, <span class="InputCode">psmatch2</span> by default reports the average treatment effect on the treated (which it refers to as ATT). The <span class="InputCode">teffects</span> command by default reports the average treatment effect (ATE) but will calculate the average treatment effect on the treated (which it refers to as ATET) if  given the <span class="InputCode">atet</span> option. Second, <span class="InputCode">psmatch2</span> by default uses a probit model for the probability of treatment. The <span class="InputCode">teffects</span> command uses a logit model by default, but will use probit if the <span class="InputCode">probit</span> option is applied to the treatment equation. So to run the same model using <span class="InputCode">teffects</span> type:</p>
<p class="InputCode">teffects psmatch (y) (t x1 x2, probit), atet </p>
<pre class="InputCode">Treatment-effects estimation                    Number of obs      =      1000
Estimator      : propensity-score matching      Matches: requested =         1
Outcome model  : matching                                      min =         1
Treatment model: probit                                        max =         1
------------------------------------------------------------------------------
             |              AI Robust
           y |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
ATET         |
           t |
   (1 vs 0)  |   <span class="Blue"><span class="InputCode">1.019685</span></span>   <span class="Red"><span class="InputCode">.1227801</span></span>     8.30   0.000     .7790407     1.26033
------------------------------------------------------------------------------</pre>
<p>The average treatment effect on the treated is identical, other than being rounded at a different place. But note that <span class="InputCode">teffects</span> reports a very different standard error (we'll discuss why that is <a href="#StandardErrors">shortly</a>), plus a Z-statistic,  p-value, and  95% confidence interval rather than just a T-statistic.</p>
<p>Running <span class="InputCode">teffects</span> with the default options gives the following:</p>
<p class="InputCode">teffects psmatch (y) (t x1 x2)</p>
<pre class="InputCode">Treatment-effects estimation                    Number of obs      =      1000
Estimator      : propensity-score matching      Matches: requested =         1
Outcome model  : matching                                      min =         1
Treatment model: logit                                         max =         1
------------------------------------------------------------------------------
             |              AI Robust
           y |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
ATE          |
           t |
   (1 vs 0)  |   <span class="Blue"><span class="InputCode">1.019367</span></span>   .1164694     8.75   0.000     .7910912    1.247643
------------------------------------------------------------------------------</pre>
<p>This is equivalent to:</p>
<p class="InputCode">psmatch2 t x1 x2, out(y) logit ate</p>
<pre class="InputCode">----------------------------------------------------------------------------------------
        Variable     Sample |    Treated     Controls   Difference         S.E.   T-stat
----------------------------+-----------------------------------------------------------
               y  Unmatched |  1.8910736  -.423243358   2.31431696   .109094342    21.21
                        ATT |  1.8910736   .930722886   <span class="Red"><span class="InputCode">.960350715</span></span>   .168252917     5.71
                        ATU |-.423243358   .625587554   1.04883091            .        .
                        ATE |                           <span class="Blue"><span class="InputCode">1.01936701</span></span>            .        .
----------------------------+-----------------------------------------------------------
Note: S.E. does not take into account that the propensity score is estimated.</pre>
<p>The ATE from this model is very similar to the ATT/ATET from the previous model. But note that <span class="InputCode">psmatch2</span> is reporting a somewhat different ATT in this model. The <span class="InputCode">teffects</span> command reports the same ATET if asked:</p>
<p class="InputCode">teffects psmatch (y) (t x1 x2), atet</p>
<p></p>
<pre class="InputCode">Treatment-effects estimation                    Number of obs      =      1000
Estimator      : propensity-score matching      Matches: requested =         1
Outcome model  : matching                                      min =         1
Treatment model: logit                                         max =         1
------------------------------------------------------------------------------
             |              AI Robust
           y |      Coef.   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
ATET         |
           t |
   (1 vs 0)  |   <span class="Red"><span class="InputCode">.9603507</span></span>   .1204748     7.97   0.000     .7242245    1.196477
------------------------------------------------------------------------------</pre>
<h2><a id="StandardErrors" name="StandardErrors"></a>Standard Errors</h2>
<p>The output of <span class="InputCode">psmatch2</span> includes the following caveat:</p>
<p><span class="InputCode">Note: S.E. does not take into account that the propensity score is estimated.</span></p>
<p>A recent paper by Abadie and Imbens (2012. <a href="http://www.hks.harvard.edu/fs/aabadie/pscore.pdf">Matching on the estimated propensity score</a>. Harvard University and National Bureau of Economic Research) established how to take into account that propensity scores are estimated, and <span class="InputCode">teffects psmatch</span> relies on their work. Interestingly, the adjustment for ATE is always negative, leading to smaller standard errors: matching based on estimated propensity scores turns out to be more efficient than matching based on true propensity scores. However, for ATET the adjustment can be positive or negative, so the standard errors reported by <span class="InputCode">psmatch2</span> may be too large or to small.</p>
<h2> <a id="HandlingTies" name="HandlingTies"></a>Handling Ties</h2>
<p>Thus far we've used <span class="InputCode">psmatch2</span> and <span class="InputCode">teffects psmatch</span> to do simple nearest-neighbor matching with one neighbor (and no caliper). However, this raises the question of what to do when two observations have the same propensity score and are thus tied for "nearest neighbor." Ties are common if the covariates in the treatment model are categorical or even integers.</p>
<p>The <span class="InputCode">psmatch2</span> command by default matches with one of the tied observations, but with the <span class="InputCode">ties</span> option it matches with all tied observations. The <span class="InputCode">teffects psmatch</span> command always matches with all ties. If your data set has multiple observations with the same propensity score, you won't get exactly the same results from <span class="InputCode">teffects psmatch</span> as you were getting from <span class="InputCode">psmatch2</span> unless you go back and add the <span class="InputCode">ties</span> option to your <span class="InputCode">psmatch2</span> commands. (At this time we are not aware of any clear guidance as to whether it is better to match with ties or not.)</p>
<h2><a id="MatchingWithMultipleNeighbors" name="MatchingWithMultipleNeighbors"></a>Matching With Multiple Neighbors</h2>
<p>By default <span class="InputCode">teffects psmatch</span> matches each observation with one other observation. You can change this with the <span class="InputCode">nneighbor()</span> (or just <span class="InputCode">nn()</span>) option. For example, you could match each observation with its three nearest neighbors with:</p>
<p class="InputCode">teffects psmatch (y) (t x1 x2), nn(3)</p>
<h2><a id="Postestimation" name="Postestimation"></a>Postestimation</h2>
<p>By default <span class="InputCode">teffects psmatch</span> does not add any new variables to the data set. However, there are a variety of useful variables that can be created with options and post-estimation <span class="InputCode">predict</span> commands.  The following table lists the 1st and 467th observations of the example data set after some of these variables have been created. We'll refer to it as we explain the commands that created the new variables. Reviewing these variables is also a good way to make sure you understand exactly how propensity score matching works.</p>
<pre class="InputCode" style="font-size: 80%">      
      +-------------------------------------------------------------------------------------------------------+
      |        x1          x2   t          y   match1        ps0        ps1          y0         y1         te |
      |-------------------------------------------------------------------------------------------------------|
   1. |  .0152526   -1.793022   0   -1.79457      467   .9081651   .0918349    -1.79457   2.231719   4.026289 |
 467. | -2.057838    .5360286   1   2.231719      781    .907606    .092394   -.6012772   2.231719   2.832996 |
      +-------------------------------------------------------------------------------------------------------+
</pre>
<p>Start with a clean slate by typing:</p>
<p class="InputCode">                use http://ssc.wisc.edu/sscc/pubs/files/psm, replace<br/>
</p>
<p>The <span class="InputCode">gen()</span> option tells <span class="InputCode">teffects psmatch</span> to create a new variable (or variables). For each observation, this new variable will contain the number of the observation that observation was matched with. If there are ties or you told <span class="InputCode">teffects psmatch</span> to use multiple neighbors, then <span class="InputCode">gen()</span> will need to create multiple variables. Thus you supply the stem of the variable name, and <span class="InputCode">teffects psmatch</span> will add suffixes as needed.</p>
<p class="InputCode">teffects psmatch (y) (t x1 x2), gen(match)</p>
<p>In this case each observation is only matched with one other, so <span class="InputCode">gen(match</span>) only creates <span class="InputCode">match1</span>. Referring to the example output, the match of observation 1 is observation 467 (which is why those two are listed).</p>
<p>Note that these observation numbers are only valid in the current sort order, so make sure you can recreate that order if needed. If necessary, run:</p>
<p class="InputCode">gen ob=_n</p>
<p>and then:</p>
<p class="InputCode">sort ob</p>
<p>to restore the current sort order.</p>
<p>The <span class="InputCode">predict</span> command with the <span class="InputCode">ps</span> option creates two variables containing the propensity scores, or that observation's predicted probability of being in either the control group or the treated group:</p>
<p class="InputCode">predict ps0 ps1, ps</p>
<p>Here <span class="InputCode">ps0</span> is the predicted probability of being in the control group (<span class="InputCode">t=0</span>) and <span class="InputCode">ps1</span> is the predicted probability of being in the treated group (<span class="InputCode">t=1</span>). Observations 1 and 467 were matched because their propensity scores are very similar.</p>
<p>The <span class="InputCode">po</span> option creates variables containing the potential outcomes for each observation:</p>
<p class="InputCode">predict y0 y1, po</p>
<p>Because observation 1 is in the control group, <span class="InputCode">y0</span> contains its observed value of <span class="InputCode">y</span>. <span class="InputCode">y1</span> is the observed value of <span class="InputCode">y</span> for observation 1's match, observation 467. The propensity score matching estimator assumes that if observation 1 had been in the treated group its value of y would have been that of the observation in the treated group most similar to it (where "similarity" is measured by the difference in their propensity scores).</p>
<p>Observation 467 is in the treated group, so its value for <span class="InputCode">y1</span> is its observed value of <span class="InputCode">y</span> while its value for <span class="InputCode">y0</span> is the observed value of <span class="InputCode">y</span> for its match, observation 781.</p>
<p>Running the predict command with no options gives the treatment effect itself:</p>
<p class="InputCode">predict te</p>
<p>The treatment effect is simply the difference between <span class="InputCode">y1</span> and <span class="InputCode">y0</span>. You could calculate the ATE yourself (but emphatically not its standard error) with:</p>
<p class="InputCode">sum te</p>
<p>and the ATET with:</p>
<p class="InputCode">sum te if t</p>
<h2>Regression on the "Matched Sample"</h2>
<p>Another way to conceptualize propensity score matching is to think of it as choosing a sample from the control group that "matches" the treatment group. Any differences between the treatment and matched control groups are then assumed to be a result of the treatment. Note that this gives the average treatment effect on the treated—to calculate the ATE you'd  create a sample of the treated group that matches the controls. Mathematically this is all equivalent to using matching to estimate what an observation's outcome would have been if it had been in the other group, as described above.</p>
<p>Sometimes researchers then want to run regressions on the "matched sample," defined as the observations in the treated group plus the observations in the control group which were matched to them. The problem with this approach is that the matched sample is based on propensity scores which are estimated, not known. Thus the matching scheme is an estimate as well. Running regressions after matching is essentially a two stage regression model, and the standard errors from the second stage must take the first stage into account, something standard regression commands do not do. This is an area of ongoing research.</p>
<p>We will discuss how to run regressions on a matched sample because it remains a popular technique, but we cannot recommend it.</p>
<p><span class="InputCode">psmatch2</span> makes it easy by creating a <span class="InputCode">_weight</span> variable automatically. For observations in the treated group, <span class="InputCode">_weight</span> is 1. For observations in the control group it is the number of observations from the treated group for which the observation is a match. If the observation is not a match, <span class="InputCode">_weight</span> is missing. <span class="InputCode">_weight</span> thus acts as a frequency weight (<span class="InputCode">fweight</span>) and can be used with Stata's standard weighting syntax. For example (starting with a clean slate again):</p>
<p class="InputCode">use http://ssc.wisc.edu/sscc/pubs/files/psm, replace<br/>
				psmatch2 t x1 x2, out(y) logit<br>
                  reg y x1 x2 t [fweight=_weight]                  <br/>
</br></p>
<p>Observations with a missing value for <span class="InputCode">_weight</span> are omitted from the regression, so it is automatically limited to the matched sample. Again, keep in mind that the standard errors given by the <span class="InputCode">reg</span> command are incorrect because they do not take into account the matching stage.</p>
<p><span class="InputCode">teffects psmatch</span> does not create a <span class="InputCode">_weight</span> variable, but it is possible to create one based on the <span class="InputCode">match1</span> variable. Here is example code, with comments:</p>
<p class="InputCode">gen ob=_n //store the observation numbers for future use<br/>
                save fulldata,replace // save the complete data set<br/>
<br/>
                keep if t // keep just the treated group<br/>
                keep match1 // keep just the match1 variable (the observation numbers of their matches)<br/>
                bysort match1: gen weight=_N // count how many times each control observation is a match<br/>
                by match1: keep if _n==1 // keep just one row per control observation<br/>
                ren match1 ob //rename for merging purposes<br/>
<br/>
                merge 1:m ob using fulldata // merge back into the full data<br/>
                replace weight=1 if t // set weight to 1 for treated observations</p>
<p>The resulting <span class="InputCode">weight</span> variable will be identical to the <span class="InputCode">_weight</span> variable created by <span class="InputCode">psmatch2</span>, as can be verified with:</p>
<p class="InputCode">assert weight==_weight</p>
<p>It is used in the same way and will give exactly the same results:</p>
<p class="InputCode">reg y x1 x2 t [fweight=weight]</p>
<p>Obviously this is a good bit more work than using <span class="InputCode">psmatch2</span>. If your propensity score matching model can be done using both <span class="InputCode">teffects psmatch</span> and <span class="InputCode">psmatch2</span>, you may want to run <span class="InputCode">teffects psmatch</span> to get the correct standard error and then <span class="InputCode">psmatch2</span> if you need a <span class="InputCode">_weight</span> variable.</p>
<p>This regression has an N of 666, 333 from the treated group and 333 from the control group. However, it only uses 189 different observations from the control group. About 1/3 of them are the matches for more than one observation from the treated group and are thus duplicated in the regression (run <span class="InputCode">tab weight if !t</span> for details). Researchers sometimes use the <span class="InputCode">norepl</span> (no replacement) option in <span class="InputCode">psmatch2</span> to ensure each observation is  used just once, even though this generally makes the matching worse. To the best of our knowledge there is no equivalent with <span class="InputCode">teffects psmatch</span>.</p>
<p>The results of this regression leave somewhat to be desired:</p>
<pre class="InputCode">------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
          x1 |    1.11891   .0440323    25.41   0.000      1.03245    1.205369
          x2 |    1.05594   .0417253    25.31   0.000       .97401     1.13787
           t |   .9563751   .0802273    11.92   0.000     .7988445    1.113906
       _cons |   .0180986   .0632538     0.29   0.775    -.1061036    .1423008
------------------------------------------------------------------------------</pre>
<p>By construction all the coefficients should be 1. Regression using all the observations (<span class="InputCode">reg y x1 x2 t</span> rather than <span class="InputCode">reg y x1 x2 t [fweight=weight]</span>) does better in this case:</p>
<pre class="InputCode">------------------------------------------------------------------------------
           y |      Coef.   Std. Err.      t    P&gt;|t|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
          x1 |   1.031167   .0346941    29.72   0.000     .9630853    1.099249
          x2 |   .9927759   .0333297    29.79   0.000     .9273715     1.05818
           t |   .9791484   .0769067    12.73   0.000     .8282306    1.130066
       _cons |   .0591595   .0416008     1.42   0.155    -.0224758    .1407948
------------------------------------------------------------------------------</pre>
<h2>Other Methods of Estimating Treatment Effects</h2>
<p>While propensity score matching is the most common method of estimating treatment effects at the SSCC, <span class="InputCode">teffects</span> also implements Regression Adjustment (<span class="InputCode">teffects ra</span>), Inverse Probability Weighting (<span class="InputCode">teffects ipw</span>), Augmented Inverse Probability Weighting (<span class="InputCode">teffects aipw</span>), Inverse Probability Weighted Regression Adjustment <span class="InputCode">(teffects ipwra</span>), and Nearest Neighbor Matching (<span class="InputCode">teffects nnmatch</span>). The syntax is similar, though it varies whether you need to specify variables for the outcome model, the treatment model, or both:</p>
<p class="InputCode">teffects ra (y x1 x2) (t)<br/>
teffects ipw (y) (t x1 x2)<br/>
teffects aipw (y x1 x2) (t x1 x2)<br/>
teffects ipwra (y x1 x2) (t x1 x2)<br/>
teffects nnmatch (y x1 x2) (t)</p>
<h2><a id="CompleteExampleCode" name="CompleteExampleCode"></a>Complete Example Code</h2>
<p>The following is the complete code for the examples in this article.</p>
<p class="InputCode">clear all<br/>
use http://www.ssc.wisc.edu/sscc/pubs/files/psm<br/>
<br/>


ttest y, by(t)<br/>

reg y x1 x2 t<br/>
<br/>


psmatch2 t x1 x2, out(y)<br/>

teffects psmatch (y) (t x1 x2, probit), atet <br/>
<br/>


teffects psmatch (y) (t x1 x2)<br/>

psmatch2 t x1 x2, out(y) logit ate<br/>

teffects psmatch (y) (t x1 x2), atet<br/>
<br/>


use http://www.ssc.wisc.edu/sscc/pubs/files/psm, replace<br/>
<br/>


teffects psmatch (y) (t x1 x2), gen(match)<br/>
<br/>


predict ps0 ps1, ps<br/>

predict y0 y1, po<br/>

predict te<br/>

l if _n==1 | _n==467<br/>
<br/>


use http://www.ssc.wisc.edu/sscc/pubs/files/psm, replace<br/>
<br/>


psmatch2 t x1 x2, out(y) logit<br/>

reg y x1 x2 t [fweight=_weight]<br/>
<br/>


gen ob=_n<br/>

save fulldata,replace<br/>
<br/>


teffects psmatch (y) (t x1 x2), gen(match)<br/>

keep if t<br/>

keep match1<br/>

bysort match1: gen weight=_N<br/>

by match1: keep if _n==1<br/>

ren match1 ob<br/>
<br/>


merge 1:m ob using fulldata<br/>

replace weight=1 if t<br/>
<br/>


assert weight==_weight<br/>
<br/>


reg y x1 x2 t [fweight=weight]<br/>

reg y x1 x2 t<br/>
<br/>


teffects ra (y x1 x2) (t)<br/>

teffects ipw (y) (t x1 x2)<br/>

teffects aipw (y x1 x2) (t x1 x2)<br/>

teffects ipwra (y x1 x2) (t x1 x2)<br/>

teffects nnmatch (y x1 x2) (t) <br/>
</p>
<p></p>
<p></p>
<p></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Creating Publication-Quality Tables in Stata</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Stata's tables are, in general, clear and informative. However, they are not in the format or of the aesthetic quality normally used in publications. Several Stata users have written programs that create publication-quality tables. This article will discuss <span class="InputCode">esttab</span> (think "estimates table") by Ben Jann. The <span class="InputCode">esttab</span> command  takes the results of previous estimation or other commands, puts them in a publication-quality table, and then saves that table in a format you cause use directly in your paper such as RTF or LaTeX. Major topics for this article include creating <a href="#basics">tables of regression results</a>, <a href="#summary">tables of summary statistics</a>, and <a href="#freqs">frequency tables</a>.
                </p>
<h2 id="estout_package">The estout Package</h2>
<p>The <span class="InputCode">esttab</span> command is just one member of a family of commands, or package, called <span class="InputCode">estout</span>. In fact, <span class="InputCode">esttab</span> is just a "wrapper" for a command called <span class="InputCode">estout</span>. The <span class="InputCode">estout</span> command gives you full control over the table to be created, but flexibility requires complexity and <span class="InputCode">estout</span> is fairly difficult to use. The <span class="InputCode">esttab</span> command runs <span class="InputCode">estout</span> for you and handles many of the details <span class="InputCode">estout</span> requires, allowing you to create the most common tables relatively easily. We will also discuss <span class="InputCode">estpost</span>, which puts results like summary statistics in a form <span class="InputCode">esttab</span> can work with. The ability to handle summary statistics and frequencies in addition to regression results is one of the reasons we elected to focus this article on <span class="InputCode">esttab</span>.</p>
<h2 id="workflow">On the Workflow of Creating Tables</h2>
<p>Keep in mind that you always have an alternative to using <span class="InputCode">esttab</span>: simply create the tables you want in Word or your favorite word processing program, copying and pasting the needed numbers from your Stata output. This is time-consuming and tedious. On the other hand, trying to figure out how to get <span class="InputCode">esttab</span> to give you the table you want can be time-consuming as well, and there's no guarantee it can make exactly the table you want. Be sure to consider the possibility that creating a particular table by hand may be quicker than using <span class="InputCode">esttab</span>. Much depends on how many tables you need to create, and how many numbers they contain. If you can get <span class="InputCode">esttab</span> to give you something close to what you want but are spending a lot of time trying to figure out how to get <em>exactly</em> what you want, consider just editing what you have.</p>
<p>Most people will find it's easier to first obtain a set of (hopefully) final results and then work on how to present them. We would not recommend running <span class="InputCode">esttab</span> until you are reasonably confident you've arrived at the results you want to publish.</p>
<h2 id="installing">Installing esttab</h2>
<p>Since the <span class="InputCode">estout</span> package is not part of official Stata, you must install it before using it. It is available from the Statistical Software Components (SSC) archive and can be installed using the <span class="InputCode">ssc install</span> command in Stata:</p>
<p class="InputCode">ssc install estout</p>
<p>You only need to do this once—do not put this command in your research do files.</p>
<p>Check for updates periodically using <span class="InputCode">adoupdate</span>.</p>
<h2 id="basics">Basics</h2>
<p>The <span class="InputCode">esttab</span> command needs some results to act on, so load the auto data set that comes with Stata and run a basic regression:</p>
<p class="InputCode">sysuse auto<br/>
                reg mpg weight foreign</p>
<p>You can see the basic function of esttab simply by running it without any options at all:</p>
<p class="InputCode">esttab</p>
<pre class="InputCode">----------------------------
                      (1)   
                      mpg   
----------------------------
weight           -0.00659***
                 (-10.34)   

foreign            -1.650   
                  (-1.53)   

_cons               41.68***
                  (19.25)   
----------------------------
N                      74   
----------------------------
t statistics in parentheses
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001</pre>
<p>This puts the model results in a table within Stata's Results window. Viewing it in the Results window is useful for testing a table specification, but when you've got what you want you'll have <span class="InputCode">esttab</span> save it in the file format you're using for your paper. The default table contains many of the features you expect from a table of regression results in a journal article, including rounded coefficients and stars for significance. Note, however, that the numbers in parentheses are the t-statistics. Use the <span class="InputCode">se</span> option if you want to replace them with standard errors:</p>
<p class="InputCode">esttab, se</p>
<pre class="InputCode">----------------------------
                      (1)   
                      mpg   
----------------------------
weight           -0.00659***
               (0.000637)   

foreign            -1.650   
                  (1.076)   

_cons               41.68***
                  (2.166)   
----------------------------
N                      74   
----------------------------
Standard errors in parentheses
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001</pre>
<p>The  <span class="InputCode">esttab</span> command uses the current contents of the e() vector (information about the last estimation command), not the results the last regression displayed. If you run a <span class="InputCode">logit</span> command with the <span class="InputCode">or</span> option Stata will display odds ratios:</p>
<p class="InputCode">logit foreign mpg, or</p>
<pre class="InputCode">Logistic regression                               Number of obs   =         74
                                                  LR chi2(1)      =      11.49
                                                  Prob &gt; chi2     =     0.0007
Log likelihood =  -39.28864                       Pseudo R2       =     0.1276

------------------------------------------------------------------------------
     foreign | Odds Ratio   Std. Err.      z    P&gt;|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
         mpg |   1.173232   .0616975     3.04   0.002      1.05833    1.300608
       _cons |   .0125396   .0151891    -3.62   0.000     .0011674    .1346911
------------------------------------------------------------------------------
</pre>
<p>However, <span class="InputCode">e(b)</span> still contains the coefficients, and by default that is what <span class="InputCode">esttab</span> will display. It also labels  the test statistics as  t statistics rather than  z statistics like the <span class="InputCode">logit</span> output does:</p>
<p class="InputCode">esttab</p>
<pre class="InputCode">----------------------------
                      (1)   
                  foreign   
----------------------------
foreign                     
mpg                 0.160** 
                   (3.04)   

_cons              -4.379***
                  (-3.62)   
----------------------------
N                      74   
----------------------------
t statistics in parentheses
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001</pre>
<p>If you want odds ratios in your table, give <span class="InputCode">esttab</span> the <span class="InputCode">eform</span> (exponentiated form) option. If you want the table to say "z statistics in parentheses" rather than t use the <span class="InputCode">z</span> option (note that the <span class="InputCode">z</span> option does not change the numbers in any way):</p>
<p class="InputCode">esttab, eform z</p>
<pre class="InputCode">----------------------------
                      (1)   
                  foreign   
----------------------------
foreign                     
mpg                 1.173** 
                   (3.04)   
----------------------------
N                      74   
----------------------------
Exponentiated coefficients; z statistics in parentheses
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001</pre>
<p>Specifying the <span class="InputCode">eform</span> option prompts <span class="InputCode">esttab</span> to drop the constant term from the table, because it doesn't make much sense to talk about the odds ratio of the constant. However, you can override this behavior by specifying the <span class="InputCode">constant</span> option.</p>
<h2 id="rtf">Saving the Table in the Format of Your Paper</h2>
<p>To save a table as an RTF (Rich Text Format) file, add <span class="InputCode">using </span><span class="Parameter">filename</span><span class="InputCode">.rtf</span> to the command, right before the comma for options. Also add the <span class="InputCode">replace</span> option so it can overwrite previous versions of the file.</p>
<p class="InputCode">esttab using logit.rtf,  replace eform z</p>
<p>Rich Text Format
                includes formatting information as well as the text itself, and can be opened directly by Word and other word processors. <a href="https://ssc.wisc.edu/sscc/pubs/files/stata_output/logit.rtf">Click here to see what the RTF file  looks like.</a></p>
<p> The process of saving the table as a LaTeX file is identical: just replace <span class="InputCode">.rtf</span> with <span class="InputCode">.tex</span>. There are some special options that apply to LaTeX, such as <span class="InputCode">fragment</span> to create a table fragment that can be added to an existing table. HTML (<span class="InputCode">.html</span>) is another useful format option, and there are many others.</p>
<p>You can  save the table as a comma separated variables (CSV) file that can easily read into Excel by setting the<span class="InputCode"></span> file extension to <span class="InputCode">.csv</span>. However, consider carefully whether what you contemplate doing in Excel can't be done better (and especially more reproducibly) within Stata.</p>
<h2 id="multiple_models">Tables with Multiple Models</h2>
<p>To create a table containing the estimates from multiple models, the first step is to run each model and store their estimates for future use. You can store the estimates either with the official Stata command <span class="InputCode">estimates store</span>, usually abbreviated <span class="InputCode">est sto</span>, or with the variant <span class="InputCode">eststo</span> included in the <span class="InputCode">estout</span> package. The <span class="InputCode">eststo</span> variant adds a few features, but we won't use any of them in this article so it doesn't matter which command you use. The basic syntax is identical: the command, then the name you want to assign to that set of estimates. Use this to build a set of nested models:</p>
<p class="InputCode">reg mpg foreign<br/>
est sto m1<br/>
reg mpg foreign weight<br/>
est sto m2<br/>
reg mpg foreign weight displacement gear_ratio<br/>
est sto m3</p>
<p>To have <span class="InputCode">esttab</span> create a table based on a single set of stored estimates, simply specify the name of the estimates you want it to use:</p>
<p class="InputCode">esttab m1</p>
<p>But you are not limited to one set:</p>
<p class="InputCode">esttab m1 m2 m3</p>
<pre class="InputCode">------------------------------------------------------------
                      (1)             (2)             (3)   
                      mpg             mpg             mpg   
------------------------------------------------------------
foreign             4.946***       -1.650          -2.246   
                   (3.63)         (-1.53)         (-1.81)   

weight                           -0.00659***     -0.00675***
                                 (-10.34)         (-5.80)   

displacement                                      0.00825   
                                                   (0.72)   

gear_ratio                                          2.058   
                                                   (1.17)   

_cons               19.83***        41.68***        34.52***
                  (26.70)         (19.25)          (5.17)   
------------------------------------------------------------
N                      74              74              74   
------------------------------------------------------------
t statistics in parentheses
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001
</pre>
<h2 id="model_stats">Summary (Model-Level) Statistics</h2>
<p>The N (number of observations) for each model is shown by default, but you can add other model-level statistics. Options include R-squared (<span class="InputCode">r2</span>), AIC (<span class="InputCode">aic</span>), and BIC (<span class="InputCode">bic</span>). Any other scalar in the e() vector can also be added using the <span class="InputCode">scalar()</span> option. For example, you could add the model's F statistic, stored as <span class="InputCode">e(F)</span>, with the option <span class="InputCode">scalar(F)</span>. You cannot control the order in which they are listed, but you can move N to the end with <span class="InputCode">obslast</span>. You can remove N entirely with <span class="InputCode">noobs</span>.</p>
<p class="InputCode">esttab m1 m2 m3, se aic obslast scalar(F) bic r2</p>
<pre class="InputCode">------------------------------------------------------------
                      (1)             (2)             (3)   
                      mpg             mpg             mpg   
------------------------------------------------------------
foreign             4.946***       -1.650          -2.246   
                  (1.362)         (1.076)         (1.240)   

weight                           -0.00659***     -0.00675***
                               (0.000637)       (0.00116)   

displacement                                      0.00825   
                                                 (0.0114)   

gear_ratio                                          2.058   
                                                  (1.755)   

_cons               19.83***        41.68***        34.52***
                  (0.743)         (2.166)         (6.675)   
------------------------------------------------------------
R-sq                0.155           0.663           0.669   
AIC                 460.3           394.4           396.9   
BIC                 465.0           401.3           408.4   
F                   13.18           69.75           34.94   
N                      74              74              74   
------------------------------------------------------------
Standard errors in parentheses
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001</pre>
<h2 id="cell_stats">Cell (Variable-Level) Statistics</h2>
<p>In addition to t statistics, z statistics, and standard errors, <span class="InputCode">esttab</span> can put p-values and confidence intervals in the parentheses with the <span class="InputCode">p</span> and <span class="InputCode">ci</span> options. You can have no secondary quantity in parentheses at all with the <span class="InputCode">not</span> (no t) option.</p>
<p>You can replace the main numbers as well. The <span class="InputCode">beta</span> option replaces them with standardized beta coefficients. The <span class="InputCode">main()</span> option lets you replace them with any other quantity from the <span class="InputCode">e()</span> vector.</p>
<p>If you prefer to have the statistic in parentheses on the same row as the coefficient, use the <span class="InputCode">wide</span> option.</p>
<p class="InputCode">esttab m1 m2 m3, wide ci noobs</p>
<pre class="InputCode">---------------------------------------------------------------------------------------------------------------------------------
                      (1)                                    (2)                                    (3)                          
                      mpg                                    mpg                                    mpg                          
---------------------------------------------------------------------------------------------------------------------------------
foreign             4.946***          [2.230,7.661]       -1.650            [-3.796,0.495]       -2.246            [-4.719,0.227]
weight                                                  -0.00659***    [-0.00786,-0.00532]     -0.00675***    [-0.00907,-0.00443]
displacement                                                                                    0.00825          [-0.0145,0.0310]
gear_ratio                                                                                        2.058            [-1.444,5.559]
_cons               19.83***          [18.35,21.31]        41.68***          [37.36,46.00]        34.52***          [21.21,47.84]
---------------------------------------------------------------------------------------------------------------------------------
95% confidence intervals in brackets
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001</pre>
<h2 id="titles">Titles, Notes, and Labels</h2>
<p>You can give the table an overall title with the <span class="InputCode">title()</span> option. Type the desired title in the parentheses.</p>
<p>If you want to remove the note at the bottom that explains the numbers in parentheses and the meaning of the stars, use the <span class="InputCode">nonotes</span> option. If you want to add notes, use the <span class="InputCode">addnotes()</span> option with the desired notes in the parentheses. If you want multiple lines of notes, put each line in quotes.</p>
<p>By default each model in a table is labeled with a number and a title. If you don't want the number to appear, use the <span class="InputCode">nonumber</span> option. The model title defaults to the the name of the model's dependent variable, but you can change model titles with  <span class="InputCode">mtitle()</span>. Each title goes in quotes inside the parentheses, and the order must match the order in which the stored estimates are listed in the main command.</p>
<p>The <span class="InputCode">label</span> option tells <span class="InputCode">esttab</span> to use the variable labels rather than the variable names. That means you can control exactly how a variable is listed by changing its label—just make sure the label provides an adequate description of the variable but is not too long. The labels below illustrate some of the potential problems.</p>
<p class="InputCode">esttab m1 m2 m3, label nonumber title("Models of MPG") mtitle("Model 1" "Model 2" "Model 3") 
                </p>
<pre class="InputCode">Models of MPG
--------------------------------------------------------------------
                          Model 1         Model 2         Model 3   
--------------------------------------------------------------------
Car type                    4.946***       -1.650          -2.246   
                          (1.362)         (1.076)         (1.240)   

Weight (lbs.)                            -0.00659***     -0.00675***
                                       (0.000637)       (0.00116)   

Displacement .. in.)                                      0.00825   
                                                         (0.0114)   

Gear Ratio                                                  2.058   
                                                          (1.755)   

Constant                    19.83***        41.68***        34.52***
                          (0.743)         (2.166)         (6.675)   
--------------------------------------------------------------------
Observations                   74              74              74   
--------------------------------------------------------------------
Standard errors in parentheses
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001</pre>
<p>If you 
                don't want to change the actual variable labels, you can override them with the <span class="InputCode">coeflabel()</span> option. Put the variable name/label pairs you want to use inside the parentheses. Any variable for which you do not specify a label will be listed with its actual name.</p>
<p class="InputCode">esttab m1 m2 m3, coeflabel(foreign "Foreign Car" displacement "Displacement" gear_ratio "Gear Ratio" _cons "Constant")<br/>
</p>
<pre class="InputCode">------------------------------------------------------------
                      (1)             (2)             (3)   
                      mpg             mpg             mpg   
------------------------------------------------------------
Foreign Car         4.946***       -1.650          -2.246   
                   (3.63)         (-1.53)         (-1.81)   

weight                           -0.00659***     -0.00675***
                                 (-10.34)         (-5.80)   

Displacement                                      0.00825   
                                                   (0.72)   

Gear Ratio                                          2.058   
                                                   (1.17)   

Constant            19.83***        41.68***        34.52***
                  (26.70)         (19.25)          (5.17)   
------------------------------------------------------------
N                      74              74              74   
------------------------------------------------------------
t statistics in parentheses
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001</pre>
<h2 id="formats">Formats</h2>
<p>In general you can change the format of a number by placing the desired format in parentheses following the option that prompts that number to be displayed. Use <span class="InputCode">b()</span> to format the betas and <span class="InputCode">t()</span> to format  t statistics.</p>
<p class="InputCode">esttab m1 m2 m3, b(%9.1f) t(%9.1f) r2(%9.6f)</p>
<pre class="InputCode">------------------------------------------------------------
                      (1)             (2)             (3)   
                      mpg             mpg             mpg   
------------------------------------------------------------
foreign               4.9***         -1.7            -2.2   
                    (3.6)          (-1.5)          (-1.8)   

weight                             -.0066***       -.0068***
                                    (-10)          (-5.8)   

displacement                                        .0082   
                                                    (.72)   

gear_ratio                                            2.1   
                                                    (1.2)   

_cons                  20***           42***           35***
                     (27)            (19)           (5.2)   
------------------------------------------------------------
N                      74              74              74   
R-sq              .154762         .662703         .669463   
------------------------------------------------------------
t statistics in parentheses
* p&lt;0.05, ** p&lt;0.01, *** p&lt;0.001</pre>
<h2 id="stars">Stars and Significance</h2>
<p>The <span class="InputCode">star()</span> option lets you control when stars are used. Inside the parentheses you'll put a list of characters paired with the numeric threshold beneath which they will be applied to a coefficient. The default is equivalent to:</p>
<p class="InputCode">star(* 0.05 ** 0.01 *** 0.001)</p>
<p>Note that <span class="InputCode">star()</span> pays attention to both the numbers and how you format them: if you don't include the leading zeros they will not appear in the table.</p>
<p class="InputCode">esttab m1 m2 m3, p star(+ 0.1 * 0.05 ** 0.01)</p>
<pre class="InputCode">---------------------------------------------------------
                      (1)            (2)            (3)  
                      mpg            mpg            mpg  
---------------------------------------------------------
foreign             4.946**       -1.650         -2.246+ 
                  (0.001)        (0.130)        (0.074)  

weight                          -0.00659**     -0.00675**
                                 (0.000)        (0.000)  

displacement                                    0.00825  
                                                (0.472)  

gear_ratio                                        2.058  
                                                (0.245)  

_cons               19.83**        41.68**        34.52**
                  (0.000)        (0.000)        (0.000)  
---------------------------------------------------------
N                      74             74             74  
---------------------------------------------------------
p-values in parentheses
+ p&lt;0.1, * p&lt;0.05, ** p&lt;0.01</pre>
<h2 id="summary">Tables of Summary Statistics</h2>
<p>The <span class="InputCode">esttab</span> command is designed to draw information from the e() vector, which is only used by estimation commands. However,  <span class="InputCode">estpost</span>  will take the results from the r() vector used by other commands and post them in the e() vector. This allows <span class="InputCode">esttab</span> to create tables based on those results, but you'll generally have to give more guidance about what that table should contain.</p>
<p>To store the results of a command in e(), put the <span class="InputCode">estpost</span> command before it:</p>
<p class="InputCode">estpost sum price foreign mpg</p>
<p>	The resulting table is designed to tell you the official name of each quantity. You will use those names in subsequent <span class="InputCode">esttab</span> commands.</p>
<pre class="InputCode">             |  e(count)   e(sum_w)    e(mean)     e(Var)      e(sd)     e(min)     e(max)     e(sum) 
-------------+----------------------------------------------------------------------------------------
       price |        74         74   6165.257    8699526   2949.496       3291      15906     456229 
     foreign |        74         74   .2972973   .2117734   .4601885          0          1         22 
         mpg |        74         74    21.2973   33.47205   5.785503         12         41       1576 </pre>
<p>When working with regression results, <span class="InputCode">esttab</span> knows that <span class="InputCode">e(b)</span> is the primary quantity of interest and builds the table accordingly. With summary statistics, you need to tell <span class="InputCode">esttab</span> what the table should contain using the <span class="InputCode">cell()</span> option. This is technically an option for <span class="InputCode">estout</span> rather than <span class="InputCode">esttab</span>, but <span class="InputCode">esttab</span> will pass it along to <span class="InputCode">estout</span> while still doing some of the other work for you. However, if you want to read the full documentation for the <span class="InputCode">cell()</span> option you need to type <span class="InputCode">help estout</span> rather than <span class="InputCode">help esttab</span>.</p>
<p>If you want a table of just means, use <span class="InputCode">cell(mean)</span>:</p>
<p class="InputCode">esttab, cell(mean)</p>
<pre class="InputCode">-------------------------
                      (1)
                         
                     mean
-------------------------
price            6165.257
foreign          .2972973
mpg               21.2973
-------------------------
N                      74
-------------------------
</pre>
<p>You can list multiple quantities:</p>
<p class="InputCode">esttab, cell(mean sd)</p>
<pre class="InputCode">-------------------------
                      (1)
                         
                  mean/sd
-------------------------
price            6165.257
                 2949.496
foreign          .2972973
                 .4601885
mpg               21.2973
                 5.785503
-------------------------
N                      74
-------------------------</pre>
<p>If you want quantities to appear on a single row, you can group them with either quotes or parentheses. The following commands are equivalent:</p>
<p class="InputCode">esttab, cell("mean sd")<br/>
            esttab, cell((mean sd))</p>
<pre class="InputCode">--------------------------------------
                      (1)             
                                      
                     mean           sd
--------------------------------------
price            6165.257     2949.496
foreign          .2972973     .4601885
mpg               21.2973     5.785503
--------------------------------------
N                      74             
--------------------------------------</pre>
<p>Note how in this case quotes do not indicate strings!</p>
<p>Model numbers and model titles make little sense for this table (especially since the title is empty at this point), so consider removing them with <span class="InputCode">nonumber</span> and <span class="InputCode">nomtitle</span>:</p>
<p class="InputCode">esttab, cell((mean sd)) nonumber nomtitle </p>
<pre class="InputCode">--------------------------------------
                     mean           sd
--------------------------------------
price            6165.257     2949.496
foreign          .2972973     .4601885
mpg               21.2973     5.785503
--------------------------------------
N                      74             
--------------------------------------</pre>
<p>To control the numeric format of results listed in <span class="InputCode">cell()</span> use the <span class="InputCode">fmt()</span> option:</p>
<p class="InputCode">esttab, cell((mean(fmt(%9.1f)) sd(fmt(%9.2f)))) nonumber nomtitle</p>
<pre class="InputCode">--------------------------------------
                     mean           sd
--------------------------------------
price              6165.3      2949.50
foreign               0.3         0.46
mpg                  21.3         5.79
--------------------------------------
N                      74             
--------------------------------------</pre>
<p>There are many other  options. A useful addition to this table is <span class="InputCode">par</span> for parentheses:</p>
<p class="InputCode">esttab, cell((mean sd(par))) nonumber nomtitle </p>
<pre class="InputCode">--------------------------------------
                     mean           sd
--------------------------------------
price            6165.257   (2949.496)
foreign          .2972973   (.4601885)
mpg               21.2973   (5.785503)
--------------------------------------
N                      74             
--------------------------------------</pre>
<p>            The column heading labels also leave somewhat to be desired. You can override them with a <span class="InputCode">label()</span> option associated with each quantity in <span class="InputCode">cell()</span>. This is different from the general <span class="InputCode">label</span> option, which tells <span class="InputCode">esttab</span> to replace the variable names at the beginning of each row with the variable labels. You are welcome to use both (or use <span class="InputCode">coeflabel()</span> to set the row labels yourself):</p>
<p class="InputCode">esttab, cell((mean(label(Mean)) sd(par label(Standard Deviation)))) label nonumber nomtitle <br/>
</p>
<pre class="InputCode">----------------------------------------------
                             Mean Standard D~n
----------------------------------------------
Price                    6165.257   (2949.496)
Car type                 .2972973   (.4601885)
Mileage (mpg)             21.2973   (5.785503)
----------------------------------------------
Observations                   74             
----------------------------------------------</pre>
<p>The problem now is that "Standard Deviation" had to be truncated because its column is not wide enough. You can set the width of the columns with the <span class="InputCode">modelwidth()</span> option (recall that when dealing with regression results each column is a model). If you put a single number in the parentheses the width in characters of all the columns will be set to that number. If you give a list of numbers, they will be applied to the columns in order:</p>
<p class="InputCode">esttab, modelwidth(10 20) cell((mean(label(Mean)) sd(par label(Standard Deviation)))) label nomtitle nonumber </p>
<pre class="InputCode">----------------------------------------------------
                           Mean   Standard Deviation
----------------------------------------------------
Price                  6165.257           (2949.496)
Car type               .2972973           (.4601885)
Mileage (mpg)           21.2973           (5.785503)
----------------------------------------------------
Observations                 74                     
----------------------------------------------------</pre>
<p>Admittedly this will never be publication-quality when rendered as plain text. But consider this <a href="https://ssc.wisc.edu/sscc/pubs/files/stata_output/means.rtf">RTF version</a>, created by:</p>
<p class="InputCode">esttab using means.rtf, modelwidth(10 20) cell((mean(label(Mean)) sd(par label(Standard Deviation)))) label nomtitle nonumber replace</p>
<h2 id="freqs">Frequency Tables</h2>
<p>Creating frequency tables also relies on using <span class="InputCode">estpost</span> to put the results in the e() vector:</p>
<p></p>
<p class="InputCode">estpost tab rep78 foreign</p>
<pre class="InputCode">foreign      |                                            
       rep78 |      e(b)     e(pct)  e(colpct)  e(rowpct) 
-------------+--------------------------------------------
Domestic     |                                            
           1 |         2   2.898551   4.166667        100 
           2 |         8    11.5942   16.66667        100 
           3 |        27   39.13043      56.25         90 
           4 |         9   13.04348      18.75         50 
           5 |         2   2.898551   4.166667   18.18182 
       Total |        48   69.56522        100   69.56522 
-------------+--------------------------------------------
Foreign      |                                            
           1 |         0          0          0          0 
           2 |         0          0          0          0 
           3 |         3   4.347826   14.28571         10 
           4 |         9   13.04348   42.85714         50 
           5 |         9   13.04348   42.85714   81.81818 
       Total |        21   30.43478        100   30.43478 
-------------+--------------------------------------------
Total        |                                            
           1 |         2   2.898551   2.898551        100 
           2 |         8    11.5942    11.5942        100 
           3 |        30   43.47826   43.47826        100 
           4 |        18   26.08696   26.08696        100 
           5 |        11   15.94203   15.94203        100 
       Total |        69        100        100        100 </pre>
<p>These are the same numbers you'd get from <span class="InputCode">tab</span> alone, just organized differently. Note that the frequencies themselves are called <span class="InputCode">e(b)</span>, but we'll still use <span class="InputCode">cell()</span> because otherwise <span class="InputCode">esttab</span> will treat them like regression coefficients:</p>
<p class="InputCode">esttab, cell(b)</p>
<pre class="InputCode">-------------------------
                      (1)
                         
                        b
-------------------------
Domestic                 
1                       2
2                       8
3                      27
4                       9
5                       2
Total                  48
-------------------------
Foreign                  
1                       0
2                       0
3                       3
4                       9
5                       9
Total                  21
-------------------------
Total                    
1                       2
2                       8
3                      30
4                      18
5                      11
Total                  69
-------------------------
N                      69
-------------------------</pre>
<p>The model number, empty model title, and column label (<span class="InputCode">b</span>) are all useless here, so remove the number and title and change the label with <span class="InputCode">collabels()</span>. You could also remove the column label entirely with <span class="InputCode">collabels(none)</span>.</p>
<p class="InputCode">esttab, cell(b) nonumber nomtitle collabels(Frequency)</p>
<pre class="InputCode">-------------------------
                Frequency
-------------------------
Domestic                 
1                       2
2                       8
3                      27
4                       9
5                       2
Total                  48
-------------------------
Foreign                  
1                       0
2                       0
3                       3
4                       9
5                       9
Total                  21
-------------------------
Total                    
1                       2
2                       8
3                      30
4                      18
5                      11
Total                  69
-------------------------
N                      69
-------------------------</pre>
<p>The <span class="InputCode">unstack</span> option converts the three sections into columns:</p>
<p class="InputCode">esttab, cell(b)  unstack nonumber nomtitle collabels(none)</p>
<pre class="InputCode">---------------------------------------------------
                 Domestic      Foreign        Total
---------------------------------------------------
1                       2            0            2
2                       8            0            8
3                      27            3           30
4                       9            9           18
5                       2            9           11
Total                  48           21           69
---------------------------------------------------
N                      69                          
---------------------------------------------------</pre>
<p>To control the label for the row variable use <span class="InputCode">eqlabels()</span>, but <span class="InputCode">esttab</span> thinks of it as being the left-hand-side of an equation (remember <span class="InputCode">esttab</span> was built for models). Thus you have to use the <span class="InputCode">lhs()</span> suboption within <span class="InputCode">eqlabels()</span>. You can adjust the amount of space available to the label with <span class="InputCode">varwidth()</span>:</p>
<p class="InputCode">esttab, cell(b) eqlabels(, lhs("Repair Record")) varwidth(15) unstack nonumber nomtitle collabels(none) </p>
<pre class="InputCode">------------------------------------------------------
Repair Record       Domestic      Foreign        Total
------------------------------------------------------
1                          2            0            2
2                          8            0            8
3                         27            3           30
4                          9            9           18
5                          2            9           11
Total                     48           21           69
------------------------------------------------------
N                         69                          
------------------------------------------------------</pre>
<p>You can add additional quantities to <span class="InputCode">cell()</span> and control their appearance and structure using all the tools we discussed in the section on summary statistics. Consider adding a note to explain what each number represents with the <span class="InputCode">note()</span> option:</p>
<p class="InputCode">esttab, cell(b rowpct(fmt(%5.1f) par)) note(Row Percentages in Parentheses) unstack nonumber nomtitle collabels(none) eqlabels(, lhs("Repair Record")) varwidth(15) </p>
<pre class="InputCode">------------------------------------------------------
Repair Record       Domestic      Foreign        Total
------------------------------------------------------
1                          2            0            2
                     (100.0)        (0.0)      (100.0)
2                          8            0            8
                     (100.0)        (0.0)      (100.0)
3                         27            3           30
                      (90.0)       (10.0)      (100.0)
4                          9            9           18
                      (50.0)       (50.0)      (100.0)
5                          2            9           11
                      (18.2)       (81.8)      (100.0)
Total                     48           21           69
                      (69.6)       (30.4)      (100.0)
------------------------------------------------------
N                         69                          
------------------------------------------------------
Row Percentages in Parentheses</pre>
<p>This is just a  fraction of what <span class="InputCode">esttab</span> (let alone <span class="InputCode">estout</span>) can do. To learn more, we suggest reading the <a href="http://www.stata-journal.com/article.html?article=st0085">Stata Journal article that introduced it</a>. For syntax details, type <span class="InputCode">help esttab</span> and/or <span class="InputCode">help estout</span>.</p>
<p> </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Search Stata's Online Help</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>
<!-- InstanceBeginEditable name="Content" -->
<form action="http://stata.com/search.cgi" id="form1" method="get" name="form1">
<p>
<label>Command:
                        <input id="query" name="query" type="text"/>
<br/>
<input id="button" name="button" type="submit" value="Submit"/>
<br/>
</label>
</p>
</form>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Articles on Using Winstat</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>
<!-- InstanceBeginEditable name="Content" -->
<p>This page lists articles on connecting to
                              	 and using Winstat and Silo, the SSCC's Windows Remote Desktop Services Farms.</p>
<h2>Connecting</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">Using Winstat</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/silo.htm">Using  Silo</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/winstat_fonts.htm">Changing Font Sizes on Winstat</a><br/>
</p>
<h2>Interacting with Linux</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Connecting to the SSCC Network via VPN</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>VPN (Virtual Private Networking) allows a computer to connect to the SSCC network as if it were in the building regardless of its physical location. This gives you access to SSCC network drives and printers. It gives you a UW IP address, which allows you to use services like the many library databases which are restricted to UW IP addresses. It also encrypts all of your network traffic, protecting your privacy on public wireless networks. UW-Madison uses Palo Alto GlobalProtect for its VPN solution.</p>
<p>Please note: Per <a href="https://kb.wisc.edu/itpolicy/it-electronic-devices-policy" target="new" title="Campus Electronic Device Policy ">campus policy for electronic devices</a>, to connect to the SSCC VPN you must be using a supported, up to date operating system. </p>
<h2>Installing  GlobalProtect</h2>
<p>To connect to the campus VPN service, you'll need to download and install the  GlobalProtect client for your computer. If you're using an SSCC-managed machine (i.e. one where you can only install new software using <a href="https://ssc.wisc.edu/sscc/pubs/softwarecenter.htm">Software Center</a>), <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">contact the Help Desk</a> and we'll install GlobalProtect for you.</p>
<p>Download the GlobalProtect  for:</p>
<ul>
<li><a href="https://uwmadison.vpn.wisc.edu/global-protect/getmsi.esp?version=64&amp;platform=windows">Windows</a></li>
<li><a href="https://uwmadison.vpn.wisc.edu/global-protect/getmsi.esp?version=none&amp;platform=mac">macOS</a></li>
</ul>
<p>Clients for iOS and Android can be found in the appropriate app store. Contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a> if you need a client for a different operating system, like Linux.</p>
<p>Once the installer has finished downloading (GlobalProtect64.msi on Windows or GlobalProtect.pkg on Mac) run the installer, keeping all the default settings. Once it is installed you are ready to <a href="#using">connect to the VPN</a>.</p>
<p>macOS may try to block the GlobalProtect client from installing due to security requirements: </p>
<img alt="macOS refusing to install client" height="284" src="https://ssc.wisc.edu/sscc/pubs/screenshots/GlobalProtect/GPMacBlocked.png" style="display: block; margin-left: auto; margin-right: auto;" width="689"/>
<p>If you see this message, click <span class="MenuOutput">Open Security Preferences</span>. Then click the <span class="MenuOutput">Allow</span> button in the bottom right, check the box next to <span class="MenuOutput">Palo Alto Networks</span>, click <span class="MenuOutput">OK</span>, then restart your computer to apply the changes.</p>
<img alt="Changing security settings" height="619" src="https://ssc.wisc.edu/sscc/pubs/screenshots/GlobalProtect/GPMacSecurity.png" style="display: block; margin-left: auto; margin-right: auto;" width="720"/>
<h2 id="using">Using  GlobalProtect</h2>
<p>To open GlobalProtect in Windows, click on the up-arrow in the bottom right of your task bar, then right-click on its icon (<img alt="GlobalProtect icon" height="16" src="https://ssc.wisc.edu/sscc/pubs/screenshots/GlobalProtect/GPIcon.jpg" width="16"/>) and choose <span class="MenuOutput">Show Panel</span>.</p>
<p>To open GlobalProtect in macOS, click on its icon (<img alt="GlobalProtect icon" height="16" src="https://ssc.wisc.edu/sscc/pubs/screenshots/GlobalProtect/GPIcon.jpg" width="16"/>) in the menu bar at the top right and choose  <span class="MenuOutput">Show Panel</span>.</p>
<p>Enter <span class="InputCode">sscc.vpn.wisc.edu</span> in <span class="MenuOutput">Portal</span> (note that it must be <span class="InputCode">sscc</span> and not <span class="InputCode">ssc</span>),  give your SSCC username and password, then click <span class="MenuOutput">Connect</span>. </p>
<img alt="" class="CenterImage" height="328" src="https://ssc.wisc.edu/sscc/pubs/screenshots/GlobalProtect/PAGP_connect.jpg" width="272"/>
<p>If it succeeds, you'll see <strong>Status: Connected</strong>.</p>
<img alt="" class="CenterImage" height="291" src="https://ssc.wisc.edu/sscc/pubs/screenshots/GlobalProtect/PAGP_success.jpg" width="273"/><!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/GlobalProtect/GPMacBlocked.png, https://ssc.wisc.edu/sscc/pubs/screenshots/GlobalProtect/GPMacSecurity.png, https://ssc.wisc.edu/sscc/pubs/screenshots/GlobalProtect/GPIcon.jpg, https://ssc.wisc.edu/sscc/pubs/screenshots/GlobalProtect/GPIcon.jpg, https://ssc.wisc.edu/sscc/pubs/screenshots/GlobalProtect/PAGP_connect.jpg, https://ssc.wisc.edu/sscc/pubs/screenshots/GlobalProtect/PAGP_success.jpg</img_base_url>
</kb_document>
<kb_document>
<kb_title>Publications about the Web</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>
<!-- #BeginEditable "Content" -->
<p>This page lists articles dealing with using the SSCC web server.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/1-4.htm">Publishing
          			 to the SSCC's Web Server</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/wordpress.htm">Creating a Web Site using WordPress</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/7-20.htm">Limiting	Access to a Web Page</a><br/>
</p>
<p>Those who wish to place material on the web should also be aware 
				of the University's <a href="http://www.wisc.edu/wiscinfo/policy/wwwap.html">Policy 
				Governing World Wide Web Accessibility</a> which applies to any 
				web pages you may create.</p>
<p>The SSCC also has a brief <a href="https://ssc.wisc.edu/sscc/policies/webpublish.htm">Web 
				Publishing Policy</a>.</p>
<!-- #EndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Welcome to the SSCC!</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- #BeginEditable "Text" -->
<p>Welcome to the SSCC! The Social Science Computing Cooperative supports researchers at UW-Madison who use statistical analysis in their work. We provide a complete research computing environment focused on statistics plus the expert help you need to use it. This includes:</p>
<ul>
<li><a href="https://www.ssc.wisc.edu/sscc/statconsult.htm">Statistical consultants</a> who are experts on the most popular statistical software and can answer many methodological questions</li>
<li>Training on statistical computing, including <a href="https://www.ssc.wisc.edu/sscc_jsp/training/">workshops</a> and an extensive <a href="https://www.ssc.wisc.edu/sscc/pubs/stat.htm">Statistical Computing Knowledge Base</a>.</li>
<li>Powerful and easy-to-use <a href="https://www.ssc.wisc.edu/sscc/pubs/winstat.htm">Windows</a> and <a href="https://www.ssc.wisc.edu/sscc/pubs/linstat.htm">Linux</a> based servers with the most popular statistical <a href="https://www.ssc.wisc.edu/sscc_jsp/software/">software</a> installed and ready for use, plus many specialized packages</li>
<li>Secure data storage suitable for most sensitive research data</li>
<li>A dedicated <a href="https://www.ssc.wisc.edu/sscc/helpdesk.htm">help desk</a> staffed by IT professionals, with immediate access to the system administrators who run the servers</li>
</ul>
<p>If you have questions or run into  problems, the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">SSCC Help Desk</a> is available to
  help you 
  from 9AM to 12PM and 1PM to 4PM.
  There	are	several ways to get in touch with the Help Desk: you can
  call 262-9917	(2-9917	if	you're 
  using a campus phone), you can email <a href="mailto:helpdesk@ssc.wisc.edu">helpdesk@ssc.wisc.edu</a>,
  or you can  stop by the SSCC staff offices in 4226 Sewell Social
  Sciences Building. Look
  for the white sign that says <span class="MenuOutput">Help Desk </span> or the red sign that says <strong>Stat Consultant</strong> so you know who's "on duty."</p>
<h2><a id="Accounts" name="Accounts"></a>Accounts</h2>
<p>An SSCC Member is someone who has been sponsored for an SSCC account by one or more of our <a href="https://ssc.wisc.edu/sscc/agencies.htm">member agencies and departments</a>. This means you have full access to all the SSCC's resources without charge. The costs of your membership are paid by your sponsor(s).</p>
<p>If you're reading this you've probably already activated your SSCC account. In the process you should have set your password and security questions, decided whether to request an SSCC orientation, and set an email address we can use to contact you. Some important reminders:</p>
<ul>
<li>Never share your SSCC account or give anyone your password (even SSCC staff)</li>
<li>We will send announcements to your your <a href="https://www.ssc.wisc.edu/sscc_jsp/email/pref.jsp">preferred email address</a>—including when it's time to renew your account. Make sure you it's one you'll continue to read.</li>
</ul>
<p> </p>
<h2><a id="InternetAccess" name="InternetAccess"></a>Internet Access</h2>
<p>You can access the Internet throughout the Sewell Social Sciences Building by connecting to the campus wireless network. To do so you'll need to give your DoIT NetID and password (so make sure you <a href="https://www.mynetid.wisc.edu/activate">activate</a> your NetID at <a href="http://www.doit.wisc.edu/">DoIT's web site</a>). This network is not provided by the SSCC, so if you run into  difficulties with it we may need to refer you to <a href="http://kb.wisc.edu/helpdesk/">DoIT's help desk</a> (264-HELP). The first time you use it you must open a web browser and log in to the campus wireless network before you can use other programs that need network access, such as email. Unfortunately the campus wireless network is not encrypted, so we suggest you turn on a <a href="https://ssc.wisc.edu/sscc/pubs/vpn.htm">VPN</a> connection whenever you use it so your communications are secure.</p>
<p>The wired network in the building is provided by the SSCC, and gives direct access to SSCC resources. When you use the wired network you are behind our firewall so we ask that before you plug into it you make sure both your operating system and your antivirus software are up-to-date and update themselves automatically. For PCs running Windows, we suggest you use the free <a href="http://www.microsoft.com/en-us/security_essentials/ProductInformation.aspx">Microsoft Security Essentials</a>. For Macs, we recommend the free <a href="http://www.sophos.com/en-us/products/free-tools/sophos-antivirus-for-mac-home-edition.aspx">Sophos Anti-Virus for Mac Home Edition</a>. If you prefer, you can drop off your computer in 4226 Sewell Social Sciences Building and our PC Support group will set up everything for you.</p>
<h2><a id="Software" name="Software"></a>Software</h2>
<p>The SSCC provides a great deal of software—most likely everything you'll need. This includes general purpose statistical programs like Stata, SAS, SPSS and R, many special purpose statistical programs, research tools like EndNote, and common software like Microsoft Office. The programs are provided  on the SSCC's servers (especially Winstat) and/or  in the computer labs so you probably won't need to purchase them or install  them on your personal computer.</p>
<p>For a full list of all SSCC software and where it is installed, see our <a href="https://www.ssc.wisc.edu/sscc_jsp/software/">software web page</a>.</p>
<h2><a id="Servers" name="Servers"></a>Servers </h2>
<p>Winstat is the SSCC's Windows Terminal Server farm. Winstat allows
	any SSCC member to log in and run Windows on the server, with full access to the SSCC network and a tremendous amount of software. You can also use it to transfer files between your computer and the network. This makes Winstat a very useful tool whether you're in the Sewell Social Sciences Building or  anywhere else in the world.</p>
<p>To use Winstat you'll need to download and install a small, free client program. Our Knowledge Base article <a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">Using Winstat</a> has instructions.</p>
<p>Linstat is the the SSCC's Linux computing cluster and provides additional computing power for those who need it. If your statistical job is taking more than a few minutes on Winstat, it would probably run  more quickly on Linstat. Running statistical software on Linstat is  easier than you might expect; <a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a> will get you started.</p>
<p>The SSCC also has an <a href="https://ssc.wisc.edu/sscc/pubs/7-1.htm">HTCondor</a> flock that is ideal for running large numbers of jobs at the same time, and a <a href="https://ssc.wisc.edu/sscc/pubs/flash.htm">High Performance  Computing Cluster</a> (HPCC) where you can break a job into hundreds of  pieces to be run in parallel.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/computing_resources.htm">Computing Resources at the
  SSCC</a> gives detailed descriptions of all the SSCC servers and suggestions for choosing the right server for your job.</p>
<h2><a id="NetworkDiskSpace" name="NetworkDiskSpace"></a>Network Disk Space</h2>
<p>The SSCC provides a very large amount of network disk space for our users. This space is secure, available from any location and backed up every night. We strongly recommend that you save all files related to your research work or other University business on the network rather than the local hard drive of your computer.</p>
<p> The SSCC has both Windows file servers and Linux file servers, and you have space on both. A program called Samba makes the Linux space available to Windows sessions as regular network drives.</p>
<p>Private space is provided in your two "home directories." When using Windows, your Windows home directory is the <span class="MenuOutput">U:</span> drive and your Linux home directory is <span class="MenuOutput">Z:</span> drive. This is where you should put anything you're working on individually. Shared space is provided in Project directories, which are on the <span class="MenuOutput">X:</span> drive (Windows) and the <span class="MenuOutput">V:</span> drive (Linux). Project directories allow groups working together on a common            		project to share files.</p>
<p>The <span class="MenuOutput">Y:</span> drive is temporary space. You can use it if you need  a lot of disk space for a brief period, or to quickly share files with people who are not part of an official "project." However, you should keep in mind that <span class="bolded">files on the Y: drive are not secure, are not backed up, and are removed after 30 days.</span></p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/disk.htm">Network Disk Space at the SSCC</a> has more information, including how to request that a file be restored from backup.</p>
<p>Personal computers running Windows or Mac OS X can be set up to access the SSCC's network disk space, and most can also use the network printers. We will be happy to do this for you—just drop off your computer in 4226 Sewell Social Sciences Building. If you're not in the building or your computer cannot log into our domain you can easily access network drives and printers using Winstat. Alternative methods include <a href="https://ssc.wisc.edu/sscc/pubs/vpn.htm">VPN</a> and <a href="https://ssc.wisc.edu/sscc/pubs/5-35.htm">FTP</a>.</p>
<h2><a id="Printers" name="Printers"></a>Printers</h2>
<p>The SSCC provides general use printers in our computer labs: 4218, 3218 and 2470 Sewell Social Sciences Building. <a href="https://ssc.wisc.edu/sscc/pubs/5-24.htm">Setting
	  			Up Network	Printers	in Windows</a> and <a href="https://ssc.wisc.edu/sscc/pubs/printfrommac.htm">Using SSCC Printers from Macs</a> will tell you how to use these printers. SSCC members are not charged for printing.</p>
<h2><a id="RemoteAccesstoSSCCResources" name="RemoteAccesstoSSCCResources"></a>Remote Access to SSCC Resources</h2>
<p>Winstat, Linstat, files on the network, and even your office PC can be used from home or any location with Internet access. <a href="https://ssc.wisc.edu/sscc/pubs/working_from_home.htm">Working From Home and Other Remote Locations</a> will tell you how.</p>
<h2><a id="ComputerLabs" name="ComputerLabs"></a>Computer Labs</h2>
<p>The SSCC provides three public computer labs in the Sewell
  Social Science building. 4218 is the main lab, 3218 is available when not
  in use by classes, and 2470 is a quiet place to work with your laptop (see
  the <a href="https://ssc.wisc.edu/sscc/infrastructure/labs.htm">SSCC Computer Labs 
    web page</a> for more details).</p>
<h2><a id="LearningMore" name="LearningMore"></a>Learning More</h2>
<p>The most valuable resource for learning about the SSCC is the SSCC's web site (<a href="http://ssc.wisc.edu">ssc.wisc.edu</a>). It includes our <a href="https://ssc.wisc.edu/sscc/policies">policies</a>, information <a href="https://ssc.wisc.edu/sscc/about">about the SSCC</a>, and <a href="https://ssc.wisc.edu/sscc/accounts">tools for working with your account</a>.</p>
<p>But the most important part of the SSCC web site is the <a href="https://ssc.wisc.edu/sscc/pubs">SSCC Knowledge Base</a>, a collection of articles on SSCC resources and statistical computing in general. Topics range from basics like <a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">logging into Winstat</a> to general introductions like <a href="https://ssc.wisc.edu/sscc/pubs/sfs/">Stata for Students</a>  or Data Wrangling in <a href="https://ssc.wisc.edu/sscc/pubs/dws/data_wrangling_stata1.htm">Stata</a>, <a href="https://ssc.wisc.edu/sscc/pubs/DWE/book/preface.html">R</a>, or <a href="https://ssc.wisc.edu/sscc/pubs/DWE/book/preface.html">Python</a>, to to specific topics  like <a href="https://ssc.wisc.edu/sscc/pubs/stata_bar_graphs.htm">making bar graphs</a> and <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">mixed models</a>.</p>
<p>We also offer  training classes each semester which are free to all SSCC members, including both introductions to statistical software and workshops on statistical topics. Visit our <a href="https://www.ssc.wisc.edu/sscc_jsp/training/index.jsp">training page</a> to see the schedule and register for classes.</p>
<p>The SSCC has a small library of statistical software documentation in 4218 for use in that lab. A few more books can be found in the 4226 staff offices.</p>
<h2><a id="GettingHelp" name="GettingHelp"></a>Getting Help</h2>
<p>The <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">SSCC Help Desk</a> is open 9AM-12PM and 1PM-4PM. You can contact the Help Desk by emailing <a href="mailto:helpdesk@ssc.wisc.edu">helpdesk@ssc.wisc.edu</a>, calling 262-9917 (2-9917 on campus) or stopping by 4226 Sewell Social Sciences Building.</p>
<p>To get help from SSCC's <a href="https://ssc.wisc.edu/sscc/statconsult.htm">statistical consultants</a> you can email your question to <a href="mailto:helpdesk@ssc.wisc.edu">helpdesk@ssc.wisc.edu</a>, make an <a href="https://ssc.wisc.edu/sscc/statconsult.htm#appt">appointment</a>, or stop by during their<a href="https://ssc.wisc.edu/sscc/statconsult.htm#dropin"> drop-in consulting hours</a> (no appointment needed).</p>
<p>Again, welcome to the SSCC. If there is anything we can do to make your computing 
  more productive, please let us know.</p>
<!-- #EndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Welcome to the SSCC!</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- #BeginEditable "Text" -->
<p>Welcome to the SSCC! The Social Science Computing Cooperative provides computing
              services for research and instruction in the social sciences. As an SSCC Lab user you'll have access to a wide variety of statistical software, powerful computers, and help in using them.</p>
<h2>Accounts</h2>
<p>The SSCC provides Lab Accounts to graduate students in the University's <a href="https://ssc.wisc.edu/sscc/accounts/socscidiv.htm">Social Science Division and Arts and Humanities Division,</a> plus anyone taking a class that uses the SSCC's computer labs. A Lab Account allows you to use the SSCC's computer labs and Winstat, the SSCC's Windows Remote Desktop Services farm, but does not give you access to the SSCC's Linux servers.</p>
<p>If you have not yet received an SSCC Lab Account, you can <a href="https://www.ssc.wisc.edu/sscc_jsp/account/lab/">request an account online</a>.</p>
<h2>Computer Labs</h2>
<p>The SSCC has two main computer labs in the Sewell Social Sciences Building. Room 4218 is the Computer Lab where you can  work on your research or your homework. 3218 is the Computer Classroom, though it is available for general use when classes are not being held there.  Both labs have printers and scanners. Room 2470, the Group Projects Room, is 
                            	available for drop-in use by groups of students
           	working together.</p>
<p>All labs are open from 9:00AM to 9:00PM Monday through Friday. Graduate students can <a href="https://www.ssc.wisc.edu/sscc_jsp/account/lab.jsp">request
                            	after-hours access</a> to the labs, which allows them to use the labs 24/7. People who are
                            	using the Computer Lab (4218)  when it closes may stay, though
                            	the doors will be locked. People who are using
                            	the Computer Classroom (3218) will be asked to move to
           	the Computer Lab.</p>
<h2>Winstat</h2>
<p>Winstat is the SSCC's Windows Windows Remote Desktop Services farm. Winstat allows
	you to log in remotely and run programs on the server, with full access to the SSCC network and the statistical software you need. You can also use it to transfer files between your computer and the network. This makes Winstat a convenient alternative to coming into the lab.</p>
<p>To use Winstat you'll need to download and install a small, free client program. Our Knowledge Base article <a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">Using Winstat</a> has instructions.</p>
<h2>Network Drives</h2>
<p>The SSCC provides a very large amount of network disk space for our users. This space is secure, available from any location and backed up every night. We strongly recommend that you save all files related to your research work or SSCC-supported class on the network.</p>
<p>The <span class="MenuOutput">U:</span> drive is your "home directory." This is private space where you can store your files. The <span class="MenuOutput">X:</span> drive is for project directories. If you need to share files with your class or research group, there will be a folder for that group on the <span class="MenuOutput">X:</span> drive.</p>
<p>The <span class="MenuOutput">Y:</span> drive is temporary space. You can use it if you need  a lot of disk space for a brief period, or to quickly share files with people who are not part of an official "project." However, you should keep in mind that <span class="bolded">files on the Y: drive are not secure, are not backed up, and are removed after 30 days.</span></p>
<h2>Printing</h2>
<p>Both computer labs have printers which you are welcome to use. The 
  printers use the campus wide pay-for-print system, GoPrint. You will
  need a valid NetID to sign in to the GoPrint system. Printing is  $.07 per side of a 
  page and is debited from your WisCard account. For more information, see <a href="https://ssc.wisc.edu/sscc/pubs/goprint.htm">Paying for Printing in the SSCC Labs</a>.</p>
<h2>Learning More</h2>
<p>While your instructor will be your primary source of information, you may find the <a href="https://ssc.wisc.edu/sscc/pubs/home.htm">SSCC Knowledge Base</a> useful. Article topics range from basics like <a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">logging into Winstat</a> to general introductions like <a href="https://ssc.wisc.edu/sscc/pubs/sfs/">Stata for Students</a> or Data Wrangling in <a href="https://ssc.wisc.edu/sscc/pubs/dws/data_wrangling_stata1.htm">Stata</a>, <a href="https://ssc.wisc.edu/sscc/pubs/DWE/book/preface.html">R</a>, or <a href="https://ssc.wisc.edu/sscc/pubs/DWE/book/preface.html">Python</a>, to specific topics  like <a href="https://ssc.wisc.edu/sscc/pubs/stata_bar_graphs.htm">making bar graphs</a> and <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">mixed models</a>.</p>
<p>We also offer  training classes each semester which are free to those with SSCC lab accounts, including both introductions to statistical software and workshops on statistical topics. These classes go into much more depth than the the brief introduction to the software given in most statistical courses and could make applying what you learn in class much easier. Visit our <a href="https://www.ssc.wisc.edu/sscc_jsp/training/index.jsp">training page</a> to see the schedule and register for classes.</p>
<p>The SSCC has a small library of statistical software documentation in 4218 for use in that lab. A few more books can be found in the 4226 staff offices.</p>
<h2>Getting Help</h2>
<p>If you are having trouble logging in or using your account, the  SSCC Help Desk can assist you. The Help Desk is available 9AM-12PM and 1PM-4PM. You can contact the Help Desk by emailing <a href="mailto:helpdesk@ssc.wisc.edu">helpdesk@ssc.wisc.edu</a>, calling 262-9917 (2-9917 on campus) or stopping by 4226 Sewell Social Sciences Building.</p>
<p>Undergraduates with lab accounts can get help from the SSCC's statistical consultants for class work related to their class that uses SSCC facilities. Graduate students with lab accounts can get help with both class work and research. Visit our <a href="https://www.ssc.wisc.edu/sscc/statconsult.htm">statistical consulting page</a> for information about how to get in touch with them.</p>
<!-- #EndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Articles on Using Windows</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>
<!-- #BeginEditable "Content" -->
<p>This page lists articles on using Windows 
                                operating system and SSCC resources.</p>
<h2>Basics</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/1-15.htm">How to Change Your SSCC Passwords</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/computing_resources.htm">Computing Resources at the
                              				SSCC<br/>
</a><a href="https://ssc.wisc.edu/sscc/pubs/disk.htm">Network Disk Space at the SSCC</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/5-24.htm">Setting Up Network Printers	
                                in Windows<br/>
</a><a href="https://ssc.wisc.edu/sscc/pubs/working_from_home.htm">Working From Home and Other Remote Locations</a><a href="https://ssc.wisc.edu/sscc/pubs/5-24.htm"> <br/>
</a><a href="https://ssc.wisc.edu/sscc/pubs/5-26.htm">Mapping a Drive to a Network Share in Windows</a><br/>
</p>
<h2>Connecting</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">Using Winstat </a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/1-13.htm">Connecting to SSCC Computers 
                                Using a WinTerm</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/vpn.htm">Connecting to the SSCC Network 
                                via VPN</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/remote_desktop.htm">Connecting to Your Office Computer Using Remote Desktop (Windows)</a></p>
<h2> Interacting with Linux</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a></p>
<h2> Tools</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/softwarecenter.htm">Installing New Software using Software Center</a><a href="https://ssc.wisc.edu/sscc/pubs/office2013.htm"><br/>
                              Upgrading to Office 2013 using SSCC's Software Center</a><a href="https://ssc.wisc.edu/sscc/pubs/5-35.htm"><br/>
                              Transferring Files Using SecureFX</a><br/>
<a href="https://ssc.wisc.edu/sscc/pubs/5-13.htm">Writing a CD Using Ahead Nero</a> </p>
<!-- #EndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Using Winstat</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Winstat is the SSCC's Windows Remote Desktop Server cluster. Winstat allows many people to share a pool of powerful servers, but each user gets a session that looks and acts just like Windows on any other computer. While using Winstat you'll have access to SSCC software, network drives and printers. You can connect to Winstat from anywhere and use it to transfer files between your computer and the SSCC network.</p>
<h2><a id="InstallingtheCitrixReceiver" name="InstallingtheCitrixReceiver"></a>Installing Citrix Workspace</h2>
<p>In order to use Winstat you'll need to download and install Citrix Workspace on each computer you use. </p>
<ul>
<li><a href="https://ssc.wisc.edu/sscc/receiver/SSCC_Citrix_Workspace.msi">Citrix Workspace for Windows</a> (Windows 7 and above)</li>
<!--	<ul><li><a href="/sscc/receiver/receiverconfig.cr">Winstat activation</a></li></ul> -->
<li><a href="https://ssc.wisc.edu/sscc/receiver/Citrix WorkspaceApp-SSCC.dmg">Citrix Workspace for Mac</a> (MacOS 10.13 and above)</li>
</ul>
<p>Versions of Citrix Workspace are also available for Linux and mobile platforms; contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a> for assistance if you need them.</p>
<h2><a id="StartingWinstat" name="StartingWinstat"></a>Starting Your Winstat Session</h2>
<p>After activating Citrix Workspace, you can start the program for the first time, and log in at the prompt using your SSCC user name and password and click the <b>Winstat</b> icon.</p>
<p><img alt="" height="479" src="https://ssc.wisc.edu/sscc/pubs/screenshots/winstat/Citrix.PNG" width="650"/></p>
<p>While your Winstat sessions launches you may receive a <span class="MenuOutput">Security Warning</span> saying that <span class="MenuOutput">An online application is attempting to access information on a device attached to your computer</span>. This is Citrix Workspace attempting to make the files on your computer's hard drive available from within your Winstat session. This is a very useful capability (see <a href="#TransferringFilesUsingWinstat">Transferring Files using Winstat</a> below) so we suggest you choose <span class="MenuOutput">Permit use</span> and check the box <span class="MenuOutput">Do not ask me again for this site</span>.</p>
<h2>Restarting Your Winstat Session</h2>
<p>If you are having trouble connecting to Winstat, the first thing you should try is to restart your session. To do so, in Citrix Workspace click <strong>Details</strong> and select <strong>Restart</strong>. Confirm the restart if prompted. </p>
<p><img alt="" height="454" src="https://ssc.wisc.edu/sscc/pubs/screenshots/winstat/Winstat restart.png" width="650"/><br/>
</p>
<h2>Winstat on Mobile Devices </h2>
<p>You can also connect to Winstat via mobile devices and tablets, including iPads, Chromebooks, and Android tablets.  A Citrix Workspace app is available for download from your device's App Store.  Once you have installed the app, you will be prompted for a server name or address.  Enter <strong>https://storefront.ssc.wisc.edu/Citrix/SSCCWeb/</strong> and your SSCC credentials when prompted and the app will be configured to connect to Winstat. </p>
<h2><a id="ActivatingCitrixWorkspace" name="ActivatingCitrixWorkspace"></a>Activating Citrix Workspace</h2>
<p>If you install Citrix Workspace from a location other than the SSCC website, you will need to activate the software before you can use it. You can do this using the <b>receiverconfig.cr</b> file available here (right click, "save link as"): </p>
<ul>
<li><a href="https://ssc.wisc.edu/sscc/receiver/receiverconfig.cr">Citrix Activation File</a></li>
</ul>
<p>Once downloaded, double click the file to run the script - it will automatically register your installation of Workspace.                </p>
<h2><a id="GuidelinesforUsingWinstat" name="GuidelinesforUsingWinstat"></a>Guidelines
                  for Using Winstat</h2>
<p>There are a few rules you must follow when using Winstat:</p>
<ol>
<li>Do not attempt to install or run your own software on the server. Unlike a regular Windows PC, Winstat consists of shared server that many users can access simultaneously, and the software installed there is selected specifically for such use. This includes the "codebook"programs that come with some data sets - you'll need to find another place to install and run them.</li>
<li>Do not  save files on the server's hard drive, <span class="MenuOutput">Local Disk (C:)</span>. Save files in <span class="MenuOutput">Documents</span>, on the <span class="MenuOutput">Desktop</span>, or on network drives. (On Winstat the <span class="MenuOutput">Desktop</span> and <span class="MenuOutput">Documents</span> folders are  saved on your <span class="MenuOutput">U:</span> drive.) Files saved elsewhere will be permanantly deleted at the end of your session and <b>cannot be recovered</b>.</li>
<li>When you're done using Winstat, log off.
                    Do not just close Citrix Workspace, or your session will continue to run in a disconnected state. If you then try to log in again, Winstat may fail to reconnect to the existing session and you won't be able to create a new one until the disconnected session is shut down automatically three hours later.</li>
</ol>
<h2><a id="ControllingtheWinstatWindow" name="ControllingtheWinstatWindow"></a>Controlling the Winstat
          		Window</h2>
<p>Once  you are logged in to your Winstat session, you can control your Winstat window  using the Receiver Control Bar at the top of your screen.</p>
<p><img alt="" height="100" src="https://ssc.wisc.edu/sscc/pubs/screenshots/winstat/winstat1.png" width="507"/></p>
<p><span class="MenuOutput">Home</span> – Returns you to the Desktop of your  computer </p>
<p><span class="MenuOutput">Ctrl+Alt+Del</span> –Allows you to open the Task Manager on the Winstat server so that you can end programs that are giving you trouble </p>
<p><span class="MenuOutput">Preferences</span> – Sets options for the Desktop Viewer, including display options and controlling access to local files.</p>
<p><span class="MenuOutput">Full-screen/Window</span> – Lets Winstat use your entire screen, or returns your Winstat session to a smaller window which also gives you access to your  computer's desktop and programs.  </p>
<p><span class="MenuOutput">Disconnect</span> – Closes the Desktop Viewer but keeps your Winstat session running, so that  when you connect again you will return to what you were doing when you  left.  You should save all work before  disconnecting if possible in case you encounter any problems returning to the  session.</p>
<p>If you have more than one monitor and want to use them in Winstat, put Winstat in Windowed mode, then drag the edges of the Winstat window such that the Window covers at least 50% of each of the monitors you want to use. Then switch to Full-screen and Winstat will use the full screen of all the monitors you put it on.</p>
<h2><a id="TransferringFilesUsingWinstat" name="TransferringFilesUsingWinstat"></a>Transferring
                  Files Using Winstat</h2>
<p>When you log in to Winstat using Citrix Workspace, it will
                  automatically create network drives that connect to the local
                  drives of your computer. They will appear at the bottom of the list of drives, with names like <span class="MenuOutput">Local Disk (C: on ...)</span> and <span class="MenuOutput">CD/DVD Drive (D: on ...)</span>. The last part of the name will be the name of your local computer. Be sure not to confuse them with the local hard drive of the server itself, <span class="MenuOutput">Local Disk (C:)</span>, which you should never use. On a Mac, <span class="MenuOutput">Local Disk (C: on ...)</span> is actually your home directory on your Mac's hard drive.</p>
<p>These drives give you a very easy way to transfer files between your computer
                  and the SSCC network. Simply open <span class="MenuOutput">Local Disk (C: on ...)</span>, locate
                  the file you want to transfer, and drag it to a network drive
                  like <span class="MenuOutput">U:</span> (your Windows home directory).
                  The process also works in reverse. Keep in mind that the file
                  must  be sent over your Internet connection, so if you have
                  a large file or a slow connection it may take a while. We do not suggest that you try to analyze data sets stored on your local hard drive: better to move them to the SSCC network and then analyze them there.</p>
<p>One warning: Winstat sees the hard drive of your computer as a network drive, and when you delete a file from a network drive it is permanently deleted rather than being sent to the Recycle Bin. Please be careful about deleting files.</p>
<h2>Printing from Winstat</h2>
<p>SSCC networked lab printers will automatically be configured and available in Winstat. Citrix Workspace also allows Winstat to print to your local default printer. Make sure the printer you want to print to is the default before connecting to Winstat.</p>
<h2>Connecting to  Winstat via the Web</h2>
<p>It is also possible to open a Winstat session directly in a web browser, though you will not be able to access files and printers using this method. We  strongly recommend using the Citrix Workspace Desktop Viewer whenever possible for its increased functionality and stability, but the web interface may be useful if you cannot install software on the computer you are using.  To access Winstat via the web go to <a href="https://winstat.ssc.wisc.edu/">winstat.ssc.wisc.edu</a>, log in, and click on the Winstat  icon. A Winstat session will open in a  new browser tab.</p>
<p>The  web client does not have the flexibility of the Desktop Viewer, but there  are buttons on the right side of the session window which allow you to copy  and paste text between your  computer and your Winstat session (the Desktop Viewer allows this automatically) and end programs running in your Winstat session.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/winstat/Citrix.PNG, https://ssc.wisc.edu/sscc/pubs/screenshots/winstat/Winstat restart.png, https://ssc.wisc.edu/sscc/pubs/screenshots/winstat/winstat1.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Connecting to Winstat using Chrome</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Chrome will not always allow the Citrix Receiver to start automatically when you connect to Winstat unless you explicitly allow it to do so. Fortunately it's a very easy change to make.</p>
<p>Start Chrome and type <span class="InputCode">chrome://plugins</span> in the address bar.</p>
<p><img alt="chrome://plugins in the address bar" height="37" src="https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_chrome/winstat_chrome1.png" width="637"/></p>
<p>Find <span class="MenuOutput">Citrix ICA Client</span> in the list, and check the box for <span class="MenuOutput">Always Allowed</span>.</p>
<p><img alt="Entry for Citri ICA Client with Always Allowed checked" height="77" src="https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_chrome/winstat_chrome2.png" width="474"/></p>
<p>Log into Winstat as usual and it will now work.</p>
<p>Note that Chrome cannot dected the presence of the Citrix Receiver on your computer, and will suggest you install it every time you log in. You do not need to do so;  click <span class="MenuOutput">Skip to Log on</span> to proceed.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_chrome/winstat_chrome1.png, https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_chrome/winstat_chrome2.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Winstat Solutions: Connecting Using Firefox</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p> Firefox will not allow the Citrix Receiver to start automatically when you connect to Winstat unless you explicitly allow it to do so. Fortunately it's a very easy change to make.</p>
<p>Start Firefox and type <span class="InputCode">about:addons</span> in the address bar.</p>
<p><img alt="Type about: addons in the address bar" height="478" src="https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_firefox/winstat_firefox_1.png" width="672"/></p>
<p>On the left side of the page, choose the <span class="MenuOutput">Plugins</span> section.</p>
<p><img alt="Choose Plugins" height="478" src="https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_firefox/winstat_firefox_2.png" width="672"/></p>
<p>Find <span class="MenuOutput">Citrix ICA Client</span> in the list, and change it from <span class="MenuOutput">Ask to Activate</span> to <span class="MenuOutput">Always Activate</span>.</p>
<p><img alt="Find Citrix ICA client, set it to Always Activate" height="478" src="https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_firefox/winstat_firefox_3.png" width="672"/></p>
<p>Log into Winstat as usual and it will now work.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_firefox/winstat_firefox_1.png, https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_firefox/winstat_firefox_2.png, https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_firefox/winstat_firefox_3.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>SSCC - Social Science Computing Cooperative</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>You can change the size of the fonts used by Windows on Winstat using the <span class="MenuOutput">ChangeFontSize</span> program. Note that <span class="MenuOutput">ChangeFontSize</span> does not control font sizes in documents, or in the windows used by many programs. Often these programs have their own tools for setting font sizes (most browsers will increase the font size if you press Control-+, for example). However, many programs use the Windows fonts and are affected by <span class="MenuOutput">ChangeFontSize</span>.</p>
<p>To start <span class="MenuOutput">ChangeFontSize</span>, click <span class="MenuOutput">Start</span>, <span class="MenuOutput">All Programs</span>, and then <span class="MenuOutput">ChangeFontSize</span> (it is not inside a folder). You'll get the following window:</p>
<table align="center" border="0" cellpadding="3" class="noBorder">
<tr>
<td><img alt="ChangeFontSize program window" height="326" src="https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_fonts/winstat_fonts1.png" width="416"/></td>
</tr>
</table>
<p>Move the slider side-to-side to preview sizes; clicking one of the size buttons will close the program and apply the new setting. It will be applied in programs immediately, but you'll have to log out and log back on for it to be applied in some places.</p>
<table align="center" border="0" cellpadding="3" class="noBorder">
<tr>
<th>TextPad with Normal Fonts</th>
</tr>
<tr>
<td align="center"><img alt="TextPad with normal fonts" height="241" src="https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_fonts/winstat_fonts2.png" width="424"/></td>
</tr>
<tr>
<th>TextPad with Large Fonts</th>
</tr>
<tr>
<td align="center"><img alt="TextPad with large fonts" height="275" src="https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_fonts/winstat_fonts3.png" width="561"/></td>
</tr>
</table>
<p>If you change your mind, start ChangeFontSize again and click the Normal button.                </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_fonts/winstat_fonts1.png, https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_fonts/winstat_fonts2.png, https://ssc.wisc.edu/sscc/pubs/screenshots/winstat_fonts/winstat_fonts3.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Using WiscList</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>WiscList is a free email distribution service for the UW Madison community. It is self serviced and administrated via the <a href="https://admin.lists.wisc.edu" title="WiscList Admin page">WiscList Admin </a>web interface. You will need your NetID credentials to access the admin site.</p>
<p>
WiscList has a 5mb message size limit. We suggest <a href="https://kb.wisc.edu/helpdesk/page.php?id=42214  " title="using Box or Google Drive">using Box or Google Drive</a> to share larger files with a list. </p>
<h2>Belonging to a WiscList </h2>
<ul>
<li><a href="https://kb.wisc.edu/page.php?id=5683" title="subscribe to WiscList">Subscribing to a WiscList</a></li>
<li><a href="https://kb.wisc.edu/helpdesk/page.php?id=16188" title="Managing Your WiscList Subscriptions">Managing Your WiscList Subscriptions</a></li>
<li><a href="https://kb.wisc.edu/helpdesk/page.php?id=7584" title="Problems Sending to a WiscList">Problems Sending to a WiscList</a> <br/>
</li>
<li><a href="https://kb.wisc.edu/helpdesk/page.php?id=5684" title="Unsubscribing from a WiscList">Unsubscribing from a WiscList</a></li>
</ul>
<h2>Administering WiscLists</h2>
<ul>
<li><a href="https://kb.wisc.edu/helpdesk/page.php?id=16150">Creating a New WiscList</a></li>
<li><a href="https://kb.wisc.edu/helpdesk/page.php?id=5686" title="Adding Members to a WiscList">Adding Members to a WiscList</a></li>
<li><a href="https://kb.wisc.edu/helpdesk/page.php?id=22034" title="Sending to a WiscList">Sending to a WiscList</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/ https:/kb.wisc.edu/helpdesk/page.php?id=31874" title="Administering a WiscList">Administering a WiscList</a></li>
<li><a href="https://kb.wisc.edu/helpdesk/page.php?id=5666" title="Sending the Same Message to Multiple WiscLists (Crossposting)">Sending the Same Message to Multiple WiscLists (Crossposting)</a></li>
<li><a href="https://kb.wisc.edu/helpdesk/page.php?id=31874" title="WiscList Security">WiscList Security</a></li>
<li><a href="https://kb.wisc.edu/helpdesk/page.php?id=17089">Searching Your WiscLists</a></li>
<li><a href="https://kb.wisc.edu/helpdesk/page.php?id=19185">Bulk Removing Members from a WiscList</a></li>
<li><a href="https://kb.wisc.edu/helpdesk/page.php?id=22004" title="Deleting a WiscList">Deleting a WiscList</a></li>
<li><a href="https://kb.wisc.edu/helpdesk/page.php?id=5591">Known Issues with WiscList</a></li>
</ul>
<p>For more information, please see the <a href="https://kb.wisc.edu/wisclist/ " title="WiscList Knowledgebase">WiscList KnowledgeBase</a></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Getting Started with WordPress</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>WordPress is open source, free blogging and website creation  software that allows users to easily create professional looking and highly  customizable websites without needing any web coding or HTML knowledge. Site creation and management is done entirely  via a web interface so no special software is needed to create a site, and it  can be edited from any computer with an internet connection. For more information on the features of  WordPress, please see <a href="http://codex.wordpress.org/WordPress_Features">http://codex.wordpress.org/WordPress_Features</a>.</p>
<p>If you are an SSCC member who is interested in using WordPress, SSCC staff would be happy to meet with you one-on-one and give you an introduction to the program. Just contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a>.</p>
<h2>Getting a WordPress site</h2>
<p>SSCC Members can request a WordPress site here:   <a href="https://www.ssc.wisc.edu/sscc_jsp/account/wordpress/">https://www.ssc.wisc.edu/sscc_jsp/account/wordpress/</a>. Your site  URL will be <span class="InputCode">http://ssc.wisc.edu/~</span><span class="Parameter">username</span> (you can also customize this location).</p>
<p>WordPress uses a separate account from your regular SSCC account. Once your site has been set up, you will receive an email with  login information. You will be prompted  to reset your password on first login.</p>
<p>The files for your site will be stored in <span class="InputCode">Z:\PUBLIC_web\ </span>(unless you chose a custom location).</p>
<h2>Setting up your  WordPress site</h2>
<p>You can access the WP site administration Dashboard at <span class="InputCode">http://ssc.wisc.edu/~</span><span class="Parameter">username</span><span class="InputCode">/wp-admin</span>. The Dashboard is where you create table and  manage your site. For more information  on the administration options for your site, please see <a href="http://codex.wordpress.org/Administration_Panels">http://codex.wordpress.org/Administration_Panels</a>.</p>
<p><img alt="WordPress Admin Dashboard" height="357" src="https://ssc.wisc.edu/sscc/pubs/screenshots/wordpress/wp1.jpg" width="648"/></p>
<p>By default your site title is set to your full name, with  “My SSCC Homepage” as the tagline. This  can be changed by going to <span class="MenuOutput">Settings</span> -&gt; <span class="MenuOutput">General</span>.</p>
<h2>Updating WordPress</h2>
<p>It is your responsibility to keep your WordPress site up to date. Outdated   versions of the WordPress software may have security problems that put your site content and the SSCC web server at risk. When a new version of WordPress is available,  a link will appear at the top of your Dashboard as in the image above. You can also check for updates by clicking <span class="MenuOutput">Dashboard</span> -&gt;   <span class="MenuOutput">Updates</span> on the navigation panel to the left.</p>
<p>A word of caution about updating: �If you use plugins or custom themes, check that they will work   with the new release before updating or you may lose their   functionality. You can check compatibility by searching for your   individual plugins at�<a href="http://wordpress.org/extend/plugins/">http://wordpress.org/extend/plugins/</a>.                </p>
<h2>Choosing a Theme</h2>
<p>The look and feel of your WordPress site is determined by the Theme you   choose. As this will effect how your site content is displayed, it is   generally recommended to choose a theme first before you add content. Your SSCC site will have a UW-Madison theme set as default. If you do   not want your site to be UW-branded, you are welcome to change your   theme to any of the included default WordPress themes or to install your   own theme from the thousands of options in WordPress’s theme library.   You can change and install themes by going to <span class="MenuOutput">Appearance -&gt; Themes</span>.  </p>
<p>For more information on choosing and working with Themes, please see <a href="http://codex.wordpress.org/Using_Themes">http://codex.wordpress.org/Using_Themes</a>.</p>
<h2>Adding your Content</h2>
<p>Your SSCC WP site will have a Home page created by default;  to create additional pages go to <span class="MenuOutput">Pages</span> -&gt; <span class="MenuOutput">Add New</span>.</p>
<p>Content (including text, media, pictures, PDFs, Word  Documents, etc.) can be added to your Pages via the “What You See Is What You  Get” editor or via HTML coding.</p>
<img alt="The WYSISWYG Editor" height="277" src="https://ssc.wisc.edu/sscc/pubs/screenshots/wordpress/wp2.jpg" width="787"/>
<h2>Using Plugins</h2>
<p>WordPress  plugins can be installed  to extend the functionality of your site to meet your needs.  Plugins can include spam filters, photo  galleries, weather reports, Twitter/RSS feeds, site counters, calendars,  etc.  For more information on using  plugins and to access the official WordPress plugin repository, please see <a href="http://codex.wordpress.org/Plugins">http://codex.wordpress.org/Plugins</a>.</p>
<p>WordPress.org has excellent documentation on WP and all of  its functions, from basic to advanced, which can be found here: <a href="http://codex.wordpress.org/">http://codex.wordpress.org/</a> </p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/wordpress/wp1.jpg, https://ssc.wisc.edu/sscc/pubs/screenshots/wordpress/wp2.jpg</img_base_url>
</kb_document>
<kb_document>
<kb_title>Working From Home or Elsewhere Off-Campus</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Most of the SSCC's resources can be used from any location, so working from home or another remote location is very practical. This article will introduce you to the available tools and point you to Knowledge Base articles that will show you how to use them. Note that for our purposes you are at a "remote location" if your computer is not plugged into the Sewell Social Sciences Building wired network. Thus this article would apply even if you're using the wireless network in the building. Topics to be covered are:</p>
<ul>
<li><a href="#UsingWinstat">Using Winstat</a></li>
<li><a href="#UsingLinstat">Using Linstat</a></li>
<li><a href="#UsingYourOfficeComputer">Using Your Office Computer</a></li>
<li><a href="#UsingFilesontheSSCCNetwork">Using Files on the SSCC Network</a></li>
</ul>
<p> </p>
<h2><a id="UsingWinstat" name="UsingWinstat"></a>Using Winstat</h2>
<p>Logging in to Winstat gives you access to almost all the statistical software available at the SSCC and all the files on the SSCC network. You can also use it to transfer files between the SSCC network and your own computer. This makes it the obvious choice for working from home.</p>
<ul>
<li><a href="https://www.ssc.wisc.edu/sscc/pubs/winstat.htm">Using Winstat</a></li>
</ul>
<p><em>Winstat is a highly convenient tool for working from home, but in the event of a pandemic, extreme weather, or other situation that prompts a large fraction of SSCC members to work from home it's possible Winstat would be overwhelmed. We suggest having a backup plan in case you can't use Winstat.</em></p>
<ul>
<li><em>If your <a href="#UsingYourOfficeComputer">office computer</a> has the software you need, you can log into it remotely. Note that this needs to be set up ahead of time—we'd suggest doing it now!</em></li>
<li><em>If you need to work with <a href="#UsingFilesontheSSCCNetwork">files on the network</a> but have the software you need on your home computer (in some cases just Word), you can get access to your files from your home computer.</em></li>
<li><em>If you need to use statistical software and are comfortable using Linux, you can connect directly to <a href="#UsingLinstat">Linstat</a> and run programs there</em></li>
</ul>
<h2><a id="UsingLinstat" name="UsingLinstat"></a>Using Linstat</h2>
<p>You can log into Linstat from home either by logging in to Winstat and running X-Win32 there, or by connecting directly from your home computer. <a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a> has instructions for Windows, Mac and Linux.</p>
<ul>
<li><a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a></li>
</ul>
<h2><a id="UsingYourOfficeComputer" name="UsingYourOfficeComputer"></a>Using Your Office Computer</h2>
<p>It's possible to log in to your office computer from home and use it via "Remote Desktop" or "Screen Sharing." The result is similar to logging in to Winstat, though Winstat will generally give you better performance and stability. However, if you have software on your office computer that is not available on Winstat, connecting to it will allow you to use that software from home. In order to use Remote Desktop, you will need to request that SSCC Staff configure your desktop for remote access.</p>
<p>If your computer is not in the Sewell Social Sciences Building it may still be possible to connect to it remotely, but check with your local IT staff.</p>
<ul>
<li><a href="https://ssc.wisc.edu/sscc/pubs/vpn.htm">Connecting to the SSCC Network via VPN</a> (Windows and Mac)</li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/remote_desktop.htm">Connecting to Your Office Computer Using Remote Desktop (Windows)</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/screen_sharing.htm">Connecting to Your Office Computer Using Screen Sharing (Mac)</a></li>
</ul>
<h2><a id="UsingFilesontheSSCCNetwork" name="UsingFilesontheSSCCNetwork"></a>Using Files on the SSCC Network</h2>
<p>You can use files on the SSCC network from any location by first connecting to the SSCC network using Virtual Private Networking (VPN) and then connecting to the usual network drives.             </p>
<p>Secure File Transfer Protocol (SFTP) is an alternative method for accessing files, with SecureFX being our suggested SFTP client for Windows.</p>
<ul>
<li><a href="https://ssc.wisc.edu/sscc/pubs/vpn.htm">Connecting to the SSCC Network via VPN</a> (Windows and Mac)</li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/5-26.htm">Mapping a Drive to a Network Share in Windows</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/diskfrommac.htm">Using SSCC Network Disk Space from Macs</a></li>
<li><a href="https://www.ssc.wisc.edu/sscc/pubs/5-35.htm">Transferring Files Using SecureFX</a></li>
<li><a href="https://www.ssc.wisc.edu/sscc/pubs/1-11.htm">Using SFTP</a></li>
</ul>
<h2><a id="LearningMore" name="LearningMore"></a>Learning More</h2>
<p>For more information about working from home see the <a href="https://ssc.wisc.edu/sscc/pubs/remote.htm">Remote Computing</a> section of our Knowledge Base, or contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a>. Campus resources include:</p>
<ul>
<li><a href="http://kb.wisc.edu/helpdesk/page.php?id=10038">Campus Tools to Work Remotely</a></li>
<li> <a href="http://kb.wisc.edu/library/page.php?id=4773">Library - Remote Access to Library Resources</a></li>
<li><a href="http://kb.wisc.edu/education/page.php?id=17196">Preparing for Instruction at a Distance</a></li>
</ul>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Opening WordPerfect Documents using Word</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>Microsoft Word for Windows can be used to open  Wordperfect documents even if you don't have WordPerfect installed on your computer. Unfortunately any changes you make can only be saved in Word format, so if you're collaborating with someone who uses WordPerfect you'll probably want to use the actual WordPerfect program instead. (WordPerfect is available on Winstat.) However, if you just need to read WordPerfect documents then this solution allows you to do so on your own computer.</p>
<p>Mac Users: The Mac version of Microsoft Word cannot open WordPerfect documents. You can use WordPerfect on Winstat to open WordPerfect documents and then save them in Word format for later use on your Mac.</p>
<p>To make all WordPefect documents open in Microsoft Word on your computer:</p>
<ol>
<li>Locate any WordPerfect document. If you do not have Wordperfect installed on your computer, the file icon will probably look like a white rectangle and you will be able to see the <span class="InputCode">.wpd</span> extension at the end of the file name. Right click on the document and choose <span class="MenuOutput">Properties</span>.</li>
<li>In the <span class="MenuOutput">Properties</span> window, make sure you're on the <span class="MenuOutput">General</span> tab and click the <span class="MenuOutput">Change</span> button next to <span class="MenuOutput">Opens with</span>. A new window will open with a list of programs on your computer.</li>
<li>Select <span class="MenuOutput">Microsoft Word</span>. Make sure <span class="MenuOutput">Always use the selected program to open this kind of file</span> is checked. Optionally type a short description, like <span class="InputCode">WordPerfect Document</span>. When you're done, click <span class="MenuOutput">OK</span>.</li>
</ol>
<table border="0" cellpadding="3" class="noBorder" width="100%">
<tr>
<td align="center"><img alt="Open with Microsoft Word" height="478" src="https://ssc.wisc.edu/sscc/pubs/screenshots/wp_word_1.png" width="579"/></td>
</tr>
</table>
<p> </p>
<p>You'll know it worked when the icon for the document changes to the Word icon. From now on, any WordPerfect documents you double-click on will open in Word automatically.</p>
<p>If Microsoft Word does not appear in the list, click <span class="MenuOutput">Browse</span> to be taken to the default location where programs are installed on your computer, usually <span class="InputCode">C:\Program Files</span>. Open
<span class="InputCode">C:\Program Files\Microsoft Office\Office</span><span class="Parameter">XX</span> (where <span class="Parameter">XX</span> is the version number of Office you have installed) and choose <span class="InputCode">WINWORD.EXE</span>. If it's not there, look under <span class="InputCode">C:\Program Files (x86)</span>. If you still can't find it (and you know Word is installed on your computer) contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a> for assistance.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/wp_word_1.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>SSCC - Social Science Computing Cooperative</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>The Refworks Write-N-Cite plugin for Microsoft Word is available on Winstat, but you'll need to install it before using it. To do so, first completely close Word. Then click <span class="MenuOutput">Start</span>, <span class="MenuOutput">Programs</span>, <span class="MenuOutput">Refworks</span>, <span class="MenuOutput">Install Write-N-Cite Plugin for Word</span>. Click <span class="MenuOutput">OK</span> in the two dialog boxes that come up, and the plugin will be ready for use.                </p>
<p>You can verify that it is installed by starting Word and then clicking the <span class="MenuOutput">Add-Ins</span> tab. You should see a box for <span class="MenuOutput">Refworks Write-N-Cite Menu Commands</span> and <span class="MenuOutput">Write-N-Cite Custom Toolbars</span>.</p>
<p><img alt="Add-Ins Tab in Word" height="259" src="https://ssc.wisc.edu/sscc/pubs/screenshots/writencite/writencite_4.png" width="564"/></p>
<p>Keep in mind that SSCC staff do not have any expertise with the Write-N-Cite Plugin or Refworks in general and can't answer questions about it.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/screenshots/writencite/writencite_4.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Resources</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>
<!-- InstanceBeginEditable name="Content" -->
<p>The following pages contain resources of interest to different groups of people:</p>
<p><a href="https://ssc.wisc.edu/sscc/resources/members.htm" title="Resources for SSCC Members">SSCC Members</a></p>
<p><span class="RightNavLink"><a href="https://ssc.wisc.edu/sscc/instruction/" title="Resources for Instructors">Instructors who would like to use SSCC resources for their class</a></span></p>
<p><span class="RightNavLink"><a href="https://ssc.wisc.edu/sscc/instruction/labusers.htm" title="Resources for Lab Users">SSCC Instructional Lab Users</a></span></p>
<p><span class="RightNavLink"><a href="https://ssc.wisc.edu/sscc/resources/newmembers.htm" title="Resources for New Members">People who have just received an SSCC account</a></span></p>
<p><span class="RightNavLink"><a href="https://ssc.wisc.edu/sscc/resources/visitors.htm" title="Resources for Visitors">Visitors to the SSCC Web Site</a></span></p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Resources for SSCC Members</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<a id="content" name="content"></a>
<div id="RightContentLeftCol"><!-- InstanceBeginEditable name="Menu" -->
<p><a href="#account">Your  Account</a></p>
<p><a href="#Email">Email</a></p>
<p><a href="#Computing">Computing</a></p>
<p><a href="#Info">Info</a></p>
<p><a href="#Services">Services</a></p>
<p><a href="#EmailLists">Email Lists</a></p>
<!-- InstanceEndEditable --></div>
<div id="RightContentRightCol"><div><!-- InstanceBeginEditable name="Content" -->
<p><a href="https://ssc.wisc.edu/sscc/about/services.htm">List of SSCC Services</a></p>
<h2><a id="account" name="account"></a>Your   Account</h2>
<p><span class="webtool" style="{margin-top:1em;"><a href="https://www.ssc.wisc.edu/sscc_jsp/password">Change 
                    your SSCC Password</a></span></p>
<p><a href="https://www.ssc.wisc.edu/sscc_jsp/password/questions.jsp">Set 
                        your Security Questions</a></p>
<p><a href="https://www.ssc.wisc.edu/sscc_jsp/password/reset.jsp">Reset 
                        your Password if you've forgotten it</a></p>
<p><a href="https://www.ssc.wisc.edu/sscc_jsp/email/pref.jsp">Set your Preferred Email Address</a></p>
<p><a href="https://www.ssc.wisc.edu/sscc_jsp/account/lab.jsp">Request 
                        After-Hours Lab Access</a></p>
<p><a href="https://www.ssc.wisc.edu/sscc_jsp/account/space">Request 
                        Additional Disk Space</a></p>
<p><a href="https://www.ssc.wisc.edu/sscc_jsp/account/project">Request Project (Shared) Disk Space</a></p>
<p><a href="https://tools.ads.ssc.wisc.edu/printstatus/index.asp">View 
                      your Printing Usage</a></p>
<h2><a id="Computing" name="Computing"></a>Computing</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/computing_resources.htm">Computing Resources at the SSCC</a></p>
<p><a href="https://ssc.wisc.edu/sscc/resources/sensitive_data.htm">Resources for Working with Sensitive Data</a></p>
<p><a href="https://ssc.wisc.edu/sscc/infrastructure/sensitive.htm">Sensitive Data Facilities</a></p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/working_from_home.htm">Working From Home and Other Remote Locations</a></p>
<p><a href="https://www.ssc.wisc.edu/sscc_jsp/condor/">Submit a Stata job to HTCondor</a></p>
<p><a href="https://www.ssc.wisc.edu/sscc_jsp/account/wordpress/">Request a Personal WordPress Web Site</a></p>
<h2><a id="Info" name="Info"></a>Info</h2>
<p><a href="https://ssc.wisc.edu/sscc/pubs/">SSCC Knowledge Base</a></p>
<p><a href="https://www.ssc.wisc.edu/sscc_jsp/software/">SSCC Software</a></p>
<p><a href="https://ssc.wisc.edu/sscc/policies/home.htm">SSCC Policies</a> </p>
<p><a href="http://flash.ssc.wisc.edu/ganglia">Flash 
                    Cluster Status</a></p>
<p><a href="http://outages.doit.wisc.edu/">Campus IT Outages</a></p>
<h2><a id="Services" name="Services"></a>Services</h2>
<p><a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a></p>
<p><a href="https://www.ssc.wisc.edu/sscc_jsp/archive">Request 
                    File Archiving</a></p>
<p><a href="https://ssc.wisc.edu/sscc/infrastructure/docscan.htm">Document Scanning</a></p>
<h2><a id="EmailLists" name="EmailLists"></a>Email Lists</h2>
<p><a href="http://listar.ssc.wisc.edu/listar.cgi">Listar 
                        Mailing List Interface</a> </p>
<!-- InstanceEndEditable --></div></div>

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Resources for New Members</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<a id="content" name="content"></a>
<div id="RightContentLeftCol"><!-- InstanceBeginEditable name="Menu" -->
<p><a href="#account">Get an Account</a></p>
<p><a href="#login">Log In</a></p>
<p><a href="#learn">Learn More</a></p>
<p><a href="#help">Get Help</a></p>
<!-- InstanceEndEditable --></div>
<div id="RightContentRightCol"><div><!-- InstanceBeginEditable name="Content" -->
<p>Welcome to the SSCC! This page will direct you to the resources you need to get starting using SSCC services. However, what those are will depend on whether you are an <strong>SSCC Member </strong>or a <strong>Lab User</strong>. In each of the sections below, look for the instructions that apply to your situation.</p>
<h2><a id="account" name="account"></a>Get an Account</h2>
<p> If you don't have an account yet, <a href="https://ssc.wisc.edu/sscc/accounts/new.htm">request one online</a>. Once it has been created, you'll then need to activate it:</p>
<p><a href="https://www.ssc.wisc.edu/sscc_jsp/account/activate.jsp">Account activation for new Members</a></p>
<p><a href="https://www.ssc.wisc.edu/sscc_jsp/account/lab/activate.jsp">Account activation for new Lab Users</a> </p>
<h2><a id="login" name="login"></a>Log In</h2>
<p>Most of your computing will probably take place on Winstat, the SSCC's Windows Terminal Server farm:</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">Using Winstat</a></p>
<p>The SSCC also has <a href="https://ssc.wisc.edu/sscc/infrastructure/labs.htm">computer labs</a> in the Sewell Social Sciences Building.</p>
<p>If you are an <strong>SSCC Member</strong> and need to work with sensitive data (including HIPAA data) you'll need to use our secure computing environment, Silo. <strong>Lab Users</strong> do not have access to Silo.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/silo.htm">Using  Silo</a></p>
<p>If you are an <strong>SSCC Member</strong> and need more <a href="https://ssc.wisc.edu/sscc/pubs/computing_resources.htm">computing power</a>, you may want to use our Linux computing cluster, Linstat.  <strong>Lab Users</strong> do not have access to Linstat.</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Using Linstat</a> </p>
<h2><a id="learn" name="learn"></a>Learn More</h2>
<p>The <a href="https://ssc.wisc.edu/sscc/pubs/home.htm">SSCC Knowledge Base</a> should be your first resource for learning about the SSCC or statistical computing in general. Knowledge Base articles can teach how to use SSCC resources, like <a href="https://ssc.wisc.edu/sscc/pubs/linstat.htm">Linstat</a> or <a href="https://ssc.wisc.edu/sscc/pubs/7-1.htm">Condor</a>. Articles on statistical computing range from general introductions like <a href="https://ssc.wisc.edu/sscc/pubs/sfs/">Stata for Students</a> or Data Wrangling in <a href="https://ssc.wisc.edu/sscc/pubs/dws/data_wrangling_stata1.htm">Stata</a>, <a href="https://ssc.wisc.edu/sscc/pubs/DWE/book/preface.html">R</a>, or <a href="https://ssc.wisc.edu/sscc/pubs/DWE/book/preface.html">Python</a>, to specific topics  like <a href="https://ssc.wisc.edu/sscc/pubs/stata_bar_graphs.htm">making bar graphs</a> and <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">mixed models</a>. Some especially good places to start are:</p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/welcome.htm">Welcome to the SSCC!</a></p>
<p><a href="https://ssc.wisc.edu/sscc/pubs/welcomelab.htm">Welcome to the SSCC! (For Lab Users) </a></p>
<p><a href="https://ssc.wisc.edu/sscc/about/services.htm">SSCC Services</a> </p>
<h2><a id="help" name="help"></a>Get Help</h2>
<p>For help with general computing issues, contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">SSCC Help Desk</a>.</p>
<p>For <a href="https://ssc.wisc.edu/sscc/statconsult.htm">statistical consulting</a>, start by contacting the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">SSCC Help Desk</a>.  This could be anything from "Why is my Stata program crashing?" to "What model should I use for these data?"</p>
<p>For help with personal computers, <strong>SSCC Members</strong> should go to the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">SSCC Help Desk</a>. <strong>Lab Users</strong> should go <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">SSCC Help Desk</a> if they're having trouble connecting to Winstat, but for general PC support they'll need to go to <a href="http://doit.wisc.edu">DoIT</a> or other outside sources.</p>
<!-- InstanceEndEditable --></div></div>

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Resources for Working with Sensitive Data</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>
<!-- InstanceBeginEditable name="Content" -->
<p>If you are part of the College of Letters and Science, the <a href="http://disc.wisc.edu/">Data &amp; Information Services Center</a> (DISC) can help you understand and comply with the rules for working with sensitive data. To request assistance, contact DISC Director Jack Solock (<a href="mailto:jsolock@ssc.wisc.edu">jsolock@ssc.wisc.edu</a>). For more about the facilities DISC provides, see <a href="https://ssc.wisc.edu/sscc/infrastructure/sensitive.htm">Sensitive Data Facilities</a>. SSCC staff can assist you in implementing DISC recommendations--just contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">Help Desk</a>.</p>
<p>The SSCC follows established best practices for maintaining the security of our computers and data. If a data agreement allows data to be stored on a network at all, it will generally allow the data to be stored on our network.  If you have any questions, DISC staff will be your primary information source for sensitive data issues.</p>
<h2>University Policies on Sensitive Data</h2>
<ul>
<li><a href="http://www.cio.wisc.edu/policies/IEncryptPolicy.pdf">Storage and Encryption of Sensitive Information</a></li>
<li><a href="http://www.cio.wisc.edu/policies/SensitiveDataDefinition.pdf">UW-Madison Sensitive Information Definition</a></li>
<li><a href="http://www.cio.wisc.edu/policies/IReportPolicy.pdf">Information Incident Reporting and Response Policy</a></li>
</ul>
<h2>Campus Initiatives</h2>
<ul>
<li> <a href="http://www.cio.wisc.edu/security/initiatives/restricted.aspx">Restricted Data Security Standards (What is Restricted Data?)</a></li>
<li> <a href="http://www.cio.wisc.edu/security/initiatives/encryption.aspx">Desktop Encryption Project                    </a></li>
<li> <a href="http://www.cio.wisc.edu/security/initiatives/preventTheft.aspx">Prevent Laptop Theft</a></li>
</ul>
<p>The SSCC's #1 recommendation is very simple: <strong>Store all sensitive data on network drives unless the rules for use of that data specifically forbid it.</strong> Files stored on network drives are much more secure than files stored on your laptop or even desktop computer—laptops in particular are very vulnerable to theft, but desktops can be stolen too.</p>
<p>If you must keep sensitive data on your own computer, log off when you leave, lock your   office door, and use passwords wisely. University policy probably requires that you encrypt your hard drive (DISC staff can tell you for sure, and <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">SSCC staff</a> can help you do so). If you had to agree to certain practices in order to get access to the data, be sure to adhere to them strictly.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Resources for Visitors</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>
<!-- InstanceBeginEditable name="Content" -->
<p>The Social Science Computing Cooperative supports researchers        at UW-Madison who use statistical analysis in their work. We provide a complete research computing environment focused on statistics plus the expert help  needed to use it. Some <a href="https://ssc.wisc.edu/sscc/about/services.htm">SSCC services</a> are available only to those affiliated with the SSCC's <a href="https://ssc.wisc.edu/sscc/agencies.htm">member agencies</a>, but others are available to the broader campus community.</p>
<p><a href="https://www.ssc.wisc.edu/sscc_jsp/training/index.jsp">SSCC training classes</a> are  available to anyone in the UW community, though there is a charge for those who are not members. Topics include statistical software and other research tools.</p>
<p>The  <a href="https://ssc.wisc.edu/sscc/pubs">SSCC Knowledge Base</a> is available to anyone. Some articles explain how to use SSCC resources, but the <a href="https://ssc.wisc.edu/sscc/pubs/stat.htm">Statistical Computing</a> section may be useful to anyone who prepares and analyzes data for research.</p>
<p>The SSCC also supports University classes in the Social Science Division. Our <a href="https://ssc.wisc.edu/sscc/instruction/home.htm">resources for instruction</a> include a computer classroom and <a href="https://ssc.wisc.edu/sscc/instruction/labusers.htm">computer labs</a> with statistical software installed, access to <a href="https://ssc.wisc.edu/sscc/pubs/winstat.htm">Winstat</a> for running statistical software from home, and staff assistance for both instructors and students. Graduate students in the Social Science division can also be given <a href="https://ssc.wisc.edu/sscc/accounts/home.htm">lab accounts</a> for their research work.</p>
<p>If you are intereseted in becoming a member of the Cooperative,  see <a href="https://ssc.wisc.edu/sscc/about/join.htm">Joining the SSCC</a>.</p>
<p> If you have any  questions about the SSCC, feel free to contact the <a href="https://ssc.wisc.edu/sscc/helpdesk.htm">SSCC Help Desk</a>.</p>
<!-- InstanceEndEditable -->

</kb_body>
<img_base_url></img_base_url>
</kb_document>
</kb_documents>