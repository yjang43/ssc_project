<?xml version="1.0"?>
<kb_documents>
<kb_document>
<kb_title>Mixed Models: Diagnostics and Inference</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<div id="TOC">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#diagnostics">Diagnostics</a></li>
<li><a href="#additional-inferences">Additional inferences</a></li>
</ul>
</div>
<p>This article is part of the Mixed Model series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">Introduction</a> article. If you're new to mixed models we highly recommend reading the articles in order.</p>
<div class="section level2" id="overview">
<h2>Overview</h2>
<p>This article describes some of the some of the currently available diagnostic tools for mixed models. Also covered in this article are some additional inferences which can be made from mixed models.</p>
<p>Model diagnostics are typically done as models are being constructed. Model construction and diagnostics were split into separate articles for pedagogical purposes, but we recommend doing model diagnostics as models are being constructed.</p>
</div>
<div class="section level2" id="diagnostics">
<h2>Diagnostics</h2>
<p>Mixed models add at least one random variable to a linear or generalized linear model. The random variables of a mixed model add the assumption that observations within a level, the random variable groups, are correlated. Mixed models are designed to address this correlation and do not cause a violation of the independence of observations assumption from the underlying model, e.g. linear or generalized linear. The assumption is relaxed to observations are independent of the other observations except where there is correlation specified by the random variable groups. There is also a new independence assumption for mixed models. This is the effects associated with the random variable groups are uncorrelated with the means of the fixed effect from the random variable groups. All other assumptions for mixed models are the same as the assumptions of the underlying model.</p>
<div class="section level3" id="model-form-diagnostics">
<h3>Model form diagnostics</h3>
<p>An OLS model is assumed to be linear with respect to the predicted value with constant variance. A GLM model is assumed to be linear on the link scale. For some GLM models the variance of the Pearson's residuals is expected to be approximate constant. Residual plots are a useful tool to examine these assumptions on model form. The plot() function will produce a residual plot when the first parameter is a lmer() or glmer() returned object. The following code produces a residual plot for the mm model (constructed in the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a> article of this series.)</p>
<ul>
<li><p>Enter the following command in your script and run it.</p>
<pre><code>plot(mm)</code></pre></li>
<li><p>The results of the above command are shown below.</p>
<div class="figure">
<img alt="Residual plot of mm for lmer object" src="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-2-1.png" width="528"/>
<p class="caption">
Residual plot of mm for lmer object
</p>
</div></li>
</ul>
<p>This residual plot does not indicate any deviations from a linear form. It also shows relatively constant variance across the fitted range. The slight reduction in apparent variance on the right and left of the graph are likely a result of there being fewer observation in these predicted areas.</p>
<p>The residual plot for a logistic model does not provide information on the appropriateness of the model form. They are typically not considered. For other generalized models the residual can assist in assessing the form of the model fit. We will produce a residual plot for our logistic example model to demonstrate how this is done for generalized model.</p>
<p>The plot() function will produce a residual plot for a glmm model that is similar to the plot for lmer models. The plot() function plots the Pearson residuals, residuals scaled by variance function, verses the fitted values on the response scale. For generalized models it is often more useful to examine the residuals plotted on the link scale, <span class="math inline">\(\eta\)</span>, instead of the response scale. The following code demonstrate producing a residual plot on the link scale.</p>
<ul>
<li><p>Enter the following command in your script and run it.</p>
<pre><code>ggplot(data.frame(eta=predict(gmm,type="link"),pearson=residuals(gmm,type="pearson")),
      aes(x=eta,y=pearson)) +
    geom_point() +
    theme_bw()</code></pre></li>
<li><p>The results of the above command are shown below.</p>
<div class="figure">
<img alt="Residual plot of gmm on eta scale" src="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-3-1.png" width="528"/>
<p class="caption">
Residual plot of gmm on eta scale
</p>
</div></li>
</ul>
<p>As expected, this residual plot does not provide information about the model form assumptions for our dichotomous response logistic model.</p>
</div>
<div class="section level3" id="linearity-in-each-variable">
<h3>Linearity in each variable</h3>
<p>Models are assumed to be linear in each of the independent variables. This assumption can be checked with plots of the residuals versus each of the variables. The following code displays the residuals plotted to the x1 and x2 variables.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>ggplot(data.frame(x1=pbDat$x1,pearson=residuals(gmm,type="pearson")),
      aes(x=x1,y=pearson)) +
    geom_point() +
    theme_bw()

ggplot(data.frame(x2=pbDat$x2,pearson=residuals(gmm,type="pearson")),
      aes(x=x2,y=pearson)) +
    geom_point() +
    theme_bw()</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<div class="figure">
<img alt="Residual plot on x1" src="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-4-1.png" width="528"/>
<p class="caption">
Residual plot on x1
</p>
</div>
<div class="figure">
<img alt="Residual plot on x2" src="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-5-1.png" width="528"/>
<p class="caption">
Residual plot on x2
</p>
</div></li>
</ul>
<p>These plot do not raise any concern about a non linear relationship for x1 or x2 variables.</p>
<p>The relationship to the g1 variable was not considered. The assumption for these random levels is that there will be differences in the means. There for we did not plot this relationship.</p>
</div>
<div class="section level3" id="independence">
<h3>Independence</h3>
<p>We will check if the group means of x1 and x2 are correlated with the g1 effects without the shrinkage of the mixed model applied. The following code extracts these values from the pbDat data frame and the model with g1 as a fixed effect. The correlation is then displayed.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>means &lt;- aggregate(pbDat[,c("x1","x2")],by=list(pbDat$g1),FUN=mean)
lmcoefs &lt;- summary(lm(y ~ x1 + x2 + g1, data=pbDat))$coefficients[,"Estimate"]
means$effects &lt;- c(0,lmcoefs[substr(names(lmcoefs),1,2) == "g1"])
means$effects &lt;- means$effects - mean(means$effects)

cor(means[,c("x1","x2","effects")])</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>                 x1         x2    effects
x1       1.00000000 0.01851362 -0.3338548
x2       0.01851362 1.00000000  0.6687850
effects -0.33385483 0.66878500  1.0000000</code></pre></li>
</ul>
<p>We see that both x1 and x2 are moderately correlated, -0.3338548 and 0.668785, with the g1 effects.</p>
<p>The following plots graphically display this correlation.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>ggplot(means, aes(x=x1,y=effects)) +
    geom_point() +
    theme_bw()

ggplot(means, aes(x=x2,y=effects)) +
    geom_point() +
    theme_bw()</code></pre></li>
<li><p>There are no console results from these commands. The following plot is produced.</p>
<div class="figure">
<img alt="plot of x1 group means" src="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-8-1.png" width="528"/>
<p class="caption">
plot of x1 group means
</p>
</div>
<div class="figure">
<img alt="plot of x2 group means" src="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-9-1.png" width="528"/>
<p class="caption">
plot of x2 group means
</p>
</div></li>
</ul>
<p>The x1 plot shows that the groups with effect values of about -100 and -200 are the source of most of the correlation between x1 and g1. The x2 plot shows that it group with the effect value of about -200 is the source of the correlation between x2 and g1.</p>
<p>This correlation may bias the estimates of the fixed effects. The follow code displays the estimated fixed effects from the mm model and the same effects from the model which uses g1 as a fixed effect.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>fixef(mm)
lmcoefs[1:3]</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>(Intercept)          x1          x2 
   3.240341   17.660738  -55.430494 </code></pre>
<pre><code>(Intercept)          x1          x2 
  100.51251    18.26735   -57.60793 </code></pre></li>
</ul>
<p>The coefficient values for x1 and x2 changed by less than 5 percent. One would need to decide based on the science of the analysis being done if this is a meaningful change in the coefficient.</p>
</div>
<div class="section level3" id="normality-of-residuals">
<h3>Normality of residuals</h3>
<p>Normality of the residuals is typically checked with with a q-q plot (quantile-quantile.) Significant deviations from linearity of the observations or non-symmetric scales indicate a deviation from normality of the residuals.</p>
<ul>
<li><p>Enter the following command in your script and run it.</p>
<pre><code>qqnorm(residuals(mm))</code></pre></li>
<li><p>There are no console results from this command. The following plot is produced.</p>
<div class="figure">
<img alt="Residual nrmal probability plot" src="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-11-1.png" width="528"/>
<p class="caption">
Residual nrmal probability plot
</p>
</div></li>
</ul>
<p>The quantile plot (also called a normal probability plot) does not raise any significant concern with normality of the weighted residuals.</p>
</div>
<div class="section level3" id="sensitivity-to-data">
<h3>Sensitivity to data</h3>
<p>It is important to check that your model is not influenced by one or a small set of observations. This might indicate your model is over fit or that your model is sensitive to the particular observations included in the model. Typical tools for measuring leverage and influence are limited for mixed models. This is due to these concepts not transferring from linear and generalized linear models to mixed models. The one tool we have is leverage for linear mixed models.</p>
<p>Mixed models work by providing some shrinkage to the random effects, this is the <span class="math inline">\(\boldsymbol{b}\)</span>s in the <span class="math inline">\(Y \, | \, \boldsymbol{B}=\boldsymbol{b} \ \  \sim \ \ N(\boldsymbol{X\beta} + \boldsymbol{Z b}, \sigma^2 \boldsymbol{I})\)</span> model. Compared to their values as <span class="math inline">\(\boldsymbol{\beta}\)</span>s as fixed effects, the <span class="math inline">\(\boldsymbol{b}\)</span>s are shrunk towards zero, which would be the same as not including the effects in the model as either a fixed or random variable. The shrinkage amount is based on how much information is contained in a random effect groups. This can be used to get a look at what what observations may be stressing the model. This would be done by creating both the fixed effect model and the model with the random effects completely dropped. These will be either linear or generalized linear models. Evaluate both of these models for observations which have high leverage and/or high Cook's distance. Then evaluate the change in the coefficients in the mixed model by dropping the observations which were identified by the linear or generalized model. See the <a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_Diagnostics.html">Regression Diagnostics</a> article for instructions and examples on identifying leverage and Cook's distance in linear and generalized linear models.</p>
<p>The following code generates a plot of the leverage (hatvalues) verse the Pearson residuals.</p>
<ul>
<li><p>Enter the following command in your script and run it.</p>
<pre><code>ggplot(data.frame(lev=hatvalues(mm),pearson=residuals(mm,type="pearson")),
      aes(x=lev,y=pearson)) +
    geom_point() +
    theme_bw()</code></pre></li>
<li><p>The results of the above command are shown below.</p>
<div class="figure">
<img alt="Residual plot verse leverage for mm model" src="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-12-1.png" width="528"/>
<p class="caption">
Residual plot verse leverage for mm model
</p>
</div></li>
</ul>
<p>The following code determines which of the observations have the highest leverage and displays these observations. The code also generates a new model without these observations and then compares the coefficients for the will all observations to this new model with some observations removed.</p>
<ul>
<li><p>Enter the following command in your script and run it.</p>
<pre><code>levId &lt;- which(hatvalues(mm) &gt;= .172)
pbDat[levId,c("y","x1","x2","g1")]
summary(pbDat[,c("y","x1","x2")])

mmLev &lt;- lmer(y ~ x1 + x2 + (1|g1), data=pbDat[-c(levId),])
mmLevCD &lt;- data.frame(effect=fixef(mm),
                     change=(fixef(mmLev) - fixef(mm)),
                     se=sqrt(diag(vcov(mm)))
                     )
rownames(mmLevCD) &lt;- names(fixef(mmLev))
mmLevCD$multiples &lt;- abs(mmLevCD$change / mmLevCD$se)
mmLevCD</code></pre></li>
<li><p>The results of the above command are shown below.</p>
<pre><code>            y        x1          x2 g1
5   -98.06299 -3.286493  0.07252566  E
42   55.73686 -2.144218 -0.98229879  F
93 -214.17818 -2.290438  2.22630416  I
72 -429.90495 -0.750835  3.21873091  L</code></pre>
<pre><code>       y                  x1                x2          
 Min.   :-429.905   Min.   :-3.2865   Min.   :-2.61004  
 1st Qu.: -95.839   1st Qu.:-0.8813   1st Qu.:-0.68087  
 Median :   3.828   Median :-0.1438   Median : 0.14794  
 Mean   :  -2.412   Mean   :-0.1418   Mean   : 0.09448  
 3rd Qu.: 104.556   3rd Qu.: 0.6261   3rd Qu.: 0.77479  
 Max.   : 243.756   Max.   : 2.6189   Max.   : 3.21873  </code></pre>
<pre><code>                effect    change        se  multiples
(Intercept)   3.240341  2.503425 29.815555 0.08396373
x1           17.660738 -4.585005  8.316416 0.55131984
x2          -55.430494  6.015218  8.602384 0.69925012</code></pre></li>
</ul>
<p>These results show that observations 5, 42, 93, and 72 have the highest leverage values. We can also see that either the x1 or x2 variable values are outside of their interquartile range (IQR.) For some of these observations both x1 and x2 are outside their IQR. When these observations are dropped from the model, the value of the coefficients change by one half and two thirds of a standard error. The science of the analysis would be used to determine if this amount of change is a cause for concern or not.</p>
<div class="section level4" id="exercises">
<h4>Exercises</h4>
<p>Use the models from sleepstudy data set for the following exercises.</p>
<ol style="list-style-type: decimal">
<li><p>Create a residual plot for your linear sleep study model, the model from exercise 5 in the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a> article.</p></li>
<li><p>Check the normality of the residuals from your linear sleep study model.</p></li>
<li><p>Check if your linear sleep study model has any leverage points of concern.</p></li>
</ol>
<p><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_Sol.html">Solutions</a></p>
</div>
</div>
</div>
<div class="section level2" id="additional-inferences">
<h2>Additional inferences</h2>
<div class="section level3" id="predictions">
<h3>Predictions</h3>
<p>The response variable for a mixed model is of the form <span class="math inline">\((Y \, | \, B = b)\)</span>, as explained in the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a> article. Predictions can be made for observations which are members of the observed levels of the random variables. This is a group level needs to be specified for each group defined in the random formula for the model. Since particular levels of random effects are not formal estimates of the model, care needs to be used when interpreting predicted values based on these levels.</p>
<p>The model results include an estimate of the mean value for each population represented by groups in the random portion of the model formula. These estimates of population means are incorporated in the fixed portion of the model. Predictions can also be made for these mean values. This is done by setting the re.form parameter of the predict() function to NA. These estimated means are formally estimated by the model and can be directly interpreted.</p>
<p>The predict() function does not produce a standard error for the predictions. This is due in part to the lack of a standard error for the estimated variance of the unobserved variables. If one was willing to make an assumptions about the variance, a parametric bootstrap could be used to produce a prediction intervals or confidence intervals.</p>
<p>We will use the predict function to estimate the predicted values for x1 = .5 at x2 = -.5 and x1 = -2 at x2 = .25. These will be estimates at the mean value of the unobserved random variable which was sampled at the level in variable g1. We then predict the response for these same two observations at the g1 level of "B". These predictions will be made on both the link scale (log odds for our gmm model) and the response scale (as probabilities.) The following code calculates these predictions.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>newDat &lt;- data.frame(x1=c(.5,-2),x2=c(-.5,.25))
predict(gmm,newDat,re.form=NA,type="link")
predict(gmm,newDat,re.form=NA,type="response")</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>        1         2 
 1.172611 -1.212977 </code></pre>
<pre><code>        1         2 
0.7636167 0.2291748 </code></pre></li>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>newDat2 &lt;- data.frame(x1=c(.5,-2),x2=c(-.5,.25),g1=c("B","B"))
predict(gmm,newDat2,type="link")
predict(gmm,newDat2,type="response")</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>         1          2 
 1.8154964 -0.5700918 </code></pre>
<pre><code>        1         2 
0.8600248 0.3612156 </code></pre></li>
</ul>
</div>
<div class="section level3" id="inter-class-correlation-icc">
<h3>Inter Class Correlation (ICC)</h3>
<p>ICC is a measure of how much of the variation in the response variable, which is not attributed to fixed effects, is accounted for by a random effect. It is the ratio of the variance of the random effect to the total random variation. The code to calculate the ICC for the mm model is demonstrated here.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>r1Var &lt;- as.numeric(VarCorr(mm)[["g1"]])
residVar &lt;- attr(VarCorr(mm), "sc")^2
r1Var
residVar
r1Var / (r1Var + residVar)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>[1] 9736.123
[1] 7564.864
[1] 0.5627496</code></pre></li>
</ul>
<p>This would be interpreted as 56 percent of the stochastic variation is accounted for by g1.</p>
<p>For the generalized model, the residual variance is a known constant. We will use <span class="math inline">\((15/16)^2 \pi^2 / 3\)</span> as an estimate of the variance of the logistic distribution.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>r1Var &lt;- as.numeric(VarCorr(gmm)[["g1"]])
residVar &lt;- (15/16)^2 * pi^2 / 3
r1Var
residVar
r1Var / (r1Var + residVar)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>[1] 4.255377
[1] 2.891486
[1] 0.5954189</code></pre></li>
</ul>
<p>The g1 variable accounts for 60 percent of the stochastic variation in the gmm model.</p>
<div class="section level4" id="exercises-1">
<h4>Exercises</h4>
<p>Use the models from sleepstudy data set for the following exercises.</p>
<ol start="4" style="list-style-type: decimal">
<li>Predict the average response time for eight days in the sleep deprivation study. The model from exercise 5 in the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a> article.</li>
</ol>
<p><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_Sol.html">Solutions</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_TestEffects.html">Testing Significance of Effects</a></p>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_MultRand.html">Multiple Random Parameters</a></p>
<p>Last Revised: 3/30/2016</p>
</div>
</div>
</div>

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-2-1.png, https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-3-1.png, https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-4-1.png, https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-5-1.png, https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-8-1.png, https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-9-1.png, https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-11-1.png, https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_files/figure-html/unnamed-chunk-12-1.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Mixed Models: Diagnostics and Inference solutions</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<p>This article contains solutions to exercises for an article in the mixed models series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">Introduction</a>.</p>
<p>There is often more than one approach to the exercises. Do not be concerned if your approach is different than the solution provided.</p>
<ul>
<li><p>We will load some packages which will be used in the solutions.</p>
<pre class="r"><code>library(ggplot2)</code></pre></li>
</ul>
<div class="section level4" id="exercise-solutions">
<h4>Exercise solutions</h4>
<p>Use the models from sleepstudy data set for the following exercises. The models used in these solutions were constructed in the the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models_Sol.html">Solutions</a> for the Model's article.</p>
<ol style="list-style-type: decimal">
<li><p>Create a residual plot for your linear sleep study model.</p>
<pre class="r"><code>plot(ssc)</code></pre>
<p><img src="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_Sol_files/figure-html/unnamed-chunk-4-1.png" width="672"/></p></li>
<li><p>Check the normality of the residuals from your linear sleep study model.</p>
<pre class="r"><code>qqnorm(residuals(ssc))</code></pre>
<p><img src="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_Sol_files/figure-html/unnamed-chunk-5-1.png" width="672"/></p></li>
<li><p>Check if your linear sleep study model has any leverage points are of concern.</p>
<pre class="r"><code>ggplot(data.frame(lev=hatvalues(ssc),pearson=residuals(ssc,type="pearson")),
    aes(x=lev,y=pearson)) +
  geom_point() +
  theme_bw()</code></pre>
<p><img src="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_Sol_files/figure-html/unnamed-chunk-6-1.png" width="672"/></p></li>
<li><p>Predict the average response time for eight days in the sleep deprivation study.</p>
<pre class="r"><code>newDatSS &lt;- data.frame(Days=c(8))
predict(ssc,newDatSS,re.form=NA,type="response")</code></pre>
<pre><code>       1 
335.1434 </code></pre></li>
</ol>
<p>Return to the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer.html">Diagnostics and Other Inferences</a> article</p>
<p>Last Revised: 3/30/2016</p>
</div>

</kb_body>
<img_base_url>https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_Sol_files/figure-html/unnamed-chunk-4-1.png, https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_Sol_files/figure-html/unnamed-chunk-5-1.png, https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer_Sol_files/figure-html/unnamed-chunk-6-1.png</img_base_url>
</kb_document>
<kb_document>
<kb_title>Mixed Models: Introduction</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<div id="TOC">
<ul>
<li><a href="#about-this-series">About This Series</a></li>
<li><a href="#materials-for-these-articles">Materials for these articles</a></li>
</ul>
</div>
<p>Mixed Models are regression models which contain random and fixed effects. These models are widely used by researchers to account for sources of variation in their studies.</p>
<p>The examples in this article series are done using the R language. Just enough R is covered to allow one to follow the examples and to do the exercises. The R results from the exercises contains similar information to the results produced by other statistical software languages, such as Stata and SAS. Thus, this article series will be useful to anyone who is learning how to include mixed models in their research.</p>
<div class="section level2" id="about-this-series">
<h2>About This Series</h2>
<p>The goal of the Mixed Model article series is to provide you with an introduction to the theory of mixed models. The focus of the included theory is to provide an understanding of how mixed models differ from fixed effect models and how these differences change diagnostics and inferences.</p>
<p>The Mixed Models article series includes the following articles:</p>
<ol style="list-style-type: decimal">
<li><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">Introduction</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_TestEffects.html">Testing Significance of Effects</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer.html">Diagnostics and Other Inferences</a></li>
<li><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_MultRand.html">Multiple Random Parameters</a></li>
</ol>
<p>The Models article provides a brief overview of mixed models theory and the terminology which will be used throughout this article series. The Models article also explains how random model parameters are specified and how to construct mixed models using lmer() and glmer() from the lme4 package in R.</p>
<p>The Testing Significance of Effects article provides an overview of testing significance in mixed models. Mixed models in many cases do not have asymptotic theory to rely on for tests of significance. This article provides some background on a few of the common tests which are available to test for significance.</p>
<p>The Diagnostics and Other Inferences article describes some of the available diagnostic tools for mixed models. Some additional inferences which can be made from mixed models are also covered.</p>
<p>The Multiple Random Parameters article cover models which contain both random intercepts and random slopes. Nested and crossed effects are also covered.</p>
</div>
<div class="section level2" id="materials-for-these-articles">
<h2>Materials for these articles</h2>
<p>The instruction for loading the data sets and R packages needed to work the examples and exercises in these articles is included in the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a> article.</p>
<p>Most of the models in the examples are constructed using the lme4 package in R. If you have any difficulties following the R code in the examples, the <a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_Introduction.html">R For Researchers</a> article series provides an introduction to R.</p>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a></p>
<p>Last Revised: 9/28/2016</p>
</div>

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Mixed Models: Models</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<div id="TOC">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#preliminaries">Preliminaries</a></li>
<li><a href="#effects">Effects</a></li>
<li><a href="#mixed-effect-models">Mixed effect models</a></li>
<li><a href="#random-intercepts-and-random-slopes">Random intercepts and random slopes</a></li>
<li><a href="#mixed-model-formula-specification-in-r">Mixed model formula specification in R</a></li>
<li><a href="#lmer-and-glmer">lmer() and glmer()</a></li>
</ul>
</div>
<p>This article is part of the Mixed Model series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">Introduction</a> article. If you're new to mixed models we highly recommend reading the articles in order.</p>
<div class="section level2" id="overview">
<h2>Overview</h2>
<p>This article provides an introduction to <strong>mixed models</strong>, models which include both random effects and fixed effects. The article provides a high level overview of the theoretical basis for mixed models. The difference between fixed and mixed models is also covered. The article ends with how to specify random terms in lmer() and glmer() and the results from these functions.</p>
</div>
<div class="section level2" id="preliminaries">
<h2>Preliminaries</h2>
<p>You will get the most from this article if you follow along with the examples in RStudio. Working the exercises will further enhance your skills with the material. The following steps will prepare your R session to run the examples included in this article.</p>
<ul>
<li><p>Start RStudio.</p></li>
<li><p>Open a new script and save it as MixMod.</p></li>
<li><p>The examples used in this article require several packages to be loaded. If the lme4, MASS, car, pbkrtest, RLRsim, ggplot2, and pbnm packages are not in your list of packages in Rstudio's Packages tab, Install the missing packages.</p>
<p>Note, instructions for loading the pbnm package can be found at <a href="https://www.ssc.wisc.edu/sscc/pubs/pbnm/pbnmInstall.html">Loading pbnm</a>.</p></li>
<li><p>Enter the following commands in your MixMod script and run them.</p>
<pre><code>#####################################################
#####################################################
##
##   Random Effect examples from UW Madison SSCC
##   
##   These example demonstrate some commonly used
##   functions for modeling random effects using
##   lme4.
## 
#####################################################
#####################################################

library(lme4)
library(MASS)
library(car)
library(ggplot2)
library(pbkrtest)
library(RLRsim)
library(pbnm)

data(pbDat)</code></pre></li>
<li><p>There are no console results of interest from these commands.</p></li>
</ul>
</div>
<div class="section level2" id="effects">
<h2>Effects</h2>
<p>An <strong>effect</strong> is a difference in a measure which is associated with an event. The coefficients of a regression model are events associated with either belonging to a group (categorical variable) or a unit change of a measure (continuous variables). Effects associated with continuous variables (typically a linear relationship) are commonly called <strong>slopes</strong> and represent variable changes in the response. The reference group of a categorical variable is called an <strong>intercept</strong>. The coefficients associated with all other groups of a categorical variable represent a change in the intercept, a single discrete change in the response.</p>
<p>There are a number of definitions of fixed and random effects in common use. Each of the definitions has its advantages and disadvantages. The definitions provided in this article series were chosen to focus on the interpretations which can be made based on the decision to model a variable as fixed or random. This choice of definitions is not intended to reject or diminish any of the other common definitions.</p>
<p>The following example highlights the different inferences associated with the choice of modelling a variable as random versus fixed. A study was done on student success rate at a university. Data was collected from students in twenty programs. If we are interested in just these twenty programs, fixed effects would be used. If we are interested in all programs at the university and these twenty are a representative sample, random effects would be used. In the first model we would be able to make inferences only about the success rate of the twenty programs and differences between these twenty programs. We could make no inferences beyond these twenty programs. In the second model we would make inferences about the success rate of the population of programs at the university. We could also make inferences about variance of the population of programs at the university.</p>
<p>When a categorical variable contains all possible levels of interest, the effects for these levels are called <strong>fixed effects</strong>. When a categorical variable contains a sample of all possible levels of interest, the effects are <strong>random effects</strong>. These sampled levels are considered independent samples of an "<strong>unobserved variable</strong>". The variable is called unobserved because we do not have a complete view of it's distribution. While a mean and variance will be estimated, information about its shape/form will not be determined. The term "unobserved" is used becuse there are other levels of interest which were not sampled. These are not missing values.</p>
<p>The decision to model a categorical variable as a set of fixed events or as a sample of possible events of some unobserved random variable determines what interpretations can be made from the model. If fixed effects are used, inferences can be made about the specific levels of the categorical variable as well as differences between levels. If random effects are used, inferences are typically made about the population. We recommend that the choice of modelling a variable as random or fixed be driven by the hypotheses being tested. While constructing models, it may be determined that a random effect needs to be changed to a fixed effect (likely due to limited data.) This change quite possibly will cause a change in the hypothesis being tested.</p>
<p>The levels of a random effect are assumed to be independent of each other and representative of the population they are sampled from. These assumptions can not be checked from the model and the modelling decision is made based on information about how the data set was created.</p>
<p>A model with random effects and no specified fixed effects will still contain an intercept. As such all models with random effects also contain at least one fixed effect. Therefore, a model is either a <strong>fixed effect model</strong> (contains no random effects) or it is a <strong>mixed effect model</strong> (contains both fixed and random effects). Mixed effects models are often referred to as mixed models.</p>
</div>
<div class="section level2" id="mixed-effect-models">
<h2>Mixed effect models</h2>
<p>Ordinary least squares models fit the unconditional response, <span class="math inline">\(\boldsymbol{Y}\)</span>, with the assumption of normally distributed errors. The response is the mean associated with a single value for each of the independent variables. The set of independent variables and their observed values are denoted as <span class="math inline">\(\boldsymbol{X}\)</span> and the estimated effects of these variables are denoted as <span class="math inline">\(\boldsymbol{\beta}\)</span>. These models can be expressed as</p>
<p><span class="math display">\[Y \ \ \sim \ \ N(\boldsymbol{X\beta},\sigma^2 \boldsymbol{I}).\]</span></p>
<p>A linear mixed model includes at least one unobserved variable. The unobserved variable is modelled in both the fixed and random parts of a mixed model. The mean of an unobserved variable is included in the estimates of the fixed portion of the model (<span class="math inline">\(\boldsymbol{\beta}\)</span>.) The variation about the mean in the unobserved variable is captured in a vector of random variables denoted as <span class="math inline">\(\boldsymbol{B}\)</span>. Since the mean has been removed, <span class="math inline">\(\boldsymbol{B}\)</span> has a mean of 0. The sampled levels of <span class="math inline">\(\boldsymbol{B}\)</span> are denoted as <span class="math inline">\(\boldsymbol{b}\)</span>. Thus, <span class="math inline">\(\boldsymbol{b}\)</span> is the observed differences from the mean of the unobserved variable. The fitted response variable, <span class="math inline">\(Y\)</span>, of a mixed model is conditional on the variable portion of sampled effects (<span class="math inline">\(\boldsymbol{b}\)</span>.) This model can be written as</p>
<p><span class="math display">\[Y \, | \, \boldsymbol{B}=\boldsymbol{b} \ \ \sim \ \ N(\boldsymbol{X\beta} + \boldsymbol{Z b},
\sigma^2 \boldsymbol{I})\]</span></p>
<p><span class="math display">\[\boldsymbol{B} \ \ \sim \ \ 
N(\boldsymbol{0}, \boldsymbol{\Sigma_{\theta}})\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{\theta}\)</span> is the variances and possibly covariances of the distributions of the unobserved random variables, <span class="math inline">\(\boldsymbol{\Sigma_{\theta}}\)</span> is the variance covariance matrix of <span class="math inline">\(\boldsymbol{B}\)</span>, and <span class="math inline">\(\boldsymbol{Z}\)</span> is the variables representing the sampled effects. The parameters of this model are <span class="math inline">\(\boldsymbol{\beta}\)</span> and <span class="math inline">\(\boldsymbol{\theta}\)</span>. The random effects, <span class="math inline">\(\boldsymbol{b}\)</span>, and the covariance matrix, <span class="math inline">\(\boldsymbol{\Sigma_{\theta}}\)</span>, are calculated as a result of estimating <span class="math inline">\(\boldsymbol{\theta}\)</span>. As such, <span class="math inline">\(\boldsymbol{b}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma_{\theta}}\)</span> are not formal parameters of the model.</p>
<p>The random effects, the individual levels of <span class="math inline">\(\boldsymbol{b}\)</span>, are assumed to be normally distributed for linear mixed models. For generalized mixed models the random effects are assumed to have a normal distribution on the link scale, which results in non normal distributions on the response scale when the link function is non linear, such as with the logit function. There are text and papers which assume the unobserved random variable is non normally distributed. The lme4 documentation specifies an assumption of normality in the unobserved variable.</p>
<p>Each variance, or covariance, in the <span class="math inline">\(\boldsymbol{\theta}\)</span> vector is associated with an intercept or slope in the fixed portion of the model, (<span class="math inline">\(\boldsymbol{\beta}\)</span>.) The intercepts and slopes which are associated with a random <span class="math inline">\(\boldsymbol{\theta}\)</span> are interpreted as the mean effect of a population. This may be in addition to an intercept being interpreted as a reference level for other categorical variables in the fixed portion of the model.</p>
<p>The predicted <span class="math inline">\(\boldsymbol{Y}\)</span>s from this model are constants only when they are conditioned on known levels of <span class="math inline">\(\boldsymbol{B}\)</span>. The unconditional <span class="math inline">\(\boldsymbol{Y}\)</span> is a vector of random variables. We have an estimate of the means (from <span class="math inline">\(\boldsymbol{X \beta}\)</span>) and variances (from <span class="math inline">\(\boldsymbol{\theta}\)</span>.)</p>
<p>Consider the following example which has a single unobserved variable and a single continuous variable. The unobserved variable in this example is sampled twenty times. This means that the variable takes on 20 different values in the data set. This variable could take on many more values, possible infinitely many if the unobserved variable is continuous. But, we only have information on the twenty sampled levels of the unobserved variable.</p>
<p><span class="math display">\[\widehat{Y} \, | \, (\boldsymbol{B}=\boldsymbol{b}) \ \ = \ \ 
\boldsymbol{\widehat{\beta}}_0 + \boldsymbol{x \widehat{\beta}}_1 +
\boldsymbol{Z b}\]</span></p>
<ul>
<li><p><span class="math inline">\(\theta\)</span> is a single value. It is the variance of the single unobserved variable.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\Sigma_{\theta}}\)</span> is a 20 by 20 matrix. There is a row and column for each of the twenty sampled values. The diagonal elements of the matrix are the value of <span class="math inline">\(\theta\)</span> since each of the sampled values are from the same unobserved random variable. All non diagonal elements are 0 since the sampled values are assumed to be independent.</p></li>
<li><p><span class="math inline">\(\boldsymbol{b}\)</span> is the twenty random effects calculated based on the estimated <span class="math inline">\(\theta\)</span>.</p></li>
<li><p><span class="math inline">\(\boldsymbol{Z}\)</span> is an <span class="math inline">\(n\)</span> by 20 matrix with the columns being the indicator variables for which sample each observation is from.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\beta}_0\)</span> is the mean value of the unobserved variable at the value of <span class="math inline">\(\boldsymbol{x}\)</span> equals zero.</p></li>
<li><p><span class="math inline">\(\boldsymbol{\beta}_1\)</span> is the change in the mean value of the response variable associated with an increase of one unit in the <span class="math inline">\(\boldsymbol{x}\)</span>.</p></li>
</ul>
</div>
<div class="section level2" id="random-intercepts-and-random-slopes">
<h2>Random intercepts and random slopes</h2>
<p>A <strong>random intercept</strong> is an intercept which has a variance from the random component of the model associated with it. A <strong>random slope</strong> similarly is a slope which has a variance associated with it. Both of these are an estimate which is expected to vary over some population which is represented by a sample in the model.</p>
<p>When a random slope and random intercept are associated with a single population (grouping variable) one needs to consider if the variance of the intercept and the variance of the slope are correlated. This will be demonstrated in the random slope example.</p>
</div>
<div class="section level2" id="mixed-model-formula-specification-in-r">
<h2>Mixed model formula specification in R</h2>
<p>Mixed models formulas are an extension of R formulas. An introduction to R formulas and specifying fixed effects are covered in the <a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_Regression.html">R For Researchers: Regression (OLS)</a> article.</p>
<p>An unobserved variable is specified in two parts. The first part identifies the intercepts and slopes which are to be modelled as random. This is done using an R formula expression. A random intercept or slope will be modelled for each term provided in the R formula expression.</p>
<p>The second part of the specification identifies the sampled levels. The sampled levels are given by a categorical variable, or a formula expression which evaluates to a categorical variable. The categorical variable given in the random effect specification is the <strong>groups</strong> identifier for the random effects.</p>
<p>These two parts are placed inside parenthesis, (), and the two parts are separated by the bar, "|". The syntax for including a random effect in a formula is shown below.</p>
<blockquote>
<p>+ ( effect expression | groups )</p>
</blockquote>
<p>The following are a few examples of specifying random effects. Each example provides the R formula, a description of the model parameters, and the mean and variance of the true model which is estimated by the regression and observed values.</p>
<ul>
<li><p>The examples will use the following variables.</p>
<ul>
<li>A: factor with 15 levels</li>
<li>B: factor with 25 levels</li>
<li>C: numeric</li>
<li>Y: numeric</li>
</ul>
<p>The following examples will use <span class="math inline">\(\boldsymbol{B}\)</span> to represent a vector which contains all of the unobserved random variables of the model and <span class="math inline">\(\boldsymbol{b}\)</span> to represent a particular instance of <span class="math inline">\(\boldsymbol{B}\)</span>. The model variable B represents something different from <span class="math inline">\(\boldsymbol{B}\)</span> and <span class="math inline">\(\boldsymbol{b}\)</span>. The model variable B identifies a set of groups. The groups of B can be modeled as fixed effects or as a sample from a population. If B is modeled as a sample, then there will be one or more random variables associated with the population and these random variables will be members of the vector <span class="math inline">\(\boldsymbol{B}\)</span>. The variable A could also be modeled as a sample, in which case the random variables assoiated with it will also be members of <span class="math inline">\(\boldsymbol{b}\)</span>.</p></li>
<li>Y ~ C + (1|B) results in the following model parameters
<ul>
<li>(intercept) mean intercept associated with the groups of B at C = 0, <span class="math inline">\(\beta_0\)</span></li>
<li>slope effect associated with C, <span class="math inline">\(\beta_1\)</span></li>
<li>variance of intercept associated with the groups of B, <span class="math inline">\(\theta\)</span></li>
<li>variance of residuals, <span class="math inline">\(\sigma^2\)</span></li>
</ul>
<p>Y<span class="math inline">\(_i\)</span> <span class="math inline">\(| (\boldsymbol{B} = \boldsymbol{b}_{j[i]})\)</span> will have a mean of <span class="math inline">\(\beta_0 + \beta_1 c_i + b_{j[i]}\)</span> with variance of <span class="math inline">\(\sigma^2\)</span>, where <span class="math inline">\(c_i\)</span> is the value of C from the <span class="math inline">\(i\)</span>th observation, <span class="math inline">\(j[i]\)</span> is the group of B that observation <span class="math inline">\(i\)</span> is a member of, and <span class="math inline">\(b_{j[i]}\)</span> is the effect associated with the <span class="math inline">\(j\)</span>th sample of the model variable B. The model variable B is our sample of the unobserved variable <span class="math inline">\(\boldsymbol{B}\)</span>.</p>
<p>Y<span class="math inline">\(_i\)</span> will have a mean of <span class="math inline">\(\beta_0 + \beta_1\)</span>c<span class="math inline">\(_i\)</span> with variance of <span class="math inline">\(\theta + \sigma^2\)</span></p></li>
<li>Y ~ C + A + (1|B) results in the following model parameters
<ul>
<li>(intercept) (mean intercept associated with the groups of B at the reference level of variable A and C = 0), <span class="math inline">\(\beta_0\)</span></li>
<li>slope effect associated with C, <span class="math inline">\(\beta_1\)</span></li>
<li>14 intercept fixed effects associated with the non-reference levels of A, <span class="math inline">\(\beta_2, \dots, \beta_{14}\)</span></li>
<li>variance of intercept associated with the groups of B, <span class="math inline">\(\theta\)</span></li>
<li>variance of residuals, <span class="math inline">\(\sigma^2\)</span></li>
</ul>
<p>Y<span class="math inline">\(_i\)</span> <span class="math inline">\(| (\boldsymbol{B} = \boldsymbol{b}_{j[i]})\)</span> will have a mean of <span class="math inline">\(\beta_0 + \beta_1 c_i  + \sum_{k=2}^{15} \beta_k a_{k[i]} + b_{j[i]}\)</span> with variance of <span class="math inline">\(\sigma^2\)</span>, where <span class="math inline">\(c_i\)</span> is the value of C from the <span class="math inline">\(i\)</span>th observation, <span class="math inline">\(k[i]\)</span> is the <span class="math inline">\(k\)</span>th group of A associated with the <span class="math inline">\(i\)</span>th observation, <span class="math inline">\(a_{k[i]}\)</span> is an indicator which is true if the <span class="math inline">\(i\)</span>th observation belongs to the <span class="math inline">\(k\)</span>th group of A, <span class="math inline">\(j[i]\)</span> is the group of B that observation <span class="math inline">\(i\)</span> is a member of, and <span class="math inline">\(b_{j[i]}\)</span> is the effect associated with the <span class="math inline">\(j\)</span>th sample of the model variable B. The model variable B is our sample of the unobserved varaible <span class="math inline">\(\boldsymbol{B}\)</span>.</p>
<p>Y<span class="math inline">\(_i\)</span> will have a mean of <span class="math inline">\(\beta_0 + \beta_1 c_i + \sum_{j=2}^{14} \beta_j A_j\)</span> with variance of <span class="math inline">\(\theta + \sigma^2\)</span></p></li>
<li>Y ~ C + (1|A) + (0+C|A) results in the following model parameters
<ul>
<li>(intercept) (mean intercept associated with the groups of A at C = 0), <span class="math inline">\(\beta_0\)</span></li>
<li>slope effect associated with C (mean slope associated with population A), <span class="math inline">\(\beta_1\)</span></li>
<li>variance of intercept associated with A, <span class="math inline">\(\theta_1\)</span></li>
<li>variance of slope of C associated with A, <span class="math inline">\(\theta_2\)</span></li>
<li>variance of residuals, <span class="math inline">\(\sigma^2\)</span></li>
</ul>
<p>Y<span class="math inline">\(_i\)</span> <span class="math inline">\(| (\boldsymbol{B} = \boldsymbol{b}_{j[i]})\)</span> will have a mean of <span class="math inline">\(\beta_0 + \beta_1 c_i + b_{1,j[i]} + b_{2,j[i]}c_i\)</span> with variance of <span class="math inline">\(\sigma^2\)</span>, where <span class="math inline">\(c_i\)</span> is the value of C from the <span class="math inline">\(i\)</span>th observation, <span class="math inline">\(j[i]\)</span> is the group of model variable A that observation <span class="math inline">\(i\)</span> is a member of, <span class="math inline">\(b_{1,j[i]}\)</span> is the intercept effect associated with the <span class="math inline">\(j\)</span>th sample of the model variable A, <span class="math inline">\(b_{2,j[i]}\)</span> is the slope effect associated with the <span class="math inline">\(j\)</span>th sample of the model variable A. There are two unobserved variables associated with with the population sampled by A. <span class="math inline">\(\boldsymbol{B}\)</span> is the random vector <span class="math inline">\([ \boldsymbol{b}_1 \ \boldsymbol{b}_2]\)</span>.</p>
<p>Y<span class="math inline">\(_i\)</span> will have a mean of <span class="math inline">\(\beta_0 + \beta_1\)</span>c<span class="math inline">\(_i\)</span> with variance of <span class="math inline">\(\theta_1 + \theta_2 + \sigma^2\)</span></p></li>
</ul>
<div class="section level4" id="exercises">
<h4>Exercises</h4>
<p>Use the variables defied above for these exercises.</p>
<ol style="list-style-type: decimal">
<li><p>Write the R formula for a model with C as a fixed effect and two unobserved random variables. The random variables are random intercepts. One of the random variables is sampled as A, the other is sampled as B.</p></li>
<li><p>What is the mean and variance for both the unconditional y and the conditional y from problem 1?</p></li>
<li><p>Write the R formula for a model with a random slope for C and a correlated random intercept. The random slope is sampled as A.</p></li>
<li><p>What is the mean and variance for both the unconditional y and the conditional y from problem 3?</p></li>
</ol>
<p><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models_Sol.html">Solutions</a></p>
</div>
</div>
<div class="section level2" id="lmer-and-glmer">
<h2>lmer() and glmer()</h2>
<p>The lmer() (pronounced el-mer) and glmer() functions are used in the examples of this article. The lmer() function is for linear mixed models and the glmer() function is for generalized mixed models.</p>
<ul>
<li><p>Syntax and use of the <strong>lmer()</strong> and <strong>glmer()</strong> functions</p>
<p>lmer(<em>formula</em>, REML=<em>logical</em>, data=<em>dataFrame</em>)</p>
<p>glmer(<em>formula</em>, family=<em>familyName</em>, data=<em>dataFrame</em>)</p>
<p>Returns a model object of class merMod. The merMod object is a list of objects which result from fitting the model.</p>
<p>The <em>formula</em> parameter is an R formula.</p>
<p>REML defaults to TRUE. Setting REML to FALSE results in the model being fit by ML. This parameter is only available for lmer(). There is no agreed upon definition for the REML condition in generalized models.</p>
<p>For generalized mixed models the <em>familyName</em> sets the link and variance function for the model. We will use the binomial family in this article. See <a href="https://ssc.wisc.edu/sscc/pubs/RFR/RFR_RegressionGLM.html">R For Researchers: Regression (GLM)</a> for further information on generalized model specification in R.</p>
<p>Data is an optional parameter. <em>dataFrame</em> specifies the data.frame which contains the variables to be fit. R will look in the current environment for variables which are not found in the data.frame.</p></li>
</ul>
<p>We will demonstrate a binomial generalized mixed model (glmer) with a single random intercept model. This model uses the response variable bin from the pbDat data set.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>gmm &lt;- glmer(bin~x1 + x2 + (1|g1), family=binomial, data=pbDat)
summary(gmm)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: bin ~ x1 + x2 + (1 | g1)
   Data: pbDat

     AIC      BIC   logLik deviance df.resid 
   113.0    123.4    -52.5    105.0       96 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-2.3497 -0.4628  0.1073  0.4802  1.8883 

Random effects:
 Groups Name        Variance Std.Dev.
 g1     (Intercept) 4.255    2.063   
Number of obs: 100, groups:  g1, 12

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   0.1651     0.6618   0.249 0.803024    
x1            0.4996     0.2983   1.675 0.093919 .  
x2           -1.5155     0.3949  -3.837 0.000124 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
   (Intr) x1    
x1  0.097       
x2 -0.029 -0.192</code></pre></li>
</ul>
<p>The glmer() summary starts with a description of the fitted model. This section indicates if the model was fit by REML or MLE and shows the R formula which generated the model.</p>
<p>The model fit criterion are displayed next. Our model was fit with the ML and not REML and it has a Log likelihood value of -52.5 and deviance of 105. This section will contain different summary stats of the model depending on the model form and REML status.</p>
<p>A summary of the scaled residuals is displayed next.</p>
<p>The random effects summary is displayed next. For each group used in a random term the variance and standard deviation is provided for each specified random intercept and slope. These group variances are the model's <span class="math inline">\(\boldsymbol{\theta}\)</span> parameters. The residual variance and standard deviation are provided after the variances of the groups, if they are estimated. There are some glm models in which the residual scale is fixed and the residual summary is not displayed. The random effects section of summary also provides the number of levels for each the groups.</p>
<p>The fixed effect summary displays the effect value, its standard error, and the t or z value for each coefficient. The t and z statistic are from Wald tests of significance for the variable. Wald tests are not the most efficient test for these models.<br/>
See the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_TestEffects.html">Testing Significance of Effects</a> article for suggested tests which provide more reliable p-values.</p>
<div class="section level4" id="exercises-1">
<h4>Exercises</h4>
<p>Use the sleepstudy data set for the following exercises. This data is loaded using</p>
<pre><code>```
data(sleepstudy)
```</code></pre>
<ol start="5" style="list-style-type: decimal">
<li><p>Create a model for Reaction time regressing on Days and accounting for the random effect of Subject.</p></li>
<li><p>The median reaction time is 288.7. Create variable for aboveAve. You can use the code provided below. Then create a model regressing on this new dichotomous variable</p>
<pre><code>```
aboveAve &lt;- ifelse(sleepstudy$Reaction &gt; 288.7, 1, 0)
```</code></pre>
<p><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models_Sol.html">Solutions</a></p></li>
</ol>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">Introduction</a></p>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_TestEffects.html">Testing Significance of Effects</a></p>
<p>Last Revised: 4/1/2016</p>
</div>
</div>

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Mixed Models: Models solutions</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<div class="fluid-row" id="header">
</div>
<p>This article contains solutions to exercises for an article in the mixed models series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">Introduction</a>.</p>
<p>There is often more than one approach to the exercises. Do not be concerned if your approach is different than the solution provided.</p>
<div class="section level4" id="exercise-solutions">
<h4>Exercise solutions</h4>
<ol style="list-style-type: decimal">
<li><p>Write the R formula for a model with C as a fixed effect and two unobserved random variables. The random variables are random intercepts. One of the random variables is sampled as A, the other is sampled as B.</p>
y ~ C + (1|A) + (1|B) results in the following model parameters
<ul>
<li>(intercept) (mean intercept associated with the groups of A and B at C = 0), <span class="math inline">\(\beta_0\)</span></li>
<li>slope effect associated with C, <span class="math inline">\(\beta_1\)</span></li>
<li>variance of intercept associated with the groups of A, <span class="math inline">\(\theta_1\)</span></li>
<li>variance of intercept associated with the groups of B, <span class="math inline">\(\theta_2\)</span></li>
<li>variance of residuals, <span class="math inline">\(\sigma^2\)</span></li>
</ul></li>
<li><p>What is the mean and variance for both the unconditional y and the conditional y from problem 1?</p>
<p>Y<span class="math inline">\(_i\)</span> <span class="math inline">\(| (\boldsymbol{B} = [b_j \ b_k ] )\)</span> will have a mean of <span class="math inline">\(\beta_0 + \beta_1 c_i + b_{1,j[i]} + b_{2,k[i]}\)</span> with variance of <span class="math inline">\(\sigma^2\)</span>, where <span class="math inline">\(c_i\)</span> is the value of C from the <span class="math inline">\(i\)</span>th observation, <span class="math inline">\(j[i]\)</span> is the group of model variable A that observation <span class="math inline">\(i\)</span> is a member of, <span class="math inline">\(k[i]\)</span> is the group of model variable B that observation <span class="math inline">\(i\)</span> is a member of, <span class="math inline">\(b_{1,j[i]}\)</span> is the intercept effect associated with the <span class="math inline">\(j\)</span>th sample of the model variable A, <span class="math inline">\(b_{2,k[i]}\)</span> is the intercept effect associated with the <span class="math inline">\(j\)</span>th sample of the model variable B.</p>
<p>Y<span class="math inline">\(_i\)</span> will have a mean of <span class="math inline">\(\beta_0 + \beta_1\)</span>c_i with variance of <span class="math inline">\(\theta_1 + \theta_2 + \sigma^2\)</span></p></li>
<li><p>Write the R formula for a model with a random slope for C and a correlated random intercept. The random slope is sampled as A.</p>
y ~ C +(1+C|A) results in the following model parameters
<ul>
<li>(intercept) (mean intercept associated with the groups of A at C = 0), <span class="math inline">\(\beta_0\)</span></li>
<li>slope effect associated with C (mean slope associate with the groups of A), <span class="math inline">\(\beta_1\)</span></li>
<li>variance of intercept associated with A, <span class="math inline">\(\theta_1\)</span></li>
<li>variance of slope of C associated with A, <span class="math inline">\(\theta_2\)</span></li>
<li>covariance of the random intercept and the random slope of C within A, <span class="math inline">\(\theta_3\)</span></li>
<li>variance of residuals, <span class="math inline">\(\sigma^2\)</span></li>
</ul>
<p>This could also have been specified by y ~ C + (C|A).</p></li>
<li><p>What is the mean and variance for both the unconditional y and the conditional y from problem 3?</p>
<p>Y<span class="math inline">\(_i\)</span> <span class="math inline">\(| (\boldsymbol{B} = \boldsymbol{b}_{j[i]})\)</span> will have a mean of <span class="math inline">\(\beta_0 + \beta_1 c_i + b_{1,j[i]} + b_{2,j[i]} c_i\)</span> with variance of <span class="math inline">\(\sigma^2\)</span>, where <span class="math inline">\(c_i\)</span> is the value of C from the <span class="math inline">\(i\)</span>th observation, <span class="math inline">\(j[i]\)</span> is the group of model variable A that observation <span class="math inline">\(i\)</span> is a member of, <span class="math inline">\(b_{1,j[i]}\)</span> is the intercept effect associated with the <span class="math inline">\(j\)</span>th sample of the model variable A, <span class="math inline">\(b_{2,j[i]}\)</span> is the slope effect associated with the <span class="math inline">\(j\)</span>th sample of the model variable A. There are two unobserved variables associated with with the population sampled by A. <span class="math inline">\(\boldsymbol{B}\)</span> is the random vector <span class="math inline">\([ \boldsymbol{b}_1 \ \boldsymbol{b}_2]\)</span>.</p>
<p>Y<span class="math inline">\(_i\)</span> will have a mean of <span class="math inline">\(\beta_0 + \beta_1\)</span>c<span class="math inline">\(_i\)</span> with variance of <span class="math inline">\(\theta_1 + \theta_2 + 2 \theta_3 + \sigma^2\)</span></p></li>
</ol>
<p>Use the sleepstudy data set for the following exercises.</p>
<ul>
<li><p>This data is load using</p>
<pre class="r"><code>library(lme4)</code></pre>
<pre><code>Loading required package: Matrix</code></pre>
<pre class="r"><code>data(sleepstudy)</code></pre></li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li><p>Create a model for Reaction time regressing on Days and accounting for the random effect of Subject.</p>
<pre class="r"><code>ssc &lt;- lmer(Reaction ~ Days + (1 | Subject), data=sleepstudy)
summary(ssc)</code></pre>
<pre><code>Linear mixed model fit by REML ['lmerMod']
Formula: Reaction ~ Days + (1 | Subject)
   Data: sleepstudy

REML criterion at convergence: 1786.5

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.2257 -0.5529  0.0109  0.5188  4.2506 

Random effects:
 Groups   Name        Variance Std.Dev.
 Subject  (Intercept) 1378.2   37.12   
 Residual              960.5   30.99   
Number of obs: 180, groups:  Subject, 18

Fixed effects:
            Estimate Std. Error t value
(Intercept) 251.4051     9.7467   25.79
Days         10.4673     0.8042   13.02

Correlation of Fixed Effects:
     (Intr)
Days -0.371</code></pre></li>
<li><p>The median reaction time is 288.7. Create variable for aboveAve. You can use the code provided below. Then create a model regressing on this new dichotomous variable</p>
<pre class="r"><code>aboveAve &lt;- ifelse(sleepstudy$Reaction &gt; 288.7, 1, 0)

ssd &lt;- glmer(aboveAve ~ Days + (1 | Subject), data=sleepstudy, family=binomial)
summary(ssd)</code></pre>
<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: aboveAve ~ Days + (1 | Subject)
   Data: sleepstudy

     AIC      BIC   logLik deviance df.resid 
   158.6    168.2    -76.3    152.6      177 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-7.5491 -0.3845  0.0003  0.3080  5.2636 

Random effects:
 Groups  Name        Variance Std.Dev.
 Subject (Intercept) 7.951    2.82    
Number of obs: 180, groups:  Subject, 18

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -3.4601     0.9370  -3.693 0.000222 ***
Days          0.7426     0.1299   5.719 1.07e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
     (Intr)
Days -0.641</code></pre></li>
</ol>
<p>Return to the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a> article</p>
<p>Last Revised: 3/23/2016</p>
</div>

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Mixed Models: Multiple Random Parameters</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<div id="TOC">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#random-slopes">Random slopes</a></li>
<li><a href="#nested-and-crossed-effects">Nested and crossed effects</a></li>
<li><a href="#crossed-random-effect-example">Crossed random effect example</a></li>
</ul>
</div>
<p>This article is part of the Mixed Model series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">Introduction</a> article. If you're new to mixed models we highly recommend reading the articles in order.</p>
<div class="section level2" id="overview">
<h2>Overview</h2>
<p>This article includes an example models which contain both a random intercept and random slope. The article also introduces nested and crossed random effects and provides an example of each.</p>
</div>
<div class="section level2" id="random-slopes">
<h2>Random slopes</h2>
<p>When a slope is random, the intercept may or may not be random as well. The gmm model, from prior articles, includes a random intercept which we accepted as significant. We will add a random slope for the x2 variable to the gmm model. The following code does a summary of the gmm to remind us of the details of the gmm model.</p>
<ul>
<li><p>Enter the following command in your script and run it.</p>
<pre><code>summary(gmm, correlation = FALSE, show.resids  = FALSE)</code></pre></li>
<li><p>The results of the above command are shown below.</p>
<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: bin ~ x1 + x2 + (1 | g1)
   Data: pbDat

     AIC      BIC   logLik deviance df.resid 
   113.0    123.4    -52.5    105.0       96 

Random effects:
 Groups Name        Variance Std.Dev.
 g1     (Intercept) 4.255    2.063   
Number of obs: 100, groups:  g1, 12

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   0.1651     0.6618   0.249 0.803024    
x1            0.4996     0.2983   1.675 0.093919 .  
x2           -1.5155     0.3949  -3.837 0.000124 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre></li>
</ul>
<p>The gmm model has 12 groups associated with the g1 variable. The g1 variable is random, which results in a mean intercept and a standard deviation for the intercept. There are also two fixed continuous variables, x1 and x2. This provides a fixed slope for each, although the slope for x1 may be 0.</p>
<p>Adding a random slope for x2 will allow for different x2 slopes for each group in g1. These random slopes may or may not be correlated with the random intercepts already associated with g1. We will start the investigation of the random slope for x2 with the assumption that it is uncorrelated with the random intercept. The following code adds the uncorrelated random slope.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>gmmSx2 &lt;- glmer(bin~x1 + x2 + (1|g1) + (0 + x2|g1),
                family=binomial, data=pbDat)
print(summary(gmmSx2, correlation = FALSE), show.resids  = FALSE)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: bin ~ x1 + x2 + (1 | g1) + (0 + x2 | g1)
   Data: pbDat

     AIC      BIC   logLik deviance df.resid 
   109.3    122.4    -49.7     99.3       95 

Random effects:
 Groups Name        Variance Std.Dev.
 g1     (Intercept) 3.001    1.732   
 g1.1   x2          5.040    2.245   
Number of obs: 100, groups:  g1, 12

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)   0.1713     0.6245   0.274   0.7839  
x1            0.6853     0.3410   2.009   0.0445 *
x2           -1.7150     0.9071  -1.891   0.0587 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre></li>
</ul>
<p>The mean x2 slope for the g1 groups is estimated as -1.715 with a standard deviation of 5.0399. The mean x2 slope is just out side the normal significance level of .05. This loss of significance is due to the estimated standard error for x2 more than doubling in this model. To know if adding the group level slope for x2 improved the model, we need a p-value for the significance of the between group variance of the x2 slope. We will use a parametric bootstrap to estimate the p-value for this variance being greater than zero.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>pbnmSx2 &lt;- pbnm(gmmSx2,gmm,nsim=1000,tasks=10,cores=2,seed=7894523)
summary(pbnmSx2)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Parametric bootstrap testing: x2 | g1 = 0 
from: glmer(formula = bin ~ x1 + x2 + (1 | g1) + (0 + x2 | g1), data = pbDat,  family = binomial) 
1000 samples were taken Thu Aug 18 14:44:28 2016 
67 samples had warnings, 60 in alternate model 20 in null model 
67 unused samples.  0.004 &lt;= P(abs(x2 | g1) &gt; |5.039862|) &lt;= 0.071</code></pre></li>
</ul>
<p>As was seen in prior articles, there are a number of the simulation runs which fail to converge. This is possibly due to not having enough observations for the model form being fit. The data set contains only 100 observations and there are 12 groups. This results in a small number of observations to use for any group level estimate. We will continue our investigation of the random slope for x2, accepting that there is a concern that there are not enough observations. The p-value for the test of significance is greater than or equal to 0.004 and less than or equal to 0.071. The test is inconclusive.</p>
<p>We will now include the correlation between the random slope of x2 and the random intercept in the model.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>gmmCSx2 &lt;- glmer(bin~x1 + x2 + (x2|g1),
                family=binomial, data=pbDat)
print(summary(gmmCSx2, correlation = FALSE), show.resids  = FALSE)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace
  Approximation) [glmerMod]
 Family: binomial  ( logit )
Formula: bin ~ x1 + x2 + (x2 | g1)
   Data: pbDat

     AIC      BIC   logLik deviance df.resid 
   111.0    126.7    -49.5     99.0       94 

Random effects:
 Groups Name        Variance Std.Dev. Corr 
 g1     (Intercept) 3.162    1.778         
        x2          5.547    2.355    -0.27
Number of obs: 100, groups:  g1, 12

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)   0.2952     0.6773   0.436   0.6630  
x1            0.6900     0.3444   2.004   0.0451 *
x2           -1.7664     0.9490  -1.861   0.0627 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre></li>
</ul>
<p>The estimated correlation between the intercepts and x2 slopes is -0.2657. We will use a parametric bootstrap to estimate the p-value for this correlation being different than zero.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>pbnmCSx2 &lt;- pbnm(gmmCSx2,gmmSx2,nsim=1000,tasks=10,cores=2,seed=13573745)
summary(pbnmCSx2)
</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Parametric bootstrap testing: (Intercept)#x2 | g1 = 0 
from: glmer(formula = bin ~ x1 + x2 + (x2 | g1), data = pbDat, family = binomial) 
1000 samples were taken Thu Aug 18 14:49:33 2016 
2 samples had errors, 2 in alternate model 2 in null model 
74 samples had warnings, 56 in alternate model 21 in null model 
76 unused samples.  0.653 &lt;= P(abs((Intercept)#x2 | g1) &gt; |-0.2656907|) &lt;= 0.729</code></pre></li>
</ul>
<p>The p-value is greater than 0.653. We retain the null assumption that the g1 group means and slopes for x2 are not correlated. The models to consider are gmm with no random x2 slope and gmmSx2 with a random slope for each g1 group. The evidence is not clear which is the better representation of the data. One would need to rely on science of the problem, which we do not have here, to make an informed judgment on selecting between these two models. Regardless of which of these two models is selected, comments on the small amount of data available would need to be reported as a strong caution with the model results.</p>
<div class="section level4" id="exercises">
<h4>Exercises</h4>
<p>Use the models from the sleepstudy data set for the following exercises.</p>
<ol style="list-style-type: decimal">
<li><p>Add a random slope for the Days variable to your linear sleep study model. Is the random slope for Days significant?</p></li>
<li><p>Add a correlation parameter for the random Days and intercept. Is the correlation parameter significant?</p></li>
</ol>
</div>
</div>
<div class="section level2" id="nested-and-crossed-effects">
<h2>Nested and crossed effects</h2>
<p>A categorical variable, say L2, is said to be <strong>nested</strong> with another categorical variable, say, L3, if each level of L2 occurs only within a single level of L3. variables are <strong>crossed</strong> if the levels of of one random variable, say R1, occur within multiple levels of a second random variable, say R2. As an example, consider boxes of products packaged on shipping pallets. If all the boxes on a shipping pallet contain the same product, the shipping pallet identifier variable is nested within product type. If instead the boxes on a shipping pallet contained different products, then the shipping pallet identifier variable is crossed with product type.</p>
<p>The <strong>nesting level</strong> is the number of levels of nesting associated with a variable. Nesting level 1 is the individual observations. Nesting level 2 is associated with a grouping variable when multiple observations are associated with at least one of its levels. Nesting level 3 is associated with a grouping variable which has a nesting level 2 variable nested within its levels. Thus the variable levels of a nesting level 3 variable has the observations associated with the nesting level 2 grouping levels nested within its levels as well as the nesting level 2 variable's levels. Nesting levels continue to count up for each higher grouping of the data. The variable at each nesting level maybe modeled as fixed or random effects. There is no effect associated with nesting level 1. There are effects associated with higher nesting levels.</p>
<p>The table below provides an example of nested and crossed variables. The Lev2 variable is nested within the Lev3 variable. Observations 1, 2, and 3 are collected in effect level A in the Lev2 variable and observations 4, 5, and 6 in level B. Effect levels A and B are collected in effect level J of the Lev3 variable. Lev3 is at nesting level 3 since it has 2 nesting levels below it, observations and Lev2's levels. The variable Cross is crossed with Lev2 and Lev3. It is crossed since Cross's level P is contained in Lev2's levels A, B, C, and D and in J and K of Lev3. Cross is a nesting level 2 variable since it has observations nested within it's levels.</p>
<!-- html table generated in R 3.3.1 by xtable 1.8-2 package -->
<!-- Thu Aug 18 14:49:33 2016 -->
<table border="1">
<tr>
<th>
obs
</th>
<th>
Lev2
</th>
<th>
Lev3
</th>
<th>
Cross
</th>
</tr>
<tr>
<td align="center">
1
</td>
<td align="center">
A
</td>
<td align="center">
J
</td>
<td align="center">
P
</td>
</tr>
<tr>
<td align="center">
2
</td>
<td align="center">
A
</td>
<td align="center">
J
</td>
<td align="center">
Q
</td>
</tr>
<tr>
<td align="center">
3
</td>
<td align="center">
A
</td>
<td align="center">
J
</td>
<td align="center">
R
</td>
</tr>
<tr>
<td align="center">
4
</td>
<td align="center">
B
</td>
<td align="center">
J
</td>
<td align="center">
P
</td>
</tr>
<tr>
<td align="center">
5
</td>
<td align="center">
B
</td>
<td align="center">
J
</td>
<td align="center">
Q
</td>
</tr>
<tr>
<td align="center">
6
</td>
<td align="center">
B
</td>
<td align="center">
J
</td>
<td align="center">
R
</td>
</tr>
<tr>
<td align="center">
7
</td>
<td align="center">
C
</td>
<td align="center">
K
</td>
<td align="center">
P
</td>
</tr>
<tr>
<td align="center">
8
</td>
<td align="center">
C
</td>
<td align="center">
K
</td>
<td align="center">
Q
</td>
</tr>
<tr>
<td align="center">
9
</td>
<td align="center">
C
</td>
<td align="center">
K
</td>
<td align="center">
R
</td>
</tr>
<tr>
<td align="center">
10
</td>
<td align="center">
D
</td>
<td align="center">
K
</td>
<td align="center">
P
</td>
</tr>
<tr>
<td align="center">
11
</td>
<td align="center">
D
</td>
<td align="center">
K
</td>
<td align="center">
Q
</td>
</tr>
<tr>
<td align="center">
12
</td>
<td align="center">
D
</td>
<td align="center">
K
</td>
<td align="center">
R
</td>
</tr>
</table>
<p>Some caution is needed when determining if variables are crossed or not. A variable r1 may take a fixed set of values, such as A, B, C and D. These values may be repeated within the levels of variable r2. The levels of r1 may represent four levels which are applied consistently across the levels of r2, but the levels of r1 may instead represent four samples for each of the levels of L2 which are labeled the same for convenience. These four samples may not have any connection from one level of r2 to another level. Although r1 and r2 may appear crossed in this case, they are hierarchical. You must understand the data to make an informed choice on nested verses crossed in these situations.</p>
<p>As will be seen later in this article, mis-specifying a variable as crossed or nested can cause estimation errors.</p>
<p>The following is an example of specifying nested random effects.</p>
<ul>
<li><p>The example will use the following variables.</p>
<ul>
<li>A: factor with 15 levels</li>
<li>B: factor with 25 levels</li>
<li>C: numeric</li>
<li>y: numeric</li>
</ul></li>
<li>y ~ C + (1|A) + (1|A:B) results in the following model parameters
<ul>
<li>(intercept) (mean intercept associate with the groups of A and A:B)</li>
<li>slope effect associated with C</li>
<li>variance of intercept associated with the groups of A</li>
<li>variance of intercept associated with the groups of A:B</li>
<li>variance of residuals</li>
</ul>
<p>The random effect B is nested in the random effect A. The population is the unique levels of A interacted with B.</p></li>
</ul>
</div>
<div class="section level2" id="crossed-random-effect-example">
<h2>Crossed random effect example</h2>
<p>The pbDat data set does not contain crossed and nested random effects. We will generate a data set which contains three random variables, r1, r2, and r3. The data set will also contain two response variables, yc (effects of r1 and r2 crossed) and yn (effects of r3 nested within the effects of r1.).</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>set.seed(9873754)
n  &lt;- 2000
n1 &lt;- 20
n2 &lt;- 25
x1 &lt;- rnorm(n)
r1 &lt;- cut(runif(n),
          breaks = c(-1,seq(1/n1,(n1-1)/n1,1/n1),2),
          labels = paste0("a", seq(1,n1) )
          )
r2 &lt;- cut(runif(n),
          breaks = c(-1,seq(1/n2,(n2-1)/n2,1/n2),2),
          labels = paste0("a", seq((n1+1),(n1+n2)) )
          )
r3 &lt;- factor(r1:r2)
error &lt;- rnorm(n,0,.1)
effectsR1 &lt;- rnorm(length(levels(r1)))[as.numeric(r1)]
effectsR2c &lt;- rnorm(length(levels(r2)))[as.numeric(r2)]
effectsR2n &lt;- rnorm(length(levels(r3)))[as.numeric(r3)]
yc &lt;- 3 - 1*x1 + error + .6*effectsR1 - .3*effectsR2c
yn &lt;- 3 - 1*x1 + error + .6*effectsR1 - .3*effectsR2n    
datUnsorted &lt;- data.frame(yc,yn,x1,r1,r2,r3,error)
dat &lt;- datUnsorted[order(r1,r2),]            </code></pre></li>
<li><p>There are no display results for the above commands.</p></li>
</ul>
<p>Crossed effects are assumed to be independent of each other and are specified as separate random terms in the model formula. The following code builds the crossed model.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>rc &lt;- lmer(yc ~ x1 + (1|r1) + (1|r2), REML=FALSE, data=dat)
print(summary(rc, correlation = FALSE), show.resids  = FALSE)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Linear mixed model fit by maximum likelihood  ['lmerMod']
Formula: yc ~ x1 + (1 | r1) + (1 | r2)
   Data: dat

     AIC      BIC   logLik deviance df.resid 
 -3141.0  -3113.0   1575.5  -3151.0     1995 

Random effects:
 Groups   Name        Variance Std.Dev.
 r2       (Intercept) 0.08729  0.2954  
 r1       (Intercept) 0.25677  0.5067  
 Residual             0.01036  0.1018  
Number of obs: 2000, groups:  r2, 25; r1, 20

Fixed effects:
            Estimate Std. Error t value
(Intercept)  2.99384    0.12781    23.4
x1          -0.99821    0.00233  -428.5</code></pre></li>
</ul>
<p>The standard deviations used for r1 and r2 when generating yc were .3 and .6 respectively. The rc model calculate these standard deviations as 0.5067 and 0.2954. The rc model does not provide standard errors for either the estimated variance or standard deviation for r1 and r2. So there is no immediate means to determine if the true effect is likely to be greater than zero. A p-value could be calculated by use of a parametric bootstrap.</p>
<div class="section level3" id="nested-random-effect-example">
<h3>Nested random effect example</h3>
<p>Nested effects, like crossed effects, are specified as separate random terms in the model formula. Nested effects are assumed to have an association between them. Each effect level of the lower nesting level is associated with only one effect level of the next higher nesting level. It is this assignment of the group identifiers that creates the association between the levels, not the formula specification. The following code builds the nested model fo yn.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>rn &lt;- lmer(yn ~ x1 + (1|r1) + (1|r3), data=dat)
print(summary(rn, correlation = FALSE), show.resids  = FALSE)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Linear mixed model fit by REML ['lmerMod']
Formula: yn ~ x1 + (1 | r1) + (1 | r3)
   Data: dat

REML criterion at convergence: -1680.5

Random effects:
 Groups   Name        Variance Std.Dev.
 r3       (Intercept) 0.08818  0.2970  
 r1       (Intercept) 0.26895  0.5186  
 Residual             0.01033  0.1016  
Number of obs: 2000, groups:  r3, 491; r1, 20

Fixed effects:
             Estimate Std. Error t value
(Intercept)  3.003918   0.116765    25.7
x1          -0.997991   0.002621  -380.7</code></pre></li>
</ul>
<p>The rn model calculate these standard deviations of r1 and r3 as 0.5186 and 0.297. As with the crossed model, a parametric bootstrap can be used to generate a p-value for these standard deviations.</p>
<p>The group variable r3 could have also been specified in the formula as r1:r3. The following code generates the model for yn with this alternate coding of the nested effect.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>rn3 &lt;- lmer(yn ~ x1 + (1|r1) + (1|r1:r3), data=dat)
print(summary(rn3, correlation = FALSE), show.resids  = FALSE)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Linear mixed model fit by REML ['lmerMod']
Formula: yn ~ x1 + (1 | r1) + (1 | r1:r3)
   Data: dat

REML criterion at convergence: -1680.5

Random effects:
 Groups   Name        Variance Std.Dev.
 r1:r3    (Intercept) 0.08818  0.2970  
 r1       (Intercept) 0.26895  0.5186  
 Residual             0.01033  0.1016  
Number of obs: 2000, groups:  r1:r3, 491; r1, 20

Fixed effects:
             Estimate Std. Error t value
(Intercept)  3.003918   0.116765    25.7
x1          -0.997991   0.002621  -380.7</code></pre></li>
</ul>
<p>The models have the same estimates for the effects. The only difference between the rn3 model and the rn model is the name of the grouping variable used for the nested effect.</p>
<p>Specifying the random term as r1:r3 has the advantage of making it clear to the readers of your code that the r3 effects are nested within the r1 effects. The group variable r3 could have also been specified in the formula as r1:r2. The r1:r2 coding is how the r3 variable was generated. This coding of the r3 groups would be used whenever the lower nesting level groups identify a group relative to the higher nesting level effect. For example in the shipping pallet example where each pallet has boxes of the same product, there would be a first box for each shipping pallet. Each of these first boxes are a different box and there is no relationship between the first boxes on any two different shipping pallets. The box grouping variable would need to be coded as interacted with the pallet grouping variable.</p>
</div>
<div class="section level3" id="mis-specifying-a-crossed-or-nested-effect">
<h3>Mis-specifying a crossed or nested effect</h3>
<p>There are times when it is not clear if a random effect is nested or crossed. If the variables' true relationship is crossed and the relationship is coded as nested, extra groups will be created for the lower nesting level and may result in an over-fit model. If the variables' true relationship is nested and the relationship is coded as crossed, there will be fewer groups than should be created for the lower nesting level. To see what this might do to a model, we will fit the nested model with the random variables crossed. The following code uses the yn response with the random terms 1|r1 and 1|r2 instead of 1|r1 and 1|r1:r2.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>rnc &lt;- lmer(yn ~ x1 + (1|r1) + (1|r2), data=dat)
print(summary(rnc, correlation = FALSE), show.resids  = FALSE)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Linear mixed model fit by REML ['lmerMod']
Formula: yn ~ x1 + (1 | r1) + (1 | r2)
   Data: dat

REML criterion at convergence: 939

Random effects:
 Groups   Name        Variance Std.Dev.
 r2       (Intercept) 0.004309 0.06564 
 r1       (Intercept) 0.264841 0.51463 
 Residual             0.086370 0.29389 
Number of obs: 2000, groups:  r2, 25; r1, 20

Fixed effects:
             Estimate Std. Error t value
(Intercept)  3.012074   0.116010   25.96
x1          -0.991309   0.006718 -147.56</code></pre></li>
</ul>
<p>This model's estimate for r1 is almost the same. The variance associated with the other random variable is now much smaller and the residual variance has increase by about 2.5. Since we generated the data we know that the residual variance should be .01 (.1 squared). The nested model (rn) has the correct residual variance. In the model assuming crossed terms (rnc) some of the variance of yn could not be identified as being associated with r2 and instead the variance was included with the residuals.</p>
<p>The following code tests the significance of the r2 random variable in the rnc model.</p>
<p>Testing the significance of the random effects</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>rnNr2  &lt;- lmer(yn ~ x1 + (1|r1), data=dat)   
pbnmrnNr2 &lt;- pbnm(rnc,rnNr2,nsim=1000,tasks=10,cores=2,seed=570445)
summary(pbnmrnNr2)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Parametric bootstrap testing: (Intercept) | r2 = 0 
from: lmer(formula = yn ~ x1 + (1 | r1) + (1 | r2), data = dat) 
1000 samples were taken Thu Aug 18 14:50:39 2016 
P(abs((Intercept) | r2) &gt; |0.00430897|) = 0</code></pre></li>
</ul>
<p>The r2 random variable is significant even though it is much smaller than its true value. There is no indication in the model that there is an error in the specification of the random terms. It is the science of the project which is needed to determine what the correct relationship for the random model terms.</p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer.html">Diagnostics and Other Inferences</a></p>
<p>Last Revised: 6/24/2016</p>
</div>
</div>

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Mixed Models: Testing Significance of Effects</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<div id="TOC">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#testing-mixed-models-parameters">Testing mixed models parameters</a></li>
<li><a href="#test-of-fixed-effects">Test of fixed effects</a></li>
<li><a href="#test-of-random-parameters">Test of random parameters</a></li>
</ul>
</div>
<p>This article is part of the Mixed Model series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">Introduction</a> article. If you're new to mixed models we highly recommend reading the articles in order.</p>
<div class="section level2" id="overview">
<h2>Overview</h2>
<p>Models with random effects do not have classic asymptotic theory which one can appeal to for inference. There currently is debate among good statisticians as to what statistical tools are appropriate to evaluate these models and to use for inference. This article presents some of the more useful tools currently available while noting the limitations of these tools.</p>
</div>
<div class="section level2" id="testing-mixed-models-parameters">
<h2>Testing mixed models parameters</h2>
<p>Mixed model parameters do not have nice asymptotic distributions to test against. This is in contrast to OLS parameters, and to some extent GLM parameters, which asymptotically converge to known distributions. This complicates the inferences which can be made from mixed models.</p>
<p>One source of the complexity is a penalty factor (shrinkage) which is applied to the random effects in the calculation of the likelihood (or restricted likelihood) function the model is optimized to. This results in distributions which are no longer chi squared or F. This penalty factor also complicates determining the degrees of freedom to associate with the estimate of a random effect. For example a variance parameter, say r1, maybe estimated from twenty levels in a model. The design matrix used to estimate the model parameters uses twenty indicator variables for these twenty levels. There is only one parameter for these twenty indicators in the model. We would typically associate one degree of freedom with one estimated value. The design matrix used includes the twenty indicator variables and we would normally associate twenty degrees of freedom with these twenty indicators. Since these twenty indicators have a shrinkage factor applied to them, we do not really need twenty degrees of freedom. So what would be the correct degrees of freedom to use for the cost to estimate this one variance parameter? One? twenty? Something in between? Unfortunately there is no generally accepted theory which provides an answer to this question. Assuming we can find a good value for the degrees of freedom, we still can not count on our test statistic (from likelihood ratio tests and the like) to be F or chi distributed with the penalty applied to the model.</p>
<p>Another source of complications is testing the significance of a variance parameter, <span class="math inline">\(\boldsymbol{\theta}\)</span>. Since the variance must be greater than or equal to zero, a test of zero is on the border of the parameter space. Tests of parameters are valid only on the interior of their space and not on the border.</p>
<p>The correlation structure within the data complicates using bootstrap procedures to test these statistics which do not have known distributions. Parametric bootstraps which can more easily account for the correlation in the model are more typically used for inference in mixed models than bootstraps, which are non-parametric.</p>
<p>This article does not discuss the details of these issues. These issues are raised to let you to know about the limitations of inference with mixed models and what can be done. Although the asymptotics of mixed models are not as classically clean as in OLS and GLM models, inference can still be useful to guide decisions. Recall that all real world (finite non-asymptotic) statistics are estimates and one of the goals of statistics is to quantify the uncertainty of estimates. With this understanding, this article will demonstrate some of the inference tools available in R to quantify the uncertainty in the estimates from lme4 mixed models. You will need to consider the assumptions and limitations of these tools in your work.</p>
</div>
<div class="section level2" id="test-of-fixed-effects">
<h2>Test of fixed effects</h2>
<p>Tests of fixed effects are typically done with either Wald or likelihood ratio (LRT) tests. With the assumptions of asymptotic distributions and independent predictors, Wald and LRT tests are equivalent. When a data set size is not large enough to be a good approximation of the asymptotic distribution or there is some correlation amongst the predictors, the Wald and LRT test results can vary considerably.</p>
<p>How large the data set needs to be for the asymptotic distribution to be a good approximation depends not only on how many observations you have, but also on the response variable type and the size of subgroups of observations formed by the categorical variables in the model. With a continuous response variable in a linear mixed model, subgroup sizes as small as five may be enough for the Wald and LRT to be similar. When the response is an indicator variable and the proportion of events of interest is small, groups size of one hundred may not be large enough for the Wald and LRT results to be similar.</p>
<p>The Wald test is based only on estimates from the model being evaluated. This results in an implied assumption that a model which holds the parameter being tested to zero will be the same with the exception of the parameter which is being tested. Correlation between the tested predictor and the other model predictors, can cause the estimate made from the model including the parameter to be different from a model which holds the parameter to zero. The LRT requires the formal estimation of a model which restricts the parameter to zero and therefore accounts for correlation in its test.</p>
<p>The LRT is generally preferred over Wald tests of fixed effects in mixed models. For linear mixed models with little correlation among predictors, a Wald test using the approach of Kenward and Rogers (1997) will be quite similar to LRT test results. The SSCC does not recommend the use of Wald tests for generalized models.</p>
<p>The most reliable inferences for mixed models are done with Markov Chain Monte Carlo (MCMC) and parametric bootstrap tests. Both of these are computationally expensive and require longer run times. The parametric bootstrap is more intuitive and easier to generally apply. This article will demonstrate the use of parametric bootstrap in some examples. MCMC will not be discussed in this article.</p>
<div class="section level3" id="test-if-coefficients-are-zero">
<h3>Test if coefficients are zero</h3>
<p>Some common test available for lme4 models are listed below. The tests are listed from least efficient to most efficient.</p>
<ul>
<li><p>Wald test. Tests of the effect size which is scaled using the estimated standard error.</p></li>
<li><p>LRT (Likelihood Ratio Test.) Tests the difference in two nested models using the Chi square distribution.</p></li>
<li><p>KRmodComp. Only available for linear mixed models (does not support glmer() models.) An F test of nested models with an estimated degrees of freedom. The KRmodcomp() function estimates which F-test distribution is the best distribution from the family of F distributions. This function addresses the degrees of freedom concern.</p></li>
<li><p>Profiled confidence interval. While not a formal test, an interval which does not contain zero indicates the parameter is significant.</p></li>
<li><p>Parametric bootstrap. Assumes the model which restricts a parameter to zero (null model) is the true distribution and generates an empirical distribution of the difference in the two models. The observed coefficient is tested against the generated empirical distribution.</p></li>
</ul>
<p>Since the distributions of coefficients are only approximately asymptotical, two or more of the above are generally done to confirm results of tests that are inconclusive.</p>
</div>
<div class="section level3" id="wald-test">
<h3>Wald test</h3>
<p>A Walt test is done by comparing the coefficient's estimated value with the estimated standard error for the coefficient. This is provided by the summary of glmer() model where the coefficient's estimate is expected to be normally distributed (z-test.) The Wald test is not provided with the summary of lmer() models.</p>
</div>
<div class="section level3" id="lrt-likelihood-ratio-test">
<h3>LRT (Likelihood Ratio Test)</h3>
<p>The Likelihood Ratio Test (LRT) of fixed effects requires the models be fit with by MLE (use REML=FALSE for linear mixed models.) The LRT of mixed models is only approximately <span class="math inline">\(\chi^2\)</span> distributed. For tests of fixed effects the p-values will be smaller. Thus if a p-value is greater than the cutoff value, you can be confident that a more accurate test would also retain the null hypothesis. For p-values that are only a little below the cutoff value, a more accurate approach would need to be used.</p>
<p>There are several R functions which can be used for the LRT. Two of these, drop1() and anova(),are used here to test if the x1 coefficient is zero.</p>
<ul>
<li><p>The LRT using drop() requires the test parameter be set to "Chisq". Enter the following command in your script and run it.</p>
<pre><code>drop1(gmm,test="Chisq")</code></pre></li>
<li><p>The results of the above command are shown below.</p>
<pre><code>Single term deletions

Model:
bin ~ x1 + x2 + (1 | g1)
       Df    AIC     LRT   Pr(Chi)    
&lt;none&gt;    112.97                      
x1      1 114.08  3.1009   0.07825 .  
x2      1 135.56 24.5834 7.116e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre></li>
<li><p>To use anova for the LRT, the nested model (without x1) needs to be generated. Enter the following commands in your script and run them.</p>
<pre><code># fit nested model and LRT uing anova
gmmDx1 &lt;- glmer(bin~ x2 + (1|g1), family=binomial, data=pbDat)
anova(gmm,gmmDx1,test="Chisq")</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Data: pbDat
Models:
gmmDx1: bin ~ x2 + (1 | g1)
gmm: bin ~ x1 + x2 + (1 | g1)
       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(&gt;Chisq)  
gmmDx1  3 114.08 121.89 -54.038   108.08                           
gmm     4 112.97 123.40 -52.488   104.97 3.1009      1    0.07825 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre></li>
</ul>
<p>The p-value from both test are the same, 0.0783. This is larger than the common cut off alpha level of .05. Since this is the lowest we would expect the p-value to be, we have determined that the coefficient is not significant. If the p-value was inconclusive, a parametric bootstrap could be used to provide a better estimated p-value.</p>
<p>The p-value from the Wald test in the summary of the gmm model is 0.0939. This is about 20% larger than the 0.0783, p-value from the LRT.</p>
</div>
<div class="section level3" id="krmodcomp">
<h3>KRmodComp</h3>
<p>The KRmodComp() function does not support generalized models. To demonstrate this function, we will create a lmer() model using the continuous y response in the pbDat data set.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>mm &lt;- lmer(y~x1 + x2 + (1|g1), data=pbDat)
mmMLE &lt;- lmer(y~x1 + x2 + (1|g1), REML=FALSE, data=pbDat)
mmDx1 &lt;- lmer(y~ x2 + (1|g1), REML=FALSE, data=pbDat)
KRmodcomp(mmMLE,mmDx1)
anova(mmMLE,mmDx1,test="Chisq")</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>F-test with Kenward-Roger approximation; computing time: 0.13 sec.
large : y ~ x1 + x2 + (1 | g1)
small : y ~ x2 + (1 | g1)
         stat     ndf     ddf F.scaling p.value  
Ftest  4.4925  1.0000 87.5747         1 0.03687 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<pre><code>Data: pbDat
Models:
mmDx1: y ~ x2 + (1 | g1)
mmMLE: y ~ x1 + x2 + (1 | g1)
      Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(&gt;Chisq)  
mmDx1  4 1215.8 1226.2 -603.91   1207.8                           
mmMLE  5 1213.4 1226.4 -601.69   1203.4 4.4586      1    0.03473 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre></li>
</ul>
<p>These models are not comparable to the glmer() example models. These were constructed only to demonstrate the KRmodcomp() function. The KRmodcomp p-value and the LRT p-value are similar.</p>
</div>
<div class="section level3" id="profiled-confidence-interval">
<h3>Profiled confidence interval</h3>
<p>The profiled confidence interval, while not a formal test, provides another method of evaluating the significance of a coefficient. The profiled confidence interval of a parameter is constructed by holding all other model parameters constant and then examining the likelihood of the the single parameter individually. If the parameter being profiled is correlated with other parameters, the profiled confidence interval assumption of the other parameters being held constant could affect the estimated interval.</p>
<ul>
<li><p>Enter the following command in your script and run it.</p>
<pre><code>confint(gmm)</code></pre></li>
<li><p>The results of the above command are shown below.</p>
<pre><code>Computing profile confidence intervals ...</code></pre>
<pre><code>                  2.5 %     97.5 %
.sig01       1.06869440  3.9476664
(Intercept) -1.33574123  1.6490301
x1          -0.05428904  1.1343119
x2          -2.39358637 -0.8247741</code></pre></li>
</ul>
<p>The confidence interval (95%) for x1 includes 0. This provides additional evidence that the p-value is greater than .05.</p>
</div>
<div class="section level3" id="parametric-bootstrap">
<h3>Parametric bootstrap</h3>
<p>A bootstrap test would not be needed for our analysis of the x1 coefficient. The p-value we received from the LRT and confirmed with the profiled confidence interval provide good evidence that x1 is not significantly different from zero in the gmm model. A bootstrap would be used if a more accurate p-value is needed for reporting or if the LRT is inconclusive (a little smaller than the cut off alpha level.) To get a more accurate p-value, one would need to do many more simulation runs than the 1000 that is used in this example.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>pbnmx1 &lt;- pbnm(gmm,gmmDx1,nsim=1000,tasks=10,cores=2,seed=31221743)
summary(pbnmx1)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Parametric bootstrap testing: x1 = 0 
from: glmer(formula = bin ~ x1 + x2 + (1 | g1), data = pbDat, family = binomial) 
1000 samples were taken Thu Aug 18 14:28:18 2016 
76 samples had warnings, 51 in alternate model 58 in null model 
76 unused samples.  0.085 &lt;= P(abs(x1) &gt; |0.4995956|) &lt;= 0.161</code></pre></li>
</ul>
<p>The p-value from this test is given as a range due to 76 of the simulated null responses resulting in models which were not able to produce final results. Bootstrap tests which produce more than a a few tenths of a percent of models with issues (displayed by pbnm as errors or warning) may suggest that there is not enough data to support the model being fit. Further diagnostics are warranted in these situations. The proportion of problematic runs is high enough in this bootstrap to warrant further investigation of this model.</p>
<p>The range of possible p-values reported from the parametric boot strap is reasonably consistent with the 0.0783, p-value from the LRT test of the coefficient of x1 equaling zero.</p>
<p>The PBmodcomp() function in the pbkrtest package is another function which will do a parametric bootstrap test when the model is linear.</p>
</div>
<div class="section level3" id="other-tests-of-coefficients">
<h3>Other tests of coefficients</h3>
<p>All tests of coefficients have the same accuracy constraints related to the efficiency of the test being done. See the introductory paragraphs of the Test of fixed effects section for a review of these issues.</p>
<p>Wald based tests of coefficients can be done using the linearHypothesis() function. The tests are specified as equations using the names of the coefficients from the model summary. Multiple tests can be done simultaneously. This allows for a single p-value for joint tests from a model.</p>
<p>We will use linearHypothesis() to test if x2 is ten times the negation of x1 (x2 = -10*x1). All coefficients need to be on the left hand side of the equation for the linearHypothesis() function. The test can be rewritten as x2 + 10*x1 = 0. As before we will use the MLE fit model for the LRT test of the restricted model</p>
<ul>
<li><p>Enter the following command in your script and run it.</p>
<pre><code>(LH &lt;- linearHypothesis(gmm,c("10*x1+x2=0") ) )</code></pre></li>
<li><p>The results of the above command are shown below.</p>
<pre><code>Linear hypothesis test

Hypothesis:
10 x1  + x2 = 0

Model 1: restricted model
Model 2: bin ~ x1 + x2 + (1 | g1)

  Df  Chisq Pr(&gt;Chisq)
1                     
2  1 1.4086     0.2353</code></pre></li>
</ul>
<p>The p-value is well above .05.</p>
<p>Linear hypothesis tests can also be done with the KRmodcomp() function, if your model is a linear mixed model. This will provide a more efficient test of the hypothesis than the linearHypothesis() function. The model from our example is a generalized mixed model. We will use the model from the KRmodcomp section above to provide an example of the KRModcomp() function. We will test the same hypothesis.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>L &lt;- cbind(0, 10, 1)
(KR2 &lt;- KRmodcomp(mmMLE,L))</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>F-test with Kenward-Roger approximation; computing time: 0.05 sec.
large : y ~ x1 + x2 + (1 | g1)
small : L beta = L betaH 
L=
1 x 3 sparse Matrix of class "dgCMatrix"

[1,] . 10 1
betaH=
[1] 0
         stat     ndf     ddf F.scaling p.value
Ftest  2.0402  1.0000 87.6484         1  0.1567</code></pre></li>
</ul>
<p>This p-value is also greater than .05.</p>
<p>The preferred testing approaches using the LRT or parametric bootstrap require that a contrast be created. The contrast for the above test results in a new variable which is equal to x1 - 10 * x2. The following example shows the code needed to create the contrast variable and do a LRT.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>x1p10x2 &lt;- pbDat$x1 - pbDat$x2*10
gmmCont &lt;- glmer(bin~ x1p10x2 + (1|g1), family=binomial, data=pbDat)
anova(gmm,gmmCont,test="Chisq")</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Data: pbDat
Models:
gmmCont: bin ~ x1p10x2 + (1 | g1)
gmm: bin ~ x1 + x2 + (1 | g1)
        Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(&gt;Chisq)
gmmCont  3 112.46 120.27 -53.228   106.46                         
gmm      4 112.97 123.40 -52.488   104.97 1.4813      1     0.2236</code></pre></li>
</ul>
<p>The p-value from the LRT, 0.2236, is fairly close to the Wald test p-value, 0.2353. A parametric bootstrap could also be done to get a more accurate p-value if needed..</p>
<div class="section level4" id="exercises">
<h4>Exercises</h4>
<p>Use the models from sleepstudy data set for the following exercises.</p>
<ol style="list-style-type: decimal">
<li><p>Test the significance of the fixed effects in your model from exercise 5 in the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a> article.</p></li>
<li><p>Test the significance of the fixed effects in your model from exercise 6 in the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a> article.</p></li>
</ol>
<p><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_TestEffects_Sol.html">Solutions</a></p>
</div>
</div>
</div>
<div class="section level2" id="test-of-random-parameters">
<h2>Test of random parameters</h2>
<div class="section level3" id="test-variance-parameter-is-equal-to-0">
<h3>Test variance parameter is equal to 0</h3>
<p>The test which are in common use for the variance parameter are listed from least efficient to most efficient.</p>
<ul>
<li><p>LRT. See the discussion in the LRT section above for its description and limitations.</p></li>
<li><p>Profiled confidence interval. See the discussion in the Profiled confidence interval section above for its description and limitations.</p></li>
<li><p>Test based on Crainiceanu, C. and Ruppert, D. ( 2004 ) for linear mixed models. There is no equivalent for generalized mixed models. The variance parameters of the model must be uncorrelated. There is no equivalent function for when the random variables are correlated, such as with hierarchical models. In R, the exactRLRT() function is an implementation of Crainiceanu and Ruppert.</p></li>
<li><p>Parametric bootstrap. See the discussion in the parametric bootstrap section above for its description and limitations.</p></li>
</ul>
<p>There is no Wald test of a variance parameter since there is no estimate for the standard error of the variance estimate.</p>
</div>
<div class="section level3" id="lrt-likelihood-ratio-test-1">
<h3>LRT (Likelihood Ratio Test)</h3>
<p>The variance parameter of a generalized mixed models does not have a known asymptotic distribution. The LRT for these variance parameters at times can be poor estimates. We recommend treating these p-values with caution. The LRT test of a variance parameter equalling zero will be conservative (larger p-value). This is due to the test being on a boundary condition (<span class="math inline">\(\sigma^2 \ge 0\)</span>). Thus if the p-value is small enough to be significant with the LRT test, your finding is likely good. There are some areas were twice the LRT p-value is used as a formal test. We do not recommend this for variance of generalized mixed models since the p-value can be a poor estimate at times.</p>
<p>It the variance parameter being tested is the only variance parameter in the model, the null model will be a fixed effects model. One needs to be sure that the functions used to calculate the likelihoods for the two models use the same constants terms. This is not always the case with R functions.</p>
<p>The gmm model has only one random effect variable, g1. We will test if the random variable g2 is needed using the LRT.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>gmmG2 &lt;- glmer(bin ~ x1 + x2 + (1|g1) + (1|g2),
               family=binomial, data=pbDat)

# LRT calculated using the loglik() function
#
G2 = -2 * logLik(gmm) + 2 * logLik(gmmG2)
pchisq(as.numeric(G2), df=1, lower.tail=F)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>[1] 1</code></pre></li>
</ul>
<p>The p-value of 1 is much larger than .05, so the variance associated with the g2 groups is likely to have occurred by chance. To confirm this result, a parametric bootstrap would be used. In the fixed effect section above we saw that our example model generates too many warnings to get an exact p-value from a parametric boot strap (likely due to not having enough data to support the model.)</p>
</div>
<div class="section level3" id="exactrlrt">
<h3>exactRLRT</h3>
<p>The exactRLRT() function does not support generalized models as we have in our example model. To demonstrate these functions, we will use the linear version of our example model, mm. The following code tests if the variance for the random effect g1 is zero.</p>
<ul>
<li><p>Enter the following command in your script and run it.</p>
<pre><code>exactRLRT(mm)</code></pre></li>
<li><p>The results of the above command are shown below.</p>
<pre><code>
    simulated finite sample distribution of RLRT.

    (p-value based on 10000 simulated values)

data:  
RLRT = 46.218, p-value &lt; 2.2e-16</code></pre></li>
</ul>
<p>The p-value of 0 is evidence that the variance has a non zero value.</p>
<p>We can also check if the random effect g2 is needed. This is demonstrated with the following code. The exactRLRT() function requires three parameters when the variance which is being tested in not the only random effect in the model. The three parameters are the null model, the m0 parameter, and the alternative model, the mA parameter, and a model object with all of the fixed effects and just the single random effect which is being tested, the m parameter.</p>
<ul>
<li><p>Enter the following command in your script and run it.</p>
<pre><code>mmG2 &lt;- lmer(y ~ x1 + x2 + (1|g1) + (1|g2), data=pbDat)
mmR &lt;- lmer(y ~ x1 + x2 + (1|g2), data=pbDat)
exactRLRT(m=mmR,mA=mmG2,m0=mm)</code></pre></li>
<li><p>The results of the above command are shown below.</p>
<pre><code>
    simulated finite sample distribution of RLRT.

    (p-value based on 10000 simulated values)

data:  
RLRT = 2.2737e-13, p-value = 0.4273</code></pre></li>
</ul>
<p>The p-value of 0.4273 does not provide evidence that the variance is different from zero and we would retain the null hypothesis assumption of a zero value.</p>
</div>
<div class="section level3" id="profiled-confidence-interval-1">
<h3>Profiled confidence interval</h3>
<p>The profiled confidence interval for all of the model parameters was demonstrated in the Test if coefficients are zero section above. See this section for the confidence interval associated with the variance of g1.</p>
</div>
<div class="section level3" id="parametric-bootstrap-1">
<h3>Parametric bootstrap</h3>
<p>To use pbnm() to test if the variance of g1 is greater than zero, we need a null model with the variance equal to zero. The following code constructs a model with the variance of g1 equal to zero and does the parametric bootstrap test.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>gmmDG1 &lt;- glm(bin ~ x1 + x2,
               family=binomial, data=pbDat)
pbgmmDg1 &lt;- pbnm(gmm,gmmDG1,nsim=1000,tasks=10,cores=2,seed=3400835) 
summary(pbgmmDg1)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Parametric bootstrap testing: (Intercept) | g1 = 0 
from: glmer(formula = bin ~ x1 + x2 + (1 | g1), data = pbDat, family = binomial) 
1000 samples were taken Thu Aug 18 14:29:04 2016 
1 samples had warnings, 1 in alternate model 0 in null model 
1 unused samples.  0 &lt;= P(abs((Intercept) | g1) &gt; |4.255377|) &lt;= 0.001</code></pre></li>
</ul>
<p>The p-value of less than or equal to 0.001 provides evidence that the variance of g1 is non zero.</p>
<p>The following code confirms that the results from the exactRLRT() function and the pbnm() function are the same.</p>
<ul>
<li><p>Enter the following commands in your script and run them.</p>
<pre><code>fm &lt;- lm(y ~ x1 + x2, data=pbDat)
pbfm &lt;- pbnm(mmMLE,fm,nsim=1000,tasks=10,cores=2,seed=98731307)
summary(pbfm)

pbmmG2 &lt;- pbnm(mmG2,mm,nsim=1000,tasks=10,cores=2,seed=4642782)
summary(pbmmG2)</code></pre></li>
<li><p>The results of the above commands are shown below.</p>
<pre><code>Parametric bootstrap testing: (Intercept) | g1 = 0 
from: lmer(formula = y ~ x1 + x2 + (1 | g1), data = pbDat, REML = FALSE) 
1000 samples were taken Thu Aug 18 14:29:17 2016 
P(abs((Intercept) | g1) &gt; |8837.818|) = 0</code></pre>
<pre><code>Parametric bootstrap testing: (Intercept) | g2 = 0 
from: lmer(formula = y ~ x1 + x2 + (1 | g1) + (1 | g2), data = pbDat) 
1000 samples were taken Thu Aug 18 14:29:48 2016 
P(abs((Intercept) | g2) &gt; |3.83661e-11|) = 0.477</code></pre></li>
</ul>
<p>These p-values are with in round errors of the p-values returned from exactRLRT() calls. It is quicker to use the exactRLRT() when you can. When exactRLRT() assumptions are not met, the pbnm() function can provide the p-value. The pbnm() function is slower. But it requires fewer assumptions and as such can be used for a greater variety of tests.</p>
</div>
<div class="section level3" id="other-tests-of-variance-parameters">
<h3>Other tests of variance parameters</h3>
<p>Tests of variance other than being equal to zero, would require a user constructed parametric bootstrap. This is beyond the intended scope of this article.</p>
<div class="section level4" id="exercises-1">
<h4>Exercises</h4>
<p>Use the models from sleepstudy data set for the following exercises.</p>
<ol start="3" style="list-style-type: decimal">
<li><p>Test the significance of the random parameter in your model from exercise 5 in the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a> article.</p></li>
<li><p>Test the significance of the random parameter in your model from exercise 6 in the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a> article.</p></li>
</ol>
<p><a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_TestEffects_Sol.html">Solutions</a></p>
<p>Previous: <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a></p>
<p>Next: <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_DiagInfer.html">Diagnostics and Inferences</a></p>
<p>Last Revised: 3/23/2016</p>
</div>
</div>
</div>

</kb_body>
<img_base_url></img_base_url>
</kb_document>
<kb_document>
<kb_title>Mixed Models: Testing Significance of Effects solutions</kb_title>
<kb_keywords>.</kb_keywords>
<kb_summary>.</kb_summary>
<kb_body>

<!-- InstanceBeginEditable name="Text" -->
<div class="fluid-row" id="header">
</div>
<p>This article contains solutions to exercises for an article in the mixed models series. For a list of topics covered by this series, see the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Introduction.html">Introduction</a>.</p>
<p>There is often more than one approach to the exercises. Do not be concerned if your approach is different than the solution provided.</p>
<div class="section level4" id="exercise-solutions">
<h4>Exercise solutions</h4>
<p>Use the models from sleepstudy data set for the following exercises. The models used in these solutions were constructed in the the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models_Sol.html">Solutions</a> for the Model's article.</p>
<ul>
<li><p>We will load some packages which will be used in the solutions.</p>
<pre class="r"><code>library(pbkrtest)
library(pbnm)
library(RLRsim)</code></pre></li>
</ul>
<ol style="list-style-type: decimal">
<li><p>Test the significance of the fixed effects in your model from exercise 5 in the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a> article.</p>
<p>The profiled confidence interval provides a good check of significance.</p>
<pre class="r"><code>confint(ssc)</code></pre>
<pre><code>Computing profile confidence intervals ...</code></pre>
<pre><code>                 2.5 %    97.5 %
.sig01       26.007120  52.93598
.sigma       27.813847  34.59105
(Intercept) 231.992326 270.81788
Days          8.886551  12.04802</code></pre>
<p>The conficence interval for the Day coefficient is far from zero.<br/>
This is evidence that the Days is significant.</p>
<p>The Kenward-Roger F test will be used to confirm the finding from confint() and also to provide a p-value.</p>
<pre class="r"><code>sscDday &lt;- lmer(Reaction ~ (1 | Subject), data=sleepstudy)
(KRsscDay &lt;- KRmodcomp(ssc,sscDday))</code></pre>
<pre><code>F-test with Kenward-Roger approximation; computing time: 0.11 sec.
large : Reaction ~ Days + (1 | Subject)
small : Reaction ~ (1 | Subject)
       stat   ndf   ddf F.scaling   p.value    
Ftest 169.4   1.0 161.0         1 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<p>The p-value of approximentely 0 provides additional evidence that Days is significant.</p></li>
<li><p>Test the significance of the fixed effects in your model from exercise 6 in the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a> article.</p>
<p>The profiled confidence interval provides a good check of significance.</p>
<pre class="r"><code>confint(ssd)</code></pre>
<pre><code>Computing profile confidence intervals ...</code></pre>
<pre><code>                 2.5 %    97.5 %
.sig01       1.6943096  4.851559
(Intercept) -5.6358535 -1.772446
Days         0.5142808  1.029079</code></pre>
<p>The conficence interval for the Days coefficient is does not include zero. This is evidence that the Day is significant.</p>
<p>A parametric bootstrap test will be used to confirm the finding from confint() and also to provide a p-value.</p>
<pre class="r"><code>ssdDday &lt;- glmer(aboveAve ~ (1 | Subject), data=sleepstudy, family=binomial)
pbssdDday &lt;- pbnm(ssd,ssdDday,nsim=5000,tasks=10,cores=2,seed=72740419)
summary(pbssdDday)</code></pre>
<pre><code>Parametric bootstrap testing: Days = 0 
from: glmer(formula = aboveAve ~ Days + (1 | Subject), data = sleepstudy,  family = binomial) 
5000 samples were taken Sun Mar 27 05:02:39 2016 
19 samples had warnings, 16 in alternate model 13 in null model 
19 unused samples.  0 &lt;= P(abs(Days) &gt; |0.7425723|) &lt;= 0.0038</code></pre>
<p>The p-value of no greater than 0.004 is small and provides additional evidence that Days is significant.</p></li>
<li><p>Test the significance of the random parameter in your model from exercise 5 in the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a> article.</p>
<p>The profiled confidence interval provides a good check of significance.</p>
<pre class="r"><code>confint(ssc)</code></pre>
<pre><code>Computing profile confidence intervals ...</code></pre>
<pre><code>                 2.5 %    97.5 %
.sig01       26.007120  52.93598
.sigma       27.813847  34.59105
(Intercept) 231.992326 270.81788
Days          8.886551  12.04802</code></pre>
<p>The conficence interval for the Subject variance parameter, sig01 in the above display, is far from zero.<br/>
This is evidence that the variance is not zero.</p>
<p>The exactRLRT() function will be used to confirm the finding from confint() and also to provide a p-value.</p>
<pre class="r"><code>(ERsscDay &lt;- exactRLRT(ssc))</code></pre>
<pre><code>
    simulated finite sample distribution of RLRT.

    (p-value based on 10000 simulated values)

data:  
RLRT = 107.2, p-value &lt; 2.2e-16</code></pre>
<p>The p-value of approximentely 0 provides additional evidence that the variance of Subject is not zero.</p></li>
<li><p>Test the significance of the random parameter in your model from exercise 6 in the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_Models.html">Models</a> article.</p>
<p>The profiled confidence interval provides a good check of significance.</p>
<pre class="r"><code>confint(ssd)</code></pre>
<pre><code>Computing profile confidence intervals ...</code></pre>
<pre><code>                 2.5 %    97.5 %
.sig01       1.6943096  4.851559
(Intercept) -5.6358535 -1.772446
Days         0.5142808  1.029079</code></pre>
<p>The conficence interval for the Subject variance parameter, sig01 in the above display, does not include zero.<br/>
This is evidence that the variance is not zero.</p>
<p>A parametric bootstrap test will be used to confirm the finding from confint() and also to provide a p-value.</p>
<pre class="r"><code>ssdDsub &lt;- glm(aboveAve ~ Days, data=sleepstudy, family=binomial)
pbssdDsub &lt;- pbnm(ssd,ssdDsub,nsim=5000,tasks=10,cores=2,seed=93057913)
summary(pbssdDsub)</code></pre>
<pre><code>Parametric bootstrap testing: (Intercept) | Subject = 0 
from: glmer(formula = aboveAve ~ Days + (1 | Subject), data = sleepstudy,  family = binomial) 
5000 samples were taken Sun Mar 27 05:06:03 2016 
1 samples had warnings, 1 in alternate model 0 in null model 
1 unused samples.  0 &lt;= P(abs((Intercept) | Subject) &gt; |7.95053|) &lt;= 2e-04</code></pre>
<p>The p-value of no greater than 0 provides additional evidence that the variance of Subject is not zero.</p></li>
</ol>
<p>Return to the <a href="https://ssc.wisc.edu/sscc/pubs/MM/MM_TestEffects.html">Testing Significance of Effects</a> article</p>
<p>Last Revised: 3/9/2016</p>
</div>

</kb_body>
<img_base_url></img_base_url>
</kb_document>
</kb_documents>